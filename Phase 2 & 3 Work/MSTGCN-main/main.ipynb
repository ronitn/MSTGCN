{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read subject 1\n",
      "Subject 1 : (924,) (924, 10, 3000)\n",
      "Read subject 2\n",
      "Subject 2 : (911,) (911, 10, 3000)\n",
      "Read subject 3\n",
      "Subject 3 : (794,) (794, 10, 3000)\n",
      "Read subject 4\n",
      "Subject 4 : (764,) (764, 10, 3000)\n",
      "Read subject 5\n",
      "Subject 5 : (914,) (914, 10, 3000)\n",
      "Read subject 6\n",
      "Subject 6 : (823,) (823, 10, 3000)\n",
      "Read subject 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRead subject\u001b[39m\u001b[38;5;124m'\u001b[39m, sub)\n\u001b[0;32m     50\u001b[0m label \u001b[38;5;241m=\u001b[39m read_label(path_RawData, sub)\n\u001b[1;32m---> 51\u001b[0m psg \u001b[38;5;241m=\u001b[39m \u001b[43mread_psg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_Extracted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubject\u001b[39m\u001b[38;5;124m'\u001b[39m, sub, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m.\u001b[39mshape, psg\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(label) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(psg)\n",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m, in \u001b[0;36mread_psg\u001b[1;34m(path_Extracted, sub_id, channels, resample)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_psg\u001b[39m(path_Extracted, sub_id, channels, resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m):\n\u001b[1;32m---> 14\u001b[0m     psg \u001b[38;5;241m=\u001b[39m \u001b[43mscio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_Extracted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubject\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     psg_use \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m channels:\n",
      "File \u001b[1;32mc:\\Users\\Victus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:235\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, spmatrix, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    234\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 235\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m \u001b[43mMR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spmatrix:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse, coo_matrix\n",
      "File \u001b[1;32mc:\\Users\\Victus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:333\u001b[0m, in \u001b[0;36mMatFile5Reader.get_variables\u001b[1;34m(self, variable_names)\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_var_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MatReadError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    335\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnreadable variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, because \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;167;01mWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Victus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:291\u001b[0m, in \u001b[0;36mMatFile5Reader.read_var_array\u001b[1;34m(self, header, process)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_var_array\u001b[39m(\u001b[38;5;28mself\u001b[39m, header, process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    275\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Read array, given `header`\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m       `process`.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matrix_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_from_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "from os import path\n",
    "from scipy import signal\n",
    "\n",
    "path_Extracted = 'D:/Python/Major_Project/dataset/mat_data/ISRUC_S3_mat'\n",
    "path_RawData   = 'D:/Python/Major_Project/data/ISRUC_S3/RawData/RawData'\n",
    "#path_output    = './data/ISRUC_S3/'\n",
    "channels = ['C3_A2', 'C4_A1', 'F3_A2', 'F4_A1', 'O1_A2', 'O2_A1',\n",
    "            'LOC_A2', 'ROC_A1','X1', 'X2']\n",
    "\n",
    "\n",
    "def read_psg(path_Extracted, sub_id, channels, resample=3000):\n",
    "    psg = scio.loadmat(path.join(path_Extracted, 'subject%d.mat' % (sub_id)))\n",
    "    psg_use = []\n",
    "    for c in channels:\n",
    "        psg_use.append(\n",
    "            np.expand_dims(signal.resample(psg[c], resample, axis=-1), 1))\n",
    "    psg_use = np.concatenate(psg_use, axis=1)\n",
    "    return psg_use\n",
    "\n",
    "\n",
    "def read_label(path_RawData, sub_id, ignore=30):\n",
    "    label = []\n",
    "    with open(path.join(path_RawData, '%d/%d_1.txt' % (sub_id, sub_id))) as f:\n",
    "        s = f.readline()\n",
    "        while True:\n",
    "            a = s.replace('\\n', '')\n",
    "            label.append(int(a))\n",
    "            s = f.readline()\n",
    "            if s == '' or s == '\\n':\n",
    "                break\n",
    "    return np.array(label[:-ignore])\n",
    "\n",
    "\n",
    "'''\n",
    "output:\n",
    "    save to $path_output/ISRUC_S3.npz:\n",
    "        Fold_data:  [k-fold] list, each element is [N,V,T]\n",
    "        Fold_label: [k-fold] list, each element is [N,C]\n",
    "        Fold_len:   [k-fold] list\n",
    "'''\n",
    "\n",
    "fold_label = []\n",
    "fold_psg = []\n",
    "fold_len = []\n",
    "\n",
    "for sub in range(1, 11):\n",
    "    print('Read subject', sub)\n",
    "    label = read_label(path_RawData, sub)\n",
    "    psg = read_psg(path_Extracted, sub, channels)\n",
    "    print('Subject', sub, ':', label.shape, psg.shape)\n",
    "    assert len(label) == len(psg)\n",
    "\n",
    "    # in ISRUC, 0-Wake, 1-N1, 2-N2, 3-N3, 5-REM\n",
    "    label[label==5] = 4  # make 4 correspond to REM\n",
    "    fold_label.append(np.eye(5)[label])\n",
    "    fold_psg.append(psg)\n",
    "    fold_len.append(len(label))\n",
    "print('Preprocess over.')\n",
    "\n",
    "# np.savez(path.join(path_output, 'ISRUC_S3.npz'),\n",
    "#     Fold_data = fold_psg,\n",
    "#     Fold_label = fold_label,\n",
    "#     Fold_len = fold_len\n",
    "# )\n",
    "# print('Saved to', path.join(path_output, 'ISRUC_S3.npz'))\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path_output = 'D:/Python/Major_Project/data/ISRUC_S3'\n",
    "os.makedirs(path_output, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "np.savez(os.path.join(path_output, 'ISRUC_S3.npz'),\n",
    "    Fold_data=np.array(fold_psg, dtype=object),  \n",
    "    Fold_label=np.array(fold_label, dtype=object),  \n",
    "    Fold_len=np.array(fold_len)  # No need for dtype=object since it's a 1D array of ints\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print('Saved to', os.path.join(path_output, 'ISRUC_S3.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################################################################\n",
      "Start to train FeatureNet.\n",
      "Config:  ./ISRUC.config\n",
      "Use CPU only\n",
      "Read data successfully\n",
      "Number of samples: 8589\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 0\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 47s - 388ms/step - acc: 0.4975 - loss: 1.8230 - val_acc: 0.5444 - val_loss: 1.2528\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 182ms/step - acc: 0.6294 - loss: 1.1095 - val_acc: 0.5649 - val_loss: 1.2460\n",
      "Epoch 3/80\n",
      "120/120 - 21s - 176ms/step - acc: 0.6795 - loss: 0.9073 - val_acc: 0.5411 - val_loss: 1.8684\n",
      "Epoch 4/80\n",
      "120/120 - 21s - 175ms/step - acc: 0.7155 - loss: 0.7842 - val_acc: 0.5444 - val_loss: 2.0595\n",
      "Epoch 5/80\n",
      "120/120 - 20s - 171ms/step - acc: 0.7372 - loss: 0.7093 - val_acc: 0.3745 - val_loss: 2.8950\n",
      "Epoch 6/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.7569 - loss: 0.6619 - val_acc: 0.3755 - val_loss: 3.0243\n",
      "Epoch 7/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.7566 - loss: 0.6546 - val_acc: 0.4935 - val_loss: 2.4832\n",
      "Epoch 8/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.7682 - loss: 0.6163 - val_acc: 0.4275 - val_loss: 3.1062\n",
      "Epoch 9/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.7785 - loss: 0.5819 - val_acc: 0.4275 - val_loss: 3.1625\n",
      "Epoch 10/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.7733 - loss: 0.5874 - val_acc: 0.4275 - val_loss: 2.9183\n",
      "Epoch 11/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.7877 - loss: 0.5452 - val_acc: 0.4773 - val_loss: 2.6898\n",
      "Epoch 12/80\n",
      "120/120 - 20s - 171ms/step - acc: 0.7960 - loss: 0.5273 - val_acc: 0.5552 - val_loss: 2.1791\n",
      "Epoch 13/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.7948 - loss: 0.5290 - val_acc: 0.4816 - val_loss: 2.7774\n",
      "Epoch 14/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.7966 - loss: 0.5154 - val_acc: 0.4892 - val_loss: 2.4006\n",
      "Epoch 15/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8013 - loss: 0.5026 - val_acc: 0.4632 - val_loss: 2.4638\n",
      "Epoch 16/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8102 - loss: 0.4894 - val_acc: 0.4697 - val_loss: 2.5231\n",
      "Epoch 17/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8094 - loss: 0.4792 - val_acc: 0.5465 - val_loss: 2.3293\n",
      "Epoch 18/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8089 - loss: 0.4756 - val_acc: 0.4740 - val_loss: 2.6198\n",
      "Epoch 19/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8204 - loss: 0.4611 - val_acc: 0.4318 - val_loss: 3.1987\n",
      "Epoch 20/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8214 - loss: 0.4606 - val_acc: 0.4838 - val_loss: 2.6044\n",
      "Epoch 21/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8188 - loss: 0.4639 - val_acc: 0.4827 - val_loss: 2.9228\n",
      "Epoch 22/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8250 - loss: 0.4579 - val_acc: 0.4286 - val_loss: 3.3259\n",
      "Epoch 23/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8215 - loss: 0.4526 - val_acc: 0.4491 - val_loss: 3.3213\n",
      "Epoch 24/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8222 - loss: 0.4438 - val_acc: 0.3842 - val_loss: 3.5165\n",
      "Epoch 25/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8288 - loss: 0.4350 - val_acc: 0.4545 - val_loss: 3.1195\n",
      "Epoch 26/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8363 - loss: 0.4213 - val_acc: 0.4123 - val_loss: 3.9276\n",
      "Epoch 27/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8261 - loss: 0.4276 - val_acc: 0.4188 - val_loss: 3.2831\n",
      "Epoch 28/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8371 - loss: 0.4057 - val_acc: 0.5465 - val_loss: 3.1597\n",
      "Epoch 29/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8419 - loss: 0.4043 - val_acc: 0.3950 - val_loss: 3.4748\n",
      "Epoch 30/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8477 - loss: 0.3925 - val_acc: 0.4383 - val_loss: 3.4820\n",
      "Epoch 31/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8476 - loss: 0.3815 - val_acc: 0.3853 - val_loss: 3.3947\n",
      "Epoch 32/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8462 - loss: 0.3975 - val_acc: 0.3690 - val_loss: 3.3681\n",
      "Epoch 33/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8530 - loss: 0.3772 - val_acc: 0.4470 - val_loss: 3.4004\n",
      "Epoch 34/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8568 - loss: 0.3730 - val_acc: 0.3690 - val_loss: 3.5530\n",
      "Epoch 35/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8562 - loss: 0.3625 - val_acc: 0.4708 - val_loss: 3.2192\n",
      "Epoch 36/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8600 - loss: 0.3651 - val_acc: 0.3994 - val_loss: 3.7536\n",
      "Epoch 37/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8672 - loss: 0.3452 - val_acc: 0.3799 - val_loss: 3.7008\n",
      "Epoch 38/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8674 - loss: 0.3409 - val_acc: 0.3918 - val_loss: 3.5246\n",
      "Epoch 39/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8701 - loss: 0.3406 - val_acc: 0.4372 - val_loss: 3.3507\n",
      "Epoch 40/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8695 - loss: 0.3372 - val_acc: 0.3799 - val_loss: 3.8757\n",
      "Epoch 41/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8750 - loss: 0.3219 - val_acc: 0.4026 - val_loss: 3.7529\n",
      "Epoch 42/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8716 - loss: 0.3272 - val_acc: 0.4686 - val_loss: 3.5616\n",
      "Epoch 43/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8763 - loss: 0.3236 - val_acc: 0.4167 - val_loss: 3.6091\n",
      "Epoch 44/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8757 - loss: 0.3168 - val_acc: 0.4123 - val_loss: 3.3408\n",
      "Epoch 45/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8849 - loss: 0.2936 - val_acc: 0.4426 - val_loss: 3.6852\n",
      "Epoch 46/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8890 - loss: 0.2937 - val_acc: 0.4188 - val_loss: 3.9544\n",
      "Epoch 47/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8808 - loss: 0.2938 - val_acc: 0.4048 - val_loss: 3.9247\n",
      "Epoch 48/80\n",
      "120/120 - 21s - 176ms/step - acc: 0.8909 - loss: 0.2829 - val_acc: 0.4156 - val_loss: 3.9354\n",
      "Epoch 49/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8908 - loss: 0.2847 - val_acc: 0.4329 - val_loss: 3.7050\n",
      "Epoch 50/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8891 - loss: 0.2831 - val_acc: 0.4297 - val_loss: 4.0010\n",
      "Epoch 51/80\n",
      "120/120 - 21s - 178ms/step - acc: 0.8980 - loss: 0.2738 - val_acc: 0.3820 - val_loss: 4.1900\n",
      "Epoch 52/80\n",
      "120/120 - 20s - 166ms/step - acc: 0.8934 - loss: 0.2835 - val_acc: 0.4232 - val_loss: 3.7226\n",
      "Epoch 53/80\n",
      "120/120 - 21s - 175ms/step - acc: 0.9008 - loss: 0.2666 - val_acc: 0.3918 - val_loss: 4.0954\n",
      "Epoch 54/80\n",
      "120/120 - 21s - 178ms/step - acc: 0.9029 - loss: 0.2614 - val_acc: 0.3788 - val_loss: 4.4764\n",
      "Epoch 55/80\n",
      "120/120 - 21s - 176ms/step - acc: 0.9059 - loss: 0.2500 - val_acc: 0.3907 - val_loss: 4.3862\n",
      "Epoch 56/80\n",
      "120/120 - 22s - 185ms/step - acc: 0.9070 - loss: 0.2533 - val_acc: 0.3961 - val_loss: 4.3765\n",
      "Epoch 57/80\n",
      "120/120 - 21s - 179ms/step - acc: 0.9025 - loss: 0.2591 - val_acc: 0.3442 - val_loss: 4.9402\n",
      "Epoch 58/80\n",
      "120/120 - 21s - 175ms/step - acc: 0.9068 - loss: 0.2530 - val_acc: 0.3463 - val_loss: 4.8646\n",
      "Epoch 59/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.9072 - loss: 0.2500 - val_acc: 0.3831 - val_loss: 4.2607\n",
      "Epoch 60/80\n",
      "120/120 - 21s - 179ms/step - acc: 0.9104 - loss: 0.2382 - val_acc: 0.4232 - val_loss: 3.8938\n",
      "Epoch 61/80\n",
      "120/120 - 21s - 175ms/step - acc: 0.9135 - loss: 0.2305 - val_acc: 0.4123 - val_loss: 4.4590\n",
      "Epoch 62/80\n",
      "120/120 - 21s - 177ms/step - acc: 0.9119 - loss: 0.2305 - val_acc: 0.4080 - val_loss: 4.1913\n",
      "Epoch 63/80\n",
      "120/120 - 21s - 176ms/step - acc: 0.9119 - loss: 0.2327 - val_acc: 0.4286 - val_loss: 3.9831\n",
      "Epoch 64/80\n",
      "120/120 - 21s - 175ms/step - acc: 0.9202 - loss: 0.2101 - val_acc: 0.4307 - val_loss: 4.1602\n",
      "Epoch 65/80\n",
      "120/120 - 21s - 174ms/step - acc: 0.9157 - loss: 0.2236 - val_acc: 0.4080 - val_loss: 4.6164\n",
      "Epoch 66/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.9175 - loss: 0.2233 - val_acc: 0.3874 - val_loss: 4.7343\n",
      "Epoch 67/80\n",
      "120/120 - 21s - 177ms/step - acc: 0.9192 - loss: 0.2200 - val_acc: 0.3712 - val_loss: 4.6274\n",
      "Epoch 68/80\n",
      "120/120 - 21s - 177ms/step - acc: 0.9181 - loss: 0.2145 - val_acc: 0.3961 - val_loss: 4.5025\n",
      "Epoch 69/80\n",
      "120/120 - 21s - 177ms/step - acc: 0.9222 - loss: 0.2093 - val_acc: 0.3842 - val_loss: 4.3969\n",
      "Epoch 70/80\n",
      "120/120 - 21s - 176ms/step - acc: 0.9175 - loss: 0.2227 - val_acc: 0.3539 - val_loss: 5.4123\n",
      "Epoch 71/80\n",
      "120/120 - 21s - 176ms/step - acc: 0.9256 - loss: 0.1961 - val_acc: 0.4026 - val_loss: 4.5573\n",
      "Epoch 72/80\n",
      "120/120 - 21s - 175ms/step - acc: 0.9326 - loss: 0.1901 - val_acc: 0.4481 - val_loss: 4.3888\n",
      "Epoch 73/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.9225 - loss: 0.2068 - val_acc: 0.4026 - val_loss: 4.5087\n",
      "Epoch 74/80\n",
      "120/120 - 21s - 175ms/step - acc: 0.9187 - loss: 0.2148 - val_acc: 0.4091 - val_loss: 4.5602\n",
      "Epoch 75/80\n",
      "120/120 - 21s - 176ms/step - acc: 0.9318 - loss: 0.1859 - val_acc: 0.3745 - val_loss: 4.7294\n",
      "Epoch 76/80\n",
      "120/120 - 21s - 175ms/step - acc: 0.9382 - loss: 0.1750 - val_acc: 0.4091 - val_loss: 4.6551\n",
      "Epoch 77/80\n",
      "120/120 - 21s - 176ms/step - acc: 0.9259 - loss: 0.2005 - val_acc: 0.4459 - val_loss: 4.0177\n",
      "Epoch 78/80\n",
      "120/120 - 21s - 175ms/step - acc: 0.9339 - loss: 0.1852 - val_acc: 0.4253 - val_loss: 4.2418\n",
      "Epoch 79/80\n",
      "120/120 - 21s - 176ms/step - acc: 0.9312 - loss: 0.1890 - val_acc: 0.4069 - val_loss: 4.3663\n",
      "Epoch 80/80\n",
      "120/120 - 21s - 176ms/step - acc: 0.9326 - loss: 0.1818 - val_acc: 0.3680 - val_loss: 5.0544\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Save feature of Fold #0 to ./output/Feature_0.npz\n",
      "WARNING:tensorflow:From c:\\Users\\Victus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Victus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 1\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 42s - 352ms/step - acc: 0.5126 - loss: 1.8312 - val_acc: 0.5038 - val_loss: 1.4181\n",
      "Epoch 2/80\n",
      "120/120 - 21s - 179ms/step - acc: 0.6103 - loss: 1.2315 - val_acc: 0.4940 - val_loss: 1.3661\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 180ms/step - acc: 0.6705 - loss: 0.9806 - val_acc: 0.5390 - val_loss: 1.2943\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 175ms/step - acc: 0.7179 - loss: 0.8048 - val_acc: 0.5840 - val_loss: 1.4507\n",
      "Epoch 5/80\n",
      "120/120 - 21s - 175ms/step - acc: 0.7420 - loss: 0.7099 - val_acc: 0.4533 - val_loss: 2.3312\n",
      "Epoch 6/80\n",
      "120/120 - 21s - 179ms/step - acc: 0.7564 - loss: 0.6550 - val_acc: 0.4380 - val_loss: 2.4611\n",
      "Epoch 7/80\n",
      "120/120 - 19s - 161ms/step - acc: 0.7665 - loss: 0.6332 - val_acc: 0.4808 - val_loss: 2.6011\n",
      "Epoch 8/80\n",
      "120/120 - 19s - 161ms/step - acc: 0.7811 - loss: 0.5960 - val_acc: 0.4413 - val_loss: 2.9589\n",
      "Epoch 9/80\n",
      "120/120 - 20s - 165ms/step - acc: 0.7828 - loss: 0.5692 - val_acc: 0.5071 - val_loss: 2.4149\n",
      "Epoch 10/80\n",
      "120/120 - 21s - 174ms/step - acc: 0.7830 - loss: 0.5758 - val_acc: 0.4358 - val_loss: 2.7065\n",
      "Epoch 11/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.7920 - loss: 0.5453 - val_acc: 0.5697 - val_loss: 2.5325\n",
      "Epoch 12/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8009 - loss: 0.5266 - val_acc: 0.5071 - val_loss: 2.6262\n",
      "Epoch 13/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8027 - loss: 0.5186 - val_acc: 0.5181 - val_loss: 2.7425\n",
      "Epoch 14/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8089 - loss: 0.5011 - val_acc: 0.5521 - val_loss: 2.5852\n",
      "Epoch 15/80\n",
      "120/120 - 20s - 166ms/step - acc: 0.8067 - loss: 0.4958 - val_acc: 0.5214 - val_loss: 2.5418\n",
      "Epoch 16/80\n",
      "120/120 - 20s - 164ms/step - acc: 0.8106 - loss: 0.4894 - val_acc: 0.4665 - val_loss: 2.7535\n",
      "Epoch 17/80\n",
      "120/120 - 20s - 164ms/step - acc: 0.8167 - loss: 0.4803 - val_acc: 0.4874 - val_loss: 3.0480\n",
      "Epoch 18/80\n",
      "120/120 - 20s - 165ms/step - acc: 0.8167 - loss: 0.4671 - val_acc: 0.5467 - val_loss: 2.5990\n",
      "Epoch 19/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8186 - loss: 0.4686 - val_acc: 0.5488 - val_loss: 2.5924\n",
      "Epoch 20/80\n",
      "120/120 - 20s - 166ms/step - acc: 0.8173 - loss: 0.4598 - val_acc: 0.4973 - val_loss: 3.0272\n",
      "Epoch 21/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8220 - loss: 0.4611 - val_acc: 0.4929 - val_loss: 2.6540\n",
      "Epoch 22/80\n",
      "120/120 - 20s - 165ms/step - acc: 0.8306 - loss: 0.4454 - val_acc: 0.4808 - val_loss: 2.8716\n",
      "Epoch 23/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8223 - loss: 0.4547 - val_acc: 0.4259 - val_loss: 2.9956\n",
      "Epoch 24/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8291 - loss: 0.4352 - val_acc: 0.4588 - val_loss: 2.5728\n",
      "Epoch 25/80\n",
      "120/120 - 20s - 166ms/step - acc: 0.8325 - loss: 0.4270 - val_acc: 0.4435 - val_loss: 2.8018\n",
      "Epoch 26/80\n",
      "120/120 - 20s - 164ms/step - acc: 0.8423 - loss: 0.4078 - val_acc: 0.4896 - val_loss: 3.0373\n",
      "Epoch 27/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.8395 - loss: 0.4110 - val_acc: 0.5554 - val_loss: 2.4764\n",
      "Epoch 28/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8384 - loss: 0.4121 - val_acc: 0.4007 - val_loss: 3.6171\n",
      "Epoch 29/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8385 - loss: 0.4052 - val_acc: 0.5192 - val_loss: 3.0328\n",
      "Epoch 30/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8416 - loss: 0.4035 - val_acc: 0.4731 - val_loss: 3.2255\n",
      "Epoch 31/80\n",
      "120/120 - 19s - 161ms/step - acc: 0.8479 - loss: 0.3862 - val_acc: 0.4819 - val_loss: 3.1351\n",
      "Epoch 32/80\n",
      "120/120 - 19s - 161ms/step - acc: 0.8472 - loss: 0.3865 - val_acc: 0.4523 - val_loss: 3.3657\n",
      "Epoch 33/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8527 - loss: 0.3749 - val_acc: 0.4391 - val_loss: 3.2897\n",
      "Epoch 34/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8536 - loss: 0.3744 - val_acc: 0.3996 - val_loss: 4.0529\n",
      "Epoch 35/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8560 - loss: 0.3701 - val_acc: 0.5049 - val_loss: 2.9994\n",
      "Epoch 36/80\n",
      "120/120 - 20s - 164ms/step - acc: 0.8553 - loss: 0.3638 - val_acc: 0.4742 - val_loss: 3.0456\n",
      "Epoch 37/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8609 - loss: 0.3588 - val_acc: 0.4336 - val_loss: 3.5784\n",
      "Epoch 38/80\n",
      "120/120 - 20s - 166ms/step - acc: 0.8617 - loss: 0.3541 - val_acc: 0.4292 - val_loss: 3.5807\n",
      "Epoch 39/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8692 - loss: 0.3426 - val_acc: 0.4259 - val_loss: 3.4086\n",
      "Epoch 40/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.8634 - loss: 0.3428 - val_acc: 0.4281 - val_loss: 3.8270\n",
      "Epoch 41/80\n",
      "120/120 - 20s - 165ms/step - acc: 0.8741 - loss: 0.3264 - val_acc: 0.4479 - val_loss: 3.5929\n",
      "Epoch 42/80\n",
      "120/120 - 20s - 165ms/step - acc: 0.8746 - loss: 0.3255 - val_acc: 0.4413 - val_loss: 3.5879\n",
      "Epoch 43/80\n",
      "120/120 - 19s - 162ms/step - acc: 0.8717 - loss: 0.3227 - val_acc: 0.4391 - val_loss: 3.3047\n",
      "Epoch 44/80\n",
      "120/120 - 19s - 161ms/step - acc: 0.8791 - loss: 0.3210 - val_acc: 0.3996 - val_loss: 4.0871\n",
      "Epoch 45/80\n",
      "120/120 - 19s - 161ms/step - acc: 0.8751 - loss: 0.3166 - val_acc: 0.4533 - val_loss: 3.1834\n",
      "Epoch 46/80\n",
      "120/120 - 19s - 161ms/step - acc: 0.8755 - loss: 0.3152 - val_acc: 0.4984 - val_loss: 3.4634\n",
      "Epoch 47/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8845 - loss: 0.3059 - val_acc: 0.4566 - val_loss: 3.6882\n",
      "Epoch 48/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8836 - loss: 0.3014 - val_acc: 0.4501 - val_loss: 3.3131\n",
      "Epoch 49/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8871 - loss: 0.2936 - val_acc: 0.4775 - val_loss: 3.3581\n",
      "Epoch 50/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8883 - loss: 0.2872 - val_acc: 0.4731 - val_loss: 3.1989\n",
      "Epoch 51/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.8893 - loss: 0.2854 - val_acc: 0.4446 - val_loss: 3.6354\n",
      "Epoch 52/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8896 - loss: 0.2855 - val_acc: 0.4369 - val_loss: 3.5062\n",
      "Epoch 53/80\n",
      "120/120 - 20s - 166ms/step - acc: 0.8957 - loss: 0.2772 - val_acc: 0.4248 - val_loss: 3.7679\n",
      "Epoch 54/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.8939 - loss: 0.2773 - val_acc: 0.4292 - val_loss: 4.0550\n",
      "Epoch 55/80\n",
      "120/120 - 20s - 166ms/step - acc: 0.8920 - loss: 0.2797 - val_acc: 0.4588 - val_loss: 3.3737\n",
      "Epoch 56/80\n",
      "120/120 - 20s - 166ms/step - acc: 0.9005 - loss: 0.2633 - val_acc: 0.4380 - val_loss: 3.7099\n",
      "Epoch 57/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8946 - loss: 0.2740 - val_acc: 0.4962 - val_loss: 3.6096\n",
      "Epoch 58/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8998 - loss: 0.2737 - val_acc: 0.4588 - val_loss: 3.5411\n",
      "Epoch 59/80\n",
      "120/120 - 20s - 166ms/step - acc: 0.8952 - loss: 0.2662 - val_acc: 0.4424 - val_loss: 3.6501\n",
      "Epoch 60/80\n",
      "120/120 - 20s - 166ms/step - acc: 0.9031 - loss: 0.2524 - val_acc: 0.4610 - val_loss: 3.4036\n",
      "Epoch 61/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.9023 - loss: 0.2617 - val_acc: 0.4852 - val_loss: 3.2440\n",
      "Epoch 62/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.9040 - loss: 0.2476 - val_acc: 0.4237 - val_loss: 3.7039\n",
      "Epoch 63/80\n",
      "120/120 - 20s - 166ms/step - acc: 0.9047 - loss: 0.2538 - val_acc: 0.5137 - val_loss: 2.9555\n",
      "Epoch 64/80\n",
      "120/120 - 20s - 165ms/step - acc: 0.9067 - loss: 0.2485 - val_acc: 0.5192 - val_loss: 3.4578\n",
      "Epoch 65/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.9071 - loss: 0.2454 - val_acc: 0.4885 - val_loss: 3.4620\n",
      "Epoch 66/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9092 - loss: 0.2428 - val_acc: 0.5071 - val_loss: 3.3282\n",
      "Epoch 67/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9181 - loss: 0.2282 - val_acc: 0.4797 - val_loss: 3.4457\n",
      "Epoch 68/80\n",
      "120/120 - 20s - 164ms/step - acc: 0.9164 - loss: 0.2236 - val_acc: 0.4764 - val_loss: 3.7121\n",
      "Epoch 69/80\n",
      "120/120 - 20s - 165ms/step - acc: 0.9186 - loss: 0.2242 - val_acc: 0.4281 - val_loss: 4.2312\n",
      "Epoch 70/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.9139 - loss: 0.2251 - val_acc: 0.4369 - val_loss: 3.7514\n",
      "Epoch 71/80\n",
      "120/120 - 21s - 174ms/step - acc: 0.9189 - loss: 0.2151 - val_acc: 0.4413 - val_loss: 3.6515\n",
      "Epoch 72/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.9148 - loss: 0.2294 - val_acc: 0.5093 - val_loss: 3.2444\n",
      "Epoch 73/80\n",
      "120/120 - 20s - 171ms/step - acc: 0.9219 - loss: 0.2087 - val_acc: 0.4490 - val_loss: 3.9305\n",
      "Epoch 74/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.9204 - loss: 0.2120 - val_acc: 0.4951 - val_loss: 3.1547\n",
      "Epoch 75/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.9234 - loss: 0.2110 - val_acc: 0.5071 - val_loss: 3.6378\n",
      "Epoch 76/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9190 - loss: 0.2160 - val_acc: 0.4457 - val_loss: 3.9101\n",
      "Epoch 77/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.9237 - loss: 0.2001 - val_acc: 0.4555 - val_loss: 3.5710\n",
      "Epoch 78/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9246 - loss: 0.2076 - val_acc: 0.4588 - val_loss: 4.0558\n",
      "Epoch 79/80\n",
      "120/120 - 20s - 167ms/step - acc: 0.9226 - loss: 0.2030 - val_acc: 0.4248 - val_loss: 4.3314\n",
      "Epoch 80/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.9307 - loss: 0.1910 - val_acc: 0.4918 - val_loss: 3.2310\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Save feature of Fold #1 to ./output/Feature_1.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 2\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 44s - 364ms/step - acc: 0.5208 - loss: 1.8320 - val_acc: 0.4332 - val_loss: 1.4583\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 23s - 187ms/step - acc: 0.6477 - loss: 1.1314 - val_acc: 0.5970 - val_loss: 1.2818\n",
      "Epoch 3/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.6883 - loss: 0.9410 - val_acc: 0.5164 - val_loss: 1.7925\n",
      "Epoch 4/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.7223 - loss: 0.7855 - val_acc: 0.5693 - val_loss: 1.8692\n",
      "Epoch 5/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.7382 - loss: 0.7234 - val_acc: 0.5554 - val_loss: 1.9601\n",
      "Epoch 6/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.7474 - loss: 0.6720 - val_acc: 0.5290 - val_loss: 2.1817\n",
      "Epoch 7/80\n",
      "122/122 - 21s - 176ms/step - acc: 0.7564 - loss: 0.6549 - val_acc: 0.5365 - val_loss: 2.3091\n",
      "Epoch 8/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.7672 - loss: 0.6285 - val_acc: 0.5668 - val_loss: 1.8458\n",
      "Epoch 9/80\n",
      "122/122 - 22s - 182ms/step - acc: 0.7759 - loss: 0.5925 - val_acc: 0.5390 - val_loss: 2.0614\n",
      "Epoch 10/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.7826 - loss: 0.5672 - val_acc: 0.5416 - val_loss: 2.2079\n",
      "Epoch 11/80\n",
      "122/122 - 21s - 174ms/step - acc: 0.7876 - loss: 0.5450 - val_acc: 0.5642 - val_loss: 2.1848\n",
      "Epoch 12/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.7910 - loss: 0.5381 - val_acc: 0.5630 - val_loss: 2.0243\n",
      "Epoch 13/80\n",
      "122/122 - 22s - 181ms/step - acc: 0.7986 - loss: 0.5291 - val_acc: 0.5693 - val_loss: 2.1935\n",
      "Epoch 14/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.8038 - loss: 0.5083 - val_acc: 0.5617 - val_loss: 2.0639\n",
      "Epoch 15/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8019 - loss: 0.5141 - val_acc: 0.5378 - val_loss: 2.2533\n",
      "Epoch 16/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.8001 - loss: 0.5136 - val_acc: 0.5567 - val_loss: 2.1798\n",
      "Epoch 17/80\n",
      "122/122 - 21s - 176ms/step - acc: 0.8090 - loss: 0.4942 - val_acc: 0.5605 - val_loss: 2.2057\n",
      "Epoch 18/80\n",
      "122/122 - 21s - 176ms/step - acc: 0.8083 - loss: 0.4876 - val_acc: 0.5819 - val_loss: 2.2615\n",
      "Epoch 19/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.8190 - loss: 0.4700 - val_acc: 0.5705 - val_loss: 2.2140\n",
      "Epoch 20/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.8160 - loss: 0.4688 - val_acc: 0.5743 - val_loss: 2.3919\n",
      "Epoch 21/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.8127 - loss: 0.4732 - val_acc: 0.5869 - val_loss: 2.3888\n",
      "Epoch 22/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.8235 - loss: 0.4641 - val_acc: 0.5768 - val_loss: 2.4368\n",
      "Epoch 23/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.8159 - loss: 0.4562 - val_acc: 0.5831 - val_loss: 2.5036\n",
      "Epoch 24/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8214 - loss: 0.4536 - val_acc: 0.5919 - val_loss: 2.3150\n",
      "Epoch 25/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.8367 - loss: 0.4190 - val_acc: 0.5806 - val_loss: 2.3577\n",
      "Epoch 26/80\n",
      "122/122 - 22s - 181ms/step - acc: 0.8287 - loss: 0.4431 - val_acc: 0.5693 - val_loss: 2.3610\n",
      "Epoch 27/80\n",
      "122/122 - 22s - 183ms/step - acc: 0.8354 - loss: 0.4271 - val_acc: 0.5957 - val_loss: 2.5016\n",
      "Epoch 28/80\n",
      "122/122 - 22s - 181ms/step - acc: 0.8353 - loss: 0.4159 - val_acc: 0.5932 - val_loss: 2.3469\n",
      "Epoch 29/80\n",
      "122/122 - 22s - 182ms/step - acc: 0.8359 - loss: 0.4114 - val_acc: 0.5856 - val_loss: 2.3467\n",
      "Epoch 30/80\n",
      "122/122 - 22s - 182ms/step - acc: 0.8414 - loss: 0.3980 - val_acc: 0.5655 - val_loss: 2.6720\n",
      "Epoch 31/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.8495 - loss: 0.3888 - val_acc: 0.5793 - val_loss: 2.5212\n",
      "Epoch 32/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 22s - 180ms/step - acc: 0.8487 - loss: 0.3869 - val_acc: 0.6008 - val_loss: 2.5902\n",
      "Epoch 33/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.8563 - loss: 0.3685 - val_acc: 0.5542 - val_loss: 2.8245\n",
      "Epoch 34/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.8600 - loss: 0.3693 - val_acc: 0.5466 - val_loss: 2.8638\n",
      "Epoch 35/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.8576 - loss: 0.3617 - val_acc: 0.5567 - val_loss: 2.9374\n",
      "Epoch 36/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.8638 - loss: 0.3505 - val_acc: 0.5567 - val_loss: 2.6328\n",
      "Epoch 37/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8666 - loss: 0.3428 - val_acc: 0.5567 - val_loss: 2.9205\n",
      "Epoch 38/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.8621 - loss: 0.3617 - val_acc: 0.5768 - val_loss: 2.6292\n",
      "Epoch 39/80\n",
      "122/122 - 22s - 179ms/step - acc: 0.8643 - loss: 0.3499 - val_acc: 0.5378 - val_loss: 2.7384\n",
      "Epoch 40/80\n",
      "122/122 - 22s - 176ms/step - acc: 0.8679 - loss: 0.3411 - val_acc: 0.5705 - val_loss: 2.5801\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 22s - 179ms/step - acc: 0.8713 - loss: 0.3339 - val_acc: 0.6020 - val_loss: 2.2286\n",
      "Epoch 42/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.8700 - loss: 0.3321 - val_acc: 0.5718 - val_loss: 2.3442\n",
      "Epoch 43/80\n",
      "122/122 - 21s - 176ms/step - acc: 0.8792 - loss: 0.3204 - val_acc: 0.5869 - val_loss: 2.2465\n",
      "Epoch 44/80\n",
      "122/122 - 22s - 176ms/step - acc: 0.8795 - loss: 0.3082 - val_acc: 0.5705 - val_loss: 2.6931\n",
      "Epoch 45/80\n",
      "122/122 - 22s - 179ms/step - acc: 0.8861 - loss: 0.3031 - val_acc: 0.5642 - val_loss: 2.7055\n",
      "Epoch 46/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.8831 - loss: 0.3086 - val_acc: 0.5617 - val_loss: 2.6776\n",
      "Epoch 47/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.8794 - loss: 0.3081 - val_acc: 0.5718 - val_loss: 2.4451\n",
      "Epoch 48/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.8879 - loss: 0.3011 - val_acc: 0.5705 - val_loss: 2.5289\n",
      "Epoch 49/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 24s - 194ms/step - acc: 0.8936 - loss: 0.2768 - val_acc: 0.6058 - val_loss: 2.4127\n",
      "Epoch 50/80\n",
      "122/122 - 23s - 188ms/step - acc: 0.8876 - loss: 0.2959 - val_acc: 0.5982 - val_loss: 2.3330\n",
      "Epoch 51/80\n",
      "122/122 - 23s - 189ms/step - acc: 0.8907 - loss: 0.2879 - val_acc: 0.5856 - val_loss: 2.4493\n",
      "Epoch 52/80\n",
      "122/122 - 23s - 188ms/step - acc: 0.8975 - loss: 0.2708 - val_acc: 0.5730 - val_loss: 2.4410\n",
      "Epoch 53/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.9001 - loss: 0.2636 - val_acc: 0.5945 - val_loss: 2.3556\n",
      "Epoch 54/80\n",
      "122/122 - 23s - 191ms/step - acc: 0.8988 - loss: 0.2672 - val_acc: 0.5831 - val_loss: 2.5339\n",
      "Epoch 55/80\n",
      "122/122 - 23s - 189ms/step - acc: 0.9031 - loss: 0.2566 - val_acc: 0.5642 - val_loss: 2.8206\n",
      "Epoch 56/80\n",
      "122/122 - 23s - 189ms/step - acc: 0.9034 - loss: 0.2585 - val_acc: 0.5919 - val_loss: 2.4465\n",
      "Epoch 57/80\n",
      "122/122 - 23s - 189ms/step - acc: 0.9079 - loss: 0.2483 - val_acc: 0.5680 - val_loss: 2.5206\n",
      "Epoch 58/80\n",
      "122/122 - 23s - 189ms/step - acc: 0.9035 - loss: 0.2487 - val_acc: 0.5856 - val_loss: 2.6534\n",
      "Epoch 59/80\n",
      "122/122 - 23s - 190ms/step - acc: 0.9058 - loss: 0.2528 - val_acc: 0.5579 - val_loss: 2.8055\n",
      "Epoch 60/80\n",
      "122/122 - 23s - 192ms/step - acc: 0.9058 - loss: 0.2487 - val_acc: 0.5768 - val_loss: 2.7178\n",
      "Epoch 61/80\n",
      "122/122 - 23s - 191ms/step - acc: 0.9098 - loss: 0.2442 - val_acc: 0.5542 - val_loss: 2.6845\n",
      "Epoch 62/80\n",
      "122/122 - 23s - 188ms/step - acc: 0.9065 - loss: 0.2506 - val_acc: 0.5680 - val_loss: 2.5558\n",
      "Epoch 63/80\n",
      "122/122 - 23s - 190ms/step - acc: 0.9152 - loss: 0.2256 - val_acc: 0.5567 - val_loss: 3.2106\n",
      "Epoch 64/80\n",
      "122/122 - 23s - 188ms/step - acc: 0.9173 - loss: 0.2245 - val_acc: 0.5970 - val_loss: 2.7001\n",
      "Epoch 65/80\n",
      "122/122 - 23s - 189ms/step - acc: 0.9174 - loss: 0.2289 - val_acc: 0.5856 - val_loss: 2.4869\n",
      "Epoch 66/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 24s - 193ms/step - acc: 0.9116 - loss: 0.2282 - val_acc: 0.6121 - val_loss: 2.7391\n",
      "Epoch 67/80\n",
      "122/122 - 24s - 194ms/step - acc: 0.9221 - loss: 0.2157 - val_acc: 0.5390 - val_loss: 3.4416\n",
      "Epoch 68/80\n",
      "122/122 - 23s - 191ms/step - acc: 0.9120 - loss: 0.2296 - val_acc: 0.5932 - val_loss: 2.6381\n",
      "Epoch 69/80\n",
      "122/122 - 23s - 188ms/step - acc: 0.9226 - loss: 0.2129 - val_acc: 0.6020 - val_loss: 2.4776\n",
      "Epoch 70/80\n",
      "122/122 - 23s - 191ms/step - acc: 0.9244 - loss: 0.2113 - val_acc: 0.5768 - val_loss: 2.6478\n",
      "Epoch 71/80\n",
      "122/122 - 23s - 190ms/step - acc: 0.9185 - loss: 0.2199 - val_acc: 0.5781 - val_loss: 2.8352\n",
      "Epoch 72/80\n",
      "122/122 - 23s - 188ms/step - acc: 0.9224 - loss: 0.2119 - val_acc: 0.5705 - val_loss: 2.7252\n",
      "Epoch 73/80\n",
      "122/122 - 23s - 191ms/step - acc: 0.9275 - loss: 0.2014 - val_acc: 0.5831 - val_loss: 2.6631\n",
      "Epoch 74/80\n",
      "122/122 - 23s - 191ms/step - acc: 0.9279 - loss: 0.2003 - val_acc: 0.5957 - val_loss: 2.7817\n",
      "Epoch 75/80\n",
      "122/122 - 23s - 190ms/step - acc: 0.9270 - loss: 0.1926 - val_acc: 0.5768 - val_loss: 3.0681\n",
      "Epoch 76/80\n",
      "122/122 - 23s - 191ms/step - acc: 0.9237 - loss: 0.2043 - val_acc: 0.5340 - val_loss: 3.7947\n",
      "Epoch 77/80\n",
      "122/122 - 23s - 189ms/step - acc: 0.9256 - loss: 0.2013 - val_acc: 0.5743 - val_loss: 2.8885\n",
      "Epoch 78/80\n",
      "122/122 - 24s - 193ms/step - acc: 0.9284 - loss: 0.1957 - val_acc: 0.5844 - val_loss: 2.8136\n",
      "Epoch 79/80\n",
      "122/122 - 24s - 194ms/step - acc: 0.9342 - loss: 0.1856 - val_acc: 0.5642 - val_loss: 3.1209\n",
      "Epoch 80/80\n",
      "122/122 - 24s - 193ms/step - acc: 0.9319 - loss: 0.1873 - val_acc: 0.5970 - val_loss: 2.8612\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Save feature of Fold #2 to ./output/Feature_2.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 3\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 45s - 363ms/step - acc: 0.5471 - loss: 1.6441 - val_acc: 0.2500 - val_loss: 2.9139\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 193ms/step - acc: 0.6769 - loss: 0.9993 - val_acc: 0.3207 - val_loss: 2.7014\n",
      "Epoch 3/80\n",
      "123/123 - 24s - 197ms/step - acc: 0.7057 - loss: 0.8407 - val_acc: 0.3089 - val_loss: 2.8673\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 195ms/step - acc: 0.7375 - loss: 0.7367 - val_acc: 0.3298 - val_loss: 2.7063\n",
      "Epoch 5/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.7468 - loss: 0.7071 - val_acc: 0.3128 - val_loss: 2.2903\n",
      "Epoch 6/80\n",
      "123/123 - 24s - 192ms/step - acc: 0.7606 - loss: 0.6403 - val_acc: 0.2880 - val_loss: 3.0299\n",
      "Epoch 7/80\n",
      "123/123 - 23s - 189ms/step - acc: 0.7635 - loss: 0.6257 - val_acc: 0.2919 - val_loss: 3.1219\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 196ms/step - acc: 0.7719 - loss: 0.6044 - val_acc: 0.3429 - val_loss: 2.5043\n",
      "Epoch 9/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.7834 - loss: 0.5632 - val_acc: 0.3416 - val_loss: 2.9075\n",
      "Epoch 10/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.7829 - loss: 0.5622 - val_acc: 0.3063 - val_loss: 3.5451\n",
      "Epoch 11/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 198ms/step - acc: 0.7875 - loss: 0.5569 - val_acc: 0.3613 - val_loss: 2.2242\n",
      "Epoch 12/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 195ms/step - acc: 0.7870 - loss: 0.5468 - val_acc: 0.3717 - val_loss: 2.1709\n",
      "Epoch 13/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.7994 - loss: 0.5156 - val_acc: 0.3613 - val_loss: 2.5649\n",
      "Epoch 14/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 195ms/step - acc: 0.8084 - loss: 0.4919 - val_acc: 0.3743 - val_loss: 2.0990\n",
      "Epoch 15/80\n",
      "123/123 - 24s - 192ms/step - acc: 0.8082 - loss: 0.4865 - val_acc: 0.3416 - val_loss: 2.5014\n",
      "Epoch 16/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 196ms/step - acc: 0.8077 - loss: 0.4822 - val_acc: 0.3809 - val_loss: 2.1151\n",
      "Epoch 17/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.8097 - loss: 0.4853 - val_acc: 0.2997 - val_loss: 3.3232\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 197ms/step - acc: 0.8091 - loss: 0.4820 - val_acc: 0.3966 - val_loss: 2.3503\n",
      "Epoch 19/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.8225 - loss: 0.4532 - val_acc: 0.3599 - val_loss: 2.8891\n",
      "Epoch 20/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8198 - loss: 0.4524 - val_acc: 0.3482 - val_loss: 2.8964\n",
      "Epoch 21/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8190 - loss: 0.4464 - val_acc: 0.3207 - val_loss: 3.5222\n",
      "Epoch 22/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.8258 - loss: 0.4406 - val_acc: 0.3403 - val_loss: 2.8293\n",
      "Epoch 23/80\n",
      "123/123 - 25s - 200ms/step - acc: 0.8299 - loss: 0.4269 - val_acc: 0.3469 - val_loss: 2.6511\n",
      "Epoch 24/80\n",
      "123/123 - 24s - 196ms/step - acc: 0.8349 - loss: 0.4253 - val_acc: 0.3482 - val_loss: 2.4611\n",
      "Epoch 25/80\n",
      "123/123 - 24s - 196ms/step - acc: 0.8332 - loss: 0.4228 - val_acc: 0.3285 - val_loss: 3.2734\n",
      "Epoch 26/80\n",
      "123/123 - 24s - 197ms/step - acc: 0.8404 - loss: 0.4095 - val_acc: 0.3639 - val_loss: 2.7454\n",
      "Epoch 27/80\n",
      "123/123 - 24s - 197ms/step - acc: 0.8446 - loss: 0.4042 - val_acc: 0.3757 - val_loss: 2.8289\n",
      "Epoch 28/80\n",
      "123/123 - 24s - 199ms/step - acc: 0.8371 - loss: 0.4115 - val_acc: 0.3887 - val_loss: 2.5264\n",
      "Epoch 29/80\n",
      "123/123 - 24s - 199ms/step - acc: 0.8312 - loss: 0.4225 - val_acc: 0.3573 - val_loss: 3.1498\n",
      "Epoch 30/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.8491 - loss: 0.3900 - val_acc: 0.3613 - val_loss: 3.0235\n",
      "Epoch 31/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 22s - 175ms/step - acc: 0.8507 - loss: 0.3905 - val_acc: 0.3979 - val_loss: 2.5296\n",
      "Epoch 32/80\n",
      "123/123 - 22s - 177ms/step - acc: 0.8456 - loss: 0.3912 - val_acc: 0.3848 - val_loss: 2.8513\n",
      "Epoch 33/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 22s - 177ms/step - acc: 0.8511 - loss: 0.3716 - val_acc: 0.4018 - val_loss: 2.2808\n",
      "Epoch 34/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 22s - 175ms/step - acc: 0.8501 - loss: 0.3812 - val_acc: 0.4123 - val_loss: 2.5069\n",
      "Epoch 35/80\n",
      "123/123 - 22s - 175ms/step - acc: 0.8551 - loss: 0.3754 - val_acc: 0.4123 - val_loss: 2.5556\n",
      "Epoch 36/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 23s - 186ms/step - acc: 0.8553 - loss: 0.3603 - val_acc: 0.4463 - val_loss: 2.0585\n",
      "Epoch 37/80\n",
      "123/123 - 24s - 196ms/step - acc: 0.8588 - loss: 0.3565 - val_acc: 0.4031 - val_loss: 2.3721\n",
      "Epoch 38/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 195ms/step - acc: 0.8603 - loss: 0.3575 - val_acc: 0.4476 - val_loss: 2.0405\n",
      "Epoch 39/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8606 - loss: 0.3607 - val_acc: 0.4188 - val_loss: 2.4124\n",
      "Epoch 40/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.8680 - loss: 0.3417 - val_acc: 0.4202 - val_loss: 2.5083\n",
      "Epoch 41/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8712 - loss: 0.3346 - val_acc: 0.4241 - val_loss: 2.9511\n",
      "Epoch 42/80\n",
      "123/123 - 23s - 187ms/step - acc: 0.8730 - loss: 0.3314 - val_acc: 0.4005 - val_loss: 2.9073\n",
      "Epoch 43/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8705 - loss: 0.3297 - val_acc: 0.4097 - val_loss: 2.5269\n",
      "Epoch 44/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8750 - loss: 0.3275 - val_acc: 0.4045 - val_loss: 2.7775\n",
      "Epoch 45/80\n",
      "123/123 - 23s - 186ms/step - acc: 0.8783 - loss: 0.3212 - val_acc: 0.4031 - val_loss: 2.7870\n",
      "Epoch 46/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8742 - loss: 0.3230 - val_acc: 0.4045 - val_loss: 2.2371\n",
      "Epoch 47/80\n",
      "123/123 - 23s - 186ms/step - acc: 0.8832 - loss: 0.3066 - val_acc: 0.3678 - val_loss: 2.8994\n",
      "Epoch 48/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8878 - loss: 0.2900 - val_acc: 0.4005 - val_loss: 2.7947\n",
      "Epoch 49/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8769 - loss: 0.3131 - val_acc: 0.4110 - val_loss: 2.6582\n",
      "Epoch 50/80\n",
      "123/123 - 23s - 186ms/step - acc: 0.8868 - loss: 0.2979 - val_acc: 0.4123 - val_loss: 2.6133\n",
      "Epoch 51/80\n",
      "123/123 - 23s - 188ms/step - acc: 0.8886 - loss: 0.2850 - val_acc: 0.4084 - val_loss: 3.0058\n",
      "Epoch 52/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8901 - loss: 0.2911 - val_acc: 0.4202 - val_loss: 3.2766\n",
      "Epoch 53/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8861 - loss: 0.2948 - val_acc: 0.4254 - val_loss: 2.9979\n",
      "Epoch 54/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8952 - loss: 0.2807 - val_acc: 0.3861 - val_loss: 3.2324\n",
      "Epoch 55/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8942 - loss: 0.2794 - val_acc: 0.4346 - val_loss: 2.8517\n",
      "Epoch 56/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8979 - loss: 0.2683 - val_acc: 0.3914 - val_loss: 2.7625\n",
      "Epoch 57/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8974 - loss: 0.2687 - val_acc: 0.4045 - val_loss: 2.6714\n",
      "Epoch 58/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.8906 - loss: 0.2717 - val_acc: 0.4424 - val_loss: 2.2835\n",
      "Epoch 59/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 23s - 185ms/step - acc: 0.9019 - loss: 0.2675 - val_acc: 0.4607 - val_loss: 2.2609\n",
      "Epoch 60/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.8980 - loss: 0.2699 - val_acc: 0.4084 - val_loss: 2.5537\n",
      "Epoch 61/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.9091 - loss: 0.2474 - val_acc: 0.4372 - val_loss: 2.5152\n",
      "Epoch 62/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.9050 - loss: 0.2552 - val_acc: 0.4267 - val_loss: 2.4689\n",
      "Epoch 63/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.9084 - loss: 0.2513 - val_acc: 0.4503 - val_loss: 2.5405\n",
      "Epoch 64/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.9150 - loss: 0.2351 - val_acc: 0.4450 - val_loss: 2.7323\n",
      "Epoch 65/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.9113 - loss: 0.2412 - val_acc: 0.4319 - val_loss: 2.4046\n",
      "Epoch 66/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 23s - 186ms/step - acc: 0.9098 - loss: 0.2367 - val_acc: 0.4751 - val_loss: 2.1893\n",
      "Epoch 67/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.9135 - loss: 0.2366 - val_acc: 0.4215 - val_loss: 2.2726\n",
      "Epoch 68/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.9146 - loss: 0.2285 - val_acc: 0.4097 - val_loss: 3.2141\n",
      "Epoch 69/80\n",
      "123/123 - 23s - 185ms/step - acc: 0.9163 - loss: 0.2243 - val_acc: 0.4529 - val_loss: 2.7988\n",
      "Epoch 70/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.9190 - loss: 0.2230 - val_acc: 0.4123 - val_loss: 2.9676\n",
      "Epoch 71/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.9139 - loss: 0.2240 - val_acc: 0.3874 - val_loss: 3.1652\n",
      "Epoch 72/80\n",
      "123/123 - 23s - 183ms/step - acc: 0.9214 - loss: 0.2198 - val_acc: 0.4241 - val_loss: 2.7565\n",
      "Epoch 73/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.9196 - loss: 0.2139 - val_acc: 0.3822 - val_loss: 3.5226\n",
      "Epoch 74/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.9181 - loss: 0.2213 - val_acc: 0.3613 - val_loss: 3.0984\n",
      "Epoch 75/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.9249 - loss: 0.2070 - val_acc: 0.3796 - val_loss: 3.2177\n",
      "Epoch 76/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.9231 - loss: 0.2179 - val_acc: 0.3613 - val_loss: 3.6317\n",
      "Epoch 77/80\n",
      "123/123 - 24s - 198ms/step - acc: 0.9278 - loss: 0.2020 - val_acc: 0.4385 - val_loss: 2.2535\n",
      "Epoch 78/80\n",
      "123/123 - 24s - 192ms/step - acc: 0.9278 - loss: 0.2005 - val_acc: 0.4136 - val_loss: 3.3581\n",
      "Epoch 79/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.9268 - loss: 0.2061 - val_acc: 0.4372 - val_loss: 2.7255\n",
      "Epoch 80/80\n",
      "123/123 - 23s - 184ms/step - acc: 0.9263 - loss: 0.1947 - val_acc: 0.3927 - val_loss: 2.9133\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Save feature of Fold #3 to ./output/Feature_3.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 4\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 44s - 365ms/step - acc: 0.5171 - loss: 1.8540 - val_acc: 0.1794 - val_loss: 2.3768\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 190ms/step - acc: 0.6216 - loss: 1.2331 - val_acc: 0.2484 - val_loss: 2.2474\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 187ms/step - acc: 0.6659 - loss: 0.9925 - val_acc: 0.2987 - val_loss: 1.9872\n",
      "Epoch 4/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.6989 - loss: 0.8633 - val_acc: 0.2845 - val_loss: 2.3107\n",
      "Epoch 5/80\n",
      "120/120 - 23s - 188ms/step - acc: 0.7187 - loss: 0.7579 - val_acc: 0.2932 - val_loss: 2.7222\n",
      "Epoch 6/80\n",
      "120/120 - 23s - 188ms/step - acc: 0.7407 - loss: 0.6910 - val_acc: 0.2702 - val_loss: 3.5191\n",
      "Epoch 7/80\n",
      "120/120 - 23s - 189ms/step - acc: 0.7571 - loss: 0.6437 - val_acc: 0.2746 - val_loss: 3.6476\n",
      "Epoch 8/80\n",
      "120/120 - 23s - 189ms/step - acc: 0.7643 - loss: 0.6216 - val_acc: 0.2735 - val_loss: 3.9007\n",
      "Epoch 9/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 191ms/step - acc: 0.7679 - loss: 0.6115 - val_acc: 0.3107 - val_loss: 3.3216\n",
      "Epoch 10/80\n",
      "120/120 - 23s - 190ms/step - acc: 0.7771 - loss: 0.5849 - val_acc: 0.3031 - val_loss: 3.3663\n",
      "Epoch 11/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.7825 - loss: 0.5624 - val_acc: 0.2823 - val_loss: 4.1320\n",
      "Epoch 12/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 188ms/step - acc: 0.7859 - loss: 0.5530 - val_acc: 0.3337 - val_loss: 3.5542\n",
      "Epoch 13/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 188ms/step - acc: 0.7870 - loss: 0.5313 - val_acc: 0.3961 - val_loss: 3.0097\n",
      "Epoch 14/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.7973 - loss: 0.5218 - val_acc: 0.3435 - val_loss: 3.8219\n",
      "Epoch 15/80\n",
      "120/120 - 22s - 185ms/step - acc: 0.8021 - loss: 0.5132 - val_acc: 0.3621 - val_loss: 4.0233\n",
      "Epoch 16/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8027 - loss: 0.5055 - val_acc: 0.3162 - val_loss: 3.7774\n",
      "Epoch 17/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8066 - loss: 0.4967 - val_acc: 0.3523 - val_loss: 3.7589\n",
      "Epoch 18/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8094 - loss: 0.4812 - val_acc: 0.3720 - val_loss: 3.6331\n",
      "Epoch 19/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8091 - loss: 0.4880 - val_acc: 0.3829 - val_loss: 3.6379\n",
      "Epoch 20/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8124 - loss: 0.4693 - val_acc: 0.3403 - val_loss: 4.3175\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 188ms/step - acc: 0.8134 - loss: 0.4734 - val_acc: 0.4158 - val_loss: 3.6897\n",
      "Epoch 22/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8149 - loss: 0.4689 - val_acc: 0.3906 - val_loss: 3.8332\n",
      "Epoch 23/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8224 - loss: 0.4600 - val_acc: 0.3796 - val_loss: 4.2403\n",
      "Epoch 24/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8229 - loss: 0.4465 - val_acc: 0.3676 - val_loss: 3.8353\n",
      "Epoch 25/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8201 - loss: 0.4597 - val_acc: 0.3928 - val_loss: 3.6665\n",
      "Epoch 26/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8258 - loss: 0.4478 - val_acc: 0.4037 - val_loss: 3.8337\n",
      "Epoch 27/80\n",
      "120/120 - 23s - 188ms/step - acc: 0.8307 - loss: 0.4320 - val_acc: 0.4015 - val_loss: 4.0626\n",
      "Epoch 28/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8326 - loss: 0.4295 - val_acc: 0.3796 - val_loss: 4.1915\n",
      "Epoch 29/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8354 - loss: 0.4154 - val_acc: 0.3600 - val_loss: 4.3773\n",
      "Epoch 30/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8379 - loss: 0.4169 - val_acc: 0.3796 - val_loss: 4.0421\n",
      "Epoch 31/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 188ms/step - acc: 0.8364 - loss: 0.4105 - val_acc: 0.4168 - val_loss: 3.6412\n",
      "Epoch 32/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 188ms/step - acc: 0.8373 - loss: 0.4142 - val_acc: 0.4234 - val_loss: 3.8703\n",
      "Epoch 33/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8469 - loss: 0.3887 - val_acc: 0.3796 - val_loss: 4.5550\n",
      "Epoch 34/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8456 - loss: 0.3940 - val_acc: 0.3720 - val_loss: 4.5545\n",
      "Epoch 35/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8503 - loss: 0.3806 - val_acc: 0.3840 - val_loss: 4.9257\n",
      "Epoch 36/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8517 - loss: 0.3849 - val_acc: 0.4048 - val_loss: 4.9365\n",
      "Epoch 37/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8575 - loss: 0.3645 - val_acc: 0.3621 - val_loss: 4.2993\n",
      "Epoch 38/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8563 - loss: 0.3655 - val_acc: 0.3884 - val_loss: 4.1531\n",
      "Epoch 39/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8534 - loss: 0.3745 - val_acc: 0.4234 - val_loss: 4.5765\n",
      "Epoch 40/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8594 - loss: 0.3648 - val_acc: 0.3873 - val_loss: 4.8907\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 187ms/step - acc: 0.8668 - loss: 0.3498 - val_acc: 0.4289 - val_loss: 3.8935\n",
      "Epoch 42/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8641 - loss: 0.3543 - val_acc: 0.4136 - val_loss: 4.4685\n",
      "Epoch 43/80\n",
      "120/120 - 23s - 188ms/step - acc: 0.8730 - loss: 0.3291 - val_acc: 0.3917 - val_loss: 4.3389\n",
      "Epoch 44/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8736 - loss: 0.3355 - val_acc: 0.3807 - val_loss: 5.2191\n",
      "Epoch 45/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8706 - loss: 0.3327 - val_acc: 0.3862 - val_loss: 4.5960\n",
      "Epoch 46/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8790 - loss: 0.3164 - val_acc: 0.4256 - val_loss: 4.7318\n",
      "Epoch 47/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8791 - loss: 0.3194 - val_acc: 0.3742 - val_loss: 4.6776\n",
      "Epoch 48/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8757 - loss: 0.3143 - val_acc: 0.3611 - val_loss: 5.4112\n",
      "Epoch 49/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8805 - loss: 0.3177 - val_acc: 0.3906 - val_loss: 4.7172\n",
      "Epoch 50/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8835 - loss: 0.3086 - val_acc: 0.3840 - val_loss: 4.4175\n",
      "Epoch 51/80\n",
      "120/120 - 23s - 188ms/step - acc: 0.8930 - loss: 0.2918 - val_acc: 0.3775 - val_loss: 4.5796\n",
      "Epoch 52/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8868 - loss: 0.3023 - val_acc: 0.3567 - val_loss: 5.1270\n",
      "Epoch 53/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8909 - loss: 0.2844 - val_acc: 0.3731 - val_loss: 5.0099\n",
      "Epoch 54/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8906 - loss: 0.2825 - val_acc: 0.3950 - val_loss: 4.7047\n",
      "Epoch 55/80\n",
      "120/120 - 23s - 188ms/step - acc: 0.8913 - loss: 0.2804 - val_acc: 0.3632 - val_loss: 5.0511\n",
      "Epoch 56/80\n",
      "120/120 - 23s - 188ms/step - acc: 0.8941 - loss: 0.2789 - val_acc: 0.3775 - val_loss: 4.7601\n",
      "Epoch 57/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.8915 - loss: 0.2861 - val_acc: 0.4289 - val_loss: 4.3285\n",
      "Epoch 58/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 187ms/step - acc: 0.8965 - loss: 0.2754 - val_acc: 0.4333 - val_loss: 4.6014\n",
      "Epoch 59/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.8997 - loss: 0.2644 - val_acc: 0.3643 - val_loss: 5.0736\n",
      "Epoch 60/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.9008 - loss: 0.2675 - val_acc: 0.3950 - val_loss: 4.8988\n",
      "Epoch 61/80\n",
      "120/120 - 23s - 192ms/step - acc: 0.9016 - loss: 0.2644 - val_acc: 0.3950 - val_loss: 5.0318\n",
      "Epoch 62/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 23s - 189ms/step - acc: 0.9068 - loss: 0.2496 - val_acc: 0.4344 - val_loss: 4.5466\n",
      "Epoch 63/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.9054 - loss: 0.2556 - val_acc: 0.3676 - val_loss: 5.3556\n",
      "Epoch 64/80\n",
      "120/120 - 23s - 188ms/step - acc: 0.9118 - loss: 0.2428 - val_acc: 0.3840 - val_loss: 4.9574\n",
      "Epoch 65/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.9063 - loss: 0.2476 - val_acc: 0.3523 - val_loss: 5.4375\n",
      "Epoch 66/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.9122 - loss: 0.2392 - val_acc: 0.3654 - val_loss: 5.0588\n",
      "Epoch 67/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.9074 - loss: 0.2442 - val_acc: 0.3731 - val_loss: 5.2674\n",
      "Epoch 68/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.9209 - loss: 0.2142 - val_acc: 0.3709 - val_loss: 5.8332\n",
      "Epoch 69/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.9104 - loss: 0.2480 - val_acc: 0.4070 - val_loss: 5.3555\n",
      "Epoch 70/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.9119 - loss: 0.2341 - val_acc: 0.4300 - val_loss: 4.5881\n",
      "Epoch 71/80\n",
      "120/120 - 22s - 187ms/step - acc: 0.9147 - loss: 0.2270 - val_acc: 0.3687 - val_loss: 4.8127\n",
      "Epoch 72/80\n",
      "120/120 - 25s - 204ms/step - acc: 0.9222 - loss: 0.2180 - val_acc: 0.3928 - val_loss: 5.3221\n",
      "Epoch 73/80\n",
      "120/120 - 23s - 196ms/step - acc: 0.9188 - loss: 0.2198 - val_acc: 0.3972 - val_loss: 5.1656\n",
      "Epoch 74/80\n",
      "120/120 - 23s - 189ms/step - acc: 0.9200 - loss: 0.2230 - val_acc: 0.4037 - val_loss: 5.1801\n",
      "Epoch 75/80\n",
      "120/120 - 22s - 186ms/step - acc: 0.9174 - loss: 0.2196 - val_acc: 0.3786 - val_loss: 6.0147\n",
      "Epoch 76/80\n",
      "120/120 - 22s - 183ms/step - acc: 0.9201 - loss: 0.2128 - val_acc: 0.4256 - val_loss: 4.6470\n",
      "Epoch 77/80\n",
      "120/120 - 22s - 180ms/step - acc: 0.9217 - loss: 0.2120 - val_acc: 0.3589 - val_loss: 5.7731\n",
      "Epoch 78/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 180ms/step - acc: 0.9251 - loss: 0.2083 - val_acc: 0.4562 - val_loss: 4.6599\n",
      "Epoch 79/80\n",
      "120/120 - 21s - 179ms/step - acc: 0.9273 - loss: 0.1980 - val_acc: 0.4048 - val_loss: 5.9098\n",
      "Epoch 80/80\n",
      "120/120 - 22s - 180ms/step - acc: 0.9246 - loss: 0.2133 - val_acc: 0.3687 - val_loss: 5.9099\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "Save feature of Fold #4 to ./output/Feature_4.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 5\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 42s - 343ms/step - acc: 0.5251 - loss: 1.7631 - val_acc: 0.5286 - val_loss: 1.1694\n",
      "Epoch 2/80\n",
      "122/122 - 21s - 176ms/step - acc: 0.6662 - loss: 1.0276 - val_acc: 0.4532 - val_loss: 1.7239\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 22s - 177ms/step - acc: 0.7154 - loss: 0.8321 - val_acc: 0.5577 - val_loss: 1.8929\n",
      "Epoch 4/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.7434 - loss: 0.7155 - val_acc: 0.4593 - val_loss: 2.3122\n",
      "Epoch 5/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.7533 - loss: 0.6937 - val_acc: 0.4192 - val_loss: 2.6976\n",
      "Epoch 6/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.7575 - loss: 0.6605 - val_acc: 0.4496 - val_loss: 2.2328\n",
      "Epoch 7/80\n",
      "122/122 - 22s - 179ms/step - acc: 0.7623 - loss: 0.6325 - val_acc: 0.4581 - val_loss: 2.1886\n",
      "Epoch 8/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.7758 - loss: 0.6110 - val_acc: 0.4289 - val_loss: 2.4280\n",
      "Epoch 9/80\n",
      "122/122 - 21s - 176ms/step - acc: 0.7801 - loss: 0.5757 - val_acc: 0.4083 - val_loss: 2.8369\n",
      "Epoch 10/80\n",
      "122/122 - 21s - 176ms/step - acc: 0.7942 - loss: 0.5495 - val_acc: 0.4338 - val_loss: 2.5976\n",
      "Epoch 11/80\n",
      "122/122 - 22s - 178ms/step - acc: 0.7838 - loss: 0.5447 - val_acc: 0.4471 - val_loss: 2.9158\n",
      "Epoch 12/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.7985 - loss: 0.5189 - val_acc: 0.4034 - val_loss: 2.9921\n",
      "Epoch 13/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.7969 - loss: 0.5146 - val_acc: 0.4180 - val_loss: 3.2391\n",
      "Epoch 14/80\n",
      "122/122 - 22s - 179ms/step - acc: 0.8090 - loss: 0.5052 - val_acc: 0.4496 - val_loss: 2.8251\n",
      "Epoch 15/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8133 - loss: 0.5005 - val_acc: 0.4860 - val_loss: 2.1680\n",
      "Epoch 16/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8152 - loss: 0.4920 - val_acc: 0.4593 - val_loss: 2.7874\n",
      "Epoch 17/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8089 - loss: 0.4994 - val_acc: 0.4399 - val_loss: 2.9563\n",
      "Epoch 18/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8119 - loss: 0.4826 - val_acc: 0.4994 - val_loss: 2.4862\n",
      "Epoch 19/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8177 - loss: 0.4662 - val_acc: 0.5261 - val_loss: 2.3909\n",
      "Epoch 20/80\n",
      "122/122 - 21s - 176ms/step - acc: 0.8240 - loss: 0.4616 - val_acc: 0.4399 - val_loss: 2.6060\n",
      "Epoch 21/80\n",
      "122/122 - 21s - 176ms/step - acc: 0.8241 - loss: 0.4557 - val_acc: 0.4800 - val_loss: 2.6264\n",
      "Epoch 22/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8272 - loss: 0.4419 - val_acc: 0.4994 - val_loss: 2.5691\n",
      "Epoch 23/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8271 - loss: 0.4486 - val_acc: 0.4326 - val_loss: 3.1737\n",
      "Epoch 24/80\n",
      "122/122 - 22s - 177ms/step - acc: 0.8331 - loss: 0.4297 - val_acc: 0.4751 - val_loss: 2.6678\n",
      "Epoch 25/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.8326 - loss: 0.4351 - val_acc: 0.4787 - val_loss: 2.8669\n",
      "Epoch 26/80\n",
      "122/122 - 24s - 197ms/step - acc: 0.8349 - loss: 0.4227 - val_acc: 0.4787 - val_loss: 2.5422\n",
      "Epoch 27/80\n",
      "122/122 - 22s - 182ms/step - acc: 0.8397 - loss: 0.4081 - val_acc: 0.4386 - val_loss: 2.8546\n",
      "Epoch 28/80\n",
      "122/122 - 21s - 176ms/step - acc: 0.8441 - loss: 0.4043 - val_acc: 0.4471 - val_loss: 2.9298\n",
      "Epoch 29/80\n",
      "122/122 - 22s - 181ms/step - acc: 0.8398 - loss: 0.4052 - val_acc: 0.4787 - val_loss: 2.7214\n",
      "Epoch 30/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8402 - loss: 0.4027 - val_acc: 0.4557 - val_loss: 3.0354\n",
      "Epoch 31/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8553 - loss: 0.3794 - val_acc: 0.4216 - val_loss: 3.6904\n",
      "Epoch 32/80\n",
      "122/122 - 21s - 175ms/step - acc: 0.8526 - loss: 0.3793 - val_acc: 0.4107 - val_loss: 4.1445\n",
      "Epoch 33/80\n",
      "122/122 - 22s - 182ms/step - acc: 0.8581 - loss: 0.3671 - val_acc: 0.4921 - val_loss: 2.7057\n",
      "Epoch 34/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.8509 - loss: 0.3726 - val_acc: 0.4520 - val_loss: 3.2589\n",
      "Epoch 35/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8623 - loss: 0.3517 - val_acc: 0.4447 - val_loss: 3.1204\n",
      "Epoch 36/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.8596 - loss: 0.3629 - val_acc: 0.4192 - val_loss: 3.7459\n",
      "Epoch 37/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.8653 - loss: 0.3636 - val_acc: 0.4313 - val_loss: 3.4209\n",
      "Epoch 38/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.8666 - loss: 0.3449 - val_acc: 0.4654 - val_loss: 2.8674\n",
      "Epoch 39/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8712 - loss: 0.3408 - val_acc: 0.4642 - val_loss: 2.7359\n",
      "Epoch 40/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8757 - loss: 0.3326 - val_acc: 0.4216 - val_loss: 3.5084\n",
      "Epoch 41/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.8791 - loss: 0.3221 - val_acc: 0.4471 - val_loss: 3.2833\n",
      "Epoch 42/80\n",
      "122/122 - 23s - 184ms/step - acc: 0.8804 - loss: 0.3224 - val_acc: 0.3998 - val_loss: 4.1989\n",
      "Epoch 43/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.8723 - loss: 0.3293 - val_acc: 0.4241 - val_loss: 3.5024\n",
      "Epoch 44/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.8850 - loss: 0.2992 - val_acc: 0.4362 - val_loss: 3.6283\n",
      "Epoch 45/80\n",
      "122/122 - 22s - 183ms/step - acc: 0.8833 - loss: 0.2996 - val_acc: 0.4289 - val_loss: 3.4599\n",
      "Epoch 46/80\n",
      "122/122 - 22s - 183ms/step - acc: 0.8849 - loss: 0.3052 - val_acc: 0.4593 - val_loss: 3.5788\n",
      "Epoch 47/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.8869 - loss: 0.2993 - val_acc: 0.4496 - val_loss: 3.2344\n",
      "Epoch 48/80\n",
      "122/122 - 22s - 183ms/step - acc: 0.8872 - loss: 0.2951 - val_acc: 0.4241 - val_loss: 3.6665\n",
      "Epoch 49/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.8936 - loss: 0.2838 - val_acc: 0.4532 - val_loss: 3.4387\n",
      "Epoch 50/80\n",
      "122/122 - 22s - 183ms/step - acc: 0.8859 - loss: 0.3045 - val_acc: 0.4775 - val_loss: 3.0409\n",
      "Epoch 51/80\n",
      "122/122 - 22s - 183ms/step - acc: 0.8900 - loss: 0.2904 - val_acc: 0.4277 - val_loss: 3.8512\n",
      "Epoch 52/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.8998 - loss: 0.2681 - val_acc: 0.4289 - val_loss: 4.0358\n",
      "Epoch 53/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.8976 - loss: 0.2786 - val_acc: 0.4727 - val_loss: 3.0044\n",
      "Epoch 54/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.8974 - loss: 0.2666 - val_acc: 0.4702 - val_loss: 3.1595\n",
      "Epoch 55/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9027 - loss: 0.2625 - val_acc: 0.4362 - val_loss: 4.0693\n",
      "Epoch 56/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8999 - loss: 0.2596 - val_acc: 0.4569 - val_loss: 3.2741\n",
      "Epoch 57/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9006 - loss: 0.2640 - val_acc: 0.4678 - val_loss: 3.2230\n",
      "Epoch 58/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9097 - loss: 0.2429 - val_acc: 0.4654 - val_loss: 3.2097\n",
      "Epoch 59/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9052 - loss: 0.2541 - val_acc: 0.4496 - val_loss: 3.2372\n",
      "Epoch 60/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9099 - loss: 0.2410 - val_acc: 0.4702 - val_loss: 3.1080\n",
      "Epoch 61/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9127 - loss: 0.2434 - val_acc: 0.4447 - val_loss: 3.5609\n",
      "Epoch 62/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.9068 - loss: 0.2469 - val_acc: 0.4654 - val_loss: 3.3696\n",
      "Epoch 63/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9074 - loss: 0.2601 - val_acc: 0.4654 - val_loss: 3.2377\n",
      "Epoch 64/80\n",
      "122/122 - 22s - 183ms/step - acc: 0.9196 - loss: 0.2240 - val_acc: 0.4666 - val_loss: 3.3226\n",
      "Epoch 65/80\n",
      "122/122 - 22s - 183ms/step - acc: 0.9155 - loss: 0.2282 - val_acc: 0.4350 - val_loss: 3.9030\n",
      "Epoch 66/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.9169 - loss: 0.2262 - val_acc: 0.4727 - val_loss: 3.4542\n",
      "Epoch 67/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9173 - loss: 0.2213 - val_acc: 0.4423 - val_loss: 4.0526\n",
      "Epoch 68/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.9137 - loss: 0.2292 - val_acc: 0.4970 - val_loss: 3.0628\n",
      "Epoch 69/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.9154 - loss: 0.2276 - val_acc: 0.4787 - val_loss: 3.1005\n",
      "Epoch 70/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.9130 - loss: 0.2377 - val_acc: 0.5128 - val_loss: 2.5821\n",
      "Epoch 71/80\n",
      "122/122 - 23s - 184ms/step - acc: 0.9206 - loss: 0.2155 - val_acc: 0.5164 - val_loss: 2.5348\n",
      "Epoch 72/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9263 - loss: 0.2052 - val_acc: 0.4617 - val_loss: 3.4244\n",
      "Epoch 73/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9245 - loss: 0.2110 - val_acc: 0.5225 - val_loss: 2.6281\n",
      "Epoch 74/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9248 - loss: 0.2019 - val_acc: 0.4666 - val_loss: 3.3039\n",
      "Epoch 75/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.9270 - loss: 0.2029 - val_acc: 0.4921 - val_loss: 3.0267\n",
      "Epoch 76/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9249 - loss: 0.2013 - val_acc: 0.5006 - val_loss: 2.9598\n",
      "Epoch 77/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.9269 - loss: 0.1992 - val_acc: 0.4824 - val_loss: 3.1863\n",
      "Epoch 78/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.9309 - loss: 0.1909 - val_acc: 0.5103 - val_loss: 2.8817\n",
      "Epoch 79/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9310 - loss: 0.1926 - val_acc: 0.4982 - val_loss: 2.9911\n",
      "Epoch 80/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.9327 - loss: 0.1822 - val_acc: 0.4933 - val_loss: 3.0960\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Save feature of Fold #5 to ./output/Feature_5.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 6\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 45s - 372ms/step - acc: 0.5158 - loss: 1.9041 - val_acc: 0.4554 - val_loss: 1.6285\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 25s - 204ms/step - acc: 0.6301 - loss: 1.1818 - val_acc: 0.5319 - val_loss: 1.2505\n",
      "Epoch 3/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.6793 - loss: 0.9695 - val_acc: 0.5242 - val_loss: 1.5836\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 25s - 204ms/step - acc: 0.7168 - loss: 0.8156 - val_acc: 0.5408 - val_loss: 1.9511\n",
      "Epoch 5/80\n",
      "122/122 - 25s - 204ms/step - acc: 0.7298 - loss: 0.7467 - val_acc: 0.5255 - val_loss: 2.7682\n",
      "Epoch 6/80\n",
      "122/122 - 25s - 205ms/step - acc: 0.7612 - loss: 0.6520 - val_acc: 0.4923 - val_loss: 3.0261\n",
      "Epoch 7/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.7671 - loss: 0.6379 - val_acc: 0.4796 - val_loss: 3.8499\n",
      "Epoch 8/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.7718 - loss: 0.6038 - val_acc: 0.4847 - val_loss: 3.1852\n",
      "Epoch 9/80\n",
      "122/122 - 25s - 204ms/step - acc: 0.7798 - loss: 0.5819 - val_acc: 0.4949 - val_loss: 3.2365\n",
      "Epoch 10/80\n",
      "122/122 - 25s - 204ms/step - acc: 0.7819 - loss: 0.5798 - val_acc: 0.4872 - val_loss: 3.5454\n",
      "Epoch 11/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.7949 - loss: 0.5462 - val_acc: 0.4872 - val_loss: 4.0138\n",
      "Epoch 12/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.7959 - loss: 0.5487 - val_acc: 0.4936 - val_loss: 3.8441\n",
      "Epoch 13/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.7968 - loss: 0.5296 - val_acc: 0.4911 - val_loss: 3.8418\n",
      "Epoch 14/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.7972 - loss: 0.5400 - val_acc: 0.4936 - val_loss: 3.0994\n",
      "Epoch 15/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8061 - loss: 0.5053 - val_acc: 0.4962 - val_loss: 3.4528\n",
      "Epoch 16/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8032 - loss: 0.5160 - val_acc: 0.4783 - val_loss: 4.0361\n",
      "Epoch 17/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8105 - loss: 0.4964 - val_acc: 0.4847 - val_loss: 4.5253\n",
      "Epoch 18/80\n",
      "122/122 - 25s - 204ms/step - acc: 0.8097 - loss: 0.5026 - val_acc: 0.4834 - val_loss: 4.0270\n",
      "Epoch 19/80\n",
      "122/122 - 25s - 204ms/step - acc: 0.8173 - loss: 0.4778 - val_acc: 0.5128 - val_loss: 3.7449\n",
      "Epoch 20/80\n",
      "122/122 - 25s - 204ms/step - acc: 0.8260 - loss: 0.4532 - val_acc: 0.4962 - val_loss: 3.9282\n",
      "Epoch 21/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8206 - loss: 0.4705 - val_acc: 0.5102 - val_loss: 3.6295\n",
      "Epoch 22/80\n",
      "122/122 - 25s - 204ms/step - acc: 0.8211 - loss: 0.4610 - val_acc: 0.4860 - val_loss: 3.8120\n",
      "Epoch 23/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8232 - loss: 0.4411 - val_acc: 0.4936 - val_loss: 4.1759\n",
      "Epoch 24/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8214 - loss: 0.4526 - val_acc: 0.4974 - val_loss: 3.7810\n",
      "Epoch 25/80\n",
      "122/122 - 25s - 204ms/step - acc: 0.8301 - loss: 0.4399 - val_acc: 0.4834 - val_loss: 4.2480\n",
      "Epoch 26/80\n",
      "122/122 - 25s - 205ms/step - acc: 0.8255 - loss: 0.4341 - val_acc: 0.4949 - val_loss: 3.3903\n",
      "Epoch 27/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8368 - loss: 0.4265 - val_acc: 0.4847 - val_loss: 3.7244\n",
      "Epoch 28/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8319 - loss: 0.4366 - val_acc: 0.5370 - val_loss: 3.6234\n",
      "Epoch 29/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8342 - loss: 0.4225 - val_acc: 0.4719 - val_loss: 4.0889\n",
      "Epoch 30/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8378 - loss: 0.4072 - val_acc: 0.4936 - val_loss: 3.7673\n",
      "Epoch 31/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8436 - loss: 0.4165 - val_acc: 0.5077 - val_loss: 3.1936\n",
      "Epoch 32/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8497 - loss: 0.3895 - val_acc: 0.4923 - val_loss: 3.7008\n",
      "Epoch 33/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8442 - loss: 0.4005 - val_acc: 0.4872 - val_loss: 3.6598\n",
      "Epoch 34/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8436 - loss: 0.3900 - val_acc: 0.5089 - val_loss: 3.3936\n",
      "Epoch 35/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8560 - loss: 0.3798 - val_acc: 0.4987 - val_loss: 3.9050\n",
      "Epoch 36/80\n",
      "122/122 - 25s - 201ms/step - acc: 0.8530 - loss: 0.3794 - val_acc: 0.4987 - val_loss: 3.6615\n",
      "Epoch 37/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8551 - loss: 0.3750 - val_acc: 0.4885 - val_loss: 3.8237\n",
      "Epoch 38/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8614 - loss: 0.3700 - val_acc: 0.4936 - val_loss: 3.4286\n",
      "Epoch 39/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8639 - loss: 0.3549 - val_acc: 0.5115 - val_loss: 3.5134\n",
      "Epoch 40/80\n",
      "122/122 - 25s - 201ms/step - acc: 0.8597 - loss: 0.3718 - val_acc: 0.4783 - val_loss: 3.9180\n",
      "Epoch 41/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8650 - loss: 0.3621 - val_acc: 0.5038 - val_loss: 3.2653\n",
      "Epoch 42/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8591 - loss: 0.3557 - val_acc: 0.4987 - val_loss: 3.4377\n",
      "Epoch 43/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8653 - loss: 0.3477 - val_acc: 0.4936 - val_loss: 3.5977\n",
      "Epoch 44/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8739 - loss: 0.3316 - val_acc: 0.4834 - val_loss: 4.1334\n",
      "Epoch 45/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8791 - loss: 0.3201 - val_acc: 0.4949 - val_loss: 3.4880\n",
      "Epoch 46/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8724 - loss: 0.3358 - val_acc: 0.4987 - val_loss: 3.5032\n",
      "Epoch 47/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8769 - loss: 0.3289 - val_acc: 0.5332 - val_loss: 3.0842\n",
      "Epoch 48/80\n",
      "122/122 - 25s - 201ms/step - acc: 0.8844 - loss: 0.3089 - val_acc: 0.4885 - val_loss: 3.4889\n",
      "Epoch 49/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 25s - 203ms/step - acc: 0.8802 - loss: 0.3162 - val_acc: 0.5536 - val_loss: 2.9104\n",
      "Epoch 50/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8796 - loss: 0.3169 - val_acc: 0.4949 - val_loss: 3.7220\n",
      "Epoch 51/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 25s - 204ms/step - acc: 0.8920 - loss: 0.2911 - val_acc: 0.5765 - val_loss: 2.6841\n",
      "Epoch 52/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8823 - loss: 0.3011 - val_acc: 0.5166 - val_loss: 3.0984\n",
      "Epoch 53/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8939 - loss: 0.2772 - val_acc: 0.5714 - val_loss: 2.8380\n",
      "Epoch 54/80\n",
      "122/122 - 25s - 201ms/step - acc: 0.8890 - loss: 0.2880 - val_acc: 0.5395 - val_loss: 3.0527\n",
      "Epoch 55/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8903 - loss: 0.2838 - val_acc: 0.5446 - val_loss: 2.8032\n",
      "Epoch 56/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.8869 - loss: 0.2852 - val_acc: 0.5434 - val_loss: 3.0121\n",
      "Epoch 57/80\n",
      "122/122 - 25s - 204ms/step - acc: 0.8922 - loss: 0.2865 - val_acc: 0.5459 - val_loss: 2.7322\n",
      "Epoch 58/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8958 - loss: 0.2802 - val_acc: 0.5638 - val_loss: 2.8353\n",
      "Epoch 59/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.8943 - loss: 0.2785 - val_acc: 0.5663 - val_loss: 2.6427\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 25s - 204ms/step - acc: 0.9056 - loss: 0.2581 - val_acc: 0.6135 - val_loss: 2.3935\n",
      "Epoch 61/80\n",
      "122/122 - 25s - 204ms/step - acc: 0.9042 - loss: 0.2584 - val_acc: 0.5332 - val_loss: 2.8848\n",
      "Epoch 62/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.9040 - loss: 0.2490 - val_acc: 0.5574 - val_loss: 2.7269\n",
      "Epoch 63/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.9003 - loss: 0.2645 - val_acc: 0.5561 - val_loss: 2.6742\n",
      "Epoch 64/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.9017 - loss: 0.2601 - val_acc: 0.5166 - val_loss: 3.3231\n",
      "Epoch 65/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.9083 - loss: 0.2416 - val_acc: 0.5204 - val_loss: 3.0898\n",
      "Epoch 66/80\n",
      "122/122 - 25s - 201ms/step - acc: 0.9101 - loss: 0.2411 - val_acc: 0.5204 - val_loss: 2.7971\n",
      "Epoch 67/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.9139 - loss: 0.2391 - val_acc: 0.5510 - val_loss: 2.5647\n",
      "Epoch 68/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.9094 - loss: 0.2395 - val_acc: 0.5867 - val_loss: 2.4715\n",
      "Epoch 69/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.9195 - loss: 0.2281 - val_acc: 0.5217 - val_loss: 2.9503\n",
      "Epoch 70/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.9152 - loss: 0.2312 - val_acc: 0.5293 - val_loss: 2.7302\n",
      "Epoch 71/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.9157 - loss: 0.2283 - val_acc: 0.6033 - val_loss: 2.1889\n",
      "Epoch 72/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.9180 - loss: 0.2290 - val_acc: 0.5128 - val_loss: 3.1201\n",
      "Epoch 73/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.9195 - loss: 0.2258 - val_acc: 0.5587 - val_loss: 2.6999\n",
      "Epoch 74/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.9254 - loss: 0.2029 - val_acc: 0.5753 - val_loss: 2.5672\n",
      "Epoch 75/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.9247 - loss: 0.2081 - val_acc: 0.5740 - val_loss: 2.5603\n",
      "Epoch 76/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.9262 - loss: 0.2006 - val_acc: 0.5612 - val_loss: 2.6441\n",
      "Epoch 77/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9224 - loss: 0.2063 - val_acc: 0.5255 - val_loss: 3.2170\n",
      "Epoch 78/80\n",
      "122/122 - 25s - 203ms/step - acc: 0.9231 - loss: 0.2135 - val_acc: 0.5880 - val_loss: 2.4572\n",
      "Epoch 79/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.9284 - loss: 0.2083 - val_acc: 0.5434 - val_loss: 3.0365\n",
      "Epoch 80/80\n",
      "122/122 - 25s - 202ms/step - acc: 0.9239 - loss: 0.2031 - val_acc: 0.5536 - val_loss: 2.9511\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "Save feature of Fold #6 to ./output/Feature_6.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 7\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 45s - 378ms/step - acc: 0.5103 - loss: 1.8270 - val_acc: 0.3041 - val_loss: 2.1345\n",
      "Epoch 2/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.5978 - loss: 1.2602 - val_acc: 0.2938 - val_loss: 1.7192\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 218ms/step - acc: 0.6343 - loss: 1.0993 - val_acc: 0.3876 - val_loss: 1.4066\n",
      "Epoch 4/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.6622 - loss: 0.9738 - val_acc: 0.3124 - val_loss: 2.0640\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 218ms/step - acc: 0.6786 - loss: 0.8844 - val_acc: 0.4814 - val_loss: 1.4721\n",
      "Epoch 6/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 219ms/step - acc: 0.7193 - loss: 0.7615 - val_acc: 0.4948 - val_loss: 1.6185\n",
      "Epoch 7/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.7324 - loss: 0.7229 - val_acc: 0.4691 - val_loss: 1.9668\n",
      "Epoch 8/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.7412 - loss: 0.6743 - val_acc: 0.4402 - val_loss: 2.2514\n",
      "Epoch 9/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.7585 - loss: 0.6343 - val_acc: 0.4567 - val_loss: 2.5936\n",
      "Epoch 10/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 216ms/step - acc: 0.7536 - loss: 0.6477 - val_acc: 0.5052 - val_loss: 2.0718\n",
      "Epoch 11/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.7657 - loss: 0.6107 - val_acc: 0.5000 - val_loss: 2.0412\n",
      "Epoch 12/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 215ms/step - acc: 0.7676 - loss: 0.6130 - val_acc: 0.5227 - val_loss: 2.1714\n",
      "Epoch 13/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 217ms/step - acc: 0.7792 - loss: 0.5774 - val_acc: 0.5485 - val_loss: 2.1170\n",
      "Epoch 14/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.7784 - loss: 0.5645 - val_acc: 0.5392 - val_loss: 2.2142\n",
      "Epoch 15/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 216ms/step - acc: 0.7840 - loss: 0.5565 - val_acc: 0.5866 - val_loss: 1.9353\n",
      "Epoch 16/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 214ms/step - acc: 0.7866 - loss: 0.5616 - val_acc: 0.6175 - val_loss: 1.4733\n",
      "Epoch 17/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.7853 - loss: 0.5461 - val_acc: 0.5660 - val_loss: 1.9993\n",
      "Epoch 18/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.7816 - loss: 0.5674 - val_acc: 0.5794 - val_loss: 2.2570\n",
      "Epoch 19/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.7942 - loss: 0.5271 - val_acc: 0.5443 - val_loss: 2.2645\n",
      "Epoch 20/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.7874 - loss: 0.5513 - val_acc: 0.5588 - val_loss: 2.1102\n",
      "Epoch 21/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8009 - loss: 0.5087 - val_acc: 0.5546 - val_loss: 2.0423\n",
      "Epoch 22/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8019 - loss: 0.5091 - val_acc: 0.5361 - val_loss: 2.3283\n",
      "Epoch 23/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8071 - loss: 0.4904 - val_acc: 0.5134 - val_loss: 2.4890\n",
      "Epoch 24/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8128 - loss: 0.4797 - val_acc: 0.4619 - val_loss: 3.0019\n",
      "Epoch 25/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8094 - loss: 0.4979 - val_acc: 0.5649 - val_loss: 2.2112\n",
      "Epoch 26/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8069 - loss: 0.4832 - val_acc: 0.5392 - val_loss: 2.5280\n",
      "Epoch 27/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8130 - loss: 0.4710 - val_acc: 0.5485 - val_loss: 2.3241\n",
      "Epoch 28/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8093 - loss: 0.4814 - val_acc: 0.5619 - val_loss: 2.0632\n",
      "Epoch 29/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8206 - loss: 0.4626 - val_acc: 0.5814 - val_loss: 2.3870\n",
      "Epoch 30/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8219 - loss: 0.4462 - val_acc: 0.5268 - val_loss: 2.7817\n",
      "Epoch 31/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8219 - loss: 0.4520 - val_acc: 0.5196 - val_loss: 2.6949\n",
      "Epoch 32/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8281 - loss: 0.4374 - val_acc: 0.5113 - val_loss: 2.8571\n",
      "Epoch 33/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8319 - loss: 0.4211 - val_acc: 0.5124 - val_loss: 2.8448\n",
      "Epoch 34/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8281 - loss: 0.4346 - val_acc: 0.6010 - val_loss: 2.1852\n",
      "Epoch 35/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8323 - loss: 0.4288 - val_acc: 0.4701 - val_loss: 3.2969\n",
      "Epoch 36/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8338 - loss: 0.4255 - val_acc: 0.4402 - val_loss: 3.8347\n",
      "Epoch 37/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8351 - loss: 0.4249 - val_acc: 0.4897 - val_loss: 3.2453\n",
      "Epoch 38/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8351 - loss: 0.4195 - val_acc: 0.4464 - val_loss: 3.7917\n",
      "Epoch 39/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8428 - loss: 0.3991 - val_acc: 0.4082 - val_loss: 3.5875\n",
      "Epoch 40/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8366 - loss: 0.4143 - val_acc: 0.4546 - val_loss: 3.4936\n",
      "Epoch 41/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8442 - loss: 0.3993 - val_acc: 0.4588 - val_loss: 3.5911\n",
      "Epoch 42/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8472 - loss: 0.3966 - val_acc: 0.4835 - val_loss: 3.0597\n",
      "Epoch 43/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8495 - loss: 0.3844 - val_acc: 0.5113 - val_loss: 3.2092\n",
      "Epoch 44/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8590 - loss: 0.3710 - val_acc: 0.5041 - val_loss: 3.1272\n",
      "Epoch 45/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8501 - loss: 0.3825 - val_acc: 0.4825 - val_loss: 3.5068\n",
      "Epoch 46/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8582 - loss: 0.3734 - val_acc: 0.5247 - val_loss: 2.9653\n",
      "Epoch 47/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8456 - loss: 0.3873 - val_acc: 0.4835 - val_loss: 3.7102\n",
      "Epoch 48/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8598 - loss: 0.3467 - val_acc: 0.5010 - val_loss: 3.3825\n",
      "Epoch 49/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8653 - loss: 0.3442 - val_acc: 0.4598 - val_loss: 4.1552\n",
      "Epoch 50/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8581 - loss: 0.3665 - val_acc: 0.4856 - val_loss: 3.6214\n",
      "Epoch 51/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8665 - loss: 0.3508 - val_acc: 0.4495 - val_loss: 3.8430\n",
      "Epoch 52/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8698 - loss: 0.3315 - val_acc: 0.4515 - val_loss: 4.0839\n",
      "Epoch 53/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8723 - loss: 0.3276 - val_acc: 0.5299 - val_loss: 2.8995\n",
      "Epoch 54/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8832 - loss: 0.3108 - val_acc: 0.4773 - val_loss: 3.8420\n",
      "Epoch 55/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8869 - loss: 0.3011 - val_acc: 0.4515 - val_loss: 4.1121\n",
      "Epoch 56/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8690 - loss: 0.3393 - val_acc: 0.5330 - val_loss: 2.7196\n",
      "Epoch 57/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8766 - loss: 0.3154 - val_acc: 0.4907 - val_loss: 4.0332\n",
      "Epoch 58/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8747 - loss: 0.3224 - val_acc: 0.4588 - val_loss: 4.0881\n",
      "Epoch 59/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8806 - loss: 0.3165 - val_acc: 0.4928 - val_loss: 3.8757\n",
      "Epoch 60/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8811 - loss: 0.3108 - val_acc: 0.4907 - val_loss: 3.7059\n",
      "Epoch 61/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8850 - loss: 0.3065 - val_acc: 0.5062 - val_loss: 3.3260\n",
      "Epoch 62/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8925 - loss: 0.2845 - val_acc: 0.5093 - val_loss: 3.5300\n",
      "Epoch 63/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8850 - loss: 0.3059 - val_acc: 0.4887 - val_loss: 3.8183\n",
      "Epoch 64/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8812 - loss: 0.3151 - val_acc: 0.4619 - val_loss: 3.8823\n",
      "Epoch 65/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8850 - loss: 0.3116 - val_acc: 0.5309 - val_loss: 2.8591\n",
      "Epoch 66/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8874 - loss: 0.2888 - val_acc: 0.5216 - val_loss: 3.1839\n",
      "Epoch 67/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8941 - loss: 0.2808 - val_acc: 0.5464 - val_loss: 2.8159\n",
      "Epoch 68/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8928 - loss: 0.2833 - val_acc: 0.5041 - val_loss: 3.2805\n",
      "Epoch 69/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8964 - loss: 0.2754 - val_acc: 0.4804 - val_loss: 3.8572\n",
      "Epoch 70/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8974 - loss: 0.2737 - val_acc: 0.5186 - val_loss: 3.3852\n",
      "Epoch 71/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.9006 - loss: 0.2655 - val_acc: 0.5412 - val_loss: 2.7651\n",
      "Epoch 72/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8855 - loss: 0.3044 - val_acc: 0.5268 - val_loss: 3.3877\n",
      "Epoch 73/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8985 - loss: 0.2715 - val_acc: 0.5474 - val_loss: 2.7692\n",
      "Epoch 74/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8911 - loss: 0.2822 - val_acc: 0.4794 - val_loss: 4.0874\n",
      "Epoch 75/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8954 - loss: 0.2811 - val_acc: 0.5371 - val_loss: 2.7517\n",
      "Epoch 76/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8921 - loss: 0.2855 - val_acc: 0.5515 - val_loss: 2.7324\n",
      "Epoch 77/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8934 - loss: 0.2813 - val_acc: 0.4856 - val_loss: 3.5884\n",
      "Epoch 78/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8938 - loss: 0.2807 - val_acc: 0.5021 - val_loss: 3.5615\n",
      "Epoch 79/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.9014 - loss: 0.2621 - val_acc: 0.5227 - val_loss: 2.9584\n",
      "Epoch 80/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.9083 - loss: 0.2492 - val_acc: 0.5186 - val_loss: 3.0687\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "Save feature of Fold #7 to ./output/Feature_7.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 8\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 45s - 379ms/step - acc: 0.5261 - loss: 1.7620 - val_acc: 0.4452 - val_loss: 1.5609\n",
      "Epoch 2/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.6498 - loss: 1.0763 - val_acc: 0.4143 - val_loss: 2.0481\n",
      "Epoch 3/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.7118 - loss: 0.8389 - val_acc: 0.4100 - val_loss: 2.3175\n",
      "Epoch 4/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.7335 - loss: 0.7517 - val_acc: 0.3855 - val_loss: 2.5367\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 216ms/step - acc: 0.7508 - loss: 0.6891 - val_acc: 0.4622 - val_loss: 2.8718\n",
      "Epoch 6/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.7647 - loss: 0.6431 - val_acc: 0.4452 - val_loss: 2.6991\n",
      "Epoch 7/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.7824 - loss: 0.5850 - val_acc: 0.4366 - val_loss: 2.9427\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 215ms/step - acc: 0.7771 - loss: 0.5945 - val_acc: 0.4856 - val_loss: 2.8549\n",
      "Epoch 9/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.7779 - loss: 0.5684 - val_acc: 0.3717 - val_loss: 3.6268\n",
      "Epoch 10/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.7905 - loss: 0.5491 - val_acc: 0.4483 - val_loss: 3.1216\n",
      "Epoch 11/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.7952 - loss: 0.5315 - val_acc: 0.4526 - val_loss: 3.1038\n",
      "Epoch 12/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.7940 - loss: 0.5271 - val_acc: 0.3994 - val_loss: 3.3216\n",
      "Epoch 13/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8119 - loss: 0.4877 - val_acc: 0.4079 - val_loss: 3.6517\n",
      "Epoch 14/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8102 - loss: 0.4931 - val_acc: 0.4228 - val_loss: 3.3663\n",
      "Epoch 15/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8137 - loss: 0.4774 - val_acc: 0.4824 - val_loss: 2.9564\n",
      "Epoch 16/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8140 - loss: 0.4780 - val_acc: 0.4814 - val_loss: 3.1350\n",
      "Epoch 17/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8157 - loss: 0.4796 - val_acc: 0.3802 - val_loss: 3.4952\n",
      "Epoch 18/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8153 - loss: 0.4752 - val_acc: 0.4175 - val_loss: 3.7357\n",
      "Epoch 19/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 216ms/step - acc: 0.8247 - loss: 0.4580 - val_acc: 0.5623 - val_loss: 2.6180\n",
      "Epoch 20/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8205 - loss: 0.4563 - val_acc: 0.4271 - val_loss: 3.3121\n",
      "Epoch 21/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8280 - loss: 0.4334 - val_acc: 0.4665 - val_loss: 3.0995\n",
      "Epoch 22/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8320 - loss: 0.4279 - val_acc: 0.4217 - val_loss: 3.4077\n",
      "Epoch 23/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8333 - loss: 0.4282 - val_acc: 0.4899 - val_loss: 3.0369\n",
      "Epoch 24/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8342 - loss: 0.4245 - val_acc: 0.3834 - val_loss: 3.7878\n",
      "Epoch 25/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8320 - loss: 0.4233 - val_acc: 0.3482 - val_loss: 4.1788\n",
      "Epoch 26/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8426 - loss: 0.4044 - val_acc: 0.3749 - val_loss: 3.5230\n",
      "Epoch 27/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8344 - loss: 0.4134 - val_acc: 0.4430 - val_loss: 3.0989\n",
      "Epoch 28/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8345 - loss: 0.4122 - val_acc: 0.4111 - val_loss: 3.3023\n",
      "Epoch 29/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8452 - loss: 0.3938 - val_acc: 0.4164 - val_loss: 3.2119\n",
      "Epoch 30/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8392 - loss: 0.4139 - val_acc: 0.4707 - val_loss: 2.8871\n",
      "Epoch 31/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8506 - loss: 0.3904 - val_acc: 0.4473 - val_loss: 3.0995\n",
      "Epoch 32/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8561 - loss: 0.3722 - val_acc: 0.4814 - val_loss: 3.0726\n",
      "Epoch 33/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8507 - loss: 0.3728 - val_acc: 0.4175 - val_loss: 3.3791\n",
      "Epoch 34/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8614 - loss: 0.3553 - val_acc: 0.4473 - val_loss: 3.2696\n",
      "Epoch 35/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8583 - loss: 0.3645 - val_acc: 0.4377 - val_loss: 3.1177\n",
      "Epoch 36/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8532 - loss: 0.3675 - val_acc: 0.3695 - val_loss: 3.8487\n",
      "Epoch 37/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8633 - loss: 0.3546 - val_acc: 0.4856 - val_loss: 3.2318\n",
      "Epoch 38/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8667 - loss: 0.3407 - val_acc: 0.4111 - val_loss: 3.4694\n",
      "Epoch 39/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8705 - loss: 0.3382 - val_acc: 0.3866 - val_loss: 3.3545\n",
      "Epoch 40/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8621 - loss: 0.3547 - val_acc: 0.4601 - val_loss: 3.2383\n",
      "Epoch 41/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8735 - loss: 0.3200 - val_acc: 0.4271 - val_loss: 3.4478\n",
      "Epoch 42/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8727 - loss: 0.3296 - val_acc: 0.3845 - val_loss: 3.4115\n",
      "Epoch 43/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8762 - loss: 0.3244 - val_acc: 0.4292 - val_loss: 3.1017\n",
      "Epoch 44/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8716 - loss: 0.3192 - val_acc: 0.4547 - val_loss: 3.1831\n",
      "Epoch 45/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8786 - loss: 0.3121 - val_acc: 0.4302 - val_loss: 3.3364\n",
      "Epoch 46/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8890 - loss: 0.3051 - val_acc: 0.4952 - val_loss: 3.1230\n",
      "Epoch 47/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8831 - loss: 0.3028 - val_acc: 0.4803 - val_loss: 3.1172\n",
      "Epoch 48/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8846 - loss: 0.2942 - val_acc: 0.3972 - val_loss: 3.9207\n",
      "Epoch 49/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8903 - loss: 0.2820 - val_acc: 0.3791 - val_loss: 4.3831\n",
      "Epoch 50/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8890 - loss: 0.2894 - val_acc: 0.4079 - val_loss: 3.7162\n",
      "Epoch 51/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8851 - loss: 0.2881 - val_acc: 0.4281 - val_loss: 4.0136\n",
      "Epoch 52/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8969 - loss: 0.2672 - val_acc: 0.3866 - val_loss: 4.2245\n",
      "Epoch 53/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8963 - loss: 0.2733 - val_acc: 0.4696 - val_loss: 3.4381\n",
      "Epoch 54/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8936 - loss: 0.2781 - val_acc: 0.4441 - val_loss: 3.5325\n",
      "Epoch 55/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9022 - loss: 0.2624 - val_acc: 0.3951 - val_loss: 4.0772\n",
      "Epoch 56/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8950 - loss: 0.2722 - val_acc: 0.3791 - val_loss: 4.4283\n",
      "Epoch 57/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.9010 - loss: 0.2552 - val_acc: 0.3621 - val_loss: 4.3880\n",
      "Epoch 58/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9094 - loss: 0.2455 - val_acc: 0.4164 - val_loss: 3.9300\n",
      "Epoch 59/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.9131 - loss: 0.2322 - val_acc: 0.4047 - val_loss: 3.9165\n",
      "Epoch 60/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.9054 - loss: 0.2503 - val_acc: 0.3717 - val_loss: 3.9476\n",
      "Epoch 61/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9122 - loss: 0.2422 - val_acc: 0.4079 - val_loss: 3.8721\n",
      "Epoch 62/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9120 - loss: 0.2345 - val_acc: 0.4271 - val_loss: 4.2409\n",
      "Epoch 63/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9156 - loss: 0.2356 - val_acc: 0.3951 - val_loss: 4.2635\n",
      "Epoch 64/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9149 - loss: 0.2314 - val_acc: 0.3791 - val_loss: 4.2606\n",
      "Epoch 65/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9222 - loss: 0.2178 - val_acc: 0.3919 - val_loss: 3.9645\n",
      "Epoch 66/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9183 - loss: 0.2229 - val_acc: 0.3876 - val_loss: 4.4582\n",
      "Epoch 67/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9193 - loss: 0.2219 - val_acc: 0.3482 - val_loss: 4.9476\n",
      "Epoch 68/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.9169 - loss: 0.2223 - val_acc: 0.3887 - val_loss: 4.0740\n",
      "Epoch 69/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9239 - loss: 0.2126 - val_acc: 0.3951 - val_loss: 3.9946\n",
      "Epoch 70/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9226 - loss: 0.2174 - val_acc: 0.4452 - val_loss: 4.0990\n",
      "Epoch 71/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.9297 - loss: 0.1983 - val_acc: 0.4058 - val_loss: 4.6753\n",
      "Epoch 72/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.9248 - loss: 0.2092 - val_acc: 0.3876 - val_loss: 4.4045\n",
      "Epoch 73/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9314 - loss: 0.1866 - val_acc: 0.3695 - val_loss: 4.9915\n",
      "Epoch 74/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9261 - loss: 0.2019 - val_acc: 0.4366 - val_loss: 4.3186\n",
      "Epoch 75/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9256 - loss: 0.2030 - val_acc: 0.3908 - val_loss: 4.8293\n",
      "Epoch 76/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9238 - loss: 0.2010 - val_acc: 0.3791 - val_loss: 4.6767\n",
      "Epoch 77/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9275 - loss: 0.2015 - val_acc: 0.4196 - val_loss: 4.4738\n",
      "Epoch 78/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9336 - loss: 0.1852 - val_acc: 0.3727 - val_loss: 4.7063\n",
      "Epoch 79/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.9248 - loss: 0.2032 - val_acc: 0.4452 - val_loss: 4.1778\n",
      "Epoch 80/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.9308 - loss: 0.1885 - val_acc: 0.3791 - val_loss: 4.4806\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "Save feature of Fold #8 to ./output/Feature_8.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 9\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 45s - 369ms/step - acc: 0.5169 - loss: 1.9341 - val_acc: 0.3068 - val_loss: 1.9493\n",
      "Epoch 2/80\n",
      "123/123 - 27s - 219ms/step - acc: 0.6506 - loss: 1.1267 - val_acc: 0.2990 - val_loss: 2.2852\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 26s - 212ms/step - acc: 0.6892 - loss: 0.9205 - val_acc: 0.3120 - val_loss: 2.7086\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 26s - 211ms/step - acc: 0.7221 - loss: 0.8084 - val_acc: 0.3133 - val_loss: 3.1839\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 26s - 210ms/step - acc: 0.7385 - loss: 0.7384 - val_acc: 0.3264 - val_loss: 3.6942\n",
      "Epoch 6/80\n",
      "123/123 - 26s - 210ms/step - acc: 0.7464 - loss: 0.6990 - val_acc: 0.3185 - val_loss: 3.2790\n",
      "Epoch 7/80\n",
      "123/123 - 26s - 210ms/step - acc: 0.7576 - loss: 0.6600 - val_acc: 0.3251 - val_loss: 3.5576\n",
      "Epoch 8/80\n",
      "123/123 - 26s - 210ms/step - acc: 0.7679 - loss: 0.6226 - val_acc: 0.3198 - val_loss: 3.5663\n",
      "Epoch 9/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 26s - 212ms/step - acc: 0.7675 - loss: 0.6183 - val_acc: 0.3486 - val_loss: 3.3240\n",
      "Epoch 10/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.7783 - loss: 0.5785 - val_acc: 0.3460 - val_loss: 3.2388\n",
      "Epoch 11/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.7856 - loss: 0.5688 - val_acc: 0.3238 - val_loss: 3.8257\n",
      "Epoch 12/80\n",
      "123/123 - 26s - 210ms/step - acc: 0.7879 - loss: 0.5644 - val_acc: 0.3290 - val_loss: 3.6119\n",
      "Epoch 13/80\n",
      "123/123 - 26s - 209ms/step - acc: 0.7952 - loss: 0.5345 - val_acc: 0.3277 - val_loss: 4.0875\n",
      "Epoch 14/80\n",
      "123/123 - 26s - 210ms/step - acc: 0.8002 - loss: 0.5091 - val_acc: 0.3277 - val_loss: 4.0427\n",
      "Epoch 15/80\n",
      "123/123 - 26s - 210ms/step - acc: 0.8069 - loss: 0.5006 - val_acc: 0.3381 - val_loss: 3.5992\n",
      "Epoch 16/80\n",
      "123/123 - 26s - 210ms/step - acc: 0.8051 - loss: 0.5052 - val_acc: 0.3329 - val_loss: 3.5010\n",
      "Epoch 17/80\n",
      "123/123 - 26s - 210ms/step - acc: 0.8109 - loss: 0.4923 - val_acc: 0.3407 - val_loss: 3.4528\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 26s - 210ms/step - acc: 0.8122 - loss: 0.4835 - val_acc: 0.3603 - val_loss: 3.8471\n",
      "Epoch 19/80\n",
      "123/123 - 26s - 210ms/step - acc: 0.8112 - loss: 0.4846 - val_acc: 0.3394 - val_loss: 3.6560\n",
      "Epoch 20/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 26s - 212ms/step - acc: 0.8276 - loss: 0.4500 - val_acc: 0.3851 - val_loss: 2.9166\n",
      "Epoch 21/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8224 - loss: 0.4561 - val_acc: 0.3486 - val_loss: 4.2851\n",
      "Epoch 22/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.8285 - loss: 0.4590 - val_acc: 0.3316 - val_loss: 3.7257\n",
      "Epoch 23/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.8287 - loss: 0.4374 - val_acc: 0.3747 - val_loss: 3.3463\n",
      "Epoch 24/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.8352 - loss: 0.4299 - val_acc: 0.3303 - val_loss: 3.5031\n",
      "Epoch 25/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8350 - loss: 0.4115 - val_acc: 0.3329 - val_loss: 3.9527\n",
      "Epoch 26/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.8345 - loss: 0.4208 - val_acc: 0.3420 - val_loss: 3.3522\n",
      "Epoch 27/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8396 - loss: 0.4077 - val_acc: 0.3499 - val_loss: 3.8961\n",
      "Epoch 28/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8425 - loss: 0.3994 - val_acc: 0.3499 - val_loss: 3.6500\n",
      "Epoch 29/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8466 - loss: 0.3876 - val_acc: 0.3460 - val_loss: 3.6849\n",
      "Epoch 30/80\n",
      "123/123 - 26s - 210ms/step - acc: 0.8494 - loss: 0.3855 - val_acc: 0.3629 - val_loss: 3.4903\n",
      "Epoch 31/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.8492 - loss: 0.3870 - val_acc: 0.3838 - val_loss: 3.8113\n",
      "Epoch 32/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.8521 - loss: 0.3789 - val_acc: 0.3446 - val_loss: 4.0281\n",
      "Epoch 33/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.8596 - loss: 0.3609 - val_acc: 0.3590 - val_loss: 3.5850\n",
      "Epoch 34/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.8554 - loss: 0.3655 - val_acc: 0.3629 - val_loss: 3.4355\n",
      "Epoch 35/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.8641 - loss: 0.3450 - val_acc: 0.3446 - val_loss: 4.2973\n",
      "Epoch 36/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.8646 - loss: 0.3450 - val_acc: 0.3734 - val_loss: 3.9439\n",
      "Epoch 37/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 27s - 217ms/step - acc: 0.8677 - loss: 0.3373 - val_acc: 0.4073 - val_loss: 3.3625\n",
      "Epoch 38/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8668 - loss: 0.3422 - val_acc: 0.3930 - val_loss: 3.6043\n",
      "Epoch 39/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.8738 - loss: 0.3302 - val_acc: 0.3551 - val_loss: 3.6022\n",
      "Epoch 40/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8761 - loss: 0.3163 - val_acc: 0.3838 - val_loss: 3.0185\n",
      "Epoch 41/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8796 - loss: 0.3162 - val_acc: 0.3786 - val_loss: 3.5609\n",
      "Epoch 42/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8802 - loss: 0.3070 - val_acc: 0.3642 - val_loss: 3.8068\n",
      "Epoch 43/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8827 - loss: 0.3070 - val_acc: 0.3603 - val_loss: 3.8870\n",
      "Epoch 44/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8787 - loss: 0.3068 - val_acc: 0.3329 - val_loss: 3.8249\n",
      "Epoch 45/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8804 - loss: 0.3139 - val_acc: 0.3916 - val_loss: 2.8645\n",
      "Epoch 46/80\n",
      "123/123 - 26s - 213ms/step - acc: 0.8878 - loss: 0.2932 - val_acc: 0.3956 - val_loss: 3.2692\n",
      "Epoch 47/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8890 - loss: 0.2913 - val_acc: 0.3681 - val_loss: 3.4701\n",
      "Epoch 48/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8970 - loss: 0.2777 - val_acc: 0.3577 - val_loss: 3.7098\n",
      "Epoch 49/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8929 - loss: 0.2724 - val_acc: 0.3655 - val_loss: 3.7064\n",
      "Epoch 50/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 26s - 212ms/step - acc: 0.8944 - loss: 0.2795 - val_acc: 0.4243 - val_loss: 3.1166\n",
      "Epoch 51/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.8998 - loss: 0.2695 - val_acc: 0.3982 - val_loss: 3.2201\n",
      "Epoch 52/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 26s - 212ms/step - acc: 0.8956 - loss: 0.2764 - val_acc: 0.4504 - val_loss: 2.8806\n",
      "Epoch 53/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9032 - loss: 0.2676 - val_acc: 0.3616 - val_loss: 3.8661\n",
      "Epoch 54/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9032 - loss: 0.2465 - val_acc: 0.4021 - val_loss: 3.2846\n",
      "Epoch 55/80\n",
      "123/123 - 26s - 213ms/step - acc: 0.9108 - loss: 0.2422 - val_acc: 0.3930 - val_loss: 3.4792\n",
      "Epoch 56/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9076 - loss: 0.2472 - val_acc: 0.3799 - val_loss: 3.8130\n",
      "Epoch 57/80\n",
      "123/123 - 26s - 213ms/step - acc: 0.9083 - loss: 0.2511 - val_acc: 0.3864 - val_loss: 3.4899\n",
      "Epoch 58/80\n",
      "123/123 - 26s - 213ms/step - acc: 0.9147 - loss: 0.2284 - val_acc: 0.3721 - val_loss: 3.8033\n",
      "Epoch 59/80\n",
      "123/123 - 26s - 213ms/step - acc: 0.9108 - loss: 0.2460 - val_acc: 0.3916 - val_loss: 3.5604\n",
      "Epoch 60/80\n",
      "123/123 - 26s - 213ms/step - acc: 0.9110 - loss: 0.2403 - val_acc: 0.3903 - val_loss: 3.3227\n",
      "Epoch 61/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9108 - loss: 0.2373 - val_acc: 0.3943 - val_loss: 3.5594\n",
      "Epoch 62/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9159 - loss: 0.2268 - val_acc: 0.3916 - val_loss: 3.3188\n",
      "Epoch 63/80\n",
      "123/123 - 26s - 214ms/step - acc: 0.9168 - loss: 0.2264 - val_acc: 0.4021 - val_loss: 3.3329\n",
      "Epoch 64/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9156 - loss: 0.2253 - val_acc: 0.3812 - val_loss: 3.7003\n",
      "Epoch 65/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9227 - loss: 0.2120 - val_acc: 0.3721 - val_loss: 4.0033\n",
      "Epoch 66/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9190 - loss: 0.2199 - val_acc: 0.3864 - val_loss: 3.6174\n",
      "Epoch 67/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.9250 - loss: 0.2048 - val_acc: 0.3890 - val_loss: 3.6353\n",
      "Epoch 68/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9218 - loss: 0.2148 - val_acc: 0.3681 - val_loss: 3.6263\n",
      "Epoch 69/80\n",
      "123/123 - 26s - 213ms/step - acc: 0.9224 - loss: 0.2083 - val_acc: 0.3616 - val_loss: 3.6922\n",
      "Epoch 70/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9232 - loss: 0.2156 - val_acc: 0.3616 - val_loss: 4.0291\n",
      "Epoch 71/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.9219 - loss: 0.2081 - val_acc: 0.3564 - val_loss: 3.9642\n",
      "Epoch 72/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.9273 - loss: 0.1971 - val_acc: 0.3564 - val_loss: 3.9869\n",
      "Epoch 73/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.9225 - loss: 0.2088 - val_acc: 0.3773 - val_loss: 3.7954\n",
      "Epoch 74/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.9251 - loss: 0.2036 - val_acc: 0.3812 - val_loss: 3.7886\n",
      "Epoch 75/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.9262 - loss: 0.1977 - val_acc: 0.3708 - val_loss: 3.9880\n",
      "Epoch 76/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9293 - loss: 0.1979 - val_acc: 0.3681 - val_loss: 3.9559\n",
      "Epoch 77/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.9273 - loss: 0.1931 - val_acc: 0.3616 - val_loss: 4.4808\n",
      "Epoch 78/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9298 - loss: 0.1879 - val_acc: 0.3577 - val_loss: 4.3388\n",
      "Epoch 79/80\n",
      "123/123 - 26s - 211ms/step - acc: 0.9320 - loss: 0.1814 - val_acc: 0.3538 - val_loss: 4.4400\n",
      "Epoch 80/80\n",
      "123/123 - 26s - 212ms/step - acc: 0.9402 - loss: 0.1665 - val_acc: 0.3551 - val_loss: 4.5949\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "Save feature of Fold #9 to ./output/Feature_9.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "End of training FeatureNet.\n",
      "################################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import shutil\n",
    "import gc\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as KTF\n",
    "\n",
    "from model.FeatureNet import build_FeatureNet\n",
    "from model.DataGenerator import kFoldGenerator\n",
    "from model.Utils import ReadConfig\n",
    "\n",
    "# Display a header\n",
    "print(128 * '#')\n",
    "print('Start to train FeatureNet.')\n",
    "\n",
    "# Configuration Setup\n",
    "parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"-c\", type=str, help=\"Configuration file\", required=True)\n",
    "# parser.add_argument(\"-g\", type=str, help=\"GPU number to use, set '-1' to use CPU\", required=True)\n",
    "# args = parser.parse_args()\n",
    "args = lambda: None\n",
    "args.c = \"./ISRUC.config\"  # Update with your actual path\n",
    "args.g = \"-1\"  # Change this based on whether you want to use a GPU or CPU\n",
    "\n",
    "Path, cfgFeature, _, _ = ReadConfig(args.c)\n",
    "\n",
    "# Set GPU or CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.g\n",
    "if args.g != \"-1\":\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "    print(\"Use GPU #\" + args.g)\n",
    "else:\n",
    "    print(\"Use CPU only\")\n",
    "\n",
    "# Training Parameters\n",
    "channels = int(cfgFeature[\"channels\"])\n",
    "fold = int(cfgFeature[\"fold\"])\n",
    "num_epochs_f = int(cfgFeature[\"epoch_f\"])\n",
    "batch_size_f = int(cfgFeature[\"batch_size_f\"])\n",
    "optimizer_f = cfgFeature[\"optimizer_f\"]\n",
    "learn_rate_f = float(cfgFeature[\"learn_rate_f\"])\n",
    "\n",
    "# Create save path\n",
    "# if not os.path.exists(Path['Save']):\n",
    "#     os.makedirs(Path['Save'])\n",
    "# shutil.copyfile(args.c, Path['Save'] + \"last.config\")\n",
    "if not os.path.exists(Path['save']):  # Use lowercase keys\n",
    "    os.makedirs(Path['save'])\n",
    "shutil.copyfile(args.c, os.path.join(Path['save'], \"last.config\"))\n",
    "\n",
    "\n",
    "# Load Data\n",
    "ReadList = np.load(Path['data'], allow_pickle=True)\n",
    "Fold_Num = ReadList['Fold_len']  # Number of samples in each fold\n",
    "Fold_Data = ReadList['Fold_data']  # Data per fold\n",
    "Fold_Label = ReadList['Fold_label']  # Labels per fold\n",
    "\n",
    "print(\"Read data successfully\")\n",
    "print(\"Number of samples:\", np.sum(Fold_Num))\n",
    "\n",
    "# Create kFoldGenerator\n",
    "DataGenerator = kFoldGenerator(Fold_Data, Fold_Label)\n",
    "\n",
    "# Training with k-Fold Cross-Validation\n",
    "all_scores = []\n",
    "for i in range(fold):\n",
    "    print(128 * '_')\n",
    "    print('Fold #', i)\n",
    "    \n",
    "    # Initialize Optimizer\n",
    "    opt_f = keras.optimizers.Adam(learning_rate=learn_rate_f)\n",
    "    \n",
    "    # Fetch Fold Data\n",
    "    train_data, train_targets, val_data, val_targets = DataGenerator.getFold(i)\n",
    "    \n",
    "    # Build FeatureNet\n",
    "    featureNet, featureNet_p = build_FeatureNet(opt_f, channels)\n",
    "    history_fea = featureNet.fit(\n",
    "        x=train_data,\n",
    "        y=train_targets,\n",
    "        epochs=num_epochs_f,\n",
    "        batch_size=batch_size_f,\n",
    "        shuffle=True,\n",
    "        validation_data=(val_data, val_targets),\n",
    "        verbose=2,\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint(\n",
    "            Path['Save'] + 'FeatureNet_Best_' + str(i) + '.h5',\n",
    "            monitor='val_acc',\n",
    "            verbose=0,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='auto',\n",
    "            save_freq='epoch'\n",
    "        )]\n",
    "    )\n",
    "    \n",
    "    # Aggregate Training Information\n",
    "    if i == 0:\n",
    "        fit_loss = np.array(history_fea.history['loss']) * Fold_Num[i]\n",
    "        fit_acc = np.array(history_fea.history['acc']) * Fold_Num[i]\n",
    "        fit_val_loss = np.array(history_fea.history['val_loss']) * Fold_Num[i]\n",
    "        fit_val_acc = np.array(history_fea.history['val_acc']) * Fold_Num[i]\n",
    "    else:\n",
    "        fit_loss += np.array(history_fea.history['loss']) * Fold_Num[i]\n",
    "        fit_acc += np.array(history_fea.history['acc']) * Fold_Num[i]\n",
    "        fit_val_loss += np.array(history_fea.history['val_loss']) * Fold_Num[i]\n",
    "        fit_val_acc += np.array(history_fea.history['val_acc']) * Fold_Num[i]\n",
    "    \n",
    "    # Load Best Weights\n",
    "    featureNet.load_weights(Path['Save'] + 'FeatureNet_Best_' + str(i) + '.h5')\n",
    "    \n",
    "    # Extract and Save Features\n",
    "    train_feature = featureNet_p.predict(train_data)\n",
    "    val_feature = featureNet_p.predict(val_data)\n",
    "    print('Save feature of Fold #' + str(i) + ' to ' + Path['Save'] + 'Feature_' + str(i) + '.npz')\n",
    "    np.savez(Path['Save'] + 'Feature_' + str(i) + '.npz',\n",
    "             train_feature=train_feature,\n",
    "             val_feature=val_feature,\n",
    "             train_targets=train_targets,\n",
    "             val_targets=val_targets)\n",
    "    \n",
    "    # Log Results\n",
    "    with open(Path['Save'] + \"Result_FeatureNet.txt\", 'a+') as saveFile:\n",
    "        print('Fold #'+str(i), file=saveFile)\n",
    "        print(history_fea.history, file=saveFile)\n",
    "    \n",
    "    # Cleanup Memory\n",
    "    keras.backend.clear_session()\n",
    "    del featureNet, featureNet_p, train_data, train_targets, val_data, val_targets, train_feature, val_feature\n",
    "    gc.collect()\n",
    "\n",
    "print(128 * '_')\n",
    "print('End of training FeatureNet.')\n",
    "print(128 * '#')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################################################################\n",
      "Start to train MSTGCN.\n",
      "Config:  ./ISRUC.config\n",
      "WARNING:tensorflow:From C:\\Users\\Victus\\AppData\\Local\\Temp\\ipykernel_5144\\3948724836.py:28: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "Use GPU #0\n",
      "Read data successfully\n",
      "Number of samples: 8589 (with context: 8549 )\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 0\n",
      "train_feature shape: (7629, 5, 10, 256)\n",
      "train_targets shape: (7629, 5)\n",
      "train_domin shape: (7629, 9)\n",
      "Epoch 1/80\n",
      "239/239 - 19s - 81ms/step - Domain_accuracy: 0.3674 - Domain_loss: 1.8994 - Label_accuracy: 0.6293 - Label_loss: 1.0884 - loss: 2.9914 - val_Domain_accuracy: 0.0315 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7467 - val_Label_loss: 0.6361 - val_loss: 0.6409\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Victus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:209: UserWarning: Can save best model only with val_Label_acc available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.4965 - Domain_loss: 1.4190 - Label_accuracy: 0.7336 - Label_loss: 0.6846 - loss: 2.1028 - val_Domain_accuracy: 0.2272 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7783 - val_Label_loss: 0.5989 - val_loss: 0.6018\n",
      "Epoch 3/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.5636 - Domain_loss: 1.2657 - Label_accuracy: 0.7544 - Label_loss: 0.6203 - loss: 1.8849 - val_Domain_accuracy: 0.1522 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7641 - val_Label_loss: 0.5549 - val_loss: 0.5585\n",
      "Epoch 4/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.6212 - Domain_loss: 1.1121 - Label_accuracy: 0.7705 - Label_loss: 0.5711 - loss: 1.6835 - val_Domain_accuracy: 0.0739 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7380 - val_Label_loss: 0.6054 - val_loss: 0.6097\n",
      "Epoch 5/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.6389 - Domain_loss: 1.0552 - Label_accuracy: 0.7804 - Label_loss: 0.5519 - loss: 1.6076 - val_Domain_accuracy: 0.0293 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8022 - val_Label_loss: 0.4862 - val_loss: 0.4897\n",
      "Epoch 6/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.6820 - Domain_loss: 0.9528 - Label_accuracy: 0.7922 - Label_loss: 0.5346 - loss: 1.4866 - val_Domain_accuracy: 0.1120 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8283 - val_Label_loss: 0.4577 - val_loss: 0.4611\n",
      "Epoch 7/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.6876 - Domain_loss: 0.9053 - Label_accuracy: 0.7962 - Label_loss: 0.5104 - loss: 1.4168 - val_Domain_accuracy: 0.0674 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8261 - val_Label_loss: 0.4695 - val_loss: 0.4731\n",
      "Epoch 8/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.7007 - Domain_loss: 0.8951 - Label_accuracy: 0.8044 - Label_loss: 0.4900 - loss: 1.3840 - val_Domain_accuracy: 0.2098 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8359 - val_Label_loss: 0.4603 - val_loss: 0.4639\n",
      "Epoch 9/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7336 - Domain_loss: 0.7801 - Label_accuracy: 0.8118 - Label_loss: 0.4636 - loss: 1.2456 - val_Domain_accuracy: 0.1620 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8250 - val_Label_loss: 0.4912 - val_loss: 0.4950\n",
      "Epoch 10/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7374 - Domain_loss: 0.7675 - Label_accuracy: 0.8091 - Label_loss: 0.4761 - loss: 1.2445 - val_Domain_accuracy: 0.2261 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8370 - val_Label_loss: 0.4255 - val_loss: 0.4285\n",
      "Epoch 11/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7342 - Domain_loss: 0.7941 - Label_accuracy: 0.8141 - Label_loss: 0.4726 - loss: 1.2670 - val_Domain_accuracy: 0.2120 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8413 - val_Label_loss: 0.4037 - val_loss: 0.4061\n",
      "Epoch 12/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7629 - Domain_loss: 0.7316 - Label_accuracy: 0.8160 - Label_loss: 0.4657 - loss: 1.1956 - val_Domain_accuracy: 0.1391 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8348 - val_Label_loss: 0.4577 - val_loss: 0.4578\n",
      "Epoch 13/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7630 - Domain_loss: 0.6996 - Label_accuracy: 0.8242 - Label_loss: 0.4393 - loss: 1.1382 - val_Domain_accuracy: 0.2804 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8478 - val_Label_loss: 0.4143 - val_loss: 0.4169\n",
      "Epoch 14/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.7748 - Domain_loss: 0.6686 - Label_accuracy: 0.8296 - Label_loss: 0.4285 - loss: 1.0985 - val_Domain_accuracy: 0.3076 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8533 - val_Label_loss: 0.4264 - val_loss: 0.4292\n",
      "Epoch 15/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.7795 - Domain_loss: 0.6616 - Label_accuracy: 0.8347 - Label_loss: 0.4246 - loss: 1.0869 - val_Domain_accuracy: 0.2446 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8446 - val_Label_loss: 0.4234 - val_loss: 0.4268\n",
      "Epoch 16/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7929 - Domain_loss: 0.6159 - Label_accuracy: 0.8347 - Label_loss: 0.4199 - loss: 1.0345 - val_Domain_accuracy: 0.2163 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8261 - val_Label_loss: 0.4432 - val_loss: 0.4446\n",
      "Epoch 17/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7920 - Domain_loss: 0.6039 - Label_accuracy: 0.8363 - Label_loss: 0.4113 - loss: 1.0158 - val_Domain_accuracy: 0.0750 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8250 - val_Label_loss: 0.4946 - val_loss: 0.4984\n",
      "Epoch 18/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.7749 - Domain_loss: 0.6636 - Label_accuracy: 0.8414 - Label_loss: 0.4087 - loss: 1.0720 - val_Domain_accuracy: 0.3174 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8185 - val_Label_loss: 0.4580 - val_loss: 0.4597\n",
      "Epoch 19/80\n",
      "239/239 - 11s - 47ms/step - Domain_accuracy: 0.8147 - Domain_loss: 0.5401 - Label_accuracy: 0.8409 - Label_loss: 0.4000 - loss: 0.9409 - val_Domain_accuracy: 0.1033 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8413 - val_Label_loss: 0.4215 - val_loss: 0.4233\n",
      "Epoch 20/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8165 - Domain_loss: 0.5251 - Label_accuracy: 0.8414 - Label_loss: 0.3859 - loss: 0.9122 - val_Domain_accuracy: 0.1511 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8380 - val_Label_loss: 0.4176 - val_loss: 0.4201\n",
      "Epoch 21/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8025 - Domain_loss: 0.5787 - Label_accuracy: 0.8494 - Label_loss: 0.3790 - loss: 0.9573 - val_Domain_accuracy: 0.1272 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8478 - val_Label_loss: 0.4190 - val_loss: 0.4214\n",
      "Epoch 22/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8089 - Domain_loss: 0.5656 - Label_accuracy: 0.8472 - Label_loss: 0.3846 - loss: 0.9508 - val_Domain_accuracy: 0.0609 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8174 - val_Label_loss: 0.4870 - val_loss: 0.4886\n",
      "Epoch 23/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8283 - Domain_loss: 0.5016 - Label_accuracy: 0.8563 - Label_loss: 0.3694 - loss: 0.8704 - val_Domain_accuracy: 0.0576 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8511 - val_Label_loss: 0.4277 - val_loss: 0.4302\n",
      "Epoch 24/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8230 - Domain_loss: 0.5362 - Label_accuracy: 0.8521 - Label_loss: 0.3720 - loss: 0.9056 - val_Domain_accuracy: 0.2293 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8467 - val_Label_loss: 0.4130 - val_loss: 0.4160\n",
      "Epoch 25/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8312 - Domain_loss: 0.4901 - Label_accuracy: 0.8494 - Label_loss: 0.3712 - loss: 0.8613 - val_Domain_accuracy: 0.1304 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8370 - val_Label_loss: 0.4044 - val_loss: 0.4071\n",
      "Epoch 26/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8225 - Domain_loss: 0.5260 - Label_accuracy: 0.8596 - Label_loss: 0.3586 - loss: 0.8847 - val_Domain_accuracy: 0.1391 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8337 - val_Label_loss: 0.4453 - val_loss: 0.4480\n",
      "Epoch 27/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8414 - Domain_loss: 0.4738 - Label_accuracy: 0.8548 - Label_loss: 0.3547 - loss: 0.8285 - val_Domain_accuracy: 0.3315 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8293 - val_Label_loss: 0.4608 - val_loss: 0.4629\n",
      "Epoch 28/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8376 - Domain_loss: 0.4888 - Label_accuracy: 0.8527 - Label_loss: 0.3571 - loss: 0.8471 - val_Domain_accuracy: 0.1217 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8326 - val_Label_loss: 0.4673 - val_loss: 0.4704\n",
      "Epoch 29/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8065 - Domain_loss: 0.5774 - Label_accuracy: 0.8573 - Label_loss: 0.3591 - loss: 0.9373 - val_Domain_accuracy: 0.1967 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8598 - val_Label_loss: 0.3803 - val_loss: 0.3827\n",
      "Epoch 30/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8360 - Domain_loss: 0.4873 - Label_accuracy: 0.8614 - Label_loss: 0.3454 - loss: 0.8336 - val_Domain_accuracy: 0.1891 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8457 - val_Label_loss: 0.4295 - val_loss: 0.4329\n",
      "Epoch 31/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8342 - Domain_loss: 0.4877 - Label_accuracy: 0.8613 - Label_loss: 0.3446 - loss: 0.8312 - val_Domain_accuracy: 0.2880 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8293 - val_Label_loss: 0.4477 - val_loss: 0.4489\n",
      "Epoch 32/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8462 - Domain_loss: 0.4533 - Label_accuracy: 0.8651 - Label_loss: 0.3328 - loss: 0.7866 - val_Domain_accuracy: 0.1402 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 0.5021 - val_loss: 0.5041\n",
      "Epoch 33/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8464 - Domain_loss: 0.4475 - Label_accuracy: 0.8633 - Label_loss: 0.3407 - loss: 0.7887 - val_Domain_accuracy: 0.1402 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8359 - val_Label_loss: 0.4718 - val_loss: 0.4755\n",
      "Epoch 34/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8384 - Domain_loss: 0.4825 - Label_accuracy: 0.8680 - Label_loss: 0.3308 - loss: 0.8121 - val_Domain_accuracy: 0.1859 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.6355 - val_loss: 0.6400\n",
      "Epoch 35/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8445 - Domain_loss: 0.4430 - Label_accuracy: 0.8687 - Label_loss: 0.3327 - loss: 0.7754 - val_Domain_accuracy: 0.1402 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8478 - val_Label_loss: 0.4520 - val_loss: 0.4548\n",
      "Epoch 36/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8385 - Domain_loss: 0.4669 - Label_accuracy: 0.8672 - Label_loss: 0.3256 - loss: 0.7928 - val_Domain_accuracy: 0.2185 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8228 - val_Label_loss: 0.5259 - val_loss: 0.5286\n",
      "Epoch 37/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8435 - Domain_loss: 0.4438 - Label_accuracy: 0.8740 - Label_loss: 0.3233 - loss: 0.7660 - val_Domain_accuracy: 0.1620 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8120 - val_Label_loss: 0.5307 - val_loss: 0.5321\n",
      "Epoch 38/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8380 - Domain_loss: 0.4863 - Label_accuracy: 0.8697 - Label_loss: 0.3222 - loss: 0.8095 - val_Domain_accuracy: 0.0815 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8489 - val_Label_loss: 0.4313 - val_loss: 0.4341\n",
      "Epoch 39/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8199 - Domain_loss: 0.5225 - Label_accuracy: 0.8687 - Label_loss: 0.3321 - loss: 0.8558 - val_Domain_accuracy: 0.2739 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8293 - val_Label_loss: 0.4901 - val_loss: 0.4936\n",
      "Epoch 40/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8465 - Domain_loss: 0.4476 - Label_accuracy: 0.8757 - Label_loss: 0.3147 - loss: 0.7635 - val_Domain_accuracy: 0.0696 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8348 - val_Label_loss: 0.4657 - val_loss: 0.4686\n",
      "Epoch 41/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8487 - Domain_loss: 0.4460 - Label_accuracy: 0.8786 - Label_loss: 0.3020 - loss: 0.7474 - val_Domain_accuracy: 0.2120 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8228 - val_Label_loss: 0.4499 - val_loss: 0.4523\n",
      "Epoch 42/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8519 - Domain_loss: 0.4435 - Label_accuracy: 0.8761 - Label_loss: 0.3106 - loss: 0.7543 - val_Domain_accuracy: 0.0967 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8315 - val_Label_loss: 0.4305 - val_loss: 0.4315\n",
      "Epoch 43/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8382 - Domain_loss: 0.4670 - Label_accuracy: 0.8776 - Label_loss: 0.3080 - loss: 0.7745 - val_Domain_accuracy: 0.1435 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8467 - val_Label_loss: 0.4605 - val_loss: 0.4643\n",
      "Epoch 44/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8398 - Domain_loss: 0.4701 - Label_accuracy: 0.8794 - Label_loss: 0.2985 - loss: 0.7689 - val_Domain_accuracy: 0.2163 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8565 - val_Label_loss: 0.3990 - val_loss: 0.4014\n",
      "Epoch 45/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8451 - Domain_loss: 0.4409 - Label_accuracy: 0.8852 - Label_loss: 0.2969 - loss: 0.7381 - val_Domain_accuracy: 0.2239 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8293 - val_Label_loss: 0.4728 - val_loss: 0.4755\n",
      "Epoch 46/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8565 - Domain_loss: 0.4378 - Label_accuracy: 0.8824 - Label_loss: 0.2921 - loss: 0.7304 - val_Domain_accuracy: 0.3087 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8326 - val_Label_loss: 0.4791 - val_loss: 0.4822\n",
      "Epoch 47/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8465 - Domain_loss: 0.4543 - Label_accuracy: 0.8805 - Label_loss: 0.3007 - loss: 0.7556 - val_Domain_accuracy: 0.1228 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8261 - val_Label_loss: 0.5261 - val_loss: 0.5291\n",
      "Epoch 48/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8469 - Domain_loss: 0.4484 - Label_accuracy: 0.8818 - Label_loss: 0.3030 - loss: 0.7515 - val_Domain_accuracy: 0.1674 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8293 - val_Label_loss: 0.4532 - val_loss: 0.4557\n",
      "Epoch 49/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8571 - Domain_loss: 0.4143 - Label_accuracy: 0.8827 - Label_loss: 0.2913 - loss: 0.7048 - val_Domain_accuracy: 0.1652 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8402 - val_Label_loss: 0.4709 - val_loss: 0.4743\n",
      "Epoch 50/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8536 - Domain_loss: 0.4317 - Label_accuracy: 0.8869 - Label_loss: 0.2841 - loss: 0.7168 - val_Domain_accuracy: 0.1370 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8402 - val_Label_loss: 0.4972 - val_loss: 0.5005\n",
      "Epoch 51/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8624 - Domain_loss: 0.4088 - Label_accuracy: 0.8907 - Label_loss: 0.2736 - loss: 0.6824 - val_Domain_accuracy: 0.1793 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8380 - val_Label_loss: 0.4543 - val_loss: 0.4574\n",
      "Epoch 52/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8457 - Domain_loss: 0.4600 - Label_accuracy: 0.8882 - Label_loss: 0.2806 - loss: 0.7416 - val_Domain_accuracy: 0.2141 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8413 - val_Label_loss: 0.4714 - val_loss: 0.4729\n",
      "Epoch 53/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8431 - Domain_loss: 0.4448 - Label_accuracy: 0.8866 - Label_loss: 0.2802 - loss: 0.7241 - val_Domain_accuracy: 0.1293 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8359 - val_Label_loss: 0.4979 - val_loss: 0.5013\n",
      "Epoch 54/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8527 - Domain_loss: 0.4257 - Label_accuracy: 0.8886 - Label_loss: 0.2775 - loss: 0.7028 - val_Domain_accuracy: 0.1728 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8217 - val_Label_loss: 0.4919 - val_loss: 0.4939\n",
      "Epoch 55/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8533 - Domain_loss: 0.4334 - Label_accuracy: 0.8976 - Label_loss: 0.2661 - loss: 0.6997 - val_Domain_accuracy: 0.0598 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8152 - val_Label_loss: 0.5325 - val_loss: 0.5360\n",
      "Epoch 56/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8556 - Domain_loss: 0.4349 - Label_accuracy: 0.8907 - Label_loss: 0.2775 - loss: 0.7130 - val_Domain_accuracy: 0.2000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8402 - val_Label_loss: 0.5122 - val_loss: 0.5160\n",
      "Epoch 57/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8502 - Domain_loss: 0.4377 - Label_accuracy: 0.8861 - Label_loss: 0.2811 - loss: 0.7188 - val_Domain_accuracy: 0.1804 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8424 - val_Label_loss: 0.4809 - val_loss: 0.4838\n",
      "Epoch 58/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8580 - Domain_loss: 0.4181 - Label_accuracy: 0.8928 - Label_loss: 0.2672 - loss: 0.6846 - val_Domain_accuracy: 0.1935 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8304 - val_Label_loss: 0.4990 - val_loss: 0.5020\n",
      "Epoch 59/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8521 - Domain_loss: 0.4247 - Label_accuracy: 0.8946 - Label_loss: 0.2650 - loss: 0.6902 - val_Domain_accuracy: 0.0609 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8435 - val_Label_loss: 0.4909 - val_loss: 0.4930\n",
      "Epoch 60/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8634 - Domain_loss: 0.4128 - Label_accuracy: 0.8962 - Label_loss: 0.2539 - loss: 0.6665 - val_Domain_accuracy: 0.0989 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8196 - val_Label_loss: 0.5253 - val_loss: 0.5267\n",
      "Epoch 61/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8591 - Domain_loss: 0.4115 - Label_accuracy: 0.8950 - Label_loss: 0.2639 - loss: 0.6760 - val_Domain_accuracy: 0.1989 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8293 - val_Label_loss: 0.5345 - val_loss: 0.5385\n",
      "Epoch 62/80\n",
      "239/239 - 129s - 541ms/step - Domain_accuracy: 0.8478 - Domain_loss: 0.4312 - Label_accuracy: 0.9005 - Label_loss: 0.2596 - loss: 0.6914 - val_Domain_accuracy: 0.0978 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8315 - val_Label_loss: 0.5513 - val_loss: 0.5545\n",
      "Epoch 63/80\n",
      "239/239 - 8s - 35ms/step - Domain_accuracy: 0.8512 - Domain_loss: 0.4261 - Label_accuracy: 0.8920 - Label_loss: 0.2684 - loss: 0.6939 - val_Domain_accuracy: 0.2739 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8304 - val_Label_loss: 0.5158 - val_loss: 0.5191\n",
      "Epoch 64/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8611 - Domain_loss: 0.4031 - Label_accuracy: 0.8980 - Label_loss: 0.2575 - loss: 0.6608 - val_Domain_accuracy: 0.0554 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8261 - val_Label_loss: 0.5424 - val_loss: 0.5449\n",
      "Epoch 65/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8647 - Domain_loss: 0.4023 - Label_accuracy: 0.8951 - Label_loss: 0.2579 - loss: 0.6595 - val_Domain_accuracy: 0.0891 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8196 - val_Label_loss: 0.5324 - val_loss: 0.5361\n",
      "Epoch 66/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8667 - Domain_loss: 0.3872 - Label_accuracy: 0.9038 - Label_loss: 0.2440 - loss: 0.6322 - val_Domain_accuracy: 0.0913 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8152 - val_Label_loss: 0.5713 - val_loss: 0.5754\n",
      "Epoch 67/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8582 - Domain_loss: 0.4097 - Label_accuracy: 0.8995 - Label_loss: 0.2517 - loss: 0.6619 - val_Domain_accuracy: 0.0848 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8402 - val_Label_loss: 0.5275 - val_loss: 0.5314\n",
      "Epoch 68/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8706 - Domain_loss: 0.3720 - Label_accuracy: 0.8996 - Label_loss: 0.2498 - loss: 0.6220 - val_Domain_accuracy: 0.1543 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8511 - val_Label_loss: 0.5167 - val_loss: 0.5207\n",
      "Epoch 69/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8612 - Domain_loss: 0.3954 - Label_accuracy: 0.8958 - Label_loss: 0.2607 - loss: 0.6560 - val_Domain_accuracy: 0.1880 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8228 - val_Label_loss: 0.5496 - val_loss: 0.5524\n",
      "Epoch 70/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8537 - Domain_loss: 0.4157 - Label_accuracy: 0.9013 - Label_loss: 0.2566 - loss: 0.6723 - val_Domain_accuracy: 0.1359 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8359 - val_Label_loss: 0.4961 - val_loss: 0.4983\n",
      "Epoch 71/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8625 - Domain_loss: 0.3973 - Label_accuracy: 0.9009 - Label_loss: 0.2494 - loss: 0.6473 - val_Domain_accuracy: 0.1217 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8446 - val_Label_loss: 0.5047 - val_loss: 0.5083\n",
      "Epoch 72/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8592 - Domain_loss: 0.4029 - Label_accuracy: 0.9031 - Label_loss: 0.2524 - loss: 0.6531 - val_Domain_accuracy: 0.1793 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8533 - val_Label_loss: 0.3962 - val_loss: 0.3982\n",
      "Epoch 73/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8677 - Domain_loss: 0.3946 - Label_accuracy: 0.9030 - Label_loss: 0.2484 - loss: 0.6418 - val_Domain_accuracy: 0.1424 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8348 - val_Label_loss: 0.5246 - val_loss: 0.5275\n",
      "Epoch 74/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8715 - Domain_loss: 0.3657 - Label_accuracy: 0.9120 - Label_loss: 0.2274 - loss: 0.5929 - val_Domain_accuracy: 0.1685 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8413 - val_Label_loss: 0.4934 - val_loss: 0.4950\n",
      "Epoch 75/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8725 - Domain_loss: 0.3776 - Label_accuracy: 0.9061 - Label_loss: 0.2377 - loss: 0.6150 - val_Domain_accuracy: 0.0957 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8217 - val_Label_loss: 0.5838 - val_loss: 0.5882\n",
      "Epoch 76/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8719 - Domain_loss: 0.3688 - Label_accuracy: 0.9068 - Label_loss: 0.2339 - loss: 0.6020 - val_Domain_accuracy: 0.1837 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8239 - val_Label_loss: 0.5397 - val_loss: 0.5428\n",
      "Epoch 77/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8706 - Domain_loss: 0.3805 - Label_accuracy: 0.9037 - Label_loss: 0.2456 - loss: 0.6256 - val_Domain_accuracy: 0.0652 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8293 - val_Label_loss: 0.5559 - val_loss: 0.5600\n",
      "Epoch 78/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8650 - Domain_loss: 0.3894 - Label_accuracy: 0.9069 - Label_loss: 0.2348 - loss: 0.6241 - val_Domain_accuracy: 0.1261 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8424 - val_Label_loss: 0.5320 - val_loss: 0.5362\n",
      "Epoch 79/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8747 - Domain_loss: 0.3667 - Label_accuracy: 0.9101 - Label_loss: 0.2323 - loss: 0.5981 - val_Domain_accuracy: 0.1185 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8402 - val_Label_loss: 0.5117 - val_loss: 0.5154\n",
      "Epoch 80/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8635 - Domain_loss: 0.4001 - Label_accuracy: 0.9061 - Label_loss: 0.2372 - loss: 0.6370 - val_Domain_accuracy: 0.1098 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8467 - val_Label_loss: 0.5259 - val_loss: 0.5300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 1\n",
      "train_feature shape: (7642, 5, 10, 256)\n",
      "train_targets shape: (7642, 5)\n",
      "train_domin shape: (7642, 9)\n",
      "Epoch 1/80\n",
      "239/239 - 19s - 80ms/step - Domain_accuracy: 0.4316 - Domain_loss: 1.7051 - Label_accuracy: 0.6731 - Label_loss: 0.9911 - loss: 2.6968 - val_Domain_accuracy: 0.1433 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6736 - val_Label_loss: 0.9267 - val_loss: 0.9293\n",
      "Epoch 2/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.5627 - Domain_loss: 1.2499 - Label_accuracy: 0.7604 - Label_loss: 0.6271 - loss: 1.8773 - val_Domain_accuracy: 0.1069 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7001 - val_Label_loss: 0.7919 - val_loss: 0.7994\n",
      "Epoch 3/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.6408 - Domain_loss: 1.0224 - Label_accuracy: 0.7829 - Label_loss: 0.5453 - loss: 1.5679 - val_Domain_accuracy: 0.0816 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7067 - val_Label_loss: 0.7825 - val_loss: 0.7910\n",
      "Epoch 4/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.6850 - Domain_loss: 0.9096 - Label_accuracy: 0.8067 - Label_loss: 0.5052 - loss: 1.4146 - val_Domain_accuracy: 0.1003 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7585 - val_Label_loss: 0.6311 - val_loss: 0.6330\n",
      "Epoch 5/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.6994 - Domain_loss: 0.8721 - Label_accuracy: 0.8057 - Label_loss: 0.4911 - loss: 1.3629 - val_Domain_accuracy: 0.0143 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6031 - val_Label_loss: 1.2678 - val_loss: 1.2859\n",
      "Epoch 6/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.7146 - Domain_loss: 0.8268 - Label_accuracy: 0.8194 - Label_loss: 0.4629 - loss: 1.2897 - val_Domain_accuracy: 0.1246 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6946 - val_Label_loss: 0.8186 - val_loss: 0.8224\n",
      "Epoch 7/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.7613 - Domain_loss: 0.6952 - Label_accuracy: 0.8232 - Label_loss: 0.4369 - loss: 1.1319 - val_Domain_accuracy: 0.0287 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7685 - val_Label_loss: 0.6010 - val_loss: 0.5967\n",
      "Epoch 8/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7410 - Domain_loss: 0.7646 - Label_accuracy: 0.8202 - Label_loss: 0.4473 - loss: 1.2120 - val_Domain_accuracy: 0.0915 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6902 - val_Label_loss: 0.7677 - val_loss: 0.7725\n",
      "Epoch 9/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7769 - Domain_loss: 0.6567 - Label_accuracy: 0.8337 - Label_loss: 0.4240 - loss: 1.0803 - val_Domain_accuracy: 0.2503 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7773 - val_Label_loss: 0.5847 - val_loss: 0.5845\n",
      "Epoch 10/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7685 - Domain_loss: 0.6806 - Label_accuracy: 0.8376 - Label_loss: 0.4052 - loss: 1.0859 - val_Domain_accuracy: 0.0375 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7806 - val_Label_loss: 0.5584 - val_loss: 0.5597\n",
      "Epoch 11/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.7824 - Domain_loss: 0.6324 - Label_accuracy: 0.8400 - Label_loss: 0.4048 - loss: 1.0371 - val_Domain_accuracy: 0.1433 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6571 - val_Label_loss: 0.9132 - val_loss: 0.9275\n",
      "Epoch 12/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.7751 - Domain_loss: 0.6667 - Label_accuracy: 0.8406 - Label_loss: 0.4000 - loss: 1.0665 - val_Domain_accuracy: 0.2194 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7552 - val_Label_loss: 0.7162 - val_loss: 0.7165\n",
      "Epoch 13/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8059 - Domain_loss: 0.5576 - Label_accuracy: 0.8407 - Label_loss: 0.3951 - loss: 0.9526 - val_Domain_accuracy: 0.0209 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7045 - val_Label_loss: 0.7365 - val_loss: 0.7470\n",
      "Epoch 14/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8088 - Domain_loss: 0.5644 - Label_accuracy: 0.8468 - Label_loss: 0.3828 - loss: 0.9472 - val_Domain_accuracy: 0.0507 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7486 - val_Label_loss: 0.7659 - val_loss: 0.7735\n",
      "Epoch 15/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8109 - Domain_loss: 0.5427 - Label_accuracy: 0.8559 - Label_loss: 0.3739 - loss: 0.9166 - val_Domain_accuracy: 0.0948 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7552 - val_Label_loss: 0.6748 - val_loss: 0.6813\n",
      "Epoch 16/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8192 - Domain_loss: 0.5156 - Label_accuracy: 0.8578 - Label_loss: 0.3613 - loss: 0.8771 - val_Domain_accuracy: 0.1974 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7729 - val_Label_loss: 0.6254 - val_loss: 0.6297\n",
      "Epoch 17/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8277 - Domain_loss: 0.4916 - Label_accuracy: 0.8506 - Label_loss: 0.3700 - loss: 0.8619 - val_Domain_accuracy: 0.1180 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7111 - val_Label_loss: 0.9095 - val_loss: 0.9155\n",
      "Epoch 18/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8292 - Domain_loss: 0.5058 - Label_accuracy: 0.8549 - Label_loss: 0.3645 - loss: 0.8705 - val_Domain_accuracy: 0.0838 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7310 - val_Label_loss: 0.7912 - val_loss: 0.7979\n",
      "Epoch 19/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8440 - Domain_loss: 0.4577 - Label_accuracy: 0.8574 - Label_loss: 0.3501 - loss: 0.8076 - val_Domain_accuracy: 0.0154 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6648 - val_Label_loss: 0.9978 - val_loss: 1.0051\n",
      "Epoch 20/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8271 - Domain_loss: 0.4995 - Label_accuracy: 0.8571 - Label_loss: 0.3509 - loss: 0.8504 - val_Domain_accuracy: 0.0198 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7244 - val_Label_loss: 0.7596 - val_loss: 0.7654\n",
      "Epoch 21/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8328 - Domain_loss: 0.4881 - Label_accuracy: 0.8655 - Label_loss: 0.3315 - loss: 0.8194 - val_Domain_accuracy: 0.0165 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7244 - val_Label_loss: 0.7914 - val_loss: 0.7920\n",
      "Epoch 22/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8445 - Domain_loss: 0.4694 - Label_accuracy: 0.8667 - Label_loss: 0.3373 - loss: 0.8069 - val_Domain_accuracy: 0.1114 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6670 - val_Label_loss: 0.9838 - val_loss: 0.9800\n",
      "Epoch 23/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8508 - Domain_loss: 0.4422 - Label_accuracy: 0.8694 - Label_loss: 0.3327 - loss: 0.7749 - val_Domain_accuracy: 0.0386 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6792 - val_Label_loss: 0.9283 - val_loss: 0.9368\n",
      "Epoch 24/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8572 - Domain_loss: 0.4185 - Label_accuracy: 0.8716 - Label_loss: 0.3197 - loss: 0.7381 - val_Domain_accuracy: 0.0408 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7078 - val_Label_loss: 0.9155 - val_loss: 0.9250\n",
      "Epoch 25/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8438 - Domain_loss: 0.4394 - Label_accuracy: 0.8739 - Label_loss: 0.3216 - loss: 0.7608 - val_Domain_accuracy: 0.0959 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7409 - val_Label_loss: 0.7307 - val_loss: 0.7375\n",
      "Epoch 26/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8445 - Domain_loss: 0.4517 - Label_accuracy: 0.8737 - Label_loss: 0.3193 - loss: 0.7709 - val_Domain_accuracy: 0.0375 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7663 - val_Label_loss: 0.6524 - val_loss: 0.6546\n",
      "Epoch 27/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8589 - Domain_loss: 0.4148 - Label_accuracy: 0.8769 - Label_loss: 0.3147 - loss: 0.7293 - val_Domain_accuracy: 0.1136 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7299 - val_Label_loss: 0.8378 - val_loss: 0.8457\n",
      "Epoch 28/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8588 - Domain_loss: 0.4096 - Label_accuracy: 0.8753 - Label_loss: 0.3085 - loss: 0.7179 - val_Domain_accuracy: 0.0474 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7332 - val_Label_loss: 0.6714 - val_loss: 0.6755\n",
      "Epoch 29/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8600 - Domain_loss: 0.4015 - Label_accuracy: 0.8818 - Label_loss: 0.2931 - loss: 0.6947 - val_Domain_accuracy: 0.0386 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7045 - val_Label_loss: 0.9064 - val_loss: 0.9143\n",
      "Epoch 30/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8553 - Domain_loss: 0.4148 - Label_accuracy: 0.8851 - Label_loss: 0.2889 - loss: 0.7038 - val_Domain_accuracy: 0.0772 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7034 - val_Label_loss: 0.8598 - val_loss: 0.8691\n",
      "Epoch 31/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8498 - Domain_loss: 0.4387 - Label_accuracy: 0.8805 - Label_loss: 0.3038 - loss: 0.7426 - val_Domain_accuracy: 0.0430 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7310 - val_Label_loss: 0.8681 - val_loss: 0.8734\n",
      "Epoch 32/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8578 - Domain_loss: 0.4182 - Label_accuracy: 0.8873 - Label_loss: 0.2868 - loss: 0.7052 - val_Domain_accuracy: 0.0639 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7122 - val_Label_loss: 0.9049 - val_loss: 0.9089\n",
      "Epoch 33/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8608 - Domain_loss: 0.4061 - Label_accuracy: 0.8936 - Label_loss: 0.2757 - loss: 0.6816 - val_Domain_accuracy: 0.0926 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7233 - val_Label_loss: 0.7896 - val_loss: 0.7973\n",
      "Epoch 34/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8605 - Domain_loss: 0.4084 - Label_accuracy: 0.8846 - Label_loss: 0.2864 - loss: 0.6946 - val_Domain_accuracy: 0.0695 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7078 - val_Label_loss: 0.8360 - val_loss: 0.8443\n",
      "Epoch 35/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8521 - Domain_loss: 0.4353 - Label_accuracy: 0.8877 - Label_loss: 0.2857 - loss: 0.7207 - val_Domain_accuracy: 0.1676 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7464 - val_Label_loss: 0.7337 - val_loss: 0.7384\n",
      "Epoch 36/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8718 - Domain_loss: 0.3747 - Label_accuracy: 0.9007 - Label_loss: 0.2639 - loss: 0.6388 - val_Domain_accuracy: 0.0606 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7541 - val_Label_loss: 0.7460 - val_loss: 0.7489\n",
      "Epoch 37/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8686 - Domain_loss: 0.3889 - Label_accuracy: 0.8918 - Label_loss: 0.2706 - loss: 0.6596 - val_Domain_accuracy: 0.1058 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 0.6186 - val_loss: 0.6195\n",
      "Epoch 38/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8678 - Domain_loss: 0.3909 - Label_accuracy: 0.9013 - Label_loss: 0.2479 - loss: 0.6388 - val_Domain_accuracy: 0.0562 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7652 - val_Label_loss: 0.6756 - val_loss: 0.6766\n",
      "Epoch 39/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8629 - Domain_loss: 0.4007 - Label_accuracy: 0.8969 - Label_loss: 0.2569 - loss: 0.6576 - val_Domain_accuracy: 0.0309 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7299 - val_Label_loss: 0.9218 - val_loss: 0.9251\n",
      "Epoch 40/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8644 - Domain_loss: 0.4028 - Label_accuracy: 0.8958 - Label_loss: 0.2648 - loss: 0.6678 - val_Domain_accuracy: 0.0386 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7387 - val_Label_loss: 0.8956 - val_loss: 0.9046\n",
      "Epoch 41/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8769 - Domain_loss: 0.3626 - Label_accuracy: 0.9040 - Label_loss: 0.2529 - loss: 0.6154 - val_Domain_accuracy: 0.0463 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7409 - val_Label_loss: 0.8885 - val_loss: 0.8974\n",
      "Epoch 42/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8708 - Domain_loss: 0.3709 - Label_accuracy: 0.9047 - Label_loss: 0.2431 - loss: 0.6141 - val_Domain_accuracy: 0.1841 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6736 - val_Label_loss: 1.1939 - val_loss: 1.2134\n",
      "Epoch 43/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8635 - Domain_loss: 0.3985 - Label_accuracy: 0.9026 - Label_loss: 0.2500 - loss: 0.6485 - val_Domain_accuracy: 0.0882 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7574 - val_Label_loss: 0.7630 - val_loss: 0.7684\n",
      "Epoch 44/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8647 - Domain_loss: 0.3932 - Label_accuracy: 0.9029 - Label_loss: 0.2446 - loss: 0.6378 - val_Domain_accuracy: 0.0761 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7596 - val_Label_loss: 0.8121 - val_loss: 0.8179\n",
      "Epoch 45/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8701 - Domain_loss: 0.3697 - Label_accuracy: 0.9029 - Label_loss: 0.2433 - loss: 0.6131 - val_Domain_accuracy: 0.0783 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7784 - val_Label_loss: 0.7191 - val_loss: 0.7249\n",
      "Epoch 46/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8651 - Domain_loss: 0.3886 - Label_accuracy: 0.9067 - Label_loss: 0.2372 - loss: 0.6255 - val_Domain_accuracy: 0.1334 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7233 - val_Label_loss: 1.0142 - val_loss: 1.0232\n",
      "Epoch 47/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8725 - Domain_loss: 0.3848 - Label_accuracy: 0.9070 - Label_loss: 0.2414 - loss: 0.6261 - val_Domain_accuracy: 0.0463 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7133 - val_Label_loss: 1.0206 - val_loss: 1.0295\n",
      "Epoch 48/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8701 - Domain_loss: 0.3896 - Label_accuracy: 0.9121 - Label_loss: 0.2296 - loss: 0.6193 - val_Domain_accuracy: 0.0926 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7552 - val_Label_loss: 0.9327 - val_loss: 0.9414\n",
      "Epoch 49/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8674 - Domain_loss: 0.3843 - Label_accuracy: 0.9049 - Label_loss: 0.2374 - loss: 0.6217 - val_Domain_accuracy: 0.1103 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7497 - val_Label_loss: 0.8816 - val_loss: 0.8877\n",
      "Epoch 50/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8769 - Domain_loss: 0.3481 - Label_accuracy: 0.9121 - Label_loss: 0.2263 - loss: 0.5744 - val_Domain_accuracy: 0.0265 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7519 - val_Label_loss: 0.7632 - val_loss: 0.7641\n",
      "Epoch 51/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8757 - Domain_loss: 0.3677 - Label_accuracy: 0.9105 - Label_loss: 0.2246 - loss: 0.5924 - val_Domain_accuracy: 0.1632 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7067 - val_Label_loss: 1.0574 - val_loss: 1.0727\n",
      "Epoch 52/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8688 - Domain_loss: 0.3824 - Label_accuracy: 0.9135 - Label_loss: 0.2202 - loss: 0.6026 - val_Domain_accuracy: 0.1224 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7166 - val_Label_loss: 0.9353 - val_loss: 0.9427\n",
      "Epoch 53/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8691 - Domain_loss: 0.3919 - Label_accuracy: 0.9105 - Label_loss: 0.2262 - loss: 0.6181 - val_Domain_accuracy: 0.0430 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7409 - val_Label_loss: 0.9258 - val_loss: 0.9287\n",
      "Epoch 54/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8787 - Domain_loss: 0.3603 - Label_accuracy: 0.9126 - Label_loss: 0.2241 - loss: 0.5845 - val_Domain_accuracy: 0.0805 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7233 - val_Label_loss: 1.0539 - val_loss: 1.0689\n",
      "Epoch 55/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8821 - Domain_loss: 0.3495 - Label_accuracy: 0.9156 - Label_loss: 0.2112 - loss: 0.5609 - val_Domain_accuracy: 0.0320 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7398 - val_Label_loss: 0.9947 - val_loss: 1.0023\n",
      "Epoch 56/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8714 - Domain_loss: 0.3796 - Label_accuracy: 0.9152 - Label_loss: 0.2113 - loss: 0.5908 - val_Domain_accuracy: 0.0584 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7343 - val_Label_loss: 0.9410 - val_loss: 0.9505\n",
      "Epoch 57/80\n",
      "239/239 - 8s - 35ms/step - Domain_accuracy: 0.8671 - Domain_loss: 0.3882 - Label_accuracy: 0.9165 - Label_loss: 0.2144 - loss: 0.6027 - val_Domain_accuracy: 0.0816 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7365 - val_Label_loss: 0.8121 - val_loss: 0.8188\n",
      "Epoch 58/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8805 - Domain_loss: 0.3461 - Label_accuracy: 0.9199 - Label_loss: 0.2014 - loss: 0.5473 - val_Domain_accuracy: 0.0551 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7464 - val_Label_loss: 0.8625 - val_loss: 0.8704\n",
      "Epoch 59/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8701 - Domain_loss: 0.3734 - Label_accuracy: 0.9211 - Label_loss: 0.2095 - loss: 0.5828 - val_Domain_accuracy: 0.1929 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7431 - val_Label_loss: 0.8358 - val_loss: 0.8410\n",
      "Epoch 60/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8714 - Domain_loss: 0.3829 - Label_accuracy: 0.9190 - Label_loss: 0.2084 - loss: 0.5915 - val_Domain_accuracy: 0.0794 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7464 - val_Label_loss: 0.9622 - val_loss: 0.9665\n",
      "Epoch 61/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8699 - Domain_loss: 0.3832 - Label_accuracy: 0.9149 - Label_loss: 0.2136 - loss: 0.5965 - val_Domain_accuracy: 0.1312 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7100 - val_Label_loss: 1.1536 - val_loss: 1.1662\n",
      "Epoch 62/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8691 - Domain_loss: 0.3820 - Label_accuracy: 0.9185 - Label_loss: 0.2081 - loss: 0.5903 - val_Domain_accuracy: 0.1885 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7398 - val_Label_loss: 0.9912 - val_loss: 1.0002\n",
      "Epoch 63/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8774 - Domain_loss: 0.3515 - Label_accuracy: 0.9193 - Label_loss: 0.2044 - loss: 0.5558 - val_Domain_accuracy: 0.0584 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7133 - val_Label_loss: 1.1042 - val_loss: 1.1158\n",
      "Epoch 64/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8769 - Domain_loss: 0.3588 - Label_accuracy: 0.9246 - Label_loss: 0.1873 - loss: 0.5461 - val_Domain_accuracy: 0.1698 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7299 - val_Label_loss: 1.1122 - val_loss: 1.1201\n",
      "Epoch 65/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8737 - Domain_loss: 0.3764 - Label_accuracy: 0.9181 - Label_loss: 0.2062 - loss: 0.5825 - val_Domain_accuracy: 0.0860 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7277 - val_Label_loss: 1.0794 - val_loss: 1.0911\n",
      "Epoch 66/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8741 - Domain_loss: 0.3566 - Label_accuracy: 0.9245 - Label_loss: 0.1995 - loss: 0.5563 - val_Domain_accuracy: 0.0331 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7387 - val_Label_loss: 0.9873 - val_loss: 0.9986\n",
      "Epoch 67/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8728 - Domain_loss: 0.3659 - Label_accuracy: 0.9225 - Label_loss: 0.1861 - loss: 0.5518 - val_Domain_accuracy: 0.1069 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7343 - val_Label_loss: 1.0007 - val_loss: 1.0080\n",
      "Epoch 68/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8672 - Domain_loss: 0.3974 - Label_accuracy: 0.9224 - Label_loss: 0.2027 - loss: 0.6001 - val_Domain_accuracy: 0.1279 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7321 - val_Label_loss: 1.0857 - val_loss: 1.0968\n",
      "Epoch 69/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8767 - Domain_loss: 0.3650 - Label_accuracy: 0.9219 - Label_loss: 0.1951 - loss: 0.5597 - val_Domain_accuracy: 0.0684 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6990 - val_Label_loss: 1.2809 - val_loss: 1.2967\n",
      "Epoch 70/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8708 - Domain_loss: 0.3643 - Label_accuracy: 0.9249 - Label_loss: 0.1963 - loss: 0.5607 - val_Domain_accuracy: 0.0805 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7442 - val_Label_loss: 0.9423 - val_loss: 0.9478\n",
      "Epoch 71/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8803 - Domain_loss: 0.3425 - Label_accuracy: 0.9291 - Label_loss: 0.1776 - loss: 0.5198 - val_Domain_accuracy: 0.0816 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7244 - val_Label_loss: 1.1644 - val_loss: 1.1710\n",
      "Epoch 72/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8732 - Domain_loss: 0.3676 - Label_accuracy: 0.9231 - Label_loss: 0.1926 - loss: 0.5601 - val_Domain_accuracy: 0.0662 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7310 - val_Label_loss: 1.1204 - val_loss: 1.1300\n",
      "Epoch 73/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8801 - Domain_loss: 0.3408 - Label_accuracy: 0.9269 - Label_loss: 0.1931 - loss: 0.5339 - val_Domain_accuracy: 0.1356 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7387 - val_Label_loss: 1.0540 - val_loss: 1.0595\n",
      "Epoch 74/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8757 - Domain_loss: 0.3698 - Label_accuracy: 0.9327 - Label_loss: 0.1807 - loss: 0.5506 - val_Domain_accuracy: 0.1180 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7244 - val_Label_loss: 1.0957 - val_loss: 1.0985\n",
      "Epoch 75/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8757 - Domain_loss: 0.3634 - Label_accuracy: 0.9255 - Label_loss: 0.1860 - loss: 0.5495 - val_Domain_accuracy: 0.2029 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7486 - val_Label_loss: 0.9488 - val_loss: 0.9540\n",
      "Epoch 76/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8763 - Domain_loss: 0.3537 - Label_accuracy: 0.9267 - Label_loss: 0.1914 - loss: 0.5450 - val_Domain_accuracy: 0.0628 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7619 - val_Label_loss: 0.8281 - val_loss: 0.8316\n",
      "Epoch 77/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8788 - Domain_loss: 0.3465 - Label_accuracy: 0.9299 - Label_loss: 0.1716 - loss: 0.5181 - val_Domain_accuracy: 0.1114 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7707 - val_Label_loss: 0.8687 - val_loss: 0.8680\n",
      "Epoch 78/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8767 - Domain_loss: 0.3547 - Label_accuracy: 0.9327 - Label_loss: 0.1723 - loss: 0.5269 - val_Domain_accuracy: 0.0650 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7519 - val_Label_loss: 0.9130 - val_loss: 0.9173\n",
      "Epoch 79/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8788 - Domain_loss: 0.3532 - Label_accuracy: 0.9321 - Label_loss: 0.1682 - loss: 0.5214 - val_Domain_accuracy: 0.0551 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7321 - val_Label_loss: 1.1106 - val_loss: 1.1163\n",
      "Epoch 80/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8769 - Domain_loss: 0.3522 - Label_accuracy: 0.9329 - Label_loss: 0.1746 - loss: 0.5265 - val_Domain_accuracy: 0.2437 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7067 - val_Label_loss: 1.3200 - val_loss: 1.3353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 2\n",
      "train_feature shape: (7759, 5, 10, 256)\n",
      "train_targets shape: (7759, 5)\n",
      "train_domin shape: (7759, 9)\n",
      "Epoch 1/80\n",
      "243/243 - 17s - 70ms/step - Domain_accuracy: 0.5278 - Domain_loss: 1.4045 - Label_accuracy: 0.7867 - Label_loss: 0.6678 - loss: 2.0724 - val_Domain_accuracy: 0.1911 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7696 - val_Label_loss: 0.8003 - val_loss: 0.8102\n",
      "Epoch 2/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.6770 - Domain_loss: 0.9413 - Label_accuracy: 0.8897 - Label_loss: 0.3062 - loss: 1.2473 - val_Domain_accuracy: 0.0899 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7747 - val_Label_loss: 0.7292 - val_loss: 0.7366\n",
      "Epoch 3/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7212 - Domain_loss: 0.8322 - Label_accuracy: 0.9175 - Label_loss: 0.2313 - loss: 1.0637 - val_Domain_accuracy: 0.1658 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7278 - val_Label_loss: 1.3331 - val_loss: 1.3491\n",
      "Epoch 4/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7118 - Domain_loss: 0.8629 - Label_accuracy: 0.9179 - Label_loss: 0.2156 - loss: 1.0766 - val_Domain_accuracy: 0.0987 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7418 - val_Label_loss: 1.0452 - val_loss: 1.0585\n",
      "Epoch 5/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7345 - Domain_loss: 0.7913 - Label_accuracy: 0.9343 - Label_loss: 0.1815 - loss: 0.9734 - val_Domain_accuracy: 0.1962 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7342 - val_Label_loss: 1.2664 - val_loss: 1.2821\n",
      "Epoch 6/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7415 - Domain_loss: 0.7798 - Label_accuracy: 0.9374 - Label_loss: 0.1793 - loss: 0.9588 - val_Domain_accuracy: 0.1468 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7797 - val_Label_loss: 1.1125 - val_loss: 1.1265\n",
      "Epoch 7/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7621 - Domain_loss: 0.6948 - Label_accuracy: 0.9425 - Label_loss: 0.1568 - loss: 0.8525 - val_Domain_accuracy: 0.0709 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7924 - val_Label_loss: 0.8932 - val_loss: 0.9045\n",
      "Epoch 8/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7708 - Domain_loss: 0.6959 - Label_accuracy: 0.9474 - Label_loss: 0.1406 - loss: 0.8377 - val_Domain_accuracy: 0.1759 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.0657 - val_loss: 1.0792\n",
      "Epoch 9/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7739 - Domain_loss: 0.6637 - Label_accuracy: 0.9461 - Label_loss: 0.1452 - loss: 0.8079 - val_Domain_accuracy: 0.1684 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7519 - val_Label_loss: 1.4164 - val_loss: 1.4341\n",
      "Epoch 10/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8103 - Domain_loss: 0.5754 - Label_accuracy: 0.9557 - Label_loss: 0.1255 - loss: 0.7016 - val_Domain_accuracy: 0.1203 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7646 - val_Label_loss: 1.3096 - val_loss: 1.3262\n",
      "Epoch 11/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7996 - Domain_loss: 0.6014 - Label_accuracy: 0.9608 - Label_loss: 0.1081 - loss: 0.7104 - val_Domain_accuracy: 0.0835 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7709 - val_Label_loss: 1.1863 - val_loss: 1.2013\n",
      "Epoch 12/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8161 - Domain_loss: 0.5643 - Label_accuracy: 0.9594 - Label_loss: 0.1041 - loss: 0.6683 - val_Domain_accuracy: 0.1063 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 1.1120 - val_loss: 1.1260\n",
      "Epoch 13/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8077 - Domain_loss: 0.5736 - Label_accuracy: 0.9566 - Label_loss: 0.1203 - loss: 0.6949 - val_Domain_accuracy: 0.1253 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7797 - val_Label_loss: 1.3863 - val_loss: 1.4039\n",
      "Epoch 14/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8094 - Domain_loss: 0.5600 - Label_accuracy: 0.9582 - Label_loss: 0.1151 - loss: 0.6736 - val_Domain_accuracy: 0.1013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7975 - val_Label_loss: 1.0764 - val_loss: 1.0899\n",
      "Epoch 15/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8151 - Domain_loss: 0.5514 - Label_accuracy: 0.9631 - Label_loss: 0.1000 - loss: 0.6527 - val_Domain_accuracy: 0.1342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7671 - val_Label_loss: 1.4605 - val_loss: 1.4790\n",
      "Epoch 16/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8287 - Domain_loss: 0.4991 - Label_accuracy: 0.9629 - Label_loss: 0.0995 - loss: 0.5985 - val_Domain_accuracy: 0.2089 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7506 - val_Label_loss: 1.5698 - val_loss: 1.5892\n",
      "Epoch 17/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8290 - Domain_loss: 0.5013 - Label_accuracy: 0.9679 - Label_loss: 0.0871 - loss: 0.5887 - val_Domain_accuracy: 0.1304 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7797 - val_Label_loss: 1.5537 - val_loss: 1.5725\n",
      "Epoch 18/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8367 - Domain_loss: 0.4653 - Label_accuracy: 0.9733 - Label_loss: 0.0779 - loss: 0.5440 - val_Domain_accuracy: 0.1025 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7633 - val_Label_loss: 1.6402 - val_loss: 1.6607\n",
      "Epoch 19/80\n",
      "243/243 - 8s - 35ms/step - Domain_accuracy: 0.8269 - Domain_loss: 0.5180 - Label_accuracy: 0.9687 - Label_loss: 0.0894 - loss: 0.6079 - val_Domain_accuracy: 0.1506 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7608 - val_Label_loss: 1.4651 - val_loss: 1.4837\n",
      "Epoch 20/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8279 - Domain_loss: 0.5109 - Label_accuracy: 0.9701 - Label_loss: 0.0786 - loss: 0.5888 - val_Domain_accuracy: 0.0848 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7734 - val_Label_loss: 1.4962 - val_loss: 1.5150\n",
      "Epoch 21/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8241 - Domain_loss: 0.5049 - Label_accuracy: 0.9713 - Label_loss: 0.0804 - loss: 0.5857 - val_Domain_accuracy: 0.0987 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8076 - val_Label_loss: 1.1336 - val_loss: 1.1480\n",
      "Epoch 22/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8390 - Domain_loss: 0.4626 - Label_accuracy: 0.9774 - Label_loss: 0.0617 - loss: 0.5238 - val_Domain_accuracy: 0.2101 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 1.4336 - val_loss: 1.4518\n",
      "Epoch 23/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8352 - Domain_loss: 0.4737 - Label_accuracy: 0.9733 - Label_loss: 0.0748 - loss: 0.5488 - val_Domain_accuracy: 0.0671 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7886 - val_Label_loss: 1.5870 - val_loss: 1.6070\n",
      "Epoch 24/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8322 - Domain_loss: 0.4866 - Label_accuracy: 0.9765 - Label_loss: 0.0693 - loss: 0.5542 - val_Domain_accuracy: 0.1722 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 1.3787 - val_loss: 1.3960\n",
      "Epoch 25/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8419 - Domain_loss: 0.4660 - Label_accuracy: 0.9715 - Label_loss: 0.0757 - loss: 0.5410 - val_Domain_accuracy: 0.1848 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7722 - val_Label_loss: 1.8473 - val_loss: 1.8707\n",
      "Epoch 26/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8505 - Domain_loss: 0.4489 - Label_accuracy: 0.9777 - Label_loss: 0.0624 - loss: 0.5119 - val_Domain_accuracy: 0.1076 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7620 - val_Label_loss: 1.8505 - val_loss: 1.8740\n",
      "Epoch 27/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8466 - Domain_loss: 0.4444 - Label_accuracy: 0.9776 - Label_loss: 0.0573 - loss: 0.5017 - val_Domain_accuracy: 0.1152 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8076 - val_Label_loss: 1.2231 - val_loss: 1.2386\n",
      "Epoch 28/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8482 - Domain_loss: 0.4367 - Label_accuracy: 0.9791 - Label_loss: 0.0590 - loss: 0.4957 - val_Domain_accuracy: 0.1481 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7823 - val_Label_loss: 1.4145 - val_loss: 1.4324\n",
      "Epoch 29/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8723 - Domain_loss: 0.3698 - Label_accuracy: 0.9821 - Label_loss: 0.0477 - loss: 0.4176 - val_Domain_accuracy: 0.1291 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7519 - val_Label_loss: 1.9130 - val_loss: 1.9372\n",
      "Epoch 30/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8727 - Domain_loss: 0.3780 - Label_accuracy: 0.9808 - Label_loss: 0.0527 - loss: 0.4313 - val_Domain_accuracy: 0.0696 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 1.5408 - val_loss: 1.5603\n",
      "Epoch 31/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8674 - Domain_loss: 0.3825 - Label_accuracy: 0.9768 - Label_loss: 0.0599 - loss: 0.4421 - val_Domain_accuracy: 0.1582 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7671 - val_Label_loss: 1.6406 - val_loss: 1.6612\n",
      "Epoch 32/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8613 - Domain_loss: 0.4096 - Label_accuracy: 0.9747 - Label_loss: 0.0682 - loss: 0.4776 - val_Domain_accuracy: 0.0949 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7722 - val_Label_loss: 1.4222 - val_loss: 1.4395\n",
      "Epoch 33/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8435 - Domain_loss: 0.4727 - Label_accuracy: 0.9817 - Label_loss: 0.0519 - loss: 0.5237 - val_Domain_accuracy: 0.1089 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 1.6201 - val_loss: 1.6407\n",
      "Epoch 34/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8626 - Domain_loss: 0.4039 - Label_accuracy: 0.9825 - Label_loss: 0.0492 - loss: 0.4535 - val_Domain_accuracy: 0.0899 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7785 - val_Label_loss: 1.8731 - val_loss: 1.8968\n",
      "Epoch 35/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8532 - Domain_loss: 0.4314 - Label_accuracy: 0.9814 - Label_loss: 0.0563 - loss: 0.4875 - val_Domain_accuracy: 0.1342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 1.6001 - val_loss: 1.6192\n",
      "Epoch 36/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8569 - Domain_loss: 0.4050 - Label_accuracy: 0.9812 - Label_loss: 0.0508 - loss: 0.4563 - val_Domain_accuracy: 0.1291 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7759 - val_Label_loss: 1.6357 - val_loss: 1.6564\n",
      "Epoch 37/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.8596 - Domain_loss: 0.4139 - Label_accuracy: 0.9808 - Label_loss: 0.0513 - loss: 0.4651 - val_Domain_accuracy: 0.1886 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7342 - val_Label_loss: 2.1191 - val_loss: 2.1391\n",
      "Epoch 38/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8737 - Domain_loss: 0.3701 - Label_accuracy: 0.9813 - Label_loss: 0.0532 - loss: 0.4235 - val_Domain_accuracy: 0.0481 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7873 - val_Label_loss: 1.6061 - val_loss: 1.6264\n",
      "Epoch 39/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8732 - Domain_loss: 0.3847 - Label_accuracy: 0.9807 - Label_loss: 0.0491 - loss: 0.4335 - val_Domain_accuracy: 0.0570 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.5125 - val_loss: 1.5317\n",
      "Epoch 40/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8777 - Domain_loss: 0.3466 - Label_accuracy: 0.9872 - Label_loss: 0.0371 - loss: 0.3842 - val_Domain_accuracy: 0.2063 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7987 - val_Label_loss: 1.4808 - val_loss: 1.4996\n",
      "Epoch 41/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8782 - Domain_loss: 0.3572 - Label_accuracy: 0.9856 - Label_loss: 0.0405 - loss: 0.3980 - val_Domain_accuracy: 0.1544 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7785 - val_Label_loss: 1.8790 - val_loss: 1.9028\n",
      "Epoch 42/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8605 - Domain_loss: 0.4151 - Label_accuracy: 0.9845 - Label_loss: 0.0494 - loss: 0.4646 - val_Domain_accuracy: 0.1241 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7772 - val_Label_loss: 1.7383 - val_loss: 1.7603\n",
      "Epoch 43/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8657 - Domain_loss: 0.3850 - Label_accuracy: 0.9847 - Label_loss: 0.0464 - loss: 0.4307 - val_Domain_accuracy: 0.1228 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 1.5922 - val_loss: 1.6123\n",
      "Epoch 44/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8711 - Domain_loss: 0.3694 - Label_accuracy: 0.9831 - Label_loss: 0.0426 - loss: 0.4122 - val_Domain_accuracy: 0.1987 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7684 - val_Label_loss: 1.9354 - val_loss: 1.9599\n",
      "Epoch 45/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8618 - Domain_loss: 0.4035 - Label_accuracy: 0.9856 - Label_loss: 0.0380 - loss: 0.4420 - val_Domain_accuracy: 0.1266 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8051 - val_Label_loss: 1.6084 - val_loss: 1.6288\n",
      "Epoch 46/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8634 - Domain_loss: 0.3970 - Label_accuracy: 0.9867 - Label_loss: 0.0356 - loss: 0.4325 - val_Domain_accuracy: 0.0823 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 1.6723 - val_loss: 1.6935\n",
      "Epoch 47/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8600 - Domain_loss: 0.4052 - Label_accuracy: 0.9867 - Label_loss: 0.0408 - loss: 0.4465 - val_Domain_accuracy: 0.1152 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7886 - val_Label_loss: 1.9170 - val_loss: 1.9412\n",
      "Epoch 48/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8680 - Domain_loss: 0.4067 - Label_accuracy: 0.9839 - Label_loss: 0.0441 - loss: 0.4505 - val_Domain_accuracy: 0.1481 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8241 - val_Label_loss: 1.4263 - val_loss: 1.4444\n",
      "Epoch 49/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8585 - Domain_loss: 0.4181 - Label_accuracy: 0.9839 - Label_loss: 0.0452 - loss: 0.4632 - val_Domain_accuracy: 0.1241 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7658 - val_Label_loss: 2.0339 - val_loss: 2.0597\n",
      "Epoch 50/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8568 - Domain_loss: 0.4016 - Label_accuracy: 0.9853 - Label_loss: 0.0460 - loss: 0.4478 - val_Domain_accuracy: 0.2456 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7886 - val_Label_loss: 1.8859 - val_loss: 1.9097\n",
      "Epoch 51/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8697 - Domain_loss: 0.3824 - Label_accuracy: 0.9884 - Label_loss: 0.0351 - loss: 0.4180 - val_Domain_accuracy: 0.1861 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7962 - val_Label_loss: 1.6914 - val_loss: 1.7128\n",
      "Epoch 52/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8709 - Domain_loss: 0.3788 - Label_accuracy: 0.9887 - Label_loss: 0.0359 - loss: 0.4143 - val_Domain_accuracy: 0.1063 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.8275 - val_loss: 1.8507\n",
      "Epoch 53/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8679 - Domain_loss: 0.3971 - Label_accuracy: 0.9897 - Label_loss: 0.0272 - loss: 0.4248 - val_Domain_accuracy: 0.0468 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7987 - val_Label_loss: 1.9423 - val_loss: 1.9669\n",
      "Epoch 54/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8642 - Domain_loss: 0.4016 - Label_accuracy: 0.9884 - Label_loss: 0.0378 - loss: 0.4392 - val_Domain_accuracy: 0.2038 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7684 - val_Label_loss: 1.9399 - val_loss: 1.9645\n",
      "Epoch 55/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8509 - Domain_loss: 0.4365 - Label_accuracy: 0.9880 - Label_loss: 0.0354 - loss: 0.4707 - val_Domain_accuracy: 0.0646 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7810 - val_Label_loss: 1.8774 - val_loss: 1.9012\n",
      "Epoch 56/80\n",
      "243/243 - 10s - 42ms/step - Domain_accuracy: 0.8417 - Domain_loss: 0.4636 - Label_accuracy: 0.9858 - Label_loss: 0.0445 - loss: 0.5080 - val_Domain_accuracy: 0.1468 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7759 - val_Label_loss: 1.9075 - val_loss: 1.9317\n",
      "Epoch 57/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8779 - Domain_loss: 0.3499 - Label_accuracy: 0.9899 - Label_loss: 0.0316 - loss: 0.3812 - val_Domain_accuracy: 0.0835 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7823 - val_Label_loss: 1.8154 - val_loss: 1.8384\n",
      "Epoch 58/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8823 - Domain_loss: 0.3417 - Label_accuracy: 0.9919 - Label_loss: 0.0246 - loss: 0.3663 - val_Domain_accuracy: 0.1101 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7658 - val_Label_loss: 2.0552 - val_loss: 2.0812\n",
      "Epoch 59/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8629 - Domain_loss: 0.3968 - Label_accuracy: 0.9902 - Label_loss: 0.0270 - loss: 0.4238 - val_Domain_accuracy: 0.0608 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7911 - val_Label_loss: 1.9406 - val_loss: 1.9652\n",
      "Epoch 60/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8448 - Domain_loss: 0.4622 - Label_accuracy: 0.9860 - Label_loss: 0.0380 - loss: 0.5006 - val_Domain_accuracy: 0.0899 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7722 - val_Label_loss: 2.2303 - val_loss: 2.2586\n",
      "Epoch 61/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8653 - Domain_loss: 0.4147 - Label_accuracy: 0.9883 - Label_loss: 0.0374 - loss: 0.4526 - val_Domain_accuracy: 0.1177 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8038 - val_Label_loss: 1.9459 - val_loss: 1.9706\n",
      "Epoch 62/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8776 - Domain_loss: 0.3622 - Label_accuracy: 0.9928 - Label_loss: 0.0213 - loss: 0.3835 - val_Domain_accuracy: 0.1443 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7810 - val_Label_loss: 2.3017 - val_loss: 2.3308\n",
      "Epoch 63/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8648 - Domain_loss: 0.3974 - Label_accuracy: 0.9896 - Label_loss: 0.0331 - loss: 0.4299 - val_Domain_accuracy: 0.1354 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7823 - val_Label_loss: 1.8744 - val_loss: 1.8981\n",
      "Epoch 64/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8529 - Domain_loss: 0.4280 - Label_accuracy: 0.9881 - Label_loss: 0.0343 - loss: 0.4630 - val_Domain_accuracy: 0.0962 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7886 - val_Label_loss: 1.8053 - val_loss: 1.8281\n",
      "Epoch 65/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8580 - Domain_loss: 0.4253 - Label_accuracy: 0.9899 - Label_loss: 0.0261 - loss: 0.4513 - val_Domain_accuracy: 0.1506 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7797 - val_Label_loss: 2.1788 - val_loss: 2.2063\n",
      "Epoch 66/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8482 - Domain_loss: 0.4413 - Label_accuracy: 0.9867 - Label_loss: 0.0452 - loss: 0.4861 - val_Domain_accuracy: 0.0949 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7848 - val_Label_loss: 1.7739 - val_loss: 1.7964\n",
      "Epoch 67/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8697 - Domain_loss: 0.3788 - Label_accuracy: 0.9875 - Label_loss: 0.0352 - loss: 0.4145 - val_Domain_accuracy: 0.1342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7924 - val_Label_loss: 1.8040 - val_loss: 1.8269\n",
      "Epoch 68/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8558 - Domain_loss: 0.4206 - Label_accuracy: 0.9910 - Label_loss: 0.0266 - loss: 0.4475 - val_Domain_accuracy: 0.1089 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7962 - val_Label_loss: 1.9099 - val_loss: 1.9341\n",
      "Epoch 69/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8618 - Domain_loss: 0.3886 - Label_accuracy: 0.9932 - Label_loss: 0.0195 - loss: 0.4079 - val_Domain_accuracy: 0.1772 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7747 - val_Label_loss: 2.3695 - val_loss: 2.3995\n",
      "Epoch 70/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8611 - Domain_loss: 0.3990 - Label_accuracy: 0.9880 - Label_loss: 0.0316 - loss: 0.4312 - val_Domain_accuracy: 0.1671 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7924 - val_Label_loss: 2.2106 - val_loss: 2.2385\n",
      "Epoch 71/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8438 - Domain_loss: 0.4500 - Label_accuracy: 0.9883 - Label_loss: 0.0373 - loss: 0.4867 - val_Domain_accuracy: 0.1911 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7620 - val_Label_loss: 2.6607 - val_loss: 2.6944\n",
      "Epoch 72/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8435 - Domain_loss: 0.4592 - Label_accuracy: 0.9878 - Label_loss: 0.0334 - loss: 0.4927 - val_Domain_accuracy: 0.0924 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7342 - val_Label_loss: 2.8039 - val_loss: 2.8394\n",
      "Epoch 73/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8651 - Domain_loss: 0.3882 - Label_accuracy: 0.9902 - Label_loss: 0.0284 - loss: 0.4171 - val_Domain_accuracy: 0.1063 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8025 - val_Label_loss: 1.9500 - val_loss: 1.9747\n",
      "Epoch 74/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8693 - Domain_loss: 0.3797 - Label_accuracy: 0.9885 - Label_loss: 0.0370 - loss: 0.4175 - val_Domain_accuracy: 0.1291 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7759 - val_Label_loss: 2.6415 - val_loss: 2.6750\n",
      "Epoch 75/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8697 - Domain_loss: 0.3815 - Label_accuracy: 0.9869 - Label_loss: 0.0365 - loss: 0.4177 - val_Domain_accuracy: 0.1038 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7975 - val_Label_loss: 2.0182 - val_loss: 2.0438\n",
      "Epoch 76/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8706 - Domain_loss: 0.3812 - Label_accuracy: 0.9908 - Label_loss: 0.0305 - loss: 0.4093 - val_Domain_accuracy: 0.0899 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8152 - val_Label_loss: 1.8793 - val_loss: 1.9030\n",
      "Epoch 77/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8554 - Domain_loss: 0.4170 - Label_accuracy: 0.9852 - Label_loss: 0.0447 - loss: 0.4621 - val_Domain_accuracy: 0.2380 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7696 - val_Label_loss: 2.1826 - val_loss: 2.2102\n",
      "Epoch 78/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8767 - Domain_loss: 0.3622 - Label_accuracy: 0.9903 - Label_loss: 0.0263 - loss: 0.3881 - val_Domain_accuracy: 0.0684 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7722 - val_Label_loss: 2.3293 - val_loss: 2.3588\n",
      "Epoch 79/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8700 - Domain_loss: 0.3798 - Label_accuracy: 0.9925 - Label_loss: 0.0238 - loss: 0.4040 - val_Domain_accuracy: 0.1620 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7582 - val_Label_loss: 2.7127 - val_loss: 2.7470\n",
      "Epoch 80/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8759 - Domain_loss: 0.3572 - Label_accuracy: 0.9927 - Label_loss: 0.0211 - loss: 0.3789 - val_Domain_accuracy: 0.2025 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7646 - val_Label_loss: 2.4603 - val_loss: 2.4915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 3\n",
      "train_feature shape: (7789, 5, 10, 256)\n",
      "train_targets shape: (7789, 5)\n",
      "train_domin shape: (7789, 9)\n",
      "Epoch 1/80\n",
      "244/244 - 17s - 70ms/step - Domain_accuracy: 0.4911 - Domain_loss: 1.5657 - Label_accuracy: 0.7719 - Label_loss: 0.6783 - loss: 2.2462 - val_Domain_accuracy: 0.0276 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7066 - val_Label_loss: 0.7940 - val_loss: 0.8018\n",
      "Epoch 2/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.6613 - Domain_loss: 1.0118 - Label_accuracy: 0.8697 - Label_loss: 0.3504 - loss: 1.3640 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7421 - val_Label_loss: 0.7933 - val_loss: 0.8008\n",
      "Epoch 3/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7142 - Domain_loss: 0.8555 - Label_accuracy: 0.8820 - Label_loss: 0.3102 - loss: 1.1670 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6895 - val_Label_loss: 1.1668 - val_loss: 1.1788\n",
      "Epoch 4/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7539 - Domain_loss: 0.7410 - Label_accuracy: 0.9054 - Label_loss: 0.2488 - loss: 0.9913 - val_Domain_accuracy: 0.0539 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7447 - val_Label_loss: 1.0914 - val_loss: 1.1023\n",
      "Epoch 5/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7817 - Domain_loss: 0.6435 - Label_accuracy: 0.9133 - Label_loss: 0.2368 - loss: 0.8819 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7237 - val_Label_loss: 1.0561 - val_loss: 1.0664\n",
      "Epoch 6/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8037 - Domain_loss: 0.6065 - Label_accuracy: 0.9133 - Label_loss: 0.2225 - loss: 0.8288 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7092 - val_Label_loss: 1.0919 - val_loss: 1.1027\n",
      "Epoch 7/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8222 - Domain_loss: 0.5471 - Label_accuracy: 0.9275 - Label_loss: 0.1886 - loss: 0.7361 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7184 - val_Label_loss: 1.1027 - val_loss: 1.1139\n",
      "Epoch 8/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8153 - Domain_loss: 0.5561 - Label_accuracy: 0.9287 - Label_loss: 0.1826 - loss: 0.7378 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7724 - val_Label_loss: 0.7877 - val_loss: 0.7958\n",
      "Epoch 9/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8358 - Domain_loss: 0.4761 - Label_accuracy: 0.9381 - Label_loss: 0.1622 - loss: 0.6386 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7382 - val_Label_loss: 1.1242 - val_loss: 1.1353\n",
      "Epoch 10/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8258 - Domain_loss: 0.5491 - Label_accuracy: 0.9327 - Label_loss: 0.1721 - loss: 0.7222 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6816 - val_Label_loss: 1.5797 - val_loss: 1.5944\n",
      "Epoch 11/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8295 - Domain_loss: 0.5080 - Label_accuracy: 0.9424 - Label_loss: 0.1626 - loss: 0.6698 - val_Domain_accuracy: 0.0382 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7500 - val_Label_loss: 1.0510 - val_loss: 1.0612\n",
      "Epoch 12/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8688 - Domain_loss: 0.3917 - Label_accuracy: 0.9449 - Label_loss: 0.1440 - loss: 0.5355 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7526 - val_Label_loss: 1.0680 - val_loss: 1.0791\n",
      "Epoch 13/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8461 - Domain_loss: 0.4625 - Label_accuracy: 0.9440 - Label_loss: 0.1427 - loss: 0.6052 - val_Domain_accuracy: 0.0658 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7197 - val_Label_loss: 1.1941 - val_loss: 1.2063\n",
      "Epoch 14/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8669 - Domain_loss: 0.3926 - Label_accuracy: 0.9516 - Label_loss: 0.1301 - loss: 0.5213 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7447 - val_Label_loss: 1.1479 - val_loss: 1.1598\n",
      "Epoch 15/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8660 - Domain_loss: 0.3974 - Label_accuracy: 0.9529 - Label_loss: 0.1309 - loss: 0.5288 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7092 - val_Label_loss: 1.4260 - val_loss: 1.4408\n",
      "Epoch 16/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8773 - Domain_loss: 0.3671 - Label_accuracy: 0.9567 - Label_loss: 0.1149 - loss: 0.4825 - val_Domain_accuracy: 0.0224 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7421 - val_Label_loss: 1.3559 - val_loss: 1.3700\n",
      "Epoch 17/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8726 - Domain_loss: 0.3641 - Label_accuracy: 0.9516 - Label_loss: 0.1301 - loss: 0.4941 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7421 - val_Label_loss: 1.2714 - val_loss: 1.2848\n",
      "Epoch 18/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8750 - Domain_loss: 0.3674 - Label_accuracy: 0.9533 - Label_loss: 0.1202 - loss: 0.4881 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7184 - val_Label_loss: 1.5008 - val_loss: 1.5165\n",
      "Epoch 19/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8791 - Domain_loss: 0.3565 - Label_accuracy: 0.9578 - Label_loss: 0.1137 - loss: 0.4706 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7145 - val_Label_loss: 1.5958 - val_loss: 1.6119\n",
      "Epoch 20/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8588 - Domain_loss: 0.4233 - Label_accuracy: 0.9557 - Label_loss: 0.1130 - loss: 0.5365 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7079 - val_Label_loss: 1.4010 - val_loss: 1.4128\n",
      "Epoch 21/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8714 - Domain_loss: 0.3648 - Label_accuracy: 0.9580 - Label_loss: 0.1119 - loss: 0.4771 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7408 - val_Label_loss: 1.3102 - val_loss: 1.3240\n",
      "Epoch 22/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8841 - Domain_loss: 0.3494 - Label_accuracy: 0.9626 - Label_loss: 0.0986 - loss: 0.4482 - val_Domain_accuracy: 0.0211 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7658 - val_Label_loss: 1.1413 - val_loss: 1.1530\n",
      "Epoch 23/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8847 - Domain_loss: 0.3369 - Label_accuracy: 0.9635 - Label_loss: 0.0948 - loss: 0.4310 - val_Domain_accuracy: 0.0408 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7368 - val_Label_loss: 1.3521 - val_loss: 1.3663\n",
      "Epoch 24/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8936 - Domain_loss: 0.3130 - Label_accuracy: 0.9612 - Label_loss: 0.1001 - loss: 0.4134 - val_Domain_accuracy: 0.0039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7513 - val_Label_loss: 1.4147 - val_loss: 1.4286\n",
      "Epoch 25/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8759 - Domain_loss: 0.3597 - Label_accuracy: 0.9642 - Label_loss: 0.0938 - loss: 0.4537 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7237 - val_Label_loss: 1.5252 - val_loss: 1.5412\n",
      "Epoch 26/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8807 - Domain_loss: 0.3491 - Label_accuracy: 0.9638 - Label_loss: 0.0997 - loss: 0.4494 - val_Domain_accuracy: 0.0316 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7408 - val_Label_loss: 1.4794 - val_loss: 1.4948\n",
      "Epoch 27/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8775 - Domain_loss: 0.3528 - Label_accuracy: 0.9662 - Label_loss: 0.0913 - loss: 0.4443 - val_Domain_accuracy: 0.0211 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7461 - val_Label_loss: 1.3826 - val_loss: 1.3967\n",
      "Epoch 28/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8788 - Domain_loss: 0.3540 - Label_accuracy: 0.9685 - Label_loss: 0.0867 - loss: 0.4406 - val_Domain_accuracy: 0.0474 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 1.4351 - val_loss: 1.4493\n",
      "Epoch 29/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8755 - Domain_loss: 0.3580 - Label_accuracy: 0.9707 - Label_loss: 0.0780 - loss: 0.4364 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7618 - val_Label_loss: 1.5281 - val_loss: 1.5437\n",
      "Epoch 30/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8806 - Domain_loss: 0.3574 - Label_accuracy: 0.9688 - Label_loss: 0.0840 - loss: 0.4418 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7355 - val_Label_loss: 1.4093 - val_loss: 1.4231\n",
      "Epoch 31/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8746 - Domain_loss: 0.3645 - Label_accuracy: 0.9647 - Label_loss: 0.0925 - loss: 0.4569 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7500 - val_Label_loss: 1.4363 - val_loss: 1.4512\n",
      "Epoch 32/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8812 - Domain_loss: 0.3412 - Label_accuracy: 0.9703 - Label_loss: 0.0798 - loss: 0.4213 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7211 - val_Label_loss: 1.6251 - val_loss: 1.6419\n",
      "Epoch 33/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8820 - Domain_loss: 0.3518 - Label_accuracy: 0.9706 - Label_loss: 0.0773 - loss: 0.4286 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 1.5782 - val_loss: 1.5943\n",
      "Epoch 34/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8716 - Domain_loss: 0.3839 - Label_accuracy: 0.9684 - Label_loss: 0.0850 - loss: 0.4691 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7211 - val_Label_loss: 1.7691 - val_loss: 1.7876\n",
      "Epoch 35/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8895 - Domain_loss: 0.3161 - Label_accuracy: 0.9720 - Label_loss: 0.0759 - loss: 0.3920 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7434 - val_Label_loss: 1.5436 - val_loss: 1.5594\n",
      "Epoch 36/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8907 - Domain_loss: 0.3133 - Label_accuracy: 0.9702 - Label_loss: 0.0779 - loss: 0.3911 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7026 - val_Label_loss: 1.5762 - val_loss: 1.5927\n",
      "Epoch 37/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8910 - Domain_loss: 0.3083 - Label_accuracy: 0.9780 - Label_loss: 0.0576 - loss: 0.3662 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7263 - val_Label_loss: 1.7503 - val_loss: 1.7687\n",
      "Epoch 38/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8906 - Domain_loss: 0.3250 - Label_accuracy: 0.9747 - Label_loss: 0.0660 - loss: 0.3910 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7395 - val_Label_loss: 1.6684 - val_loss: 1.6857\n",
      "Epoch 39/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8950 - Domain_loss: 0.3005 - Label_accuracy: 0.9696 - Label_loss: 0.0753 - loss: 0.3757 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7250 - val_Label_loss: 1.8191 - val_loss: 1.8378\n",
      "Epoch 40/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8963 - Domain_loss: 0.2864 - Label_accuracy: 0.9788 - Label_loss: 0.0609 - loss: 0.3468 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7132 - val_Label_loss: 1.9988 - val_loss: 2.0167\n",
      "Epoch 41/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8873 - Domain_loss: 0.3261 - Label_accuracy: 0.9694 - Label_loss: 0.0873 - loss: 0.4139 - val_Domain_accuracy: 0.0224 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7368 - val_Label_loss: 1.6633 - val_loss: 1.6768\n",
      "Epoch 42/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.9108 - Domain_loss: 0.2585 - Label_accuracy: 0.9801 - Label_loss: 0.0545 - loss: 0.3121 - val_Domain_accuracy: 0.0276 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7211 - val_Label_loss: 1.8269 - val_loss: 1.8448\n",
      "Epoch 43/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.9000 - Domain_loss: 0.2868 - Label_accuracy: 0.9814 - Label_loss: 0.0515 - loss: 0.3387 - val_Domain_accuracy: 0.0355 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7329 - val_Label_loss: 1.9616 - val_loss: 1.9793\n",
      "Epoch 44/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8963 - Domain_loss: 0.3068 - Label_accuracy: 0.9777 - Label_loss: 0.0599 - loss: 0.3663 - val_Domain_accuracy: 0.0211 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7026 - val_Label_loss: 1.8517 - val_loss: 1.8711\n",
      "Epoch 45/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8959 - Domain_loss: 0.3054 - Label_accuracy: 0.9800 - Label_loss: 0.0521 - loss: 0.3558 - val_Domain_accuracy: 0.0276 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7618 - val_Label_loss: 1.6536 - val_loss: 1.6709\n",
      "Epoch 46/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8933 - Domain_loss: 0.3095 - Label_accuracy: 0.9778 - Label_loss: 0.0703 - loss: 0.3802 - val_Domain_accuracy: 0.0368 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7408 - val_Label_loss: 1.6331 - val_loss: 1.6499\n",
      "Epoch 47/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8982 - Domain_loss: 0.2956 - Label_accuracy: 0.9761 - Label_loss: 0.0633 - loss: 0.3589 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7368 - val_Label_loss: 1.7062 - val_loss: 1.7241\n",
      "Epoch 48/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8946 - Domain_loss: 0.3074 - Label_accuracy: 0.9791 - Label_loss: 0.0581 - loss: 0.3646 - val_Domain_accuracy: 0.0487 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7237 - val_Label_loss: 1.9316 - val_loss: 1.9508\n",
      "Epoch 49/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8936 - Domain_loss: 0.3050 - Label_accuracy: 0.9805 - Label_loss: 0.0545 - loss: 0.3571 - val_Domain_accuracy: 0.0250 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7026 - val_Label_loss: 1.9282 - val_loss: 1.9453\n",
      "Epoch 50/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8901 - Domain_loss: 0.3078 - Label_accuracy: 0.9768 - Label_loss: 0.0638 - loss: 0.3715 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7368 - val_Label_loss: 1.8115 - val_loss: 1.8305\n",
      "Epoch 51/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.9019 - Domain_loss: 0.2815 - Label_accuracy: 0.9814 - Label_loss: 0.0523 - loss: 0.3331 - val_Domain_accuracy: 0.0263 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6961 - val_Label_loss: 2.1765 - val_loss: 2.1993\n",
      "Epoch 52/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8901 - Domain_loss: 0.3125 - Label_accuracy: 0.9771 - Label_loss: 0.0681 - loss: 0.3807 - val_Domain_accuracy: 0.0105 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 1.5339 - val_loss: 1.5499\n",
      "Epoch 53/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8988 - Domain_loss: 0.2887 - Label_accuracy: 0.9852 - Label_loss: 0.0416 - loss: 0.3306 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7553 - val_Label_loss: 1.8098 - val_loss: 1.8281\n",
      "Epoch 54/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8993 - Domain_loss: 0.2861 - Label_accuracy: 0.9845 - Label_loss: 0.0487 - loss: 0.3348 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7382 - val_Label_loss: 1.8158 - val_loss: 1.8349\n",
      "Epoch 55/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.9058 - Domain_loss: 0.2789 - Label_accuracy: 0.9802 - Label_loss: 0.0535 - loss: 0.3320 - val_Domain_accuracy: 0.0382 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7513 - val_Label_loss: 1.6000 - val_loss: 1.6167\n",
      "Epoch 56/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8873 - Domain_loss: 0.3293 - Label_accuracy: 0.9816 - Label_loss: 0.0506 - loss: 0.3796 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7697 - val_Label_loss: 1.6898 - val_loss: 1.7062\n",
      "Epoch 57/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.9011 - Domain_loss: 0.2912 - Label_accuracy: 0.9815 - Label_loss: 0.0544 - loss: 0.3448 - val_Domain_accuracy: 0.0263 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7763 - val_Label_loss: 1.5230 - val_loss: 1.5386\n",
      "Epoch 58/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.9027 - Domain_loss: 0.2823 - Label_accuracy: 0.9775 - Label_loss: 0.0626 - loss: 0.3452 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7395 - val_Label_loss: 1.7363 - val_loss: 1.7545\n",
      "Epoch 59/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.9011 - Domain_loss: 0.2794 - Label_accuracy: 0.9829 - Label_loss: 0.0487 - loss: 0.3280 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7658 - val_Label_loss: 1.4072 - val_loss: 1.4210\n",
      "Epoch 60/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.9023 - Domain_loss: 0.2803 - Label_accuracy: 0.9822 - Label_loss: 0.0510 - loss: 0.3317 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7500 - val_Label_loss: 1.7079 - val_loss: 1.7256\n",
      "Epoch 61/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.9060 - Domain_loss: 0.2651 - Label_accuracy: 0.9869 - Label_loss: 0.0381 - loss: 0.3029 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7566 - val_Label_loss: 1.8038 - val_loss: 1.8227\n",
      "Epoch 62/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8961 - Domain_loss: 0.2939 - Label_accuracy: 0.9825 - Label_loss: 0.0471 - loss: 0.3408 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7671 - val_Label_loss: 1.8174 - val_loss: 1.8363\n",
      "Epoch 63/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8879 - Domain_loss: 0.3242 - Label_accuracy: 0.9778 - Label_loss: 0.0611 - loss: 0.3849 - val_Domain_accuracy: 0.0145 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7237 - val_Label_loss: 1.8243 - val_loss: 1.8379\n",
      "Epoch 64/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8870 - Domain_loss: 0.3197 - Label_accuracy: 0.9806 - Label_loss: 0.0571 - loss: 0.3772 - val_Domain_accuracy: 0.0145 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7184 - val_Label_loss: 2.1136 - val_loss: 2.1358\n",
      "Epoch 65/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8952 - Domain_loss: 0.2928 - Label_accuracy: 0.9838 - Label_loss: 0.0455 - loss: 0.3383 - val_Domain_accuracy: 0.0105 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7592 - val_Label_loss: 1.8154 - val_loss: 1.8338\n",
      "Epoch 66/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.9101 - Domain_loss: 0.2630 - Label_accuracy: 0.9841 - Label_loss: 0.0466 - loss: 0.3085 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7842 - val_Label_loss: 1.5630 - val_loss: 1.5789\n",
      "Epoch 67/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.9013 - Domain_loss: 0.2912 - Label_accuracy: 0.9851 - Label_loss: 0.0441 - loss: 0.3356 - val_Domain_accuracy: 0.0908 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7132 - val_Label_loss: 2.3630 - val_loss: 2.3878\n",
      "Epoch 68/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.9059 - Domain_loss: 0.2691 - Label_accuracy: 0.9847 - Label_loss: 0.0443 - loss: 0.3138 - val_Domain_accuracy: 0.0368 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7461 - val_Label_loss: 1.9574 - val_loss: 1.9779\n",
      "Epoch 69/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8945 - Domain_loss: 0.3048 - Label_accuracy: 0.9845 - Label_loss: 0.0418 - loss: 0.3460 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6789 - val_Label_loss: 2.7096 - val_loss: 2.7380\n",
      "Epoch 70/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8914 - Domain_loss: 0.3207 - Label_accuracy: 0.9831 - Label_loss: 0.0540 - loss: 0.3756 - val_Domain_accuracy: 0.0421 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7342 - val_Label_loss: 2.0336 - val_loss: 2.0513\n",
      "Epoch 71/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8943 - Domain_loss: 0.3051 - Label_accuracy: 0.9846 - Label_loss: 0.0412 - loss: 0.3465 - val_Domain_accuracy: 0.0434 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7276 - val_Label_loss: 2.0654 - val_loss: 2.0861\n",
      "Epoch 72/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8954 - Domain_loss: 0.3039 - Label_accuracy: 0.9840 - Label_loss: 0.0473 - loss: 0.3512 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7500 - val_Label_loss: 2.0550 - val_loss: 2.0739\n",
      "Epoch 73/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8874 - Domain_loss: 0.3202 - Label_accuracy: 0.9846 - Label_loss: 0.0444 - loss: 0.3652 - val_Domain_accuracy: 0.0237 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7645 - val_Label_loss: 1.7385 - val_loss: 1.7547\n",
      "Epoch 74/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8895 - Domain_loss: 0.3257 - Label_accuracy: 0.9833 - Label_loss: 0.0448 - loss: 0.3711 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7329 - val_Label_loss: 2.1991 - val_loss: 2.2222\n",
      "Epoch 75/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8946 - Domain_loss: 0.3040 - Label_accuracy: 0.9852 - Label_loss: 0.0425 - loss: 0.3463 - val_Domain_accuracy: 0.0342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7224 - val_Label_loss: 2.1959 - val_loss: 2.2182\n",
      "Epoch 76/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.8874 - Domain_loss: 0.3331 - Label_accuracy: 0.9843 - Label_loss: 0.0462 - loss: 0.3795 - val_Domain_accuracy: 0.0211 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7421 - val_Label_loss: 1.8377 - val_loss: 1.8561\n",
      "Epoch 77/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.8836 - Domain_loss: 0.3447 - Label_accuracy: 0.9837 - Label_loss: 0.0459 - loss: 0.3911 - val_Domain_accuracy: 0.0145 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7526 - val_Label_loss: 2.3627 - val_loss: 2.3875\n",
      "Epoch 78/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.8970 - Domain_loss: 0.2909 - Label_accuracy: 0.9869 - Label_loss: 0.0372 - loss: 0.3288 - val_Domain_accuracy: 0.0382 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7566 - val_Label_loss: 2.0527 - val_loss: 2.0742\n",
      "Epoch 79/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8959 - Domain_loss: 0.2881 - Label_accuracy: 0.9900 - Label_loss: 0.0313 - loss: 0.3193 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 2.2061 - val_loss: 2.2284\n",
      "Epoch 80/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8873 - Domain_loss: 0.3265 - Label_accuracy: 0.9828 - Label_loss: 0.0536 - loss: 0.3797 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7382 - val_Label_loss: 2.3017 - val_loss: 2.3253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 4\n",
      "train_feature shape: (7639, 5, 10, 256)\n",
      "train_targets shape: (7639, 5)\n",
      "train_domin shape: (7639, 9)\n",
      "Epoch 1/80\n",
      "239/239 - 17s - 71ms/step - Domain_accuracy: 0.5179 - Domain_loss: 1.4990 - Label_accuracy: 0.7819 - Label_loss: 0.6721 - loss: 2.1718 - val_Domain_accuracy: 0.1835 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7901 - val_Label_loss: 0.6372 - val_loss: 0.6360\n",
      "Epoch 2/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.6509 - Domain_loss: 1.0469 - Label_accuracy: 0.8697 - Label_loss: 0.3410 - loss: 1.3883 - val_Domain_accuracy: 0.2648 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7670 - val_Label_loss: 0.8600 - val_loss: 0.8611\n",
      "Epoch 3/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.7111 - Domain_loss: 0.8619 - Label_accuracy: 0.9005 - Label_loss: 0.2650 - loss: 1.1273 - val_Domain_accuracy: 0.3220 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8033 - val_Label_loss: 0.9032 - val_loss: 0.9059\n",
      "Epoch 4/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.7497 - Domain_loss: 0.7351 - Label_accuracy: 0.9084 - Label_loss: 0.2435 - loss: 0.9786 - val_Domain_accuracy: 0.0868 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8044 - val_Label_loss: 0.7371 - val_loss: 0.7363\n",
      "Epoch 5/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.7600 - Domain_loss: 0.7225 - Label_accuracy: 0.9229 - Label_loss: 0.1996 - loss: 0.9217 - val_Domain_accuracy: 0.0681 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8198 - val_Label_loss: 0.7744 - val_loss: 0.7785\n",
      "Epoch 6/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.7737 - Domain_loss: 0.6677 - Label_accuracy: 0.9311 - Label_loss: 0.1833 - loss: 0.8511 - val_Domain_accuracy: 0.0780 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8297 - val_Label_loss: 0.7217 - val_loss: 0.7246\n",
      "Epoch 7/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.7957 - Domain_loss: 0.5728 - Label_accuracy: 0.9331 - Label_loss: 0.1742 - loss: 0.7473 - val_Domain_accuracy: 0.1824 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7945 - val_Label_loss: 0.7545 - val_loss: 0.7567\n",
      "Epoch 8/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8114 - Domain_loss: 0.5386 - Label_accuracy: 0.9395 - Label_loss: 0.1632 - loss: 0.7021 - val_Domain_accuracy: 0.1516 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7813 - val_Label_loss: 1.0971 - val_loss: 1.0965\n",
      "Epoch 9/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8090 - Domain_loss: 0.5619 - Label_accuracy: 0.9410 - Label_loss: 0.1541 - loss: 0.7162 - val_Domain_accuracy: 0.2044 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 1.1398 - val_loss: 1.1473\n",
      "Epoch 10/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8243 - Domain_loss: 0.4962 - Label_accuracy: 0.9425 - Label_loss: 0.1470 - loss: 0.6436 - val_Domain_accuracy: 0.2022 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7923 - val_Label_loss: 0.9805 - val_loss: 0.9772\n",
      "Epoch 11/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8451 - Domain_loss: 0.4349 - Label_accuracy: 0.9497 - Label_loss: 0.1254 - loss: 0.5598 - val_Domain_accuracy: 0.1659 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7824 - val_Label_loss: 0.9978 - val_loss: 0.9979\n",
      "Epoch 12/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8497 - Domain_loss: 0.4167 - Label_accuracy: 0.9582 - Label_loss: 0.1121 - loss: 0.5293 - val_Domain_accuracy: 0.1022 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 0.9687 - val_loss: 0.9702\n",
      "Epoch 13/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8412 - Domain_loss: 0.4545 - Label_accuracy: 0.9607 - Label_loss: 0.1093 - loss: 0.5635 - val_Domain_accuracy: 0.1011 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7923 - val_Label_loss: 1.0935 - val_loss: 1.1006\n",
      "Epoch 14/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8424 - Domain_loss: 0.4419 - Label_accuracy: 0.9626 - Label_loss: 0.1006 - loss: 0.5427 - val_Domain_accuracy: 0.1582 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7736 - val_Label_loss: 1.0910 - val_loss: 1.0822\n",
      "Epoch 15/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8237 - Domain_loss: 0.5256 - Label_accuracy: 0.9603 - Label_loss: 0.1108 - loss: 0.6365 - val_Domain_accuracy: 0.1538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7813 - val_Label_loss: 1.2168 - val_loss: 1.2242\n",
      "Epoch 16/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8419 - Domain_loss: 0.4340 - Label_accuracy: 0.9631 - Label_loss: 0.0994 - loss: 0.5334 - val_Domain_accuracy: 0.1396 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7879 - val_Label_loss: 1.2798 - val_loss: 1.2926\n",
      "Epoch 17/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8581 - Domain_loss: 0.3896 - Label_accuracy: 0.9670 - Label_loss: 0.0912 - loss: 0.4806 - val_Domain_accuracy: 0.2055 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 1.1401 - val_loss: 1.1374\n",
      "Epoch 18/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8570 - Domain_loss: 0.4033 - Label_accuracy: 0.9673 - Label_loss: 0.0875 - loss: 0.4908 - val_Domain_accuracy: 0.2374 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7901 - val_Label_loss: 1.1319 - val_loss: 1.1312\n",
      "Epoch 19/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8742 - Domain_loss: 0.3606 - Label_accuracy: 0.9671 - Label_loss: 0.0902 - loss: 0.4508 - val_Domain_accuracy: 0.2198 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7407 - val_Label_loss: 1.7275 - val_loss: 1.7225\n",
      "Epoch 20/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8611 - Domain_loss: 0.3845 - Label_accuracy: 0.9694 - Label_loss: 0.0811 - loss: 0.4653 - val_Domain_accuracy: 0.1967 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 1.0808 - val_loss: 1.0848\n",
      "Epoch 21/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8572 - Domain_loss: 0.4104 - Label_accuracy: 0.9715 - Label_loss: 0.0743 - loss: 0.4848 - val_Domain_accuracy: 0.2330 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7868 - val_Label_loss: 1.3154 - val_loss: 1.3251\n",
      "Epoch 22/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8729 - Domain_loss: 0.3589 - Label_accuracy: 0.9724 - Label_loss: 0.0765 - loss: 0.4349 - val_Domain_accuracy: 0.2044 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7604 - val_Label_loss: 1.5119 - val_loss: 1.5207\n",
      "Epoch 23/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8661 - Domain_loss: 0.3852 - Label_accuracy: 0.9724 - Label_loss: 0.0762 - loss: 0.4617 - val_Domain_accuracy: 0.1769 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 1.1786 - val_loss: 1.1820\n",
      "Epoch 24/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8678 - Domain_loss: 0.3879 - Label_accuracy: 0.9747 - Label_loss: 0.0675 - loss: 0.4549 - val_Domain_accuracy: 0.2099 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7714 - val_Label_loss: 1.6878 - val_loss: 1.6935\n",
      "Epoch 25/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8628 - Domain_loss: 0.4026 - Label_accuracy: 0.9696 - Label_loss: 0.0802 - loss: 0.4827 - val_Domain_accuracy: 0.1330 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8198 - val_Label_loss: 0.9866 - val_loss: 0.9905\n",
      "Epoch 26/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8650 - Domain_loss: 0.3769 - Label_accuracy: 0.9753 - Label_loss: 0.0640 - loss: 0.4410 - val_Domain_accuracy: 0.1560 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7527 - val_Label_loss: 1.6951 - val_loss: 1.6933\n",
      "Epoch 27/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8512 - Domain_loss: 0.4098 - Label_accuracy: 0.9764 - Label_loss: 0.0660 - loss: 0.4760 - val_Domain_accuracy: 0.1484 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7538 - val_Label_loss: 1.5147 - val_loss: 1.4996\n",
      "Epoch 28/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8686 - Domain_loss: 0.3848 - Label_accuracy: 0.9711 - Label_loss: 0.0745 - loss: 0.4595 - val_Domain_accuracy: 0.1066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7681 - val_Label_loss: 1.2198 - val_loss: 1.1979\n",
      "Epoch 29/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8578 - Domain_loss: 0.4089 - Label_accuracy: 0.9777 - Label_loss: 0.0598 - loss: 0.4685 - val_Domain_accuracy: 0.2055 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7692 - val_Label_loss: 1.5581 - val_loss: 1.5598\n",
      "Epoch 30/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8669 - Domain_loss: 0.3732 - Label_accuracy: 0.9801 - Label_loss: 0.0555 - loss: 0.4285 - val_Domain_accuracy: 0.1549 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 1.0219 - val_loss: 1.0176\n",
      "Epoch 31/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8590 - Domain_loss: 0.3953 - Label_accuracy: 0.9804 - Label_loss: 0.0538 - loss: 0.4491 - val_Domain_accuracy: 0.1626 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7824 - val_Label_loss: 1.2384 - val_loss: 1.2432\n",
      "Epoch 32/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8708 - Domain_loss: 0.3719 - Label_accuracy: 0.9791 - Label_loss: 0.0595 - loss: 0.4317 - val_Domain_accuracy: 0.3352 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 1.3747 - val_loss: 1.3828\n",
      "Epoch 33/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8707 - Domain_loss: 0.3695 - Label_accuracy: 0.9813 - Label_loss: 0.0525 - loss: 0.4222 - val_Domain_accuracy: 0.1956 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7758 - val_Label_loss: 1.4413 - val_loss: 1.4401\n",
      "Epoch 34/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8775 - Domain_loss: 0.3476 - Label_accuracy: 0.9822 - Label_loss: 0.0506 - loss: 0.3981 - val_Domain_accuracy: 0.1604 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7813 - val_Label_loss: 1.6905 - val_loss: 1.6933\n",
      "Epoch 35/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8623 - Domain_loss: 0.3871 - Label_accuracy: 0.9789 - Label_loss: 0.0574 - loss: 0.4447 - val_Domain_accuracy: 0.1385 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 1.2213 - val_loss: 1.2120\n",
      "Epoch 36/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8652 - Domain_loss: 0.3831 - Label_accuracy: 0.9823 - Label_loss: 0.0518 - loss: 0.4353 - val_Domain_accuracy: 0.1912 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7824 - val_Label_loss: 1.6125 - val_loss: 1.6136\n",
      "Epoch 37/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8679 - Domain_loss: 0.3805 - Label_accuracy: 0.9825 - Label_loss: 0.0470 - loss: 0.4278 - val_Domain_accuracy: 0.1582 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7747 - val_Label_loss: 1.7845 - val_loss: 1.7804\n",
      "Epoch 38/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8553 - Domain_loss: 0.4039 - Label_accuracy: 0.9822 - Label_loss: 0.0521 - loss: 0.4558 - val_Domain_accuracy: 0.2231 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7868 - val_Label_loss: 1.3069 - val_loss: 1.2961\n",
      "Epoch 39/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8607 - Domain_loss: 0.3881 - Label_accuracy: 0.9829 - Label_loss: 0.0477 - loss: 0.4359 - val_Domain_accuracy: 0.1385 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.5068 - val_loss: 1.4966\n",
      "Epoch 40/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8661 - Domain_loss: 0.3776 - Label_accuracy: 0.9809 - Label_loss: 0.0542 - loss: 0.4315 - val_Domain_accuracy: 0.1121 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7308 - val_Label_loss: 1.8730 - val_loss: 1.8551\n",
      "Epoch 41/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8745 - Domain_loss: 0.3501 - Label_accuracy: 0.9818 - Label_loss: 0.0445 - loss: 0.3948 - val_Domain_accuracy: 0.1912 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7703 - val_Label_loss: 1.5209 - val_loss: 1.5140\n",
      "Epoch 42/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8734 - Domain_loss: 0.3632 - Label_accuracy: 0.9827 - Label_loss: 0.0480 - loss: 0.4111 - val_Domain_accuracy: 0.3198 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7538 - val_Label_loss: 2.1029 - val_loss: 2.1012\n",
      "Epoch 43/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8669 - Domain_loss: 0.3799 - Label_accuracy: 0.9847 - Label_loss: 0.0426 - loss: 0.4224 - val_Domain_accuracy: 0.2022 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7934 - val_Label_loss: 1.5020 - val_loss: 1.5023\n",
      "Epoch 44/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8851 - Domain_loss: 0.3234 - Label_accuracy: 0.9890 - Label_loss: 0.0338 - loss: 0.3572 - val_Domain_accuracy: 0.1714 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8022 - val_Label_loss: 1.4076 - val_loss: 1.4141\n",
      "Epoch 45/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8645 - Domain_loss: 0.3858 - Label_accuracy: 0.9840 - Label_loss: 0.0528 - loss: 0.4389 - val_Domain_accuracy: 0.1901 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7934 - val_Label_loss: 1.3420 - val_loss: 1.3343\n",
      "Epoch 46/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8735 - Domain_loss: 0.3523 - Label_accuracy: 0.9815 - Label_loss: 0.0501 - loss: 0.4024 - val_Domain_accuracy: 0.2198 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 1.1327 - val_loss: 1.1206\n",
      "Epoch 47/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8754 - Domain_loss: 0.3507 - Label_accuracy: 0.9851 - Label_loss: 0.0410 - loss: 0.3916 - val_Domain_accuracy: 0.2000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7659 - val_Label_loss: 1.6293 - val_loss: 1.6140\n",
      "Epoch 48/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8762 - Domain_loss: 0.3460 - Label_accuracy: 0.9885 - Label_loss: 0.0293 - loss: 0.3755 - val_Domain_accuracy: 0.2066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7956 - val_Label_loss: 1.4903 - val_loss: 1.4746\n",
      "Epoch 49/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8769 - Domain_loss: 0.3364 - Label_accuracy: 0.9860 - Label_loss: 0.0402 - loss: 0.3767 - val_Domain_accuracy: 0.2165 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8044 - val_Label_loss: 1.2037 - val_loss: 1.1846\n",
      "Epoch 50/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8705 - Domain_loss: 0.3542 - Label_accuracy: 0.9825 - Label_loss: 0.0481 - loss: 0.4022 - val_Domain_accuracy: 0.1495 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 1.5671 - val_loss: 1.5632\n",
      "Epoch 51/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8641 - Domain_loss: 0.3899 - Label_accuracy: 0.9868 - Label_loss: 0.0378 - loss: 0.4274 - val_Domain_accuracy: 0.3231 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7868 - val_Label_loss: 1.6008 - val_loss: 1.6036\n",
      "Epoch 52/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8686 - Domain_loss: 0.3809 - Label_accuracy: 0.9831 - Label_loss: 0.0493 - loss: 0.4305 - val_Domain_accuracy: 0.1967 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7516 - val_Label_loss: 1.8677 - val_loss: 1.8642\n",
      "Epoch 53/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8614 - Domain_loss: 0.3843 - Label_accuracy: 0.9882 - Label_loss: 0.0340 - loss: 0.4182 - val_Domain_accuracy: 0.1934 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7604 - val_Label_loss: 1.9762 - val_loss: 1.9770\n",
      "Epoch 54/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8605 - Domain_loss: 0.3960 - Label_accuracy: 0.9860 - Label_loss: 0.0436 - loss: 0.4396 - val_Domain_accuracy: 0.2143 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7725 - val_Label_loss: 1.6693 - val_loss: 1.6594\n",
      "Epoch 55/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8547 - Domain_loss: 0.4298 - Label_accuracy: 0.9857 - Label_loss: 0.0427 - loss: 0.4728 - val_Domain_accuracy: 0.1637 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8022 - val_Label_loss: 1.2239 - val_loss: 1.2063\n",
      "Epoch 56/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8754 - Domain_loss: 0.3512 - Label_accuracy: 0.9877 - Label_loss: 0.0365 - loss: 0.3878 - val_Domain_accuracy: 0.2066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 1.5091 - val_loss: 1.5060\n",
      "Epoch 57/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8882 - Domain_loss: 0.3134 - Label_accuracy: 0.9907 - Label_loss: 0.0235 - loss: 0.3368 - val_Domain_accuracy: 0.2462 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 1.3423 - val_loss: 1.3343\n",
      "Epoch 58/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8843 - Domain_loss: 0.3204 - Label_accuracy: 0.9870 - Label_loss: 0.0356 - loss: 0.3558 - val_Domain_accuracy: 0.1769 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 1.5694 - val_loss: 1.5569\n",
      "Epoch 59/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8564 - Domain_loss: 0.4223 - Label_accuracy: 0.9843 - Label_loss: 0.0424 - loss: 0.4645 - val_Domain_accuracy: 0.2132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7505 - val_Label_loss: 2.0110 - val_loss: 2.0090\n",
      "Epoch 60/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8553 - Domain_loss: 0.4053 - Label_accuracy: 0.9865 - Label_loss: 0.0433 - loss: 0.4487 - val_Domain_accuracy: 0.1363 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 1.8964 - val_loss: 1.8990\n",
      "Epoch 61/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8890 - Domain_loss: 0.3151 - Label_accuracy: 0.9886 - Label_loss: 0.0297 - loss: 0.3450 - val_Domain_accuracy: 0.1088 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.6415 - val_loss: 1.6435\n",
      "Epoch 62/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8747 - Domain_loss: 0.3516 - Label_accuracy: 0.9876 - Label_loss: 0.0389 - loss: 0.3907 - val_Domain_accuracy: 0.1440 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7868 - val_Label_loss: 1.8458 - val_loss: 1.8553\n",
      "Epoch 63/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8789 - Domain_loss: 0.3331 - Label_accuracy: 0.9880 - Label_loss: 0.0331 - loss: 0.3663 - val_Domain_accuracy: 0.1912 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8055 - val_Label_loss: 1.6468 - val_loss: 1.6476\n",
      "Epoch 64/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8806 - Domain_loss: 0.3331 - Label_accuracy: 0.9897 - Label_loss: 0.0309 - loss: 0.3641 - val_Domain_accuracy: 0.1242 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8066 - val_Label_loss: 1.5258 - val_loss: 1.5263\n",
      "Epoch 65/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8670 - Domain_loss: 0.3797 - Label_accuracy: 0.9908 - Label_loss: 0.0281 - loss: 0.4079 - val_Domain_accuracy: 0.1670 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8077 - val_Label_loss: 1.7625 - val_loss: 1.7643\n",
      "Epoch 66/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8671 - Domain_loss: 0.3870 - Label_accuracy: 0.9877 - Label_loss: 0.0382 - loss: 0.4249 - val_Domain_accuracy: 0.2692 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7747 - val_Label_loss: 2.2694 - val_loss: 2.2732\n",
      "Epoch 67/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8783 - Domain_loss: 0.3511 - Label_accuracy: 0.9881 - Label_loss: 0.0316 - loss: 0.3828 - val_Domain_accuracy: 0.1989 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7824 - val_Label_loss: 2.0970 - val_loss: 2.1090\n",
      "Epoch 68/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8766 - Domain_loss: 0.3515 - Label_accuracy: 0.9899 - Label_loss: 0.0329 - loss: 0.3841 - val_Domain_accuracy: 0.1604 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7451 - val_Label_loss: 2.1990 - val_loss: 2.2057\n",
      "Epoch 69/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8525 - Domain_loss: 0.4407 - Label_accuracy: 0.9895 - Label_loss: 0.0313 - loss: 0.4719 - val_Domain_accuracy: 0.1143 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7758 - val_Label_loss: 1.9408 - val_loss: 1.9401\n",
      "Epoch 70/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8688 - Domain_loss: 0.3756 - Label_accuracy: 0.9893 - Label_loss: 0.0344 - loss: 0.4097 - val_Domain_accuracy: 0.1923 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 1.8243 - val_loss: 1.8169\n",
      "Epoch 71/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8845 - Domain_loss: 0.3376 - Label_accuracy: 0.9906 - Label_loss: 0.0289 - loss: 0.3663 - val_Domain_accuracy: 0.2286 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7451 - val_Label_loss: 2.4083 - val_loss: 2.4085\n",
      "Epoch 72/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8792 - Domain_loss: 0.3472 - Label_accuracy: 0.9919 - Label_loss: 0.0255 - loss: 0.3728 - val_Domain_accuracy: 0.1374 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7780 - val_Label_loss: 2.1633 - val_loss: 2.1632\n",
      "Epoch 73/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8879 - Domain_loss: 0.3246 - Label_accuracy: 0.9895 - Label_loss: 0.0299 - loss: 0.3547 - val_Domain_accuracy: 0.2000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7769 - val_Label_loss: 1.9303 - val_loss: 1.9321\n",
      "Epoch 74/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8792 - Domain_loss: 0.3372 - Label_accuracy: 0.9925 - Label_loss: 0.0217 - loss: 0.3589 - val_Domain_accuracy: 0.2077 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8055 - val_Label_loss: 1.8080 - val_loss: 1.8014\n",
      "Epoch 75/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8759 - Domain_loss: 0.3573 - Label_accuracy: 0.9883 - Label_loss: 0.0396 - loss: 0.3970 - val_Domain_accuracy: 0.2044 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7758 - val_Label_loss: 2.0282 - val_loss: 2.0271\n",
      "Epoch 76/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8810 - Domain_loss: 0.3446 - Label_accuracy: 0.9894 - Label_loss: 0.0289 - loss: 0.3737 - val_Domain_accuracy: 0.2341 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7692 - val_Label_loss: 2.1777 - val_loss: 2.1599\n",
      "Epoch 77/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8640 - Domain_loss: 0.3782 - Label_accuracy: 0.9898 - Label_loss: 0.0297 - loss: 0.4080 - val_Domain_accuracy: 0.1912 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 1.8959 - val_loss: 1.8923\n",
      "Epoch 78/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8548 - Domain_loss: 0.4192 - Label_accuracy: 0.9901 - Label_loss: 0.0303 - loss: 0.4492 - val_Domain_accuracy: 0.2923 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7791 - val_Label_loss: 1.8946 - val_loss: 1.8881\n",
      "Epoch 79/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8564 - Domain_loss: 0.4083 - Label_accuracy: 0.9880 - Label_loss: 0.0355 - loss: 0.4439 - val_Domain_accuracy: 0.3143 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 1.6318 - val_loss: 1.6318\n",
      "Epoch 80/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8764 - Domain_loss: 0.3489 - Label_accuracy: 0.9916 - Label_loss: 0.0254 - loss: 0.3743 - val_Domain_accuracy: 0.1495 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7582 - val_Label_loss: 2.5437 - val_loss: 2.5556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 5\n",
      "train_feature shape: (7730, 5, 10, 256)\n",
      "train_targets shape: (7730, 5)\n",
      "train_domin shape: (7730, 9)\n",
      "Epoch 1/80\n",
      "242/242 - 17s - 70ms/step - Domain_accuracy: 0.4175 - Domain_loss: 1.7964 - Label_accuracy: 0.6537 - Label_loss: 1.0808 - loss: 2.8783 - val_Domain_accuracy: 0.1343 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7350 - val_Label_loss: 0.6331 - val_loss: 0.6360\n",
      "Epoch 2/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.5890 - Domain_loss: 1.2117 - Label_accuracy: 0.7680 - Label_loss: 0.5883 - loss: 1.8000 - val_Domain_accuracy: 0.1502 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7436 - val_Label_loss: 0.6325 - val_loss: 0.6368\n",
      "Epoch 3/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.6340 - Domain_loss: 1.0616 - Label_accuracy: 0.7955 - Label_loss: 0.5323 - loss: 1.5934 - val_Domain_accuracy: 0.2576 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7399 - val_Label_loss: 0.6234 - val_loss: 0.6260\n",
      "Epoch 4/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.6512 - Domain_loss: 1.0133 - Label_accuracy: 0.7968 - Label_loss: 0.5121 - loss: 1.5259 - val_Domain_accuracy: 0.0904 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7631 - val_Label_loss: 0.5814 - val_loss: 0.5829\n",
      "Epoch 5/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.6869 - Domain_loss: 0.9510 - Label_accuracy: 0.8075 - Label_loss: 0.4896 - loss: 1.4400 - val_Domain_accuracy: 0.0220 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7778 - val_Label_loss: 0.6000 - val_loss: 0.6026\n",
      "Epoch 6/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.6872 - Domain_loss: 0.8997 - Label_accuracy: 0.8159 - Label_loss: 0.4694 - loss: 1.3693 - val_Domain_accuracy: 0.1929 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 0.5105 - val_loss: 0.5122\n",
      "Epoch 7/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.6961 - Domain_loss: 0.9128 - Label_accuracy: 0.8197 - Label_loss: 0.4639 - loss: 1.3754 - val_Domain_accuracy: 0.1685 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7485 - val_Label_loss: 0.5817 - val_loss: 0.5837\n",
      "Epoch 8/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.7291 - Domain_loss: 0.8230 - Label_accuracy: 0.8188 - Label_loss: 0.4466 - loss: 1.2696 - val_Domain_accuracy: 0.2076 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7900 - val_Label_loss: 0.5190 - val_loss: 0.5199\n",
      "Epoch 9/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.7250 - Domain_loss: 0.8115 - Label_accuracy: 0.8357 - Label_loss: 0.4227 - loss: 1.2337 - val_Domain_accuracy: 0.1404 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8022 - val_Label_loss: 0.4988 - val_loss: 0.5008\n",
      "Epoch 10/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.7229 - Domain_loss: 0.7913 - Label_accuracy: 0.8334 - Label_loss: 0.4174 - loss: 1.2090 - val_Domain_accuracy: 0.3700 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7888 - val_Label_loss: 0.5292 - val_loss: 0.5310\n",
      "Epoch 11/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.7498 - Domain_loss: 0.7564 - Label_accuracy: 0.8326 - Label_loss: 0.4110 - loss: 1.1671 - val_Domain_accuracy: 0.1282 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7863 - val_Label_loss: 0.5116 - val_loss: 0.5142\n",
      "Epoch 12/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.7543 - Domain_loss: 0.7170 - Label_accuracy: 0.8395 - Label_loss: 0.4093 - loss: 1.1265 - val_Domain_accuracy: 0.0806 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7998 - val_Label_loss: 0.5144 - val_loss: 0.5166\n",
      "Epoch 13/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.7454 - Domain_loss: 0.7485 - Label_accuracy: 0.8424 - Label_loss: 0.4016 - loss: 1.1502 - val_Domain_accuracy: 0.0965 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7961 - val_Label_loss: 0.5148 - val_loss: 0.5147\n",
      "Epoch 14/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.7592 - Domain_loss: 0.7111 - Label_accuracy: 0.8444 - Label_loss: 0.3972 - loss: 1.1086 - val_Domain_accuracy: 0.1197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7900 - val_Label_loss: 0.5275 - val_loss: 0.5299\n",
      "Epoch 15/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.7684 - Domain_loss: 0.6833 - Label_accuracy: 0.8476 - Label_loss: 0.3880 - loss: 1.0699 - val_Domain_accuracy: 0.0379 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 0.5200 - val_loss: 0.5189\n",
      "Epoch 16/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.7828 - Domain_loss: 0.6519 - Label_accuracy: 0.8475 - Label_loss: 0.3771 - loss: 1.0286 - val_Domain_accuracy: 0.0635 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7717 - val_Label_loss: 0.5728 - val_loss: 0.5759\n",
      "Epoch 17/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.7880 - Domain_loss: 0.6326 - Label_accuracy: 0.8492 - Label_loss: 0.3751 - loss: 1.0082 - val_Domain_accuracy: 0.0513 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7827 - val_Label_loss: 0.5825 - val_loss: 0.5825\n",
      "Epoch 18/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.7935 - Domain_loss: 0.6169 - Label_accuracy: 0.8501 - Label_loss: 0.3725 - loss: 0.9895 - val_Domain_accuracy: 0.1343 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7643 - val_Label_loss: 0.5936 - val_loss: 0.5958\n",
      "Epoch 19/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8071 - Domain_loss: 0.5954 - Label_accuracy: 0.8549 - Label_loss: 0.3630 - loss: 0.9584 - val_Domain_accuracy: 0.2088 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 0.5641 - val_loss: 0.5669\n",
      "Epoch 20/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.7957 - Domain_loss: 0.6000 - Label_accuracy: 0.8571 - Label_loss: 0.3645 - loss: 0.9641 - val_Domain_accuracy: 0.1148 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7900 - val_Label_loss: 0.5262 - val_loss: 0.5259\n",
      "Epoch 21/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8009 - Domain_loss: 0.5974 - Label_accuracy: 0.8620 - Label_loss: 0.3527 - loss: 0.9497 - val_Domain_accuracy: 0.1917 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 0.6135 - val_loss: 0.6176\n",
      "Epoch 22/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8048 - Domain_loss: 0.5783 - Label_accuracy: 0.8622 - Label_loss: 0.3454 - loss: 0.9232 - val_Domain_accuracy: 0.0977 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7839 - val_Label_loss: 0.6004 - val_loss: 0.6031\n",
      "Epoch 23/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8116 - Domain_loss: 0.5474 - Label_accuracy: 0.8649 - Label_loss: 0.3463 - loss: 0.8922 - val_Domain_accuracy: 0.1770 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7497 - val_Label_loss: 0.6691 - val_loss: 0.6740\n",
      "Epoch 24/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8224 - Domain_loss: 0.5286 - Label_accuracy: 0.8625 - Label_loss: 0.3440 - loss: 0.8723 - val_Domain_accuracy: 0.1673 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 0.5515 - val_loss: 0.5522\n",
      "Epoch 25/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8154 - Domain_loss: 0.5536 - Label_accuracy: 0.8687 - Label_loss: 0.3290 - loss: 0.8833 - val_Domain_accuracy: 0.2063 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7656 - val_Label_loss: 0.6943 - val_loss: 0.7000\n",
      "Epoch 26/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8181 - Domain_loss: 0.5536 - Label_accuracy: 0.8648 - Label_loss: 0.3319 - loss: 0.8856 - val_Domain_accuracy: 0.1795 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7546 - val_Label_loss: 0.6284 - val_loss: 0.6308\n",
      "Epoch 27/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8154 - Domain_loss: 0.5468 - Label_accuracy: 0.8679 - Label_loss: 0.3302 - loss: 0.8772 - val_Domain_accuracy: 0.0891 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7985 - val_Label_loss: 0.5262 - val_loss: 0.5267\n",
      "Epoch 28/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8220 - Domain_loss: 0.5235 - Label_accuracy: 0.8669 - Label_loss: 0.3278 - loss: 0.8506 - val_Domain_accuracy: 0.0562 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7643 - val_Label_loss: 0.6822 - val_loss: 0.6839\n",
      "Epoch 29/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8226 - Domain_loss: 0.5272 - Label_accuracy: 0.8728 - Label_loss: 0.3135 - loss: 0.8414 - val_Domain_accuracy: 0.0891 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8010 - val_Label_loss: 0.5314 - val_loss: 0.5336\n",
      "Epoch 30/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8344 - Domain_loss: 0.4871 - Label_accuracy: 0.8767 - Label_loss: 0.3071 - loss: 0.7934 - val_Domain_accuracy: 0.1917 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8010 - val_Label_loss: 0.5360 - val_loss: 0.5389\n",
      "Epoch 31/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8219 - Domain_loss: 0.5129 - Label_accuracy: 0.8784 - Label_loss: 0.3019 - loss: 0.8134 - val_Domain_accuracy: 0.1270 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 0.5514 - val_loss: 0.5517\n",
      "Epoch 32/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8367 - Domain_loss: 0.4724 - Label_accuracy: 0.8801 - Label_loss: 0.3015 - loss: 0.7734 - val_Domain_accuracy: 0.1160 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 0.6049 - val_loss: 0.6047\n",
      "Epoch 33/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8252 - Domain_loss: 0.5115 - Label_accuracy: 0.8768 - Label_loss: 0.3058 - loss: 0.8170 - val_Domain_accuracy: 0.1844 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7607 - val_Label_loss: 0.6662 - val_loss: 0.6690\n",
      "Epoch 34/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8242 - Domain_loss: 0.5193 - Label_accuracy: 0.8854 - Label_loss: 0.2885 - loss: 0.8056 - val_Domain_accuracy: 0.0098 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7839 - val_Label_loss: 0.6853 - val_loss: 0.6851\n",
      "Epoch 35/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8277 - Domain_loss: 0.5241 - Label_accuracy: 0.8805 - Label_loss: 0.3001 - loss: 0.8240 - val_Domain_accuracy: 0.1404 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7863 - val_Label_loss: 0.5661 - val_loss: 0.5673\n",
      "Epoch 36/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8281 - Domain_loss: 0.4963 - Label_accuracy: 0.8855 - Label_loss: 0.2907 - loss: 0.7871 - val_Domain_accuracy: 0.1282 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 0.6072 - val_loss: 0.6102\n",
      "Epoch 37/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8334 - Domain_loss: 0.4717 - Label_accuracy: 0.8887 - Label_loss: 0.2772 - loss: 0.7485 - val_Domain_accuracy: 0.1258 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7973 - val_Label_loss: 0.5406 - val_loss: 0.5414\n",
      "Epoch 38/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8291 - Domain_loss: 0.4993 - Label_accuracy: 0.8915 - Label_loss: 0.2754 - loss: 0.7756 - val_Domain_accuracy: 0.1087 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7753 - val_Label_loss: 0.6788 - val_loss: 0.6798\n",
      "Epoch 39/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8233 - Domain_loss: 0.5167 - Label_accuracy: 0.8843 - Label_loss: 0.2888 - loss: 0.8059 - val_Domain_accuracy: 0.1172 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7888 - val_Label_loss: 0.5734 - val_loss: 0.5753\n",
      "Epoch 40/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8313 - Domain_loss: 0.4805 - Label_accuracy: 0.8912 - Label_loss: 0.2753 - loss: 0.7557 - val_Domain_accuracy: 0.0891 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7875 - val_Label_loss: 0.5935 - val_loss: 0.5933\n",
      "Epoch 41/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8300 - Domain_loss: 0.4911 - Label_accuracy: 0.8843 - Label_loss: 0.2877 - loss: 0.7793 - val_Domain_accuracy: 0.0525 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7753 - val_Label_loss: 0.6181 - val_loss: 0.6198\n",
      "Epoch 42/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8383 - Domain_loss: 0.4665 - Label_accuracy: 0.8891 - Label_loss: 0.2638 - loss: 0.7300 - val_Domain_accuracy: 0.0623 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 0.6046 - val_loss: 0.6079\n",
      "Epoch 43/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8273 - Domain_loss: 0.5036 - Label_accuracy: 0.8881 - Label_loss: 0.2733 - loss: 0.7766 - val_Domain_accuracy: 0.0647 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7534 - val_Label_loss: 0.7714 - val_loss: 0.7750\n",
      "Epoch 44/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8386 - Domain_loss: 0.4722 - Label_accuracy: 0.8979 - Label_loss: 0.2568 - loss: 0.7297 - val_Domain_accuracy: 0.0098 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7741 - val_Label_loss: 0.6634 - val_loss: 0.6653\n",
      "Epoch 45/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8369 - Domain_loss: 0.4742 - Label_accuracy: 0.8920 - Label_loss: 0.2709 - loss: 0.7447 - val_Domain_accuracy: 0.0977 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7680 - val_Label_loss: 0.6826 - val_loss: 0.6844\n",
      "Epoch 46/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8348 - Domain_loss: 0.4927 - Label_accuracy: 0.8899 - Label_loss: 0.2745 - loss: 0.7680 - val_Domain_accuracy: 0.1380 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7363 - val_Label_loss: 0.8527 - val_loss: 0.8579\n",
      "Epoch 47/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8348 - Domain_loss: 0.4798 - Label_accuracy: 0.8926 - Label_loss: 0.2626 - loss: 0.7424 - val_Domain_accuracy: 0.0867 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7680 - val_Label_loss: 0.6230 - val_loss: 0.6232\n",
      "Epoch 48/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8502 - Domain_loss: 0.4336 - Label_accuracy: 0.8986 - Label_loss: 0.2579 - loss: 0.6920 - val_Domain_accuracy: 0.1026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 0.6112 - val_loss: 0.6157\n",
      "Epoch 49/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8605 - Domain_loss: 0.4107 - Label_accuracy: 0.9050 - Label_loss: 0.2330 - loss: 0.6435 - val_Domain_accuracy: 0.0623 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7753 - val_Label_loss: 0.7285 - val_loss: 0.7259\n",
      "Epoch 50/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8418 - Domain_loss: 0.4765 - Label_accuracy: 0.8965 - Label_loss: 0.2573 - loss: 0.7334 - val_Domain_accuracy: 0.0647 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7778 - val_Label_loss: 0.6439 - val_loss: 0.6479\n",
      "Epoch 51/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8483 - Domain_loss: 0.4563 - Label_accuracy: 0.9047 - Label_loss: 0.2465 - loss: 0.7016 - val_Domain_accuracy: 0.1087 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 0.6405 - val_loss: 0.6426\n",
      "Epoch 52/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8475 - Domain_loss: 0.4517 - Label_accuracy: 0.9056 - Label_loss: 0.2357 - loss: 0.6874 - val_Domain_accuracy: 0.0794 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7888 - val_Label_loss: 0.6914 - val_loss: 0.6946\n",
      "Epoch 53/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8431 - Domain_loss: 0.4670 - Label_accuracy: 0.8996 - Label_loss: 0.2483 - loss: 0.7149 - val_Domain_accuracy: 0.0549 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7656 - val_Label_loss: 0.6884 - val_loss: 0.6894\n",
      "Epoch 54/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8393 - Domain_loss: 0.4672 - Label_accuracy: 0.9027 - Label_loss: 0.2438 - loss: 0.7110 - val_Domain_accuracy: 0.1062 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7729 - val_Label_loss: 0.6599 - val_loss: 0.6613\n",
      "Epoch 55/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8468 - Domain_loss: 0.4698 - Label_accuracy: 0.9035 - Label_loss: 0.2329 - loss: 0.7026 - val_Domain_accuracy: 0.0501 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7448 - val_Label_loss: 0.6679 - val_loss: 0.6702\n",
      "Epoch 56/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8281 - Domain_loss: 0.4838 - Label_accuracy: 0.9065 - Label_loss: 0.2377 - loss: 0.7214 - val_Domain_accuracy: 0.1380 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7790 - val_Label_loss: 0.6818 - val_loss: 0.6863\n",
      "Epoch 57/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8345 - Domain_loss: 0.4743 - Label_accuracy: 0.9048 - Label_loss: 0.2405 - loss: 0.7149 - val_Domain_accuracy: 0.0537 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 0.7018 - val_loss: 0.7042\n",
      "Epoch 58/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8406 - Domain_loss: 0.4634 - Label_accuracy: 0.9078 - Label_loss: 0.2332 - loss: 0.6967 - val_Domain_accuracy: 0.1477 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7595 - val_Label_loss: 0.6462 - val_loss: 0.6493\n",
      "Epoch 59/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8384 - Domain_loss: 0.4737 - Label_accuracy: 0.9076 - Label_loss: 0.2298 - loss: 0.7034 - val_Domain_accuracy: 0.0977 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7766 - val_Label_loss: 0.7372 - val_loss: 0.7415\n",
      "Epoch 60/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8418 - Domain_loss: 0.4770 - Label_accuracy: 0.9114 - Label_loss: 0.2234 - loss: 0.6996 - val_Domain_accuracy: 0.1245 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7766 - val_Label_loss: 0.7023 - val_loss: 0.7024\n",
      "Epoch 61/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8404 - Domain_loss: 0.4592 - Label_accuracy: 0.9072 - Label_loss: 0.2400 - loss: 0.6990 - val_Domain_accuracy: 0.1868 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7595 - val_Label_loss: 0.7774 - val_loss: 0.7818\n",
      "Epoch 62/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8464 - Domain_loss: 0.4391 - Label_accuracy: 0.9113 - Label_loss: 0.2294 - loss: 0.6683 - val_Domain_accuracy: 0.1013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7643 - val_Label_loss: 0.6391 - val_loss: 0.6403\n",
      "Epoch 63/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8473 - Domain_loss: 0.4563 - Label_accuracy: 0.9146 - Label_loss: 0.2136 - loss: 0.6696 - val_Domain_accuracy: 0.1136 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 0.6427 - val_loss: 0.6440\n",
      "Epoch 64/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8464 - Domain_loss: 0.4420 - Label_accuracy: 0.9088 - Label_loss: 0.2346 - loss: 0.6766 - val_Domain_accuracy: 0.0598 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7717 - val_Label_loss: 0.6397 - val_loss: 0.6391\n",
      "Epoch 65/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8583 - Domain_loss: 0.4011 - Label_accuracy: 0.9133 - Label_loss: 0.2172 - loss: 0.6184 - val_Domain_accuracy: 0.1978 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7900 - val_Label_loss: 0.6759 - val_loss: 0.6783\n",
      "Epoch 66/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8488 - Domain_loss: 0.4340 - Label_accuracy: 0.9093 - Label_loss: 0.2282 - loss: 0.6617 - val_Domain_accuracy: 0.0733 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7741 - val_Label_loss: 0.6574 - val_loss: 0.6609\n",
      "Epoch 67/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8484 - Domain_loss: 0.4388 - Label_accuracy: 0.9122 - Label_loss: 0.2144 - loss: 0.6535 - val_Domain_accuracy: 0.1770 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7570 - val_Label_loss: 0.7534 - val_loss: 0.7559\n",
      "Epoch 68/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8426 - Domain_loss: 0.4481 - Label_accuracy: 0.9116 - Label_loss: 0.2234 - loss: 0.6715 - val_Domain_accuracy: 0.1331 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7668 - val_Label_loss: 0.7726 - val_loss: 0.7753\n",
      "Epoch 69/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8429 - Domain_loss: 0.4663 - Label_accuracy: 0.9157 - Label_loss: 0.2139 - loss: 0.6805 - val_Domain_accuracy: 0.1111 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7680 - val_Label_loss: 0.7616 - val_loss: 0.7634\n",
      "Epoch 70/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8466 - Domain_loss: 0.4550 - Label_accuracy: 0.9146 - Label_loss: 0.2160 - loss: 0.6713 - val_Domain_accuracy: 0.0647 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7411 - val_Label_loss: 0.9679 - val_loss: 0.9704\n",
      "Epoch 71/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8449 - Domain_loss: 0.4521 - Label_accuracy: 0.9155 - Label_loss: 0.2145 - loss: 0.6666 - val_Domain_accuracy: 0.2381 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7863 - val_Label_loss: 0.6631 - val_loss: 0.6651\n",
      "Epoch 72/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8517 - Domain_loss: 0.4367 - Label_accuracy: 0.9202 - Label_loss: 0.1993 - loss: 0.6361 - val_Domain_accuracy: 0.2088 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7582 - val_Label_loss: 0.7863 - val_loss: 0.7934\n",
      "Epoch 73/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8433 - Domain_loss: 0.4513 - Label_accuracy: 0.9150 - Label_loss: 0.2144 - loss: 0.6657 - val_Domain_accuracy: 0.1844 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7790 - val_Label_loss: 0.7294 - val_loss: 0.7297\n",
      "Epoch 74/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8396 - Domain_loss: 0.4549 - Label_accuracy: 0.9191 - Label_loss: 0.2093 - loss: 0.6644 - val_Domain_accuracy: 0.0781 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7656 - val_Label_loss: 0.8047 - val_loss: 0.8066\n",
      "Epoch 75/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8432 - Domain_loss: 0.4510 - Label_accuracy: 0.9216 - Label_loss: 0.1994 - loss: 0.6498 - val_Domain_accuracy: 0.1905 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7643 - val_Label_loss: 0.7301 - val_loss: 0.7343\n",
      "Epoch 76/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8530 - Domain_loss: 0.4378 - Label_accuracy: 0.9225 - Label_loss: 0.1969 - loss: 0.6348 - val_Domain_accuracy: 0.0867 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7546 - val_Label_loss: 0.9033 - val_loss: 0.9097\n",
      "Epoch 77/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8508 - Domain_loss: 0.4246 - Label_accuracy: 0.9153 - Label_loss: 0.2096 - loss: 0.6340 - val_Domain_accuracy: 0.1514 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7302 - val_Label_loss: 0.8609 - val_loss: 0.8623\n",
      "Epoch 78/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8450 - Domain_loss: 0.4591 - Label_accuracy: 0.9243 - Label_loss: 0.1943 - loss: 0.6540 - val_Domain_accuracy: 0.1490 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7607 - val_Label_loss: 0.7149 - val_loss: 0.7154\n",
      "Epoch 79/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8338 - Domain_loss: 0.4742 - Label_accuracy: 0.9226 - Label_loss: 0.2030 - loss: 0.6776 - val_Domain_accuracy: 0.1783 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7668 - val_Label_loss: 0.7070 - val_loss: 0.7083\n",
      "Epoch 80/80\n",
      "242/242 - 8s - 33ms/step - Domain_accuracy: 0.8454 - Domain_loss: 0.4579 - Label_accuracy: 0.9163 - Label_loss: 0.2124 - loss: 0.6707 - val_Domain_accuracy: 0.0647 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7717 - val_Label_loss: 0.8419 - val_loss: 0.8449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 6\n",
      "train_feature shape: (7769, 5, 10, 256)\n",
      "train_targets shape: (7769, 5)\n",
      "train_domin shape: (7769, 9)\n",
      "Epoch 1/80\n",
      "243/243 - 17s - 70ms/step - Domain_accuracy: 0.5410 - Domain_loss: 1.4237 - Label_accuracy: 0.7674 - Label_loss: 0.7196 - loss: 2.1437 - val_Domain_accuracy: 0.6244 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7359 - val_Label_loss: 0.8089 - val_loss: 0.7644\n",
      "Epoch 2/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.6782 - Domain_loss: 0.9405 - Label_accuracy: 0.8632 - Label_loss: 0.3716 - loss: 1.3119 - val_Domain_accuracy: 0.4462 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7910 - val_Label_loss: 0.6893 - val_loss: 0.6721\n",
      "Epoch 3/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7234 - Domain_loss: 0.7993 - Label_accuracy: 0.8853 - Label_loss: 0.3005 - loss: 1.0998 - val_Domain_accuracy: 0.4449 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7923 - val_Label_loss: 0.6970 - val_loss: 0.6869\n",
      "Epoch 4/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7306 - Domain_loss: 0.7761 - Label_accuracy: 0.9086 - Label_loss: 0.2504 - loss: 1.0264 - val_Domain_accuracy: 0.5372 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7769 - val_Label_loss: 0.9747 - val_loss: 0.9638\n",
      "Epoch 5/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7714 - Domain_loss: 0.6651 - Label_accuracy: 0.9126 - Label_loss: 0.2265 - loss: 0.8921 - val_Domain_accuracy: 0.3885 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8077 - val_Label_loss: 0.7232 - val_loss: 0.7201\n",
      "Epoch 6/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7811 - Domain_loss: 0.6472 - Label_accuracy: 0.9154 - Label_loss: 0.2204 - loss: 0.8675 - val_Domain_accuracy: 0.5333 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 0.8513 - val_loss: 0.8411\n",
      "Epoch 7/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7875 - Domain_loss: 0.6253 - Label_accuracy: 0.9268 - Label_loss: 0.1949 - loss: 0.8201 - val_Domain_accuracy: 0.5474 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7679 - val_Label_loss: 0.9711 - val_loss: 0.9459\n",
      "Epoch 8/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.7966 - Domain_loss: 0.5776 - Label_accuracy: 0.9268 - Label_loss: 0.1919 - loss: 0.7698 - val_Domain_accuracy: 0.6385 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7667 - val_Label_loss: 0.9361 - val_loss: 0.9419\n",
      "Epoch 9/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8190 - Domain_loss: 0.5401 - Label_accuracy: 0.9385 - Label_loss: 0.1669 - loss: 0.7068 - val_Domain_accuracy: 0.6000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7385 - val_Label_loss: 1.1884 - val_loss: 1.1847\n",
      "Epoch 10/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8190 - Domain_loss: 0.5314 - Label_accuracy: 0.9386 - Label_loss: 0.1608 - loss: 0.6917 - val_Domain_accuracy: 0.7756 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7654 - val_Label_loss: 1.1791 - val_loss: 1.1644\n",
      "Epoch 11/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8231 - Domain_loss: 0.5237 - Label_accuracy: 0.9445 - Label_loss: 0.1587 - loss: 0.6827 - val_Domain_accuracy: 0.6397 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7987 - val_Label_loss: 0.9524 - val_loss: 0.9258\n",
      "Epoch 12/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8390 - Domain_loss: 0.4725 - Label_accuracy: 0.9441 - Label_loss: 0.1480 - loss: 0.6206 - val_Domain_accuracy: 0.6885 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7987 - val_Label_loss: 0.9355 - val_loss: 0.9233\n",
      "Epoch 13/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8435 - Domain_loss: 0.4599 - Label_accuracy: 0.9483 - Label_loss: 0.1345 - loss: 0.5944 - val_Domain_accuracy: 0.4115 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7577 - val_Label_loss: 1.4120 - val_loss: 1.3660\n",
      "Epoch 14/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8267 - Domain_loss: 0.5026 - Label_accuracy: 0.9475 - Label_loss: 0.1390 - loss: 0.6420 - val_Domain_accuracy: 0.5577 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7962 - val_Label_loss: 0.9502 - val_loss: 0.9493\n",
      "Epoch 15/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8301 - Domain_loss: 0.4999 - Label_accuracy: 0.9494 - Label_loss: 0.1335 - loss: 0.6336 - val_Domain_accuracy: 0.3821 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7885 - val_Label_loss: 1.1019 - val_loss: 1.1029\n",
      "Epoch 16/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8468 - Domain_loss: 0.4547 - Label_accuracy: 0.9560 - Label_loss: 0.1179 - loss: 0.5727 - val_Domain_accuracy: 0.3474 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8103 - val_Label_loss: 1.0389 - val_loss: 1.0488\n",
      "Epoch 17/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8409 - Domain_loss: 0.4618 - Label_accuracy: 0.9521 - Label_loss: 0.1231 - loss: 0.5847 - val_Domain_accuracy: 0.5038 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7923 - val_Label_loss: 1.0841 - val_loss: 1.0698\n",
      "Epoch 18/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8392 - Domain_loss: 0.4546 - Label_accuracy: 0.9565 - Label_loss: 0.1137 - loss: 0.5679 - val_Domain_accuracy: 0.6256 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8167 - val_Label_loss: 0.9033 - val_loss: 0.9053\n",
      "Epoch 19/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8374 - Domain_loss: 0.4482 - Label_accuracy: 0.9553 - Label_loss: 0.1174 - loss: 0.5653 - val_Domain_accuracy: 0.5859 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8218 - val_Label_loss: 0.9892 - val_loss: 0.9822\n",
      "Epoch 20/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8569 - Domain_loss: 0.4164 - Label_accuracy: 0.9579 - Label_loss: 0.1080 - loss: 0.5242 - val_Domain_accuracy: 0.5962 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 1.1955 - val_loss: 1.1872\n",
      "Epoch 21/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8524 - Domain_loss: 0.4328 - Label_accuracy: 0.9624 - Label_loss: 0.1058 - loss: 0.5387 - val_Domain_accuracy: 0.5385 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7910 - val_Label_loss: 1.2235 - val_loss: 1.2208\n",
      "Epoch 22/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8527 - Domain_loss: 0.4247 - Label_accuracy: 0.9579 - Label_loss: 0.1057 - loss: 0.5305 - val_Domain_accuracy: 0.4192 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7962 - val_Label_loss: 0.9413 - val_loss: 0.9302\n",
      "Epoch 23/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8652 - Domain_loss: 0.4007 - Label_accuracy: 0.9663 - Label_loss: 0.0933 - loss: 0.4942 - val_Domain_accuracy: 0.4449 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7756 - val_Label_loss: 1.5510 - val_loss: 1.5676\n",
      "Epoch 24/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8596 - Domain_loss: 0.3939 - Label_accuracy: 0.9633 - Label_loss: 0.1000 - loss: 0.4936 - val_Domain_accuracy: 0.6218 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7808 - val_Label_loss: 1.5449 - val_loss: 1.5445\n",
      "Epoch 25/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8566 - Domain_loss: 0.4148 - Label_accuracy: 0.9643 - Label_loss: 0.0935 - loss: 0.5083 - val_Domain_accuracy: 0.4936 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7603 - val_Label_loss: 1.5078 - val_loss: 1.5062\n",
      "Epoch 26/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8449 - Domain_loss: 0.4595 - Label_accuracy: 0.9631 - Label_loss: 0.1011 - loss: 0.5607 - val_Domain_accuracy: 0.3667 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7910 - val_Label_loss: 1.3917 - val_loss: 1.3678\n",
      "Epoch 27/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8569 - Domain_loss: 0.4094 - Label_accuracy: 0.9660 - Label_loss: 0.0893 - loss: 0.4988 - val_Domain_accuracy: 0.6308 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 1.4819 - val_loss: 1.4764\n",
      "Epoch 28/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8601 - Domain_loss: 0.4127 - Label_accuracy: 0.9721 - Label_loss: 0.0761 - loss: 0.4887 - val_Domain_accuracy: 0.3590 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 1.6938 - val_loss: 1.6843\n",
      "Epoch 29/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8446 - Domain_loss: 0.4612 - Label_accuracy: 0.9700 - Label_loss: 0.0809 - loss: 0.5419 - val_Domain_accuracy: 0.7538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7654 - val_Label_loss: 1.4271 - val_loss: 1.3869\n",
      "Epoch 30/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8467 - Domain_loss: 0.4531 - Label_accuracy: 0.9685 - Label_loss: 0.0842 - loss: 0.5377 - val_Domain_accuracy: 0.4821 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7769 - val_Label_loss: 1.9676 - val_loss: 1.9621\n",
      "Epoch 31/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8571 - Domain_loss: 0.4186 - Label_accuracy: 0.9708 - Label_loss: 0.0791 - loss: 0.4976 - val_Domain_accuracy: 0.2500 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 1.7157 - val_loss: 1.7057\n",
      "Epoch 32/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8594 - Domain_loss: 0.4029 - Label_accuracy: 0.9730 - Label_loss: 0.0695 - loss: 0.4718 - val_Domain_accuracy: 0.5141 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 1.5499 - val_loss: 1.5131\n",
      "Epoch 33/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8508 - Domain_loss: 0.4286 - Label_accuracy: 0.9681 - Label_loss: 0.0870 - loss: 0.5155 - val_Domain_accuracy: 0.6013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7538 - val_Label_loss: 1.9757 - val_loss: 1.8993\n",
      "Epoch 34/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8682 - Domain_loss: 0.3711 - Label_accuracy: 0.9718 - Label_loss: 0.0762 - loss: 0.4475 - val_Domain_accuracy: 0.6282 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8013 - val_Label_loss: 1.3096 - val_loss: 1.3006\n",
      "Epoch 35/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8813 - Domain_loss: 0.3440 - Label_accuracy: 0.9791 - Label_loss: 0.0570 - loss: 0.4004 - val_Domain_accuracy: 0.5269 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7410 - val_Label_loss: 2.6449 - val_loss: 2.6360\n",
      "Epoch 36/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8724 - Domain_loss: 0.3716 - Label_accuracy: 0.9731 - Label_loss: 0.0736 - loss: 0.4448 - val_Domain_accuracy: 0.6141 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7654 - val_Label_loss: 1.9421 - val_loss: 1.9051\n",
      "Epoch 37/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8732 - Domain_loss: 0.3556 - Label_accuracy: 0.9786 - Label_loss: 0.0559 - loss: 0.4114 - val_Domain_accuracy: 0.6128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 1.9611 - val_loss: 1.9210\n",
      "Epoch 38/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8636 - Domain_loss: 0.3835 - Label_accuracy: 0.9705 - Label_loss: 0.0786 - loss: 0.4621 - val_Domain_accuracy: 0.4269 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7987 - val_Label_loss: 1.5743 - val_loss: 1.5494\n",
      "Epoch 39/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8692 - Domain_loss: 0.3750 - Label_accuracy: 0.9746 - Label_loss: 0.0684 - loss: 0.4435 - val_Domain_accuracy: 0.3615 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7962 - val_Label_loss: 1.4376 - val_loss: 1.4388\n",
      "Epoch 40/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8705 - Domain_loss: 0.3725 - Label_accuracy: 0.9798 - Label_loss: 0.0566 - loss: 0.4292 - val_Domain_accuracy: 0.5474 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7859 - val_Label_loss: 1.3775 - val_loss: 1.3518\n",
      "Epoch 41/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8717 - Domain_loss: 0.3652 - Label_accuracy: 0.9731 - Label_loss: 0.0748 - loss: 0.4398 - val_Domain_accuracy: 0.6910 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8038 - val_Label_loss: 1.4990 - val_loss: 1.4838\n",
      "Epoch 42/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8781 - Domain_loss: 0.3533 - Label_accuracy: 0.9794 - Label_loss: 0.0565 - loss: 0.4099 - val_Domain_accuracy: 0.7308 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8167 - val_Label_loss: 1.2257 - val_loss: 1.2052\n",
      "Epoch 43/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8766 - Domain_loss: 0.3478 - Label_accuracy: 0.9791 - Label_loss: 0.0556 - loss: 0.4034 - val_Domain_accuracy: 0.6282 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7782 - val_Label_loss: 1.4444 - val_loss: 1.4369\n",
      "Epoch 44/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8656 - Domain_loss: 0.3888 - Label_accuracy: 0.9781 - Label_loss: 0.0656 - loss: 0.4544 - val_Domain_accuracy: 0.6577 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7590 - val_Label_loss: 1.9422 - val_loss: 1.9072\n",
      "Epoch 45/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8712 - Domain_loss: 0.3588 - Label_accuracy: 0.9800 - Label_loss: 0.0563 - loss: 0.4153 - val_Domain_accuracy: 0.3692 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7654 - val_Label_loss: 1.9882 - val_loss: 1.9575\n",
      "Epoch 46/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8880 - Domain_loss: 0.3271 - Label_accuracy: 0.9826 - Label_loss: 0.0498 - loss: 0.3768 - val_Domain_accuracy: 0.3987 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7974 - val_Label_loss: 1.8220 - val_loss: 1.7688\n",
      "Epoch 47/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8760 - Domain_loss: 0.3500 - Label_accuracy: 0.9748 - Label_loss: 0.0658 - loss: 0.4159 - val_Domain_accuracy: 0.3949 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7923 - val_Label_loss: 1.8033 - val_loss: 1.7759\n",
      "Epoch 48/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8830 - Domain_loss: 0.3410 - Label_accuracy: 0.9795 - Label_loss: 0.0627 - loss: 0.4030 - val_Domain_accuracy: 0.3885 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8090 - val_Label_loss: 1.3659 - val_loss: 1.3740\n",
      "Epoch 49/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8750 - Domain_loss: 0.3516 - Label_accuracy: 0.9812 - Label_loss: 0.0523 - loss: 0.4041 - val_Domain_accuracy: 0.5513 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7923 - val_Label_loss: 1.8510 - val_loss: 1.8477\n",
      "Epoch 50/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8723 - Domain_loss: 0.3613 - Label_accuracy: 0.9797 - Label_loss: 0.0608 - loss: 0.4219 - val_Domain_accuracy: 0.6564 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7962 - val_Label_loss: 1.5079 - val_loss: 1.4754\n",
      "Epoch 51/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8800 - Domain_loss: 0.3497 - Label_accuracy: 0.9790 - Label_loss: 0.0527 - loss: 0.4025 - val_Domain_accuracy: 0.4577 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7603 - val_Label_loss: 1.9079 - val_loss: 1.8948\n",
      "Epoch 52/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8705 - Domain_loss: 0.3573 - Label_accuracy: 0.9770 - Label_loss: 0.0673 - loss: 0.4246 - val_Domain_accuracy: 0.5897 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 1.2870 - val_loss: 1.2753\n",
      "Epoch 53/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8827 - Domain_loss: 0.3305 - Label_accuracy: 0.9794 - Label_loss: 0.0551 - loss: 0.3855 - val_Domain_accuracy: 0.4846 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 1.5881 - val_loss: 1.5358\n",
      "Epoch 54/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8696 - Domain_loss: 0.3656 - Label_accuracy: 0.9829 - Label_loss: 0.0465 - loss: 0.4121 - val_Domain_accuracy: 0.6128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7782 - val_Label_loss: 1.9003 - val_loss: 1.8401\n",
      "Epoch 55/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8817 - Domain_loss: 0.3453 - Label_accuracy: 0.9800 - Label_loss: 0.0506 - loss: 0.3960 - val_Domain_accuracy: 0.5000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7538 - val_Label_loss: 2.5981 - val_loss: 2.5746\n",
      "Epoch 56/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8623 - Domain_loss: 0.3952 - Label_accuracy: 0.9793 - Label_loss: 0.0618 - loss: 0.4570 - val_Domain_accuracy: 0.5231 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7756 - val_Label_loss: 1.8381 - val_loss: 1.8163\n",
      "Epoch 57/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8751 - Domain_loss: 0.3583 - Label_accuracy: 0.9838 - Label_loss: 0.0412 - loss: 0.3996 - val_Domain_accuracy: 0.6192 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8013 - val_Label_loss: 1.6798 - val_loss: 1.6097\n",
      "Epoch 58/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8769 - Domain_loss: 0.3469 - Label_accuracy: 0.9779 - Label_loss: 0.0593 - loss: 0.4058 - val_Domain_accuracy: 0.5974 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7885 - val_Label_loss: 1.6356 - val_loss: 1.6018\n",
      "Epoch 59/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8791 - Domain_loss: 0.3370 - Label_accuracy: 0.9847 - Label_loss: 0.0427 - loss: 0.3797 - val_Domain_accuracy: 0.5385 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7718 - val_Label_loss: 1.8875 - val_loss: 1.8010\n",
      "Epoch 60/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8748 - Domain_loss: 0.3590 - Label_accuracy: 0.9828 - Label_loss: 0.0505 - loss: 0.4092 - val_Domain_accuracy: 0.4923 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7718 - val_Label_loss: 2.3077 - val_loss: 2.3131\n",
      "Epoch 61/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8888 - Domain_loss: 0.3213 - Label_accuracy: 0.9807 - Label_loss: 0.0530 - loss: 0.3743 - val_Domain_accuracy: 0.5244 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7513 - val_Label_loss: 2.5502 - val_loss: 2.5347\n",
      "Epoch 62/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8897 - Domain_loss: 0.3114 - Label_accuracy: 0.9825 - Label_loss: 0.0463 - loss: 0.3579 - val_Domain_accuracy: 0.5769 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7628 - val_Label_loss: 2.2961 - val_loss: 2.2883\n",
      "Epoch 63/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8908 - Domain_loss: 0.3026 - Label_accuracy: 0.9828 - Label_loss: 0.0477 - loss: 0.3504 - val_Domain_accuracy: 0.6628 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7897 - val_Label_loss: 1.7265 - val_loss: 1.6536\n",
      "Epoch 64/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8911 - Domain_loss: 0.3160 - Label_accuracy: 0.9834 - Label_loss: 0.0468 - loss: 0.3630 - val_Domain_accuracy: 0.3679 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 2.0721 - val_loss: 2.0600\n",
      "Epoch 65/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8903 - Domain_loss: 0.3271 - Label_accuracy: 0.9825 - Label_loss: 0.0508 - loss: 0.3779 - val_Domain_accuracy: 0.4974 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 2.3435 - val_loss: 2.2910\n",
      "Epoch 66/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8685 - Domain_loss: 0.3838 - Label_accuracy: 0.9826 - Label_loss: 0.0495 - loss: 0.4332 - val_Domain_accuracy: 0.5949 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7962 - val_Label_loss: 1.8537 - val_loss: 1.8002\n",
      "Epoch 67/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8776 - Domain_loss: 0.3467 - Label_accuracy: 0.9855 - Label_loss: 0.0412 - loss: 0.3880 - val_Domain_accuracy: 0.1846 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7679 - val_Label_loss: 2.3142 - val_loss: 2.2807\n",
      "Epoch 68/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8718 - Domain_loss: 0.3664 - Label_accuracy: 0.9828 - Label_loss: 0.0501 - loss: 0.4166 - val_Domain_accuracy: 0.6205 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7731 - val_Label_loss: 1.7006 - val_loss: 1.6057\n",
      "Epoch 69/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8748 - Domain_loss: 0.3650 - Label_accuracy: 0.9817 - Label_loss: 0.0474 - loss: 0.4123 - val_Domain_accuracy: 0.3833 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 2.1574 - val_loss: 2.0905\n",
      "Epoch 70/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8695 - Domain_loss: 0.3766 - Label_accuracy: 0.9794 - Label_loss: 0.0551 - loss: 0.4318 - val_Domain_accuracy: 0.4949 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7769 - val_Label_loss: 2.0774 - val_loss: 2.0111\n",
      "Epoch 71/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8893 - Domain_loss: 0.3148 - Label_accuracy: 0.9848 - Label_loss: 0.0471 - loss: 0.3618 - val_Domain_accuracy: 0.4808 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8026 - val_Label_loss: 1.8690 - val_loss: 1.8238\n",
      "Epoch 72/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8921 - Domain_loss: 0.3186 - Label_accuracy: 0.9855 - Label_loss: 0.0447 - loss: 0.3632 - val_Domain_accuracy: 0.2423 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 1.9454 - val_loss: 1.8997\n",
      "Epoch 73/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8833 - Domain_loss: 0.3257 - Label_accuracy: 0.9858 - Label_loss: 0.0380 - loss: 0.3635 - val_Domain_accuracy: 0.5218 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7731 - val_Label_loss: 1.9613 - val_loss: 1.8999\n",
      "Epoch 74/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8736 - Domain_loss: 0.3607 - Label_accuracy: 0.9849 - Label_loss: 0.0418 - loss: 0.4023 - val_Domain_accuracy: 0.5641 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7641 - val_Label_loss: 2.1232 - val_loss: 2.0135\n",
      "Epoch 75/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8794 - Domain_loss: 0.3538 - Label_accuracy: 0.9871 - Label_loss: 0.0368 - loss: 0.3907 - val_Domain_accuracy: 0.3731 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7692 - val_Label_loss: 2.1370 - val_loss: 2.1085\n",
      "Epoch 76/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8776 - Domain_loss: 0.3643 - Label_accuracy: 0.9815 - Label_loss: 0.0541 - loss: 0.4186 - val_Domain_accuracy: 0.4141 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7628 - val_Label_loss: 2.2852 - val_loss: 2.1729\n",
      "Epoch 77/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8824 - Domain_loss: 0.3541 - Label_accuracy: 0.9833 - Label_loss: 0.0485 - loss: 0.4028 - val_Domain_accuracy: 0.5346 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7692 - val_Label_loss: 2.1427 - val_loss: 2.0230\n",
      "Epoch 78/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8919 - Domain_loss: 0.3135 - Label_accuracy: 0.9848 - Label_loss: 0.0402 - loss: 0.3535 - val_Domain_accuracy: 0.5500 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7654 - val_Label_loss: 2.2082 - val_loss: 2.1838\n",
      "Epoch 79/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8750 - Domain_loss: 0.3557 - Label_accuracy: 0.9844 - Label_loss: 0.0432 - loss: 0.3989 - val_Domain_accuracy: 0.5013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7718 - val_Label_loss: 2.3668 - val_loss: 2.3601\n",
      "Epoch 80/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8889 - Domain_loss: 0.3198 - Label_accuracy: 0.9839 - Label_loss: 0.0466 - loss: 0.3665 - val_Domain_accuracy: 0.4577 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 1.8281 - val_loss: 1.8071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 7\n",
      "train_feature shape: (7583, 5, 10, 256)\n",
      "train_targets shape: (7583, 5)\n",
      "train_domin shape: (7583, 9)\n",
      "Epoch 1/80\n",
      "237/237 - 17s - 71ms/step - Domain_accuracy: 0.4406 - Domain_loss: 1.7367 - Label_accuracy: 0.6860 - Label_loss: 1.0196 - loss: 2.7564 - val_Domain_accuracy: 0.0963 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8582 - val_Label_loss: 0.3611 - val_loss: 0.3683\n",
      "Epoch 2/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.6013 - Domain_loss: 1.1706 - Label_accuracy: 0.7717 - Label_loss: 0.5925 - loss: 1.7631 - val_Domain_accuracy: 0.3364 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8468 - val_Label_loss: 0.4369 - val_loss: 0.4252\n",
      "Epoch 3/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.6586 - Domain_loss: 1.0123 - Label_accuracy: 0.7941 - Label_loss: 0.5125 - loss: 1.5249 - val_Domain_accuracy: 0.2340 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9006 - val_Label_loss: 0.2688 - val_loss: 0.2729\n",
      "Epoch 4/80\n",
      "237/237 - 8s - 34ms/step - Domain_accuracy: 0.7291 - Domain_loss: 0.8168 - Label_accuracy: 0.8162 - Label_loss: 0.4630 - loss: 1.2798 - val_Domain_accuracy: 0.3230 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8986 - val_Label_loss: 0.2651 - val_loss: 0.2713\n",
      "Epoch 5/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.7221 - Domain_loss: 0.8197 - Label_accuracy: 0.8217 - Label_loss: 0.4497 - loss: 1.2694 - val_Domain_accuracy: 0.1211 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8716 - val_Label_loss: 0.3204 - val_loss: 0.3161\n",
      "Epoch 6/80\n",
      "237/237 - 8s - 34ms/step - Domain_accuracy: 0.7661 - Domain_loss: 0.7066 - Label_accuracy: 0.8342 - Label_loss: 0.4255 - loss: 1.1320 - val_Domain_accuracy: 0.1004 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8954 - val_Label_loss: 0.2569 - val_loss: 0.2602\n",
      "Epoch 7/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.7380 - Domain_loss: 0.8155 - Label_accuracy: 0.8316 - Label_loss: 0.4329 - loss: 1.2484 - val_Domain_accuracy: 0.1439 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8841 - val_Label_loss: 0.2761 - val_loss: 0.2815\n",
      "Epoch 8/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.7792 - Domain_loss: 0.6943 - Label_accuracy: 0.8301 - Label_loss: 0.4182 - loss: 1.1125 - val_Domain_accuracy: 0.0538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8851 - val_Label_loss: 0.2702 - val_loss: 0.2709\n",
      "Epoch 9/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.7976 - Domain_loss: 0.6188 - Label_accuracy: 0.8412 - Label_loss: 0.3897 - loss: 1.0086 - val_Domain_accuracy: 0.1449 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8965 - val_Label_loss: 0.2514 - val_loss: 0.2571\n",
      "Epoch 10/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.7910 - Domain_loss: 0.6449 - Label_accuracy: 0.8421 - Label_loss: 0.3887 - loss: 1.0336 - val_Domain_accuracy: 0.0776 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9037 - val_Label_loss: 0.2493 - val_loss: 0.2532\n",
      "Epoch 11/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8006 - Domain_loss: 0.6063 - Label_accuracy: 0.8489 - Label_loss: 0.3802 - loss: 0.9865 - val_Domain_accuracy: 0.0839 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9048 - val_Label_loss: 0.2326 - val_loss: 0.2385\n",
      "Epoch 12/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.7976 - Domain_loss: 0.6117 - Label_accuracy: 0.8548 - Label_loss: 0.3600 - loss: 0.9716 - val_Domain_accuracy: 0.1159 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8954 - val_Label_loss: 0.2652 - val_loss: 0.2699\n",
      "Epoch 13/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8059 - Domain_loss: 0.5946 - Label_accuracy: 0.8560 - Label_loss: 0.3554 - loss: 0.9499 - val_Domain_accuracy: 0.1097 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9058 - val_Label_loss: 0.2517 - val_loss: 0.2558\n",
      "Epoch 14/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8286 - Domain_loss: 0.5104 - Label_accuracy: 0.8568 - Label_loss: 0.3625 - loss: 0.8728 - val_Domain_accuracy: 0.1325 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8944 - val_Label_loss: 0.2498 - val_loss: 0.2544\n",
      "Epoch 15/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8226 - Domain_loss: 0.5546 - Label_accuracy: 0.8514 - Label_loss: 0.3613 - loss: 0.9159 - val_Domain_accuracy: 0.3509 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9089 - val_Label_loss: 0.2294 - val_loss: 0.2341\n",
      "Epoch 16/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8350 - Domain_loss: 0.4986 - Label_accuracy: 0.8576 - Label_loss: 0.3436 - loss: 0.8421 - val_Domain_accuracy: 0.0725 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9058 - val_Label_loss: 0.2261 - val_loss: 0.2314\n",
      "Epoch 17/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8416 - Domain_loss: 0.4908 - Label_accuracy: 0.8613 - Label_loss: 0.3372 - loss: 0.8281 - val_Domain_accuracy: 0.1770 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8820 - val_Label_loss: 0.3007 - val_loss: 0.3038\n",
      "Epoch 18/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8358 - Domain_loss: 0.5071 - Label_accuracy: 0.8671 - Label_loss: 0.3301 - loss: 0.8372 - val_Domain_accuracy: 0.1273 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8975 - val_Label_loss: 0.2819 - val_loss: 0.2881\n",
      "Epoch 19/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8506 - Domain_loss: 0.4547 - Label_accuracy: 0.8809 - Label_loss: 0.3048 - loss: 0.7594 - val_Domain_accuracy: 0.2226 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8716 - val_Label_loss: 0.3340 - val_loss: 0.3421\n",
      "Epoch 20/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8545 - Domain_loss: 0.4277 - Label_accuracy: 0.8766 - Label_loss: 0.3180 - loss: 0.7457 - val_Domain_accuracy: 0.0973 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8934 - val_Label_loss: 0.2635 - val_loss: 0.2694\n",
      "Epoch 21/80\n",
      "237/237 - 8s - 34ms/step - Domain_accuracy: 0.8493 - Domain_loss: 0.4640 - Label_accuracy: 0.8727 - Label_loss: 0.3194 - loss: 0.7833 - val_Domain_accuracy: 0.1925 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8861 - val_Label_loss: 0.2696 - val_loss: 0.2758\n",
      "Epoch 22/80\n",
      "237/237 - 8s - 34ms/step - Domain_accuracy: 0.8522 - Domain_loss: 0.4510 - Label_accuracy: 0.8762 - Label_loss: 0.3151 - loss: 0.7661 - val_Domain_accuracy: 0.0973 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8851 - val_Label_loss: 0.3023 - val_loss: 0.3094\n",
      "Epoch 23/80\n",
      "237/237 - 8s - 34ms/step - Domain_accuracy: 0.8466 - Domain_loss: 0.4651 - Label_accuracy: 0.8808 - Label_loss: 0.3058 - loss: 0.7709 - val_Domain_accuracy: 0.3623 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8737 - val_Label_loss: 0.3311 - val_loss: 0.3391\n",
      "Epoch 24/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8414 - Domain_loss: 0.4590 - Label_accuracy: 0.8830 - Label_loss: 0.2965 - loss: 0.7555 - val_Domain_accuracy: 0.1584 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8965 - val_Label_loss: 0.2567 - val_loss: 0.2616\n",
      "Epoch 25/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8486 - Domain_loss: 0.4518 - Label_accuracy: 0.8809 - Label_loss: 0.2819 - loss: 0.7336 - val_Domain_accuracy: 0.0859 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8872 - val_Label_loss: 0.2815 - val_loss: 0.2882\n",
      "Epoch 26/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8567 - Domain_loss: 0.4295 - Label_accuracy: 0.8878 - Label_loss: 0.2819 - loss: 0.7113 - val_Domain_accuracy: 0.0590 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9006 - val_Label_loss: 0.2611 - val_loss: 0.2662\n",
      "Epoch 27/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8704 - Domain_loss: 0.3947 - Label_accuracy: 0.8858 - Label_loss: 0.2870 - loss: 0.6817 - val_Domain_accuracy: 0.0766 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8872 - val_Label_loss: 0.3164 - val_loss: 0.3170\n",
      "Epoch 28/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8639 - Domain_loss: 0.4096 - Label_accuracy: 0.8822 - Label_loss: 0.2840 - loss: 0.6935 - val_Domain_accuracy: 0.0704 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8820 - val_Label_loss: 0.3026 - val_loss: 0.3099\n",
      "Epoch 29/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8524 - Domain_loss: 0.4333 - Label_accuracy: 0.8853 - Label_loss: 0.2830 - loss: 0.7163 - val_Domain_accuracy: 0.0911 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8934 - val_Label_loss: 0.2955 - val_loss: 0.3028\n",
      "Epoch 30/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8570 - Domain_loss: 0.4412 - Label_accuracy: 0.8843 - Label_loss: 0.2888 - loss: 0.7300 - val_Domain_accuracy: 0.0631 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9006 - val_Label_loss: 0.2562 - val_loss: 0.2626\n",
      "Epoch 31/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8607 - Domain_loss: 0.4222 - Label_accuracy: 0.8925 - Label_loss: 0.2718 - loss: 0.6939 - val_Domain_accuracy: 0.0725 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8965 - val_Label_loss: 0.2805 - val_loss: 0.2876\n",
      "Epoch 32/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8648 - Domain_loss: 0.4123 - Label_accuracy: 0.8895 - Label_loss: 0.2749 - loss: 0.6872 - val_Domain_accuracy: 0.0952 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8758 - val_Label_loss: 0.3350 - val_loss: 0.3433\n",
      "Epoch 33/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8706 - Domain_loss: 0.3748 - Label_accuracy: 0.8957 - Label_loss: 0.2573 - loss: 0.6321 - val_Domain_accuracy: 0.1605 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8913 - val_Label_loss: 0.3105 - val_loss: 0.3187\n",
      "Epoch 34/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8701 - Domain_loss: 0.3954 - Label_accuracy: 0.8971 - Label_loss: 0.2581 - loss: 0.6534 - val_Domain_accuracy: 0.0963 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8810 - val_Label_loss: 0.3422 - val_loss: 0.3492\n",
      "Epoch 35/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8733 - Domain_loss: 0.3866 - Label_accuracy: 0.9031 - Label_loss: 0.2473 - loss: 0.6339 - val_Domain_accuracy: 0.0735 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8851 - val_Label_loss: 0.3085 - val_loss: 0.3163\n",
      "Epoch 36/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8654 - Domain_loss: 0.4027 - Label_accuracy: 0.8991 - Label_loss: 0.2531 - loss: 0.6559 - val_Domain_accuracy: 0.0559 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9017 - val_Label_loss: 0.2627 - val_loss: 0.2682\n",
      "Epoch 37/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8664 - Domain_loss: 0.3917 - Label_accuracy: 0.9003 - Label_loss: 0.2531 - loss: 0.6448 - val_Domain_accuracy: 0.1025 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9006 - val_Label_loss: 0.2598 - val_loss: 0.2659\n",
      "Epoch 38/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8577 - Domain_loss: 0.4081 - Label_accuracy: 0.9002 - Label_loss: 0.2498 - loss: 0.6579 - val_Domain_accuracy: 0.0714 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8789 - val_Label_loss: 0.3212 - val_loss: 0.3289\n",
      "Epoch 39/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8627 - Domain_loss: 0.4088 - Label_accuracy: 0.9077 - Label_loss: 0.2382 - loss: 0.6470 - val_Domain_accuracy: 0.2319 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8634 - val_Label_loss: 0.3770 - val_loss: 0.3860\n",
      "Epoch 40/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8712 - Domain_loss: 0.3784 - Label_accuracy: 0.9078 - Label_loss: 0.2289 - loss: 0.6072 - val_Domain_accuracy: 0.1232 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9099 - val_Label_loss: 0.2711 - val_loss: 0.2769\n",
      "Epoch 41/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8718 - Domain_loss: 0.3750 - Label_accuracy: 0.9070 - Label_loss: 0.2327 - loss: 0.6077 - val_Domain_accuracy: 0.1087 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8685 - val_Label_loss: 0.3642 - val_loss: 0.3738\n",
      "Epoch 42/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8700 - Domain_loss: 0.3799 - Label_accuracy: 0.9019 - Label_loss: 0.2473 - loss: 0.6271 - val_Domain_accuracy: 0.1501 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8996 - val_Label_loss: 0.2799 - val_loss: 0.2872\n",
      "Epoch 43/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8758 - Domain_loss: 0.3677 - Label_accuracy: 0.9074 - Label_loss: 0.2381 - loss: 0.6058 - val_Domain_accuracy: 0.0694 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8872 - val_Label_loss: 0.2890 - val_loss: 0.2965\n",
      "Epoch 44/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8785 - Domain_loss: 0.3633 - Label_accuracy: 0.9111 - Label_loss: 0.2212 - loss: 0.5845 - val_Domain_accuracy: 0.0683 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8892 - val_Label_loss: 0.2958 - val_loss: 0.3033\n",
      "Epoch 45/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8762 - Domain_loss: 0.3754 - Label_accuracy: 0.9093 - Label_loss: 0.2250 - loss: 0.6004 - val_Domain_accuracy: 0.0694 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8986 - val_Label_loss: 0.2747 - val_loss: 0.2818\n",
      "Epoch 46/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8739 - Domain_loss: 0.3689 - Label_accuracy: 0.9143 - Label_loss: 0.2193 - loss: 0.5881 - val_Domain_accuracy: 0.1211 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8965 - val_Label_loss: 0.3224 - val_loss: 0.3305\n",
      "Epoch 47/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8725 - Domain_loss: 0.3784 - Label_accuracy: 0.9149 - Label_loss: 0.2151 - loss: 0.5934 - val_Domain_accuracy: 0.0932 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8975 - val_Label_loss: 0.3059 - val_loss: 0.3137\n",
      "Epoch 48/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8741 - Domain_loss: 0.3740 - Label_accuracy: 0.9167 - Label_loss: 0.2117 - loss: 0.5856 - val_Domain_accuracy: 0.0828 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8654 - val_Label_loss: 0.4370 - val_loss: 0.4486\n",
      "Epoch 49/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8700 - Domain_loss: 0.3832 - Label_accuracy: 0.9167 - Label_loss: 0.2105 - loss: 0.5937 - val_Domain_accuracy: 0.1946 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8830 - val_Label_loss: 0.3391 - val_loss: 0.3477\n",
      "Epoch 50/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8712 - Domain_loss: 0.3779 - Label_accuracy: 0.9205 - Label_loss: 0.2058 - loss: 0.5837 - val_Domain_accuracy: 0.1222 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9058 - val_Label_loss: 0.2811 - val_loss: 0.2880\n",
      "Epoch 51/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8660 - Domain_loss: 0.4035 - Label_accuracy: 0.9171 - Label_loss: 0.2110 - loss: 0.6145 - val_Domain_accuracy: 0.1066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9110 - val_Label_loss: 0.2751 - val_loss: 0.2816\n",
      "Epoch 52/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8673 - Domain_loss: 0.3891 - Label_accuracy: 0.9139 - Label_loss: 0.2206 - loss: 0.6098 - val_Domain_accuracy: 0.0921 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8675 - val_Label_loss: 0.4173 - val_loss: 0.4262\n",
      "Epoch 53/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8713 - Domain_loss: 0.3699 - Label_accuracy: 0.9205 - Label_loss: 0.1992 - loss: 0.5690 - val_Domain_accuracy: 0.2329 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8975 - val_Label_loss: 0.2953 - val_loss: 0.3027\n",
      "Epoch 54/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8829 - Domain_loss: 0.3555 - Label_accuracy: 0.9188 - Label_loss: 0.2029 - loss: 0.5584 - val_Domain_accuracy: 0.3551 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9068 - val_Label_loss: 0.2769 - val_loss: 0.2843\n",
      "Epoch 55/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8915 - Domain_loss: 0.3194 - Label_accuracy: 0.9268 - Label_loss: 0.1834 - loss: 0.5027 - val_Domain_accuracy: 0.3395 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8861 - val_Label_loss: 0.3692 - val_loss: 0.3781\n",
      "Epoch 56/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8828 - Domain_loss: 0.3441 - Label_accuracy: 0.9273 - Label_loss: 0.1848 - loss: 0.5289 - val_Domain_accuracy: 0.1480 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8923 - val_Label_loss: 0.3507 - val_loss: 0.3588\n",
      "Epoch 57/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8783 - Domain_loss: 0.3584 - Label_accuracy: 0.9223 - Label_loss: 0.1939 - loss: 0.5523 - val_Domain_accuracy: 0.1190 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9058 - val_Label_loss: 0.3165 - val_loss: 0.3249\n",
      "Epoch 58/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8723 - Domain_loss: 0.3798 - Label_accuracy: 0.9272 - Label_loss: 0.1938 - loss: 0.5736 - val_Domain_accuracy: 0.2298 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9017 - val_Label_loss: 0.2933 - val_loss: 0.3008\n",
      "Epoch 59/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8792 - Domain_loss: 0.3650 - Label_accuracy: 0.9181 - Label_loss: 0.2051 - loss: 0.5701 - val_Domain_accuracy: 0.0683 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8975 - val_Label_loss: 0.3363 - val_loss: 0.3450\n",
      "Epoch 60/80\n",
      "237/237 - 8s - 34ms/step - Domain_accuracy: 0.8793 - Domain_loss: 0.3557 - Label_accuracy: 0.9231 - Label_loss: 0.1874 - loss: 0.5431 - val_Domain_accuracy: 0.2723 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8934 - val_Label_loss: 0.3570 - val_loss: 0.3661\n",
      "Epoch 61/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8913 - Domain_loss: 0.3267 - Label_accuracy: 0.9251 - Label_loss: 0.1880 - loss: 0.5147 - val_Domain_accuracy: 0.1439 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8820 - val_Label_loss: 0.4163 - val_loss: 0.4270\n",
      "Epoch 62/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8841 - Domain_loss: 0.3513 - Label_accuracy: 0.9223 - Label_loss: 0.1990 - loss: 0.5504 - val_Domain_accuracy: 0.0839 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8923 - val_Label_loss: 0.3650 - val_loss: 0.3745\n",
      "Epoch 63/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8846 - Domain_loss: 0.3462 - Label_accuracy: 0.9251 - Label_loss: 0.1894 - loss: 0.5356 - val_Domain_accuracy: 0.1201 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8996 - val_Label_loss: 0.3375 - val_loss: 0.3465\n",
      "Epoch 64/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8884 - Domain_loss: 0.3237 - Label_accuracy: 0.9255 - Label_loss: 0.1832 - loss: 0.5069 - val_Domain_accuracy: 0.0901 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9048 - val_Label_loss: 0.3061 - val_loss: 0.3142\n",
      "Epoch 65/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8780 - Domain_loss: 0.3587 - Label_accuracy: 0.9267 - Label_loss: 0.1890 - loss: 0.5478 - val_Domain_accuracy: 0.1822 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8986 - val_Label_loss: 0.3088 - val_loss: 0.3167\n",
      "Epoch 66/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8932 - Domain_loss: 0.3136 - Label_accuracy: 0.9256 - Label_loss: 0.1852 - loss: 0.4988 - val_Domain_accuracy: 0.0725 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8768 - val_Label_loss: 0.4128 - val_loss: 0.4233\n",
      "Epoch 67/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8900 - Domain_loss: 0.3370 - Label_accuracy: 0.9301 - Label_loss: 0.1825 - loss: 0.5195 - val_Domain_accuracy: 0.1925 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8923 - val_Label_loss: 0.3511 - val_loss: 0.3600\n",
      "Epoch 68/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8898 - Domain_loss: 0.3304 - Label_accuracy: 0.9309 - Label_loss: 0.1758 - loss: 0.5062 - val_Domain_accuracy: 0.3489 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8830 - val_Label_loss: 0.3938 - val_loss: 0.4037\n",
      "Epoch 69/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8837 - Domain_loss: 0.3341 - Label_accuracy: 0.9327 - Label_loss: 0.1719 - loss: 0.5061 - val_Domain_accuracy: 0.1035 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8965 - val_Label_loss: 0.3415 - val_loss: 0.3499\n",
      "Epoch 70/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8938 - Domain_loss: 0.3126 - Label_accuracy: 0.9276 - Label_loss: 0.1817 - loss: 0.4942 - val_Domain_accuracy: 0.0994 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8892 - val_Label_loss: 0.3836 - val_loss: 0.3934\n",
      "Epoch 71/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8876 - Domain_loss: 0.3330 - Label_accuracy: 0.9309 - Label_loss: 0.1729 - loss: 0.5059 - val_Domain_accuracy: 0.1035 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9048 - val_Label_loss: 0.3117 - val_loss: 0.3197\n",
      "Epoch 72/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8942 - Domain_loss: 0.3197 - Label_accuracy: 0.9352 - Label_loss: 0.1702 - loss: 0.4899 - val_Domain_accuracy: 0.1159 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8882 - val_Label_loss: 0.3506 - val_loss: 0.3598\n",
      "Epoch 73/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8871 - Domain_loss: 0.3231 - Label_accuracy: 0.9337 - Label_loss: 0.1718 - loss: 0.4949 - val_Domain_accuracy: 0.1522 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8965 - val_Label_loss: 0.3515 - val_loss: 0.3600\n",
      "Epoch 74/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8867 - Domain_loss: 0.3400 - Label_accuracy: 0.9342 - Label_loss: 0.1710 - loss: 0.5110 - val_Domain_accuracy: 0.1118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8975 - val_Label_loss: 0.3229 - val_loss: 0.3315\n",
      "Epoch 75/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8907 - Domain_loss: 0.3265 - Label_accuracy: 0.9366 - Label_loss: 0.1703 - loss: 0.4968 - val_Domain_accuracy: 0.0911 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8830 - val_Label_loss: 0.3712 - val_loss: 0.3806\n",
      "Epoch 76/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8855 - Domain_loss: 0.3387 - Label_accuracy: 0.9339 - Label_loss: 0.1676 - loss: 0.5063 - val_Domain_accuracy: 0.1667 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8965 - val_Label_loss: 0.3849 - val_loss: 0.3946\n",
      "Epoch 77/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8876 - Domain_loss: 0.3260 - Label_accuracy: 0.9265 - Label_loss: 0.1813 - loss: 0.5073 - val_Domain_accuracy: 0.1687 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8892 - val_Label_loss: 0.4194 - val_loss: 0.4297\n",
      "Epoch 78/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8973 - Domain_loss: 0.3051 - Label_accuracy: 0.9359 - Label_loss: 0.1651 - loss: 0.4702 - val_Domain_accuracy: 0.2164 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8934 - val_Label_loss: 0.3495 - val_loss: 0.3583\n",
      "Epoch 79/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8854 - Domain_loss: 0.3266 - Label_accuracy: 0.9388 - Label_loss: 0.1546 - loss: 0.4812 - val_Domain_accuracy: 0.1180 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9027 - val_Label_loss: 0.2880 - val_loss: 0.2955\n",
      "Epoch 80/80\n",
      "237/237 - 8s - 33ms/step - Domain_accuracy: 0.8932 - Domain_loss: 0.3174 - Label_accuracy: 0.9379 - Label_loss: 0.1620 - loss: 0.4794 - val_Domain_accuracy: 0.1284 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8561 - val_Label_loss: 0.4908 - val_loss: 0.5035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 8\n",
      "train_feature shape: (7614, 5, 10, 256)\n",
      "train_targets shape: (7614, 5)\n",
      "train_domin shape: (7614, 9)\n",
      "Epoch 1/80\n",
      "238/238 - 17s - 71ms/step - Domain_accuracy: 0.4295 - Domain_loss: 1.7549 - Label_accuracy: 0.7193 - Label_loss: 0.8616 - loss: 2.6167 - val_Domain_accuracy: 0.1412 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6845 - val_Label_loss: 1.0018 - val_loss: 1.0280\n",
      "Epoch 2/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.6061 - Domain_loss: 1.1481 - Label_accuracy: 0.7951 - Label_loss: 0.5392 - loss: 1.6873 - val_Domain_accuracy: 0.0321 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7797 - val_Label_loss: 0.6036 - val_loss: 0.6172\n",
      "Epoch 3/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.6605 - Domain_loss: 0.9784 - Label_accuracy: 0.8119 - Label_loss: 0.4813 - loss: 1.4596 - val_Domain_accuracy: 0.0460 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7743 - val_Label_loss: 0.5525 - val_loss: 0.5616\n",
      "Epoch 4/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.6977 - Domain_loss: 0.8977 - Label_accuracy: 0.8235 - Label_loss: 0.4521 - loss: 1.3497 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8043 - val_Label_loss: 0.5609 - val_loss: 0.5714\n",
      "Epoch 5/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.7216 - Domain_loss: 0.8235 - Label_accuracy: 0.8357 - Label_loss: 0.4194 - loss: 1.2429 - val_Domain_accuracy: 0.0278 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7711 - val_Label_loss: 0.5818 - val_loss: 0.5936\n",
      "Epoch 6/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.7439 - Domain_loss: 0.7709 - Label_accuracy: 0.8346 - Label_loss: 0.4135 - loss: 1.1844 - val_Domain_accuracy: 0.0963 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7690 - val_Label_loss: 0.6307 - val_loss: 0.6458\n",
      "Epoch 7/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.7645 - Domain_loss: 0.7199 - Label_accuracy: 0.8415 - Label_loss: 0.3926 - loss: 1.1126 - val_Domain_accuracy: 0.0257 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 0.6166 - val_loss: 0.6275\n",
      "Epoch 8/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.7595 - Domain_loss: 0.7304 - Label_accuracy: 0.8466 - Label_loss: 0.3846 - loss: 1.1149 - val_Domain_accuracy: 0.0321 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7840 - val_Label_loss: 0.5910 - val_loss: 0.5890\n",
      "Epoch 9/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.7671 - Domain_loss: 0.7154 - Label_accuracy: 0.8487 - Label_loss: 0.3747 - loss: 1.0902 - val_Domain_accuracy: 0.0513 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.6293 - val_loss: 0.6383\n",
      "Epoch 10/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.7851 - Domain_loss: 0.6344 - Label_accuracy: 0.8537 - Label_loss: 0.3688 - loss: 1.0033 - val_Domain_accuracy: 0.0556 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.5662 - val_loss: 0.5746\n",
      "Epoch 11/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.7959 - Domain_loss: 0.6089 - Label_accuracy: 0.8599 - Label_loss: 0.3582 - loss: 0.9670 - val_Domain_accuracy: 0.0235 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7775 - val_Label_loss: 0.6701 - val_loss: 0.6769\n",
      "Epoch 12/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8130 - Domain_loss: 0.5796 - Label_accuracy: 0.8595 - Label_loss: 0.3544 - loss: 0.9342 - val_Domain_accuracy: 0.0139 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7636 - val_Label_loss: 0.7984 - val_loss: 0.8127\n",
      "Epoch 13/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8148 - Domain_loss: 0.5520 - Label_accuracy: 0.8621 - Label_loss: 0.3472 - loss: 0.8992 - val_Domain_accuracy: 0.0246 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7882 - val_Label_loss: 0.5868 - val_loss: 0.5969\n",
      "Epoch 14/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8117 - Domain_loss: 0.5560 - Label_accuracy: 0.8679 - Label_loss: 0.3420 - loss: 0.8979 - val_Domain_accuracy: 0.0439 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 0.5853 - val_loss: 0.5915\n",
      "Epoch 15/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8077 - Domain_loss: 0.5774 - Label_accuracy: 0.8718 - Label_loss: 0.3201 - loss: 0.8973 - val_Domain_accuracy: 0.0246 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.5904 - val_loss: 0.6026\n",
      "Epoch 16/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8210 - Domain_loss: 0.5420 - Label_accuracy: 0.8662 - Label_loss: 0.3372 - loss: 0.8792 - val_Domain_accuracy: 0.0075 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7882 - val_Label_loss: 0.6129 - val_loss: 0.6256\n",
      "Epoch 17/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8340 - Domain_loss: 0.5073 - Label_accuracy: 0.8775 - Label_loss: 0.3113 - loss: 0.8186 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7968 - val_Label_loss: 0.6895 - val_loss: 0.7039\n",
      "Epoch 18/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8298 - Domain_loss: 0.5039 - Label_accuracy: 0.8730 - Label_loss: 0.3145 - loss: 0.8183 - val_Domain_accuracy: 0.0610 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8043 - val_Label_loss: 0.6299 - val_loss: 0.6359\n",
      "Epoch 19/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8461 - Domain_loss: 0.4485 - Label_accuracy: 0.8796 - Label_loss: 0.3017 - loss: 0.7502 - val_Domain_accuracy: 0.0588 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7807 - val_Label_loss: 0.6843 - val_loss: 0.7012\n",
      "Epoch 20/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8495 - Domain_loss: 0.4441 - Label_accuracy: 0.8759 - Label_loss: 0.3024 - loss: 0.7465 - val_Domain_accuracy: 0.0075 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7701 - val_Label_loss: 0.6769 - val_loss: 0.6876\n",
      "Epoch 21/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8454 - Domain_loss: 0.4814 - Label_accuracy: 0.8794 - Label_loss: 0.2960 - loss: 0.7774 - val_Domain_accuracy: 0.0374 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8064 - val_Label_loss: 0.5933 - val_loss: 0.6031\n",
      "Epoch 22/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8415 - Domain_loss: 0.4845 - Label_accuracy: 0.8846 - Label_loss: 0.2902 - loss: 0.7748 - val_Domain_accuracy: 0.0374 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8032 - val_Label_loss: 0.6417 - val_loss: 0.6488\n",
      "Epoch 23/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8369 - Domain_loss: 0.4806 - Label_accuracy: 0.8890 - Label_loss: 0.2806 - loss: 0.7613 - val_Domain_accuracy: 0.0225 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7818 - val_Label_loss: 0.7411 - val_loss: 0.7591\n",
      "Epoch 24/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8413 - Domain_loss: 0.4669 - Label_accuracy: 0.8889 - Label_loss: 0.2782 - loss: 0.7450 - val_Domain_accuracy: 0.0032 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8139 - val_Label_loss: 0.6509 - val_loss: 0.6644\n",
      "Epoch 25/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8458 - Domain_loss: 0.4483 - Label_accuracy: 0.8973 - Label_loss: 0.2717 - loss: 0.7201 - val_Domain_accuracy: 0.0246 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7979 - val_Label_loss: 0.6340 - val_loss: 0.6445\n",
      "Epoch 26/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8444 - Domain_loss: 0.4603 - Label_accuracy: 0.8932 - Label_loss: 0.2694 - loss: 0.7296 - val_Domain_accuracy: 0.0043 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 0.7107 - val_loss: 0.7226\n",
      "Epoch 27/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8377 - Domain_loss: 0.4871 - Label_accuracy: 0.8865 - Label_loss: 0.2705 - loss: 0.7576 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7968 - val_Label_loss: 0.6591 - val_loss: 0.6717\n",
      "Epoch 28/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8562 - Domain_loss: 0.4191 - Label_accuracy: 0.8962 - Label_loss: 0.2537 - loss: 0.6728 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 0.6980 - val_loss: 0.7065\n",
      "Epoch 29/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8522 - Domain_loss: 0.4400 - Label_accuracy: 0.8948 - Label_loss: 0.2641 - loss: 0.7042 - val_Domain_accuracy: 0.0096 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7979 - val_Label_loss: 0.6331 - val_loss: 0.6453\n",
      "Epoch 30/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8524 - Domain_loss: 0.4361 - Label_accuracy: 0.9014 - Label_loss: 0.2498 - loss: 0.6859 - val_Domain_accuracy: 0.0225 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7765 - val_Label_loss: 0.7577 - val_loss: 0.7763\n",
      "Epoch 31/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8427 - Domain_loss: 0.4635 - Label_accuracy: 0.8994 - Label_loss: 0.2571 - loss: 0.7207 - val_Domain_accuracy: 0.0182 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7722 - val_Label_loss: 0.7997 - val_loss: 0.8189\n",
      "Epoch 32/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8441 - Domain_loss: 0.4581 - Label_accuracy: 0.9037 - Label_loss: 0.2416 - loss: 0.6996 - val_Domain_accuracy: 0.0075 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7904 - val_Label_loss: 0.7439 - val_loss: 0.7604\n",
      "Epoch 33/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8424 - Domain_loss: 0.4593 - Label_accuracy: 0.9039 - Label_loss: 0.2486 - loss: 0.7079 - val_Domain_accuracy: 0.0139 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7711 - val_Label_loss: 0.6768 - val_loss: 0.6745\n",
      "Epoch 34/80\n",
      "238/238 - 8s - 33ms/step - Domain_accuracy: 0.8588 - Domain_loss: 0.4170 - Label_accuracy: 0.9053 - Label_loss: 0.2435 - loss: 0.6604 - val_Domain_accuracy: 0.0214 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 0.7052 - val_loss: 0.7185\n",
      "Epoch 35/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8605 - Domain_loss: 0.4086 - Label_accuracy: 0.9033 - Label_loss: 0.2370 - loss: 0.6457 - val_Domain_accuracy: 0.0460 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.7205 - val_loss: 0.7376\n",
      "Epoch 36/80\n",
      "238/238 - 8s - 33ms/step - Domain_accuracy: 0.8567 - Domain_loss: 0.4319 - Label_accuracy: 0.9098 - Label_loss: 0.2263 - loss: 0.6583 - val_Domain_accuracy: 0.0278 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7583 - val_Label_loss: 0.8574 - val_loss: 0.8484\n",
      "Epoch 37/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8599 - Domain_loss: 0.4128 - Label_accuracy: 0.9096 - Label_loss: 0.2312 - loss: 0.6440 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8043 - val_Label_loss: 0.6736 - val_loss: 0.6883\n",
      "Epoch 38/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8621 - Domain_loss: 0.4125 - Label_accuracy: 0.9092 - Label_loss: 0.2242 - loss: 0.6366 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7626 - val_Label_loss: 0.8912 - val_loss: 0.8732\n",
      "Epoch 39/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8681 - Domain_loss: 0.3891 - Label_accuracy: 0.9138 - Label_loss: 0.2197 - loss: 0.6087 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 0.7683 - val_loss: 0.7745\n",
      "Epoch 40/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8629 - Domain_loss: 0.4051 - Label_accuracy: 0.9137 - Label_loss: 0.2217 - loss: 0.6267 - val_Domain_accuracy: 0.0417 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7957 - val_Label_loss: 0.7535 - val_loss: 0.7699\n",
      "Epoch 41/80\n",
      "238/238 - 8s - 33ms/step - Domain_accuracy: 0.8654 - Domain_loss: 0.3986 - Label_accuracy: 0.9144 - Label_loss: 0.2135 - loss: 0.6122 - val_Domain_accuracy: 0.0182 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7765 - val_Label_loss: 0.8188 - val_loss: 0.8325\n",
      "Epoch 42/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8688 - Domain_loss: 0.3793 - Label_accuracy: 0.9196 - Label_loss: 0.2079 - loss: 0.5872 - val_Domain_accuracy: 0.0406 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7893 - val_Label_loss: 0.9077 - val_loss: 0.9101\n",
      "Epoch 43/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8538 - Domain_loss: 0.4370 - Label_accuracy: 0.9213 - Label_loss: 0.2052 - loss: 0.6423 - val_Domain_accuracy: 0.0235 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 0.8274 - val_loss: 0.8485\n",
      "Epoch 44/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8639 - Domain_loss: 0.3978 - Label_accuracy: 0.9132 - Label_loss: 0.2139 - loss: 0.6118 - val_Domain_accuracy: 0.0193 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7775 - val_Label_loss: 0.9014 - val_loss: 0.9178\n",
      "Epoch 45/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8599 - Domain_loss: 0.4213 - Label_accuracy: 0.9259 - Label_loss: 0.1944 - loss: 0.6157 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7904 - val_Label_loss: 0.8058 - val_loss: 0.8179\n",
      "Epoch 46/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8459 - Domain_loss: 0.4589 - Label_accuracy: 0.9153 - Label_loss: 0.2106 - loss: 0.6696 - val_Domain_accuracy: 0.0150 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7829 - val_Label_loss: 0.8513 - val_loss: 0.8728\n",
      "Epoch 47/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8646 - Domain_loss: 0.3993 - Label_accuracy: 0.9232 - Label_loss: 0.1957 - loss: 0.5949 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7765 - val_Label_loss: 0.9009 - val_loss: 0.9160\n",
      "Epoch 48/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8543 - Domain_loss: 0.4351 - Label_accuracy: 0.9233 - Label_loss: 0.1965 - loss: 0.6316 - val_Domain_accuracy: 0.0182 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7829 - val_Label_loss: 0.8237 - val_loss: 0.8382\n",
      "Epoch 49/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8621 - Domain_loss: 0.4126 - Label_accuracy: 0.9205 - Label_loss: 0.1981 - loss: 0.6107 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7840 - val_Label_loss: 0.9575 - val_loss: 0.9794\n",
      "Epoch 50/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8631 - Domain_loss: 0.4065 - Label_accuracy: 0.9257 - Label_loss: 0.1998 - loss: 0.6062 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7807 - val_Label_loss: 0.8368 - val_loss: 0.8506\n",
      "Epoch 51/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8549 - Domain_loss: 0.4355 - Label_accuracy: 0.9219 - Label_loss: 0.2032 - loss: 0.6387 - val_Domain_accuracy: 0.0214 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7914 - val_Label_loss: 0.7463 - val_loss: 0.7608\n",
      "Epoch 52/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8681 - Domain_loss: 0.3929 - Label_accuracy: 0.9271 - Label_loss: 0.1786 - loss: 0.5716 - val_Domain_accuracy: 0.0321 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7807 - val_Label_loss: 0.8554 - val_loss: 0.8732\n",
      "Epoch 53/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8607 - Domain_loss: 0.4135 - Label_accuracy: 0.9284 - Label_loss: 0.1829 - loss: 0.5963 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7893 - val_Label_loss: 0.8297 - val_loss: 0.8481\n",
      "Epoch 54/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8608 - Domain_loss: 0.3988 - Label_accuracy: 0.9230 - Label_loss: 0.1951 - loss: 0.5939 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7733 - val_Label_loss: 0.9463 - val_loss: 0.9661\n",
      "Epoch 55/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8695 - Domain_loss: 0.3953 - Label_accuracy: 0.9238 - Label_loss: 0.1917 - loss: 0.5869 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7701 - val_Label_loss: 0.9534 - val_loss: 0.9569\n",
      "Epoch 56/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8758 - Domain_loss: 0.3611 - Label_accuracy: 0.9250 - Label_loss: 0.1838 - loss: 0.5448 - val_Domain_accuracy: 0.0064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7722 - val_Label_loss: 0.9744 - val_loss: 0.9954\n",
      "Epoch 57/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8630 - Domain_loss: 0.3966 - Label_accuracy: 0.9333 - Label_loss: 0.1768 - loss: 0.5735 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7679 - val_Label_loss: 1.0324 - val_loss: 1.0563\n",
      "Epoch 58/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.8521 - Domain_loss: 0.4273 - Label_accuracy: 0.9275 - Label_loss: 0.1823 - loss: 0.6096 - val_Domain_accuracy: 0.0193 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 0.8862 - val_loss: 0.9088\n",
      "Epoch 59/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8562 - Domain_loss: 0.4372 - Label_accuracy: 0.9326 - Label_loss: 0.1713 - loss: 0.6083 - val_Domain_accuracy: 0.0139 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7743 - val_Label_loss: 1.0547 - val_loss: 1.0787\n",
      "Epoch 60/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8643 - Domain_loss: 0.3993 - Label_accuracy: 0.9297 - Label_loss: 0.1761 - loss: 0.5755 - val_Domain_accuracy: 0.0086 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7840 - val_Label_loss: 0.8824 - val_loss: 0.9035\n",
      "Epoch 61/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8643 - Domain_loss: 0.3961 - Label_accuracy: 0.9296 - Label_loss: 0.1790 - loss: 0.5752 - val_Domain_accuracy: 0.0096 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7818 - val_Label_loss: 1.0304 - val_loss: 1.0544\n",
      "Epoch 62/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8628 - Domain_loss: 0.3945 - Label_accuracy: 0.9335 - Label_loss: 0.1696 - loss: 0.5641 - val_Domain_accuracy: 0.0086 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7733 - val_Label_loss: 1.0088 - val_loss: 1.0323\n",
      "Epoch 63/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8727 - Domain_loss: 0.3785 - Label_accuracy: 0.9329 - Label_loss: 0.1703 - loss: 0.5487 - val_Domain_accuracy: 0.0267 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7850 - val_Label_loss: 0.9636 - val_loss: 0.9886\n",
      "Epoch 64/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8763 - Domain_loss: 0.3647 - Label_accuracy: 0.9351 - Label_loss: 0.1594 - loss: 0.5242 - val_Domain_accuracy: 0.0032 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7679 - val_Label_loss: 1.0011 - val_loss: 1.0158\n",
      "Epoch 65/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8708 - Domain_loss: 0.3744 - Label_accuracy: 0.9370 - Label_loss: 0.1584 - loss: 0.5329 - val_Domain_accuracy: 0.0086 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7882 - val_Label_loss: 0.9325 - val_loss: 0.9385\n",
      "Epoch 66/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8524 - Domain_loss: 0.4542 - Label_accuracy: 0.9354 - Label_loss: 0.1615 - loss: 0.6157 - val_Domain_accuracy: 0.0107 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7818 - val_Label_loss: 0.8868 - val_loss: 0.9068\n",
      "Epoch 67/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8752 - Domain_loss: 0.3574 - Label_accuracy: 0.9421 - Label_loss: 0.1551 - loss: 0.5125 - val_Domain_accuracy: 0.0193 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7701 - val_Label_loss: 1.0365 - val_loss: 1.0564\n",
      "Epoch 68/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8576 - Domain_loss: 0.4159 - Label_accuracy: 0.9385 - Label_loss: 0.1569 - loss: 0.5728 - val_Domain_accuracy: 0.0086 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7786 - val_Label_loss: 1.0154 - val_loss: 1.0355\n",
      "Epoch 69/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8696 - Domain_loss: 0.3829 - Label_accuracy: 0.9385 - Label_loss: 0.1615 - loss: 0.5444 - val_Domain_accuracy: 0.0160 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7840 - val_Label_loss: 1.1243 - val_loss: 1.1483\n",
      "Epoch 70/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8667 - Domain_loss: 0.3907 - Label_accuracy: 0.9381 - Label_loss: 0.1553 - loss: 0.5459 - val_Domain_accuracy: 0.0128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7775 - val_Label_loss: 0.9968 - val_loss: 1.0209\n",
      "Epoch 71/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8597 - Domain_loss: 0.4122 - Label_accuracy: 0.9376 - Label_loss: 0.1594 - loss: 0.5716 - val_Domain_accuracy: 0.0032 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7594 - val_Label_loss: 1.1521 - val_loss: 1.1715\n",
      "Epoch 72/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8685 - Domain_loss: 0.3845 - Label_accuracy: 0.9358 - Label_loss: 0.1624 - loss: 0.5469 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7668 - val_Label_loss: 1.0408 - val_loss: 1.0624\n",
      "Epoch 73/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8701 - Domain_loss: 0.3750 - Label_accuracy: 0.9392 - Label_loss: 0.1521 - loss: 0.5270 - val_Domain_accuracy: 0.0032 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7807 - val_Label_loss: 1.0715 - val_loss: 1.0962\n",
      "Epoch 74/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8652 - Domain_loss: 0.3857 - Label_accuracy: 0.9396 - Label_loss: 0.1590 - loss: 0.5446 - val_Domain_accuracy: 0.0107 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7754 - val_Label_loss: 1.1107 - val_loss: 1.1399\n",
      "Epoch 75/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8751 - Domain_loss: 0.3721 - Label_accuracy: 0.9477 - Label_loss: 0.1454 - loss: 0.5174 - val_Domain_accuracy: 0.0310 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7807 - val_Label_loss: 0.9774 - val_loss: 0.9991\n",
      "Epoch 76/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8727 - Domain_loss: 0.3849 - Label_accuracy: 0.9402 - Label_loss: 0.1580 - loss: 0.5429 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7722 - val_Label_loss: 0.9148 - val_loss: 0.9319\n",
      "Epoch 77/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8761 - Domain_loss: 0.3634 - Label_accuracy: 0.9404 - Label_loss: 0.1474 - loss: 0.5106 - val_Domain_accuracy: 0.0139 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7572 - val_Label_loss: 1.2522 - val_loss: 1.2725\n",
      "Epoch 78/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8738 - Domain_loss: 0.3631 - Label_accuracy: 0.9397 - Label_loss: 0.1534 - loss: 0.5166 - val_Domain_accuracy: 0.0075 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7540 - val_Label_loss: 1.2520 - val_loss: 1.2519\n",
      "Epoch 79/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8825 - Domain_loss: 0.3462 - Label_accuracy: 0.9425 - Label_loss: 0.1472 - loss: 0.4933 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7743 - val_Label_loss: 1.0073 - val_loss: 1.0299\n",
      "Epoch 80/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8658 - Domain_loss: 0.3743 - Label_accuracy: 0.9425 - Label_loss: 0.1480 - loss: 0.5223 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7668 - val_Label_loss: 1.0967 - val_loss: 1.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 9\n",
      "train_feature shape: (7787, 5, 10, 256)\n",
      "train_targets shape: (7787, 5)\n",
      "train_domin shape: (7787, 9)\n",
      "Epoch 1/80\n",
      "244/244 - 17s - 70ms/step - Domain_accuracy: 0.4913 - Domain_loss: 1.5453 - Label_accuracy: 0.7723 - Label_loss: 0.6994 - loss: 2.2476 - val_Domain_accuracy: 0.1798 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6955 - val_Label_loss: 0.9837 - val_loss: 0.9576\n",
      "Epoch 2/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.6700 - Domain_loss: 0.9558 - Label_accuracy: 0.8619 - Label_loss: 0.3588 - loss: 1.3150 - val_Domain_accuracy: 0.0472 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6575 - val_Label_loss: 1.0586 - val_loss: 1.0457\n",
      "Epoch 3/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.6843 - Domain_loss: 0.9045 - Label_accuracy: 0.8860 - Label_loss: 0.3021 - loss: 1.2081 - val_Domain_accuracy: 0.1955 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7349 - val_Label_loss: 1.0103 - val_loss: 0.9795\n",
      "Epoch 4/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.6967 - Domain_loss: 0.8799 - Label_accuracy: 0.8983 - Label_loss: 0.2700 - loss: 1.1493 - val_Domain_accuracy: 0.0131 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7192 - val_Label_loss: 0.9435 - val_loss: 0.9308\n",
      "Epoch 5/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7113 - Domain_loss: 0.8549 - Label_accuracy: 0.9100 - Label_loss: 0.2394 - loss: 1.0936 - val_Domain_accuracy: 0.1877 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7270 - val_Label_loss: 0.9743 - val_loss: 0.9634\n",
      "Epoch 6/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7539 - Domain_loss: 0.7143 - Label_accuracy: 0.9218 - Label_loss: 0.2046 - loss: 0.9197 - val_Domain_accuracy: 0.1050 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7598 - val_Label_loss: 0.9090 - val_loss: 0.8905\n",
      "Epoch 7/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7703 - Domain_loss: 0.6753 - Label_accuracy: 0.9260 - Label_loss: 0.1970 - loss: 0.8731 - val_Domain_accuracy: 0.2598 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7480 - val_Label_loss: 0.9152 - val_loss: 0.9090\n",
      "Epoch 8/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7453 - Domain_loss: 0.7464 - Label_accuracy: 0.9322 - Label_loss: 0.1845 - loss: 0.9313 - val_Domain_accuracy: 0.0971 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7402 - val_Label_loss: 1.0926 - val_loss: 1.0675\n",
      "Epoch 9/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7652 - Domain_loss: 0.6852 - Label_accuracy: 0.9339 - Label_loss: 0.1736 - loss: 0.8593 - val_Domain_accuracy: 0.2362 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7388 - val_Label_loss: 1.2482 - val_loss: 1.2232\n",
      "Epoch 10/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7916 - Domain_loss: 0.5983 - Label_accuracy: 0.9369 - Label_loss: 0.1622 - loss: 0.7608 - val_Domain_accuracy: 0.0879 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7480 - val_Label_loss: 1.1165 - val_loss: 1.0929\n",
      "Epoch 11/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7718 - Domain_loss: 0.6515 - Label_accuracy: 0.9414 - Label_loss: 0.1567 - loss: 0.8082 - val_Domain_accuracy: 0.5236 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7402 - val_Label_loss: 1.3650 - val_loss: 1.3612\n",
      "Epoch 12/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7981 - Domain_loss: 0.5845 - Label_accuracy: 0.9435 - Label_loss: 0.1505 - loss: 0.7355 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7507 - val_Label_loss: 1.0979 - val_loss: 1.0726\n",
      "Epoch 13/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7861 - Domain_loss: 0.6430 - Label_accuracy: 0.9435 - Label_loss: 0.1417 - loss: 0.7850 - val_Domain_accuracy: 0.0630 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7257 - val_Label_loss: 1.2256 - val_loss: 1.1917\n",
      "Epoch 14/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7995 - Domain_loss: 0.5768 - Label_accuracy: 0.9500 - Label_loss: 0.1256 - loss: 0.7027 - val_Domain_accuracy: 0.1667 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7244 - val_Label_loss: 1.4063 - val_loss: 1.3901\n",
      "Epoch 15/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8003 - Domain_loss: 0.5623 - Label_accuracy: 0.9531 - Label_loss: 0.1280 - loss: 0.6907 - val_Domain_accuracy: 0.0919 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7493 - val_Label_loss: 1.1476 - val_loss: 1.1362\n",
      "Epoch 16/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8017 - Domain_loss: 0.5814 - Label_accuracy: 0.9543 - Label_loss: 0.1250 - loss: 0.7040 - val_Domain_accuracy: 0.0407 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7362 - val_Label_loss: 1.3466 - val_loss: 1.3242\n",
      "Epoch 17/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7835 - Domain_loss: 0.6362 - Label_accuracy: 0.9540 - Label_loss: 0.1271 - loss: 0.7627 - val_Domain_accuracy: 0.0486 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7310 - val_Label_loss: 1.1544 - val_loss: 1.1495\n",
      "Epoch 18/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7864 - Domain_loss: 0.6190 - Label_accuracy: 0.9542 - Label_loss: 0.1202 - loss: 0.7390 - val_Domain_accuracy: 0.0761 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7559 - val_Label_loss: 1.1698 - val_loss: 1.1585\n",
      "Epoch 19/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7999 - Domain_loss: 0.5844 - Label_accuracy: 0.9583 - Label_loss: 0.1158 - loss: 0.6995 - val_Domain_accuracy: 0.0945 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7572 - val_Label_loss: 1.0331 - val_loss: 1.0157\n",
      "Epoch 20/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7945 - Domain_loss: 0.5918 - Label_accuracy: 0.9579 - Label_loss: 0.1140 - loss: 0.7061 - val_Domain_accuracy: 0.1181 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7520 - val_Label_loss: 1.2664 - val_loss: 1.2478\n",
      "Epoch 21/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8051 - Domain_loss: 0.5619 - Label_accuracy: 0.9615 - Label_loss: 0.1005 - loss: 0.6601 - val_Domain_accuracy: 0.0853 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7572 - val_Label_loss: 1.2145 - val_loss: 1.2033\n",
      "Epoch 22/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8048 - Domain_loss: 0.5566 - Label_accuracy: 0.9620 - Label_loss: 0.1020 - loss: 0.6580 - val_Domain_accuracy: 0.1745 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7336 - val_Label_loss: 1.5063 - val_loss: 1.4956\n",
      "Epoch 23/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8262 - Domain_loss: 0.5043 - Label_accuracy: 0.9633 - Label_loss: 0.0915 - loss: 0.5962 - val_Domain_accuracy: 0.0420 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7507 - val_Label_loss: 1.2735 - val_loss: 1.2521\n",
      "Epoch 24/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8224 - Domain_loss: 0.5087 - Label_accuracy: 0.9683 - Label_loss: 0.0873 - loss: 0.5969 - val_Domain_accuracy: 0.0735 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7428 - val_Label_loss: 1.3663 - val_loss: 1.3497\n",
      "Epoch 25/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8219 - Domain_loss: 0.5180 - Label_accuracy: 0.9647 - Label_loss: 0.0945 - loss: 0.6130 - val_Domain_accuracy: 0.0472 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7493 - val_Label_loss: 1.3268 - val_loss: 1.3053\n",
      "Epoch 26/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8358 - Domain_loss: 0.4721 - Label_accuracy: 0.9702 - Label_loss: 0.0799 - loss: 0.5526 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6549 - val_Label_loss: 2.2355 - val_loss: 2.2106\n",
      "Epoch 27/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8040 - Domain_loss: 0.5654 - Label_accuracy: 0.9652 - Label_loss: 0.0916 - loss: 0.6574 - val_Domain_accuracy: 0.0525 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7415 - val_Label_loss: 1.4986 - val_loss: 1.4635\n",
      "Epoch 28/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7993 - Domain_loss: 0.5770 - Label_accuracy: 0.9653 - Label_loss: 0.0966 - loss: 0.6742 - val_Domain_accuracy: 0.0433 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7493 - val_Label_loss: 1.3624 - val_loss: 1.3514\n",
      "Epoch 29/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7911 - Domain_loss: 0.6099 - Label_accuracy: 0.9701 - Label_loss: 0.0810 - loss: 0.6915 - val_Domain_accuracy: 0.0617 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7533 - val_Label_loss: 1.2259 - val_loss: 1.2118\n",
      "Epoch 30/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8114 - Domain_loss: 0.5506 - Label_accuracy: 0.9662 - Label_loss: 0.0943 - loss: 0.6428 - val_Domain_accuracy: 0.0486 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6732 - val_Label_loss: 1.9597 - val_loss: 1.9314\n",
      "Epoch 31/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8030 - Domain_loss: 0.5556 - Label_accuracy: 0.9698 - Label_loss: 0.0816 - loss: 0.6382 - val_Domain_accuracy: 0.1759 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7612 - val_Label_loss: 1.4550 - val_loss: 1.4502\n",
      "Epoch 32/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8359 - Domain_loss: 0.4723 - Label_accuracy: 0.9750 - Label_loss: 0.0691 - loss: 0.5410 - val_Domain_accuracy: 0.1352 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7703 - val_Label_loss: 1.4261 - val_loss: 1.4004\n",
      "Epoch 33/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8144 - Domain_loss: 0.5431 - Label_accuracy: 0.9675 - Label_loss: 0.0808 - loss: 0.6237 - val_Domain_accuracy: 0.0932 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7388 - val_Label_loss: 1.5704 - val_loss: 1.5630\n",
      "Epoch 34/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8200 - Domain_loss: 0.5172 - Label_accuracy: 0.9688 - Label_loss: 0.0893 - loss: 0.6068 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7310 - val_Label_loss: 1.6714 - val_loss: 1.6520\n",
      "Epoch 35/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8491 - Domain_loss: 0.4359 - Label_accuracy: 0.9755 - Label_loss: 0.0653 - loss: 0.4989 - val_Domain_accuracy: 0.0538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7467 - val_Label_loss: 1.4694 - val_loss: 1.4514\n",
      "Epoch 36/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8503 - Domain_loss: 0.4273 - Label_accuracy: 0.9737 - Label_loss: 0.0686 - loss: 0.4966 - val_Domain_accuracy: 0.1194 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7336 - val_Label_loss: 1.8666 - val_loss: 1.8291\n",
      "Epoch 37/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8301 - Domain_loss: 0.4796 - Label_accuracy: 0.9757 - Label_loss: 0.0660 - loss: 0.5454 - val_Domain_accuracy: 0.0157 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7231 - val_Label_loss: 1.7580 - val_loss: 1.7266\n",
      "Epoch 38/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8319 - Domain_loss: 0.4683 - Label_accuracy: 0.9752 - Label_loss: 0.0702 - loss: 0.5372 - val_Domain_accuracy: 0.0709 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7388 - val_Label_loss: 1.6147 - val_loss: 1.5906\n",
      "Epoch 39/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8384 - Domain_loss: 0.4713 - Label_accuracy: 0.9706 - Label_loss: 0.0762 - loss: 0.5474 - val_Domain_accuracy: 0.0669 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7638 - val_Label_loss: 1.5991 - val_loss: 1.5827\n",
      "Epoch 40/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8327 - Domain_loss: 0.4740 - Label_accuracy: 0.9764 - Label_loss: 0.0697 - loss: 0.5447 - val_Domain_accuracy: 0.1010 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7598 - val_Label_loss: 1.5235 - val_loss: 1.5077\n",
      "Epoch 41/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8458 - Domain_loss: 0.4464 - Label_accuracy: 0.9777 - Label_loss: 0.0602 - loss: 0.5071 - val_Domain_accuracy: 0.0774 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7493 - val_Label_loss: 1.5650 - val_loss: 1.5511\n",
      "Epoch 42/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8328 - Domain_loss: 0.4818 - Label_accuracy: 0.9735 - Label_loss: 0.0699 - loss: 0.5504 - val_Domain_accuracy: 0.0354 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7375 - val_Label_loss: 1.6378 - val_loss: 1.6307\n",
      "Epoch 43/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8381 - Domain_loss: 0.4637 - Label_accuracy: 0.9764 - Label_loss: 0.0600 - loss: 0.5242 - val_Domain_accuracy: 0.2113 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7467 - val_Label_loss: 1.8595 - val_loss: 1.8328\n",
      "Epoch 44/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8406 - Domain_loss: 0.4678 - Label_accuracy: 0.9813 - Label_loss: 0.0527 - loss: 0.5206 - val_Domain_accuracy: 0.0932 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7454 - val_Label_loss: 1.7966 - val_loss: 1.7561\n",
      "Epoch 45/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8316 - Domain_loss: 0.4778 - Label_accuracy: 0.9764 - Label_loss: 0.0654 - loss: 0.5441 - val_Domain_accuracy: 0.0367 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7362 - val_Label_loss: 1.6124 - val_loss: 1.5968\n",
      "Epoch 46/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8436 - Domain_loss: 0.4474 - Label_accuracy: 0.9780 - Label_loss: 0.0558 - loss: 0.5032 - val_Domain_accuracy: 0.2178 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7480 - val_Label_loss: 1.6197 - val_loss: 1.6040\n",
      "Epoch 47/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8322 - Domain_loss: 0.4750 - Label_accuracy: 0.9791 - Label_loss: 0.0570 - loss: 0.5297 - val_Domain_accuracy: 0.0801 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7283 - val_Label_loss: 1.8018 - val_loss: 1.7794\n",
      "Epoch 48/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8307 - Domain_loss: 0.4805 - Label_accuracy: 0.9769 - Label_loss: 0.0623 - loss: 0.5431 - val_Domain_accuracy: 0.0420 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7546 - val_Label_loss: 1.5590 - val_loss: 1.5496\n",
      "Epoch 49/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8438 - Domain_loss: 0.4645 - Label_accuracy: 0.9798 - Label_loss: 0.0563 - loss: 0.5194 - val_Domain_accuracy: 0.0381 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7205 - val_Label_loss: 1.8089 - val_loss: 1.7838\n",
      "Epoch 50/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8387 - Domain_loss: 0.4565 - Label_accuracy: 0.9810 - Label_loss: 0.0527 - loss: 0.5094 - val_Domain_accuracy: 0.0814 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7402 - val_Label_loss: 1.8614 - val_loss: 1.8266\n",
      "Epoch 51/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8399 - Domain_loss: 0.4727 - Label_accuracy: 0.9792 - Label_loss: 0.0574 - loss: 0.5296 - val_Domain_accuracy: 0.0538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7454 - val_Label_loss: 1.7498 - val_loss: 1.7159\n",
      "Epoch 52/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8283 - Domain_loss: 0.4967 - Label_accuracy: 0.9769 - Label_loss: 0.0641 - loss: 0.5607 - val_Domain_accuracy: 0.0157 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7297 - val_Label_loss: 2.0317 - val_loss: 2.0113\n",
      "Epoch 53/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8358 - Domain_loss: 0.4678 - Label_accuracy: 0.9809 - Label_loss: 0.0552 - loss: 0.5235 - val_Domain_accuracy: 0.0591 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7598 - val_Label_loss: 1.6724 - val_loss: 1.6463\n",
      "Epoch 54/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8480 - Domain_loss: 0.4296 - Label_accuracy: 0.9816 - Label_loss: 0.0439 - loss: 0.4730 - val_Domain_accuracy: 0.1417 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7454 - val_Label_loss: 1.7648 - val_loss: 1.7572\n",
      "Epoch 55/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8256 - Domain_loss: 0.5125 - Label_accuracy: 0.9798 - Label_loss: 0.0541 - loss: 0.5673 - val_Domain_accuracy: 0.1667 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7362 - val_Label_loss: 1.8543 - val_loss: 1.8292\n",
      "Epoch 56/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8370 - Domain_loss: 0.4704 - Label_accuracy: 0.9811 - Label_loss: 0.0542 - loss: 0.5258 - val_Domain_accuracy: 0.1680 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7375 - val_Label_loss: 1.9111 - val_loss: 1.8744\n",
      "Epoch 57/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8506 - Domain_loss: 0.4363 - Label_accuracy: 0.9827 - Label_loss: 0.0486 - loss: 0.4843 - val_Domain_accuracy: 0.0367 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7375 - val_Label_loss: 1.6693 - val_loss: 1.6494\n",
      "Epoch 58/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8472 - Domain_loss: 0.4411 - Label_accuracy: 0.9810 - Label_loss: 0.0479 - loss: 0.4898 - val_Domain_accuracy: 0.0249 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7467 - val_Label_loss: 1.8624 - val_loss: 1.8504\n",
      "Epoch 59/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8468 - Domain_loss: 0.4491 - Label_accuracy: 0.9811 - Label_loss: 0.0543 - loss: 0.5041 - val_Domain_accuracy: 0.0354 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7493 - val_Label_loss: 1.8881 - val_loss: 1.8549\n",
      "Epoch 60/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8536 - Domain_loss: 0.4193 - Label_accuracy: 0.9787 - Label_loss: 0.0589 - loss: 0.4778 - val_Domain_accuracy: 0.0814 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7533 - val_Label_loss: 1.9179 - val_loss: 1.8915\n",
      "Epoch 61/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8436 - Domain_loss: 0.4523 - Label_accuracy: 0.9827 - Label_loss: 0.0519 - loss: 0.5045 - val_Domain_accuracy: 0.1286 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7362 - val_Label_loss: 1.7511 - val_loss: 1.7354\n",
      "Epoch 62/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8464 - Domain_loss: 0.4434 - Label_accuracy: 0.9842 - Label_loss: 0.0415 - loss: 0.4849 - val_Domain_accuracy: 0.0315 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7231 - val_Label_loss: 2.0095 - val_loss: 1.9757\n",
      "Epoch 63/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8562 - Domain_loss: 0.4190 - Label_accuracy: 0.9855 - Label_loss: 0.0427 - loss: 0.4622 - val_Domain_accuracy: 0.1745 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7625 - val_Label_loss: 1.8382 - val_loss: 1.8145\n",
      "Epoch 64/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8361 - Domain_loss: 0.4864 - Label_accuracy: 0.9782 - Label_loss: 0.0572 - loss: 0.5437 - val_Domain_accuracy: 0.0354 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7428 - val_Label_loss: 2.1298 - val_loss: 2.0890\n",
      "Epoch 65/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8378 - Domain_loss: 0.4443 - Label_accuracy: 0.9851 - Label_loss: 0.0397 - loss: 0.4827 - val_Domain_accuracy: 0.0617 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7638 - val_Label_loss: 2.0839 - val_loss: 2.0384\n",
      "Epoch 66/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8300 - Domain_loss: 0.4844 - Label_accuracy: 0.9813 - Label_loss: 0.0552 - loss: 0.5392 - val_Domain_accuracy: 0.1719 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7428 - val_Label_loss: 2.1733 - val_loss: 2.1214\n",
      "Epoch 67/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8460 - Domain_loss: 0.4422 - Label_accuracy: 0.9825 - Label_loss: 0.0522 - loss: 0.4941 - val_Domain_accuracy: 0.0486 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7362 - val_Label_loss: 2.0008 - val_loss: 1.9649\n",
      "Epoch 68/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8379 - Domain_loss: 0.4677 - Label_accuracy: 0.9816 - Label_loss: 0.0516 - loss: 0.5194 - val_Domain_accuracy: 0.1260 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7493 - val_Label_loss: 1.9859 - val_loss: 1.9647\n",
      "Epoch 69/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8447 - Domain_loss: 0.4591 - Label_accuracy: 0.9845 - Label_loss: 0.0463 - loss: 0.5045 - val_Domain_accuracy: 0.0853 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7231 - val_Label_loss: 2.2869 - val_loss: 2.2592\n",
      "Epoch 70/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8476 - Domain_loss: 0.4373 - Label_accuracy: 0.9847 - Label_loss: 0.0406 - loss: 0.4783 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7402 - val_Label_loss: 2.1813 - val_loss: 2.1624\n",
      "Epoch 71/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8338 - Domain_loss: 0.4669 - Label_accuracy: 0.9845 - Label_loss: 0.0478 - loss: 0.5155 - val_Domain_accuracy: 0.1076 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7546 - val_Label_loss: 2.1645 - val_loss: 2.1159\n",
      "Epoch 72/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8454 - Domain_loss: 0.4378 - Label_accuracy: 0.9827 - Label_loss: 0.0485 - loss: 0.4867 - val_Domain_accuracy: 0.1089 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7572 - val_Label_loss: 1.8168 - val_loss: 1.7936\n",
      "Epoch 73/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8593 - Domain_loss: 0.4096 - Label_accuracy: 0.9859 - Label_loss: 0.0390 - loss: 0.4495 - val_Domain_accuracy: 0.1037 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7218 - val_Label_loss: 2.3103 - val_loss: 2.2739\n",
      "Epoch 74/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8555 - Domain_loss: 0.4160 - Label_accuracy: 0.9851 - Label_loss: 0.0437 - loss: 0.4589 - val_Domain_accuracy: 0.0577 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7323 - val_Label_loss: 2.2925 - val_loss: 2.2426\n",
      "Epoch 75/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8572 - Domain_loss: 0.4094 - Label_accuracy: 0.9869 - Label_loss: 0.0350 - loss: 0.4430 - val_Domain_accuracy: 0.0932 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7402 - val_Label_loss: 2.1965 - val_loss: 2.1676\n",
      "Epoch 76/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8292 - Domain_loss: 0.4966 - Label_accuracy: 0.9824 - Label_loss: 0.0513 - loss: 0.5472 - val_Domain_accuracy: 0.1312 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7218 - val_Label_loss: 2.1544 - val_loss: 2.1225\n",
      "Epoch 77/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8393 - Domain_loss: 0.4498 - Label_accuracy: 0.9845 - Label_loss: 0.0478 - loss: 0.4971 - val_Domain_accuracy: 0.1352 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7270 - val_Label_loss: 2.2862 - val_loss: 2.2613\n",
      "Epoch 78/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8581 - Domain_loss: 0.3923 - Label_accuracy: 0.9882 - Label_loss: 0.0315 - loss: 0.4241 - val_Domain_accuracy: 0.1142 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7349 - val_Label_loss: 2.3936 - val_loss: 2.3445\n",
      "Epoch 79/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8377 - Domain_loss: 0.4694 - Label_accuracy: 0.9829 - Label_loss: 0.0471 - loss: 0.5169 - val_Domain_accuracy: 0.1417 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7467 - val_Label_loss: 2.1457 - val_loss: 2.1316\n",
      "Epoch 80/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8462 - Domain_loss: 0.4484 - Label_accuracy: 0.9813 - Label_loss: 0.0547 - loss: 0.5031 - val_Domain_accuracy: 0.0774 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7270 - val_Label_loss: 2.3616 - val_loss: 2.3327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fit_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 134\u001b[0m\n\u001b[0;32m    131\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# 4. Final Results\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m fit_acc \u001b[38;5;241m=\u001b[39m \u001b[43mfit_acc\u001b[49m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(Fold_Num_c)\n\u001b[0;32m    135\u001b[0m fit_loss \u001b[38;5;241m=\u001b[39m fit_loss \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(Fold_Num_c)\n\u001b[0;32m    136\u001b[0m fit_val_loss \u001b[38;5;241m=\u001b[39m fit_val_loss \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(Fold_Num_c)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fit_acc' is not defined"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import shutil\n",
    "# import gc\n",
    "# import keras\n",
    "# import tensorflow as tf\n",
    "# from keras import backend as KTF\n",
    "# import argparse\n",
    "\n",
    "# from model.MSTGCN import build_MSTGCN\n",
    "# from model.DataGenerator import DominGenerator\n",
    "# from model.Utils import *\n",
    "\n",
    "# # Display setup\n",
    "# print(128 * '#')\n",
    "# print('Start to train MSTGCN.')\n",
    "\n",
    "# # 1. Get Configuration\n",
    "\n",
    "# # Configuration File Path (Manually Set in Jupyter Notebook)\n",
    "# config_file = \"./ISRUC.config\"  # Update with actual path\n",
    "# gpu_number = \"0\"  # Set GPU number or \"-1\" to use CPU\n",
    "# Path, _, cfgTrain, cfgModel = ReadConfig(config_file)\n",
    "\n",
    "# # Set GPU number or use CPU only\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_number\n",
    "# if gpu_number != \"-1\":\n",
    "#     config = tf.compat.v1.ConfigProto()\n",
    "#     config.gpu_options.allow_growth = True\n",
    "#     sess = tf.compat.v1.Session(config=config)\n",
    "#     print(\"Use GPU #\" + gpu_number)\n",
    "# else:\n",
    "#     print(\"Use CPU only\")\n",
    "\n",
    "# # 1.2. Analytic Parameters\n",
    "# channels = int(cfgTrain[\"channels\"])\n",
    "# fold = int(cfgTrain[\"fold\"])\n",
    "# context = int(cfgTrain[\"context\"])\n",
    "# num_epochs = int(cfgTrain[\"epoch\"])\n",
    "# batch_size = int(cfgTrain[\"batch_size\"])\n",
    "# optimizer = cfgTrain[\"optimizer\"]\n",
    "# learn_rate = float(cfgTrain[\"learn_rate\"])\n",
    "# lambda_GRL = float(cfgTrain[\"lambda_GRL\"])\n",
    "\n",
    "# dense_size = np.array(str.split(cfgModel[\"Globaldense\"], ','), dtype=int)\n",
    "# GLalpha = float(cfgModel[\"GLalpha\"])\n",
    "# num_of_chev_filters = int(cfgModel[\"cheb_filters\"])\n",
    "# num_of_time_filters = int(cfgModel[\"time_filters\"])\n",
    "# time_conv_strides = int(cfgModel[\"time_conv_strides\"])\n",
    "# time_conv_kernel = int(cfgModel[\"time_conv_kernel\"])\n",
    "# num_block = int(cfgModel[\"num_block\"])\n",
    "# cheb_k = int(cfgModel[\"cheb_k\"])\n",
    "# l1 = float(cfgModel[\"l1\"])\n",
    "# l2 = float(cfgModel[\"l2\"])\n",
    "# dropout = float(cfgModel[\"dropout\"])\n",
    "\n",
    "# # Create save path\n",
    "# if not os.path.exists(Path['Save']):\n",
    "#     os.makedirs(Path['Save'])\n",
    "# shutil.copyfile(config_file, Path['Save'] + \"last.config\")\n",
    "\n",
    "# # 2. Read Data\n",
    "# ReadList = np.load(Path['data'], allow_pickle=True)\n",
    "# Fold_Num = ReadList['Fold_len']\n",
    "\n",
    "# Dis_Conn = np.load(Path['disM'], allow_pickle=True)\n",
    "# L_DC = scaled_Laplacian(Dis_Conn)\n",
    "# cheb_poly_DC = cheb_polynomial(L_DC, cheb_k)\n",
    "\n",
    "# print(\"Read data successfully\")\n",
    "# Fold_Num_c = Fold_Num + 1 - context\n",
    "# print('Number of samples:', np.sum(Fold_Num), '(with context:', np.sum(Fold_Num_c), ')')\n",
    "\n",
    "# Dom_Generator = DominGenerator(Fold_Num_c)\n",
    "\n",
    "# # 3. Model Training (Cross-Validation)\n",
    "# all_scores = []\n",
    "# for i in range(fold):\n",
    "#     print(128 * '_')\n",
    "#     print('Fold #', i)\n",
    "    \n",
    "#     opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "#     regularizer = Instantiation_regularizer(l1, l2)\n",
    "    \n",
    "#     Features = np.load(Path['Save']+'Feature_'+str(i)+'.npz', allow_pickle=True)\n",
    "#     train_feature = Features['train_feature']\n",
    "#     val_feature = Features['val_feature']\n",
    "#     train_targets = Features['train_targets']\n",
    "#     val_targets = Features['val_targets']\n",
    "    \n",
    "#     train_feature, train_targets = AddContext_MultiSub(train_feature, train_targets,\n",
    "#                                                        np.delete(Fold_Num.copy(), i), context, i)\n",
    "#     val_feature, val_targets = AddContext_SingleSub(val_feature, val_targets, context)\n",
    "#     train_domin, val_domin = Dom_Generator.getFold(i)\n",
    "\n",
    "#     sample_shape = (val_feature.shape[1:])\n",
    "    \n",
    "#     model, model_p = build_MSTGCN(cheb_k, num_of_chev_filters, num_of_time_filters, time_conv_strides, cheb_poly_DC,\n",
    "#                                   time_conv_kernel, sample_shape, num_block, dense_size, opt, GLalpha, regularizer, \n",
    "#                                   dropout, lambda_GRL, num_classes=5, num_domain=9)\n",
    "    \n",
    "#     print(\"train_feature shape:\", train_feature.shape)\n",
    "#     print(\"train_targets shape:\", train_targets.shape)\n",
    "#     print(\"train_domin shape:\", train_domin.shape)\n",
    "\n",
    "#     history = model.fit(\n",
    "#         x=train_feature,\n",
    "#         y=[train_targets, train_domin],\n",
    "#         epochs=num_epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=True,\n",
    "#         validation_data=(val_feature, [val_targets, val_domin]),\n",
    "#         verbose=2,\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint(Path['Save']+'FeatureNet_Best_'+str(i)+'.h5',\n",
    "#                                            monitor='val_Label_acc',\n",
    "#                                            verbose=0,  \n",
    "#                                            save_best_only=True,\n",
    "#                                            save_weights_only=False, \n",
    "#                                            mode='auto',\n",
    "#                                            save_freq='epoch')] )\n",
    "    \n",
    "#     model.save(Path['Save']+'MSTGCN_Final_'+str(i)+'.h5')\n",
    "    \n",
    "#     saveFile = open(Path['Save'] + \"Result_MSTGCN.txt\", 'a+')\n",
    "#     print('Fold #'+str(i), file=saveFile)\n",
    "#     print(history.history, file=saveFile)\n",
    "#     saveFile.close()\n",
    "    \n",
    "#     keras.backend.clear_session()\n",
    "#     del model, model_p, train_feature, train_targets, val_feature, val_targets\n",
    "#     gc.collect()\n",
    "\n",
    "# # 4. Final Results\n",
    "\n",
    "# fit_acc = fit_acc / np.sum(Fold_Num_c)\n",
    "# fit_loss = fit_loss / np.sum(Fold_Num_c)\n",
    "# fit_val_loss = fit_val_loss / np.sum(Fold_Num_c)\n",
    "# fit_val_acc = fit_val_acc / np.sum(Fold_Num_c)\n",
    "\n",
    "# VariationCurve(fit_acc, fit_val_acc, 'Acc', Path['Save'], figsize=(9, 6))\n",
    "# VariationCurve(fit_loss, fit_val_loss, 'Loss', Path['Save'], figsize=(9, 6))\n",
    "\n",
    "# saveFile = open(Path['Save'] + \"Result_MSTGCN.txt\", 'a+')\n",
    "# print(history.history, file=saveFile)\n",
    "# saveFile.close()\n",
    "\n",
    "# print(128 * '_')\n",
    "# print('End of training MSTGCN.')\n",
    "# print(128 * '#')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_acc = 0.0\n",
    "# fit_loss = 0.0\n",
    "# fit_val_loss = 0.0\n",
    "# fit_val_acc = 0.0\n",
    "\n",
    "# fit_acc = fit_acc / np.sum(Fold_Num_c)\n",
    "# fit_loss = fit_loss / np.sum(Fold_Num_c)\n",
    "# fit_val_loss = fit_val_loss / np.sum(Fold_Num_c)\n",
    "# fit_val_acc = fit_val_acc / np.sum(Fold_Num_c)\n",
    "\n",
    "# VariationCurve(fit_acc, fit_val_acc, 'Acc', Path['Save'], figsize=(9, 6))\n",
    "# VariationCurve(fit_loss, fit_val_loss, 'Loss', Path['Save'], figsize=(9, 6))\n",
    "\n",
    "# saveFile = open(Path['Save'] + \"Result_MSTGCN.txt\", 'a+')\n",
    "# print(history.history, file=saveFile)\n",
    "# saveFile.close()\n",
    "\n",
    "# print(128 * '_')\n",
    "# print('End of training MSTGCN.')\n",
    "# print(128 * '#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################################################################\n",
      "Start to train MSTGCN.\n",
      "Config:  ./ISRUC.config\n",
      "Using GPU #0\n",
      "Read data successfully\n",
      "Number of samples: 8589 (with context: 8549)\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold #0\n",
      "train_feature shape: (7629, 5, 10, 256)\n",
      "train_targets shape: (7629, 5)\n",
      "train_domin shape: (7629, 9)\n",
      "Epoch 1/80\n",
      "239/239 - 16s - 69ms/step - Domain_accuracy: 0.4058 - Domain_loss: 1.7913 - Label_accuracy: 0.6326 - Label_loss: 1.0780 - loss: 2.8709 - val_Domain_accuracy: 0.1087 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7946 - val_Label_loss: 0.5582 - val_loss: 0.5616\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Victus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:209: UserWarning: Can save best model only with val_categorical_accuracy available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.5541 - Domain_loss: 1.2822 - Label_accuracy: 0.7339 - Label_loss: 0.6839 - loss: 1.9686 - val_Domain_accuracy: 0.0837 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7870 - val_Label_loss: 0.5777 - val_loss: 0.5819\n",
      "Epoch 3/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.6150 - Domain_loss: 1.1133 - Label_accuracy: 0.7603 - Label_loss: 0.6040 - loss: 1.7180 - val_Domain_accuracy: 0.3196 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8054 - val_Label_loss: 0.5259 - val_loss: 0.5293\n",
      "Epoch 4/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.6193 - Domain_loss: 1.1181 - Label_accuracy: 0.7759 - Label_loss: 0.5763 - loss: 1.6924 - val_Domain_accuracy: 0.0870 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8152 - val_Label_loss: 0.4878 - val_loss: 0.4910\n",
      "Epoch 5/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.6494 - Domain_loss: 1.0164 - Label_accuracy: 0.7803 - Label_loss: 0.5635 - loss: 1.5790 - val_Domain_accuracy: 0.3261 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7663 - val_Label_loss: 0.6905 - val_loss: 0.6949\n",
      "Epoch 6/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.6749 - Domain_loss: 0.9543 - Label_accuracy: 0.7950 - Label_loss: 0.5198 - loss: 1.4729 - val_Domain_accuracy: 0.3413 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8033 - val_Label_loss: 0.4952 - val_loss: 0.4985\n",
      "Epoch 7/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.6795 - Domain_loss: 0.9602 - Label_accuracy: 0.7975 - Label_loss: 0.5158 - loss: 1.4742 - val_Domain_accuracy: 0.1163 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8109 - val_Label_loss: 0.4640 - val_loss: 0.4660\n",
      "Epoch 8/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.6743 - Domain_loss: 0.9637 - Label_accuracy: 0.7998 - Label_loss: 0.5032 - loss: 1.4678 - val_Domain_accuracy: 0.2576 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8141 - val_Label_loss: 0.4663 - val_loss: 0.4684\n",
      "Epoch 9/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7119 - Domain_loss: 0.8740 - Label_accuracy: 0.8030 - Label_loss: 0.4902 - loss: 1.3641 - val_Domain_accuracy: 0.2957 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8315 - val_Label_loss: 0.4394 - val_loss: 0.4423\n",
      "Epoch 10/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.7068 - Domain_loss: 0.8920 - Label_accuracy: 0.8173 - Label_loss: 0.4635 - loss: 1.3546 - val_Domain_accuracy: 0.2033 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.5266 - val_loss: 0.5307\n",
      "Epoch 11/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7216 - Domain_loss: 0.8357 - Label_accuracy: 0.8157 - Label_loss: 0.4606 - loss: 1.2962 - val_Domain_accuracy: 0.3152 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8304 - val_Label_loss: 0.4475 - val_loss: 0.4509\n",
      "Epoch 12/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7340 - Domain_loss: 0.8014 - Label_accuracy: 0.8165 - Label_loss: 0.4625 - loss: 1.2632 - val_Domain_accuracy: 0.4022 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.5331 - val_loss: 0.5370\n",
      "Epoch 13/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7424 - Domain_loss: 0.7586 - Label_accuracy: 0.8157 - Label_loss: 0.4533 - loss: 1.2104 - val_Domain_accuracy: 0.3848 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8130 - val_Label_loss: 0.4830 - val_loss: 0.4868\n",
      "Epoch 14/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7393 - Domain_loss: 0.7671 - Label_accuracy: 0.8168 - Label_loss: 0.4571 - loss: 1.2249 - val_Domain_accuracy: 0.2228 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8033 - val_Label_loss: 0.4998 - val_loss: 0.5021\n",
      "Epoch 15/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7565 - Domain_loss: 0.7081 - Label_accuracy: 0.8299 - Label_loss: 0.4352 - loss: 1.1436 - val_Domain_accuracy: 0.3913 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7826 - val_Label_loss: 0.5731 - val_loss: 0.5716\n",
      "Epoch 16/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7660 - Domain_loss: 0.6885 - Label_accuracy: 0.8300 - Label_loss: 0.4313 - loss: 1.1197 - val_Domain_accuracy: 0.3522 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8315 - val_Label_loss: 0.4336 - val_loss: 0.4347\n",
      "Epoch 17/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.7618 - Domain_loss: 0.7019 - Label_accuracy: 0.8265 - Label_loss: 0.4344 - loss: 1.1370 - val_Domain_accuracy: 0.2457 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8326 - val_Label_loss: 0.4479 - val_loss: 0.4503\n",
      "Epoch 18/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7643 - Domain_loss: 0.6994 - Label_accuracy: 0.8289 - Label_loss: 0.4286 - loss: 1.1277 - val_Domain_accuracy: 0.4098 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8207 - val_Label_loss: 0.4964 - val_loss: 0.4985\n",
      "Epoch 19/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7677 - Domain_loss: 0.6841 - Label_accuracy: 0.8321 - Label_loss: 0.4134 - loss: 1.0964 - val_Domain_accuracy: 0.2880 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8250 - val_Label_loss: 0.4720 - val_loss: 0.4733\n",
      "Epoch 20/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7717 - Domain_loss: 0.6687 - Label_accuracy: 0.8368 - Label_loss: 0.4020 - loss: 1.0708 - val_Domain_accuracy: 0.2935 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8217 - val_Label_loss: 0.4788 - val_loss: 0.4813\n",
      "Epoch 21/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.7844 - Domain_loss: 0.6368 - Label_accuracy: 0.8419 - Label_loss: 0.4077 - loss: 1.0457 - val_Domain_accuracy: 0.2022 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8239 - val_Label_loss: 0.4575 - val_loss: 0.4585\n",
      "Epoch 22/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7846 - Domain_loss: 0.6270 - Label_accuracy: 0.8453 - Label_loss: 0.3890 - loss: 1.0153 - val_Domain_accuracy: 0.3924 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8054 - val_Label_loss: 0.5965 - val_loss: 0.6010\n",
      "Epoch 23/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8014 - Domain_loss: 0.5743 - Label_accuracy: 0.8519 - Label_loss: 0.3847 - loss: 0.9587 - val_Domain_accuracy: 0.3728 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.6119 - val_loss: 0.6162\n",
      "Epoch 24/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7811 - Domain_loss: 0.6268 - Label_accuracy: 0.8439 - Label_loss: 0.3983 - loss: 1.0252 - val_Domain_accuracy: 0.3707 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8087 - val_Label_loss: 0.4779 - val_loss: 0.4802\n",
      "Epoch 25/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8085 - Domain_loss: 0.5594 - Label_accuracy: 0.8495 - Label_loss: 0.3711 - loss: 0.9309 - val_Domain_accuracy: 0.3152 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8087 - val_Label_loss: 0.5380 - val_loss: 0.5412\n",
      "Epoch 26/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8002 - Domain_loss: 0.5875 - Label_accuracy: 0.8514 - Label_loss: 0.3758 - loss: 0.9633 - val_Domain_accuracy: 0.3261 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8174 - val_Label_loss: 0.4770 - val_loss: 0.4801\n",
      "Epoch 27/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8085 - Domain_loss: 0.5621 - Label_accuracy: 0.8520 - Label_loss: 0.3670 - loss: 0.9277 - val_Domain_accuracy: 0.3120 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7772 - val_Label_loss: 0.6391 - val_loss: 0.6409\n",
      "Epoch 28/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8154 - Domain_loss: 0.5539 - Label_accuracy: 0.8559 - Label_loss: 0.3605 - loss: 0.9137 - val_Domain_accuracy: 0.3424 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8315 - val_Label_loss: 0.4737 - val_loss: 0.4769\n",
      "Epoch 29/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8000 - Domain_loss: 0.6081 - Label_accuracy: 0.8588 - Label_loss: 0.3606 - loss: 0.9696 - val_Domain_accuracy: 0.3348 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8120 - val_Label_loss: 0.5271 - val_loss: 0.5291\n",
      "Epoch 30/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8057 - Domain_loss: 0.5655 - Label_accuracy: 0.8561 - Label_loss: 0.3663 - loss: 0.9329 - val_Domain_accuracy: 0.2130 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8196 - val_Label_loss: 0.5522 - val_loss: 0.5566\n",
      "Epoch 31/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8102 - Domain_loss: 0.5528 - Label_accuracy: 0.8611 - Label_loss: 0.3556 - loss: 0.9088 - val_Domain_accuracy: 0.4293 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8152 - val_Label_loss: 0.5094 - val_loss: 0.5119\n",
      "Epoch 32/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8090 - Domain_loss: 0.5599 - Label_accuracy: 0.8596 - Label_loss: 0.3608 - loss: 0.9205 - val_Domain_accuracy: 0.2272 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8130 - val_Label_loss: 0.5593 - val_loss: 0.5631\n",
      "Epoch 33/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8085 - Domain_loss: 0.5664 - Label_accuracy: 0.8592 - Label_loss: 0.3524 - loss: 0.9194 - val_Domain_accuracy: 0.2739 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8022 - val_Label_loss: 0.5314 - val_loss: 0.5344\n",
      "Epoch 34/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.7992 - Domain_loss: 0.5825 - Label_accuracy: 0.8629 - Label_loss: 0.3416 - loss: 0.9227 - val_Domain_accuracy: 0.2815 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8207 - val_Label_loss: 0.5328 - val_loss: 0.5372\n",
      "Epoch 35/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8144 - Domain_loss: 0.5402 - Label_accuracy: 0.8671 - Label_loss: 0.3289 - loss: 0.8695 - val_Domain_accuracy: 0.2652 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8098 - val_Label_loss: 0.5334 - val_loss: 0.5371\n",
      "Epoch 36/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8119 - Domain_loss: 0.5446 - Label_accuracy: 0.8670 - Label_loss: 0.3393 - loss: 0.8828 - val_Domain_accuracy: 0.2902 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.5397 - val_loss: 0.5410\n",
      "Epoch 37/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8082 - Domain_loss: 0.5552 - Label_accuracy: 0.8609 - Label_loss: 0.3460 - loss: 0.9018 - val_Domain_accuracy: 0.4511 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7935 - val_Label_loss: 0.5701 - val_loss: 0.5744\n",
      "Epoch 38/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8145 - Domain_loss: 0.5450 - Label_accuracy: 0.8670 - Label_loss: 0.3305 - loss: 0.8763 - val_Domain_accuracy: 0.3793 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8054 - val_Label_loss: 0.5729 - val_loss: 0.5758\n",
      "Epoch 39/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8255 - Domain_loss: 0.5084 - Label_accuracy: 0.8708 - Label_loss: 0.3198 - loss: 0.8277 - val_Domain_accuracy: 0.2402 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8109 - val_Label_loss: 0.5197 - val_loss: 0.5219\n",
      "Epoch 40/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8181 - Domain_loss: 0.5289 - Label_accuracy: 0.8664 - Label_loss: 0.3303 - loss: 0.8578 - val_Domain_accuracy: 0.2913 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8185 - val_Label_loss: 0.5690 - val_loss: 0.5736\n",
      "Epoch 41/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8289 - Domain_loss: 0.5027 - Label_accuracy: 0.8698 - Label_loss: 0.3228 - loss: 0.8258 - val_Domain_accuracy: 0.2283 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7946 - val_Label_loss: 0.6211 - val_loss: 0.6228\n",
      "Epoch 42/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8185 - Domain_loss: 0.5286 - Label_accuracy: 0.8729 - Label_loss: 0.3259 - loss: 0.8548 - val_Domain_accuracy: 0.3098 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8228 - val_Label_loss: 0.4970 - val_loss: 0.4992\n",
      "Epoch 43/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8216 - Domain_loss: 0.5150 - Label_accuracy: 0.8799 - Label_loss: 0.3050 - loss: 0.8211 - val_Domain_accuracy: 0.2413 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8076 - val_Label_loss: 0.6068 - val_loss: 0.6097\n",
      "Epoch 44/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8145 - Domain_loss: 0.5326 - Label_accuracy: 0.8711 - Label_loss: 0.3239 - loss: 0.8569 - val_Domain_accuracy: 0.2500 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8185 - val_Label_loss: 0.5798 - val_loss: 0.5843\n",
      "Epoch 45/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8202 - Domain_loss: 0.5197 - Label_accuracy: 0.8782 - Label_loss: 0.3044 - loss: 0.8248 - val_Domain_accuracy: 0.2717 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8033 - val_Label_loss: 0.5611 - val_loss: 0.5642\n",
      "Epoch 46/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8215 - Domain_loss: 0.5063 - Label_accuracy: 0.8740 - Label_loss: 0.3128 - loss: 0.8207 - val_Domain_accuracy: 0.1598 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7967 - val_Label_loss: 0.5719 - val_loss: 0.5751\n",
      "Epoch 47/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8274 - Domain_loss: 0.4934 - Label_accuracy: 0.8844 - Label_loss: 0.2968 - loss: 0.7913 - val_Domain_accuracy: 0.2087 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8043 - val_Label_loss: 0.5562 - val_loss: 0.5587\n",
      "Epoch 48/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8365 - Domain_loss: 0.4588 - Label_accuracy: 0.8782 - Label_loss: 0.2957 - loss: 0.7558 - val_Domain_accuracy: 0.2500 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8380 - val_Label_loss: 0.5274 - val_loss: 0.5316\n",
      "Epoch 49/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8333 - Domain_loss: 0.4887 - Label_accuracy: 0.8849 - Label_loss: 0.2924 - loss: 0.7803 - val_Domain_accuracy: 0.2946 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8076 - val_Label_loss: 0.6367 - val_loss: 0.6415\n",
      "Epoch 50/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8293 - Domain_loss: 0.4806 - Label_accuracy: 0.8784 - Label_loss: 0.2988 - loss: 0.7800 - val_Domain_accuracy: 0.1989 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8152 - val_Label_loss: 0.5339 - val_loss: 0.5378\n",
      "Epoch 51/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8274 - Domain_loss: 0.4906 - Label_accuracy: 0.8849 - Label_loss: 0.2940 - loss: 0.7853 - val_Domain_accuracy: 0.3120 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8098 - val_Label_loss: 0.5905 - val_loss: 0.5952\n",
      "Epoch 52/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8401 - Domain_loss: 0.4671 - Label_accuracy: 0.8841 - Label_loss: 0.2832 - loss: 0.7500 - val_Domain_accuracy: 0.2022 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8098 - val_Label_loss: 0.5816 - val_loss: 0.5856\n",
      "Epoch 53/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8320 - Domain_loss: 0.4891 - Label_accuracy: 0.8878 - Label_loss: 0.2857 - loss: 0.7729 - val_Domain_accuracy: 0.3185 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8130 - val_Label_loss: 0.6592 - val_loss: 0.6647\n",
      "Epoch 54/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8347 - Domain_loss: 0.4874 - Label_accuracy: 0.8811 - Label_loss: 0.2997 - loss: 0.7869 - val_Domain_accuracy: 0.2598 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8033 - val_Label_loss: 0.6363 - val_loss: 0.6406\n",
      "Epoch 55/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8313 - Domain_loss: 0.4796 - Label_accuracy: 0.8822 - Label_loss: 0.2914 - loss: 0.7701 - val_Domain_accuracy: 0.2946 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.6169 - val_loss: 0.6204\n",
      "Epoch 56/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8329 - Domain_loss: 0.4839 - Label_accuracy: 0.8860 - Label_loss: 0.2846 - loss: 0.7691 - val_Domain_accuracy: 0.2511 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7804 - val_Label_loss: 0.7129 - val_loss: 0.7160\n",
      "Epoch 57/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8414 - Domain_loss: 0.4497 - Label_accuracy: 0.8882 - Label_loss: 0.2769 - loss: 0.7268 - val_Domain_accuracy: 0.2717 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8033 - val_Label_loss: 0.6065 - val_loss: 0.6108\n",
      "Epoch 58/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8225 - Domain_loss: 0.5143 - Label_accuracy: 0.8900 - Label_loss: 0.2911 - loss: 0.8051 - val_Domain_accuracy: 0.2772 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8141 - val_Label_loss: 0.5588 - val_loss: 0.5618\n",
      "Epoch 59/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8215 - Domain_loss: 0.5206 - Label_accuracy: 0.8870 - Label_loss: 0.2912 - loss: 0.8123 - val_Domain_accuracy: 0.2793 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 0.6724 - val_loss: 0.6767\n",
      "Epoch 60/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8364 - Domain_loss: 0.4560 - Label_accuracy: 0.8881 - Label_loss: 0.2782 - loss: 0.7347 - val_Domain_accuracy: 0.1989 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8163 - val_Label_loss: 0.5684 - val_loss: 0.5717\n",
      "Epoch 61/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8570 - Domain_loss: 0.4004 - Label_accuracy: 0.8940 - Label_loss: 0.2769 - loss: 0.6774 - val_Domain_accuracy: 0.1207 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8087 - val_Label_loss: 0.6004 - val_loss: 0.6040\n",
      "Epoch 62/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8426 - Domain_loss: 0.4522 - Label_accuracy: 0.8945 - Label_loss: 0.2723 - loss: 0.7244 - val_Domain_accuracy: 0.1000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7761 - val_Label_loss: 0.8386 - val_loss: 0.8434\n",
      "Epoch 63/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8531 - Domain_loss: 0.4268 - Label_accuracy: 0.8932 - Label_loss: 0.2685 - loss: 0.6958 - val_Domain_accuracy: 0.2283 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8239 - val_Label_loss: 0.5953 - val_loss: 0.6000\n",
      "Epoch 64/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8423 - Domain_loss: 0.4601 - Label_accuracy: 0.8919 - Label_loss: 0.2736 - loss: 0.7327 - val_Domain_accuracy: 0.1337 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8033 - val_Label_loss: 0.6557 - val_loss: 0.6573\n",
      "Epoch 65/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8424 - Domain_loss: 0.4554 - Label_accuracy: 0.8963 - Label_loss: 0.2632 - loss: 0.7184 - val_Domain_accuracy: 0.2304 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7913 - val_Label_loss: 0.6217 - val_loss: 0.6247\n",
      "Epoch 66/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8390 - Domain_loss: 0.4538 - Label_accuracy: 0.8920 - Label_loss: 0.2735 - loss: 0.7274 - val_Domain_accuracy: 0.1511 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8120 - val_Label_loss: 0.5963 - val_loss: 0.5996\n",
      "Epoch 67/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8512 - Domain_loss: 0.4274 - Label_accuracy: 0.8961 - Label_loss: 0.2638 - loss: 0.6917 - val_Domain_accuracy: 0.1283 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.6431 - val_loss: 0.6473\n",
      "Epoch 68/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8320 - Domain_loss: 0.4778 - Label_accuracy: 0.8996 - Label_loss: 0.2639 - loss: 0.7423 - val_Domain_accuracy: 0.0891 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7967 - val_Label_loss: 0.7127 - val_loss: 0.7164\n",
      "Epoch 69/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8479 - Domain_loss: 0.4296 - Label_accuracy: 0.8930 - Label_loss: 0.2567 - loss: 0.6868 - val_Domain_accuracy: 0.0967 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7913 - val_Label_loss: 0.6865 - val_loss: 0.6899\n",
      "Epoch 70/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8380 - Domain_loss: 0.4653 - Label_accuracy: 0.8949 - Label_loss: 0.2656 - loss: 0.7310 - val_Domain_accuracy: 0.2478 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7870 - val_Label_loss: 0.7805 - val_loss: 0.7862\n",
      "Epoch 71/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8542 - Domain_loss: 0.4227 - Label_accuracy: 0.8968 - Label_loss: 0.2595 - loss: 0.6828 - val_Domain_accuracy: 0.1065 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8065 - val_Label_loss: 0.6544 - val_loss: 0.6595\n",
      "Epoch 72/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8594 - Domain_loss: 0.4113 - Label_accuracy: 0.8997 - Label_loss: 0.2471 - loss: 0.6582 - val_Domain_accuracy: 0.1793 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 0.7215 - val_loss: 0.7268\n",
      "Epoch 73/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8561 - Domain_loss: 0.4151 - Label_accuracy: 0.9002 - Label_loss: 0.2453 - loss: 0.6611 - val_Domain_accuracy: 0.2804 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7870 - val_Label_loss: 0.7311 - val_loss: 0.7361\n",
      "Epoch 74/80\n",
      "239/239 - 7s - 31ms/step - Domain_accuracy: 0.8432 - Domain_loss: 0.4463 - Label_accuracy: 0.8992 - Label_loss: 0.2573 - loss: 0.7037 - val_Domain_accuracy: 0.1217 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 0.6612 - val_loss: 0.6648\n",
      "Epoch 75/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8493 - Domain_loss: 0.4289 - Label_accuracy: 0.9048 - Label_loss: 0.2436 - loss: 0.6735 - val_Domain_accuracy: 0.3011 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8076 - val_Label_loss: 0.6154 - val_loss: 0.6198\n",
      "Epoch 76/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8401 - Domain_loss: 0.4682 - Label_accuracy: 0.9016 - Label_loss: 0.2502 - loss: 0.7180 - val_Domain_accuracy: 0.2435 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8130 - val_Label_loss: 0.5555 - val_loss: 0.5579\n",
      "Epoch 77/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8512 - Domain_loss: 0.4160 - Label_accuracy: 0.9037 - Label_loss: 0.2454 - loss: 0.6618 - val_Domain_accuracy: 0.0848 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8239 - val_Label_loss: 0.6313 - val_loss: 0.6342\n",
      "Epoch 78/80\n",
      "239/239 - 8s - 31ms/step - Domain_accuracy: 0.8293 - Domain_loss: 0.5003 - Label_accuracy: 0.8985 - Label_loss: 0.2631 - loss: 0.7647 - val_Domain_accuracy: 0.2043 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8217 - val_Label_loss: 0.6136 - val_loss: 0.6177\n",
      "Epoch 79/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8352 - Domain_loss: 0.4737 - Label_accuracy: 0.8975 - Label_loss: 0.2517 - loss: 0.7261 - val_Domain_accuracy: 0.2848 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8022 - val_Label_loss: 0.6680 - val_loss: 0.6725\n",
      "Epoch 80/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8519 - Domain_loss: 0.4321 - Label_accuracy: 0.9048 - Label_loss: 0.2423 - loss: 0.6742 - val_Domain_accuracy: 0.1315 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8033 - val_Label_loss: 0.7077 - val_loss: 0.7130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #1\n",
      "train_feature shape: (7642, 5, 10, 256)\n",
      "train_targets shape: (7642, 5)\n",
      "train_domin shape: (7642, 9)\n",
      "Epoch 1/80\n",
      "239/239 - 16s - 68ms/step - Domain_accuracy: 0.4410 - Domain_loss: 1.7760 - Label_accuracy: 0.6856 - Label_loss: 1.0053 - loss: 2.7820 - val_Domain_accuracy: 0.0121 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7277 - val_Label_loss: 0.7567 - val_loss: 0.7541\n",
      "Epoch 2/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.6188 - Domain_loss: 1.1066 - Label_accuracy: 0.7736 - Label_loss: 0.5908 - loss: 1.6977 - val_Domain_accuracy: 0.3539 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7012 - val_Label_loss: 0.7865 - val_loss: 0.7914\n",
      "Epoch 3/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.6284 - Domain_loss: 1.0822 - Label_accuracy: 0.7965 - Label_loss: 0.5269 - loss: 1.6092 - val_Domain_accuracy: 0.2007 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7343 - val_Label_loss: 0.6514 - val_loss: 0.6542\n",
      "Epoch 4/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.6805 - Domain_loss: 0.9436 - Label_accuracy: 0.8088 - Label_loss: 0.4931 - loss: 1.4368 - val_Domain_accuracy: 0.0926 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7464 - val_Label_loss: 0.6987 - val_loss: 0.6979\n",
      "Epoch 5/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7078 - Domain_loss: 0.8733 - Label_accuracy: 0.8148 - Label_loss: 0.4772 - loss: 1.3504 - val_Domain_accuracy: 0.1709 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7255 - val_Label_loss: 0.6768 - val_loss: 0.6805\n",
      "Epoch 6/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7334 - Domain_loss: 0.7779 - Label_accuracy: 0.8274 - Label_loss: 0.4418 - loss: 1.2196 - val_Domain_accuracy: 0.0706 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7222 - val_Label_loss: 0.7765 - val_loss: 0.7823\n",
      "Epoch 7/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.7567 - Domain_loss: 0.7058 - Label_accuracy: 0.8295 - Label_loss: 0.4399 - loss: 1.1455 - val_Domain_accuracy: 0.2359 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7012 - val_Label_loss: 0.7862 - val_loss: 0.7939\n",
      "Epoch 8/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7539 - Domain_loss: 0.7383 - Label_accuracy: 0.8308 - Label_loss: 0.4203 - loss: 1.1586 - val_Domain_accuracy: 0.1356 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7288 - val_Label_loss: 0.7219 - val_loss: 0.7244\n",
      "Epoch 9/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7523 - Domain_loss: 0.7492 - Label_accuracy: 0.8401 - Label_loss: 0.4065 - loss: 1.1560 - val_Domain_accuracy: 0.2459 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7089 - val_Label_loss: 0.7863 - val_loss: 0.7951\n",
      "Epoch 10/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7476 - Domain_loss: 0.7649 - Label_accuracy: 0.8390 - Label_loss: 0.4139 - loss: 1.1787 - val_Domain_accuracy: 0.0739 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6516 - val_Label_loss: 0.9372 - val_loss: 0.9447\n",
      "Epoch 11/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7604 - Domain_loss: 0.6840 - Label_accuracy: 0.8445 - Label_loss: 0.3864 - loss: 1.0701 - val_Domain_accuracy: 0.2150 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6858 - val_Label_loss: 0.9009 - val_loss: 0.9038\n",
      "Epoch 12/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7590 - Domain_loss: 0.7278 - Label_accuracy: 0.8387 - Label_loss: 0.4012 - loss: 1.1291 - val_Domain_accuracy: 0.1577 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6979 - val_Label_loss: 0.8319 - val_loss: 0.8387\n",
      "Epoch 13/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7832 - Domain_loss: 0.6386 - Label_accuracy: 0.8427 - Label_loss: 0.3905 - loss: 1.0286 - val_Domain_accuracy: 0.0926 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6957 - val_Label_loss: 0.7980 - val_loss: 0.8089\n",
      "Epoch 14/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7727 - Domain_loss: 0.6737 - Label_accuracy: 0.8499 - Label_loss: 0.3736 - loss: 1.0474 - val_Domain_accuracy: 0.1907 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7067 - val_Label_loss: 0.8331 - val_loss: 0.8394\n",
      "Epoch 15/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7783 - Domain_loss: 0.6494 - Label_accuracy: 0.8551 - Label_loss: 0.3633 - loss: 1.0130 - val_Domain_accuracy: 0.1345 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7288 - val_Label_loss: 0.7191 - val_loss: 0.7268\n",
      "Epoch 16/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7921 - Domain_loss: 0.6043 - Label_accuracy: 0.8597 - Label_loss: 0.3529 - loss: 0.9571 - val_Domain_accuracy: 0.2326 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7398 - val_Label_loss: 0.6997 - val_loss: 0.7024\n",
      "Epoch 17/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8067 - Domain_loss: 0.5730 - Label_accuracy: 0.8579 - Label_loss: 0.3566 - loss: 0.9295 - val_Domain_accuracy: 0.0772 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6902 - val_Label_loss: 0.9593 - val_loss: 0.9696\n",
      "Epoch 18/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.7957 - Domain_loss: 0.5934 - Label_accuracy: 0.8587 - Label_loss: 0.3534 - loss: 0.9470 - val_Domain_accuracy: 0.1047 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7409 - val_Label_loss: 0.8618 - val_loss: 0.8677\n",
      "Epoch 19/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8195 - Domain_loss: 0.5354 - Label_accuracy: 0.8695 - Label_loss: 0.3282 - loss: 0.8635 - val_Domain_accuracy: 0.2128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7619 - val_Label_loss: 0.6852 - val_loss: 0.6866\n",
      "Epoch 20/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8050 - Domain_loss: 0.5672 - Label_accuracy: 0.8631 - Label_loss: 0.3457 - loss: 0.9129 - val_Domain_accuracy: 0.1929 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7144 - val_Label_loss: 0.8903 - val_loss: 0.9004\n",
      "Epoch 21/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8097 - Domain_loss: 0.5560 - Label_accuracy: 0.8626 - Label_loss: 0.3393 - loss: 0.8952 - val_Domain_accuracy: 0.1863 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7563 - val_Label_loss: 0.6915 - val_loss: 0.6959\n",
      "Epoch 22/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8202 - Domain_loss: 0.5380 - Label_accuracy: 0.8695 - Label_loss: 0.3294 - loss: 0.8670 - val_Domain_accuracy: 0.1246 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6836 - val_Label_loss: 0.9918 - val_loss: 1.0054\n",
      "Epoch 23/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8176 - Domain_loss: 0.5270 - Label_accuracy: 0.8646 - Label_loss: 0.3356 - loss: 0.8626 - val_Domain_accuracy: 0.1180 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7133 - val_Label_loss: 0.7574 - val_loss: 0.7640\n",
      "Epoch 24/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8193 - Domain_loss: 0.5218 - Label_accuracy: 0.8707 - Label_loss: 0.3284 - loss: 0.8501 - val_Domain_accuracy: 0.2128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6858 - val_Label_loss: 1.0773 - val_loss: 1.0937\n",
      "Epoch 25/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8337 - Domain_loss: 0.4885 - Label_accuracy: 0.8767 - Label_loss: 0.3088 - loss: 0.7974 - val_Domain_accuracy: 0.2370 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7045 - val_Label_loss: 0.9037 - val_loss: 0.9095\n",
      "Epoch 26/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8362 - Domain_loss: 0.4795 - Label_accuracy: 0.8752 - Label_loss: 0.3114 - loss: 0.7909 - val_Domain_accuracy: 0.3440 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7155 - val_Label_loss: 0.8281 - val_loss: 0.8364\n",
      "Epoch 27/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8328 - Domain_loss: 0.4925 - Label_accuracy: 0.8737 - Label_loss: 0.3092 - loss: 0.8018 - val_Domain_accuracy: 0.2095 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7354 - val_Label_loss: 0.8444 - val_loss: 0.8400\n",
      "Epoch 28/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8440 - Domain_loss: 0.4531 - Label_accuracy: 0.8778 - Label_loss: 0.3021 - loss: 0.7554 - val_Domain_accuracy: 0.1918 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7100 - val_Label_loss: 1.0573 - val_loss: 1.0609\n",
      "Epoch 29/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8337 - Domain_loss: 0.4910 - Label_accuracy: 0.8837 - Label_loss: 0.2966 - loss: 0.7875 - val_Domain_accuracy: 0.1323 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7100 - val_Label_loss: 1.0303 - val_loss: 1.0361\n",
      "Epoch 30/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8364 - Domain_loss: 0.4781 - Label_accuracy: 0.8811 - Label_loss: 0.2987 - loss: 0.7770 - val_Domain_accuracy: 0.2007 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7398 - val_Label_loss: 0.8531 - val_loss: 0.8584\n",
      "Epoch 31/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8473 - Domain_loss: 0.4498 - Label_accuracy: 0.8826 - Label_loss: 0.2914 - loss: 0.7411 - val_Domain_accuracy: 0.1709 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7398 - val_Label_loss: 0.7858 - val_loss: 0.7946\n",
      "Epoch 32/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8487 - Domain_loss: 0.4455 - Label_accuracy: 0.8839 - Label_loss: 0.2959 - loss: 0.7415 - val_Domain_accuracy: 0.1742 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7189 - val_Label_loss: 1.0526 - val_loss: 1.0653\n",
      "Epoch 33/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8451 - Domain_loss: 0.4361 - Label_accuracy: 0.8846 - Label_loss: 0.2839 - loss: 0.7201 - val_Domain_accuracy: 0.1720 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7288 - val_Label_loss: 0.8494 - val_loss: 0.8575\n",
      "Epoch 34/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8510 - Domain_loss: 0.4460 - Label_accuracy: 0.8911 - Label_loss: 0.2740 - loss: 0.7200 - val_Domain_accuracy: 0.1797 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7332 - val_Label_loss: 0.9477 - val_loss: 0.9558\n",
      "Epoch 35/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8496 - Domain_loss: 0.4339 - Label_accuracy: 0.8915 - Label_loss: 0.2783 - loss: 0.7120 - val_Domain_accuracy: 0.2183 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7122 - val_Label_loss: 1.0789 - val_loss: 1.0920\n",
      "Epoch 36/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8568 - Domain_loss: 0.4264 - Label_accuracy: 0.8911 - Label_loss: 0.2744 - loss: 0.7007 - val_Domain_accuracy: 0.1367 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7244 - val_Label_loss: 0.9378 - val_loss: 0.9443\n",
      "Epoch 37/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8635 - Domain_loss: 0.4059 - Label_accuracy: 0.8890 - Label_loss: 0.2651 - loss: 0.6712 - val_Domain_accuracy: 0.1477 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7144 - val_Label_loss: 1.0852 - val_loss: 1.0961\n",
      "Epoch 38/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8591 - Domain_loss: 0.4125 - Label_accuracy: 0.8964 - Label_loss: 0.2645 - loss: 0.6769 - val_Domain_accuracy: 0.1885 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7343 - val_Label_loss: 0.9534 - val_loss: 0.9523\n",
      "Epoch 39/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8541 - Domain_loss: 0.4289 - Label_accuracy: 0.8982 - Label_loss: 0.2595 - loss: 0.6887 - val_Domain_accuracy: 0.1191 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7277 - val_Label_loss: 0.8765 - val_loss: 0.8809\n",
      "Epoch 40/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8655 - Domain_loss: 0.3980 - Label_accuracy: 0.8971 - Label_loss: 0.2612 - loss: 0.6594 - val_Domain_accuracy: 0.1301 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7310 - val_Label_loss: 0.9485 - val_loss: 0.9465\n",
      "Epoch 41/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8448 - Domain_loss: 0.4607 - Label_accuracy: 0.8910 - Label_loss: 0.2731 - loss: 0.7340 - val_Domain_accuracy: 0.1731 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7078 - val_Label_loss: 1.0895 - val_loss: 1.0948\n",
      "Epoch 42/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8622 - Domain_loss: 0.4083 - Label_accuracy: 0.9032 - Label_loss: 0.2559 - loss: 0.6641 - val_Domain_accuracy: 0.0673 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7155 - val_Label_loss: 0.9161 - val_loss: 0.9234\n",
      "Epoch 43/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8706 - Domain_loss: 0.3870 - Label_accuracy: 0.9016 - Label_loss: 0.2458 - loss: 0.6330 - val_Domain_accuracy: 0.0507 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7100 - val_Label_loss: 1.1364 - val_loss: 1.1492\n",
      "Epoch 44/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8673 - Domain_loss: 0.3947 - Label_accuracy: 0.9055 - Label_loss: 0.2372 - loss: 0.6317 - val_Domain_accuracy: 0.0772 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7211 - val_Label_loss: 1.0253 - val_loss: 1.0362\n",
      "Epoch 45/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8639 - Domain_loss: 0.4023 - Label_accuracy: 0.9064 - Label_loss: 0.2411 - loss: 0.6434 - val_Domain_accuracy: 0.2150 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7310 - val_Label_loss: 0.9547 - val_loss: 0.9668\n",
      "Epoch 46/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8487 - Domain_loss: 0.4413 - Label_accuracy: 0.9008 - Label_loss: 0.2472 - loss: 0.6882 - val_Domain_accuracy: 0.0893 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7685 - val_Label_loss: 0.8511 - val_loss: 0.8488\n",
      "Epoch 47/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8589 - Domain_loss: 0.4138 - Label_accuracy: 0.9045 - Label_loss: 0.2441 - loss: 0.6579 - val_Domain_accuracy: 0.1312 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7122 - val_Label_loss: 1.1378 - val_loss: 1.1521\n",
      "Epoch 48/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8661 - Domain_loss: 0.3898 - Label_accuracy: 0.9106 - Label_loss: 0.2303 - loss: 0.6201 - val_Domain_accuracy: 0.2007 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7277 - val_Label_loss: 1.0851 - val_loss: 1.1002\n",
      "Epoch 49/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8635 - Domain_loss: 0.4029 - Label_accuracy: 0.9102 - Label_loss: 0.2267 - loss: 0.6296 - val_Domain_accuracy: 0.0750 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7464 - val_Label_loss: 0.9332 - val_loss: 0.9354\n",
      "Epoch 50/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8629 - Domain_loss: 0.4000 - Label_accuracy: 0.9075 - Label_loss: 0.2318 - loss: 0.6318 - val_Domain_accuracy: 0.0915 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7288 - val_Label_loss: 0.9844 - val_loss: 0.9939\n",
      "Epoch 51/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8578 - Domain_loss: 0.4066 - Label_accuracy: 0.9182 - Label_loss: 0.2177 - loss: 0.6246 - val_Domain_accuracy: 0.2106 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7144 - val_Label_loss: 1.1564 - val_loss: 1.1716\n",
      "Epoch 52/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8610 - Domain_loss: 0.3918 - Label_accuracy: 0.9050 - Label_loss: 0.2369 - loss: 0.6288 - val_Domain_accuracy: 0.1974 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7442 - val_Label_loss: 0.9220 - val_loss: 0.9173\n",
      "Epoch 53/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8638 - Domain_loss: 0.4052 - Label_accuracy: 0.9077 - Label_loss: 0.2297 - loss: 0.6348 - val_Domain_accuracy: 0.1356 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6968 - val_Label_loss: 1.1226 - val_loss: 1.1298\n",
      "Epoch 54/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8634 - Domain_loss: 0.3881 - Label_accuracy: 0.9164 - Label_loss: 0.2204 - loss: 0.6083 - val_Domain_accuracy: 0.1092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7365 - val_Label_loss: 1.0414 - val_loss: 1.0476\n",
      "Epoch 55/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8618 - Domain_loss: 0.3902 - Label_accuracy: 0.9172 - Label_loss: 0.2155 - loss: 0.6057 - val_Domain_accuracy: 0.0750 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7100 - val_Label_loss: 1.1212 - val_loss: 1.1347\n",
      "Epoch 56/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8646 - Domain_loss: 0.4025 - Label_accuracy: 0.9117 - Label_loss: 0.2280 - loss: 0.6307 - val_Domain_accuracy: 0.1080 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7365 - val_Label_loss: 1.0809 - val_loss: 1.0880\n",
      "Epoch 57/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8691 - Domain_loss: 0.3797 - Label_accuracy: 0.9143 - Label_loss: 0.2157 - loss: 0.5949 - val_Domain_accuracy: 0.2084 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7343 - val_Label_loss: 1.0524 - val_loss: 1.0601\n",
      "Epoch 58/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8656 - Domain_loss: 0.3896 - Label_accuracy: 0.9113 - Label_loss: 0.2179 - loss: 0.6079 - val_Domain_accuracy: 0.2580 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7442 - val_Label_loss: 1.0178 - val_loss: 1.0268\n",
      "Epoch 59/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8716 - Domain_loss: 0.3723 - Label_accuracy: 0.9140 - Label_loss: 0.2213 - loss: 0.5939 - val_Domain_accuracy: 0.1422 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7530 - val_Label_loss: 1.1702 - val_loss: 1.1734\n",
      "Epoch 60/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8517 - Domain_loss: 0.4458 - Label_accuracy: 0.9101 - Label_loss: 0.2298 - loss: 0.6757 - val_Domain_accuracy: 0.0507 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7155 - val_Label_loss: 1.1273 - val_loss: 1.1356\n",
      "Epoch 61/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8745 - Domain_loss: 0.3634 - Label_accuracy: 0.9138 - Label_loss: 0.2167 - loss: 0.5799 - val_Domain_accuracy: 0.0562 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7078 - val_Label_loss: 1.2373 - val_loss: 1.2485\n",
      "Epoch 62/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8737 - Domain_loss: 0.3639 - Label_accuracy: 0.9163 - Label_loss: 0.2111 - loss: 0.5745 - val_Domain_accuracy: 0.0298 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6913 - val_Label_loss: 1.4313 - val_loss: 1.4451\n",
      "Epoch 63/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8715 - Domain_loss: 0.3780 - Label_accuracy: 0.9156 - Label_loss: 0.2115 - loss: 0.5892 - val_Domain_accuracy: 0.1510 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7244 - val_Label_loss: 1.1270 - val_loss: 1.1306\n",
      "Epoch 64/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8703 - Domain_loss: 0.3785 - Label_accuracy: 0.9234 - Label_loss: 0.1970 - loss: 0.5750 - val_Domain_accuracy: 0.2051 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7332 - val_Label_loss: 1.0170 - val_loss: 1.0317\n",
      "Epoch 65/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8729 - Domain_loss: 0.3743 - Label_accuracy: 0.9185 - Label_loss: 0.2050 - loss: 0.5791 - val_Domain_accuracy: 0.1797 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7475 - val_Label_loss: 1.0236 - val_loss: 1.0314\n",
      "Epoch 66/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8745 - Domain_loss: 0.3588 - Label_accuracy: 0.9233 - Label_loss: 0.1974 - loss: 0.5560 - val_Domain_accuracy: 0.2183 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7442 - val_Label_loss: 1.0771 - val_loss: 1.0858\n",
      "Epoch 67/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8703 - Domain_loss: 0.3739 - Label_accuracy: 0.9166 - Label_loss: 0.2093 - loss: 0.5832 - val_Domain_accuracy: 0.0540 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7012 - val_Label_loss: 1.3923 - val_loss: 1.4062\n",
      "Epoch 68/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8740 - Domain_loss: 0.3600 - Label_accuracy: 0.9203 - Label_loss: 0.2043 - loss: 0.5643 - val_Domain_accuracy: 0.0309 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7354 - val_Label_loss: 1.1027 - val_loss: 1.1173\n",
      "Epoch 69/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8725 - Domain_loss: 0.3812 - Label_accuracy: 0.9190 - Label_loss: 0.2002 - loss: 0.5812 - val_Domain_accuracy: 0.0474 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7233 - val_Label_loss: 1.2174 - val_loss: 1.2339\n",
      "Epoch 70/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8811 - Domain_loss: 0.3435 - Label_accuracy: 0.9181 - Label_loss: 0.1894 - loss: 0.5328 - val_Domain_accuracy: 0.0915 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7343 - val_Label_loss: 1.1562 - val_loss: 1.1662\n",
      "Epoch 71/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8727 - Domain_loss: 0.3609 - Label_accuracy: 0.9244 - Label_loss: 0.1914 - loss: 0.5524 - val_Domain_accuracy: 0.0573 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7189 - val_Label_loss: 1.1523 - val_loss: 1.1663\n",
      "Epoch 72/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8703 - Domain_loss: 0.3768 - Label_accuracy: 0.9241 - Label_loss: 0.1882 - loss: 0.5652 - val_Domain_accuracy: 0.0463 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7266 - val_Label_loss: 1.1013 - val_loss: 1.1131\n",
      "Epoch 73/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8759 - Domain_loss: 0.3580 - Label_accuracy: 0.9270 - Label_loss: 0.1895 - loss: 0.5477 - val_Domain_accuracy: 0.1720 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7409 - val_Label_loss: 1.0581 - val_loss: 1.0685\n",
      "Epoch 74/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8753 - Domain_loss: 0.3608 - Label_accuracy: 0.9261 - Label_loss: 0.1921 - loss: 0.5528 - val_Domain_accuracy: 0.0551 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7486 - val_Label_loss: 1.0626 - val_loss: 1.0722\n",
      "Epoch 75/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8831 - Domain_loss: 0.3525 - Label_accuracy: 0.9262 - Label_loss: 0.1877 - loss: 0.5401 - val_Domain_accuracy: 0.1036 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7376 - val_Label_loss: 1.1596 - val_loss: 1.1717\n",
      "Epoch 76/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8718 - Domain_loss: 0.3634 - Label_accuracy: 0.9284 - Label_loss: 0.1756 - loss: 0.5391 - val_Domain_accuracy: 0.0816 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6858 - val_Label_loss: 1.3327 - val_loss: 1.3486\n",
      "Epoch 77/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8706 - Domain_loss: 0.3855 - Label_accuracy: 0.9259 - Label_loss: 0.1808 - loss: 0.5663 - val_Domain_accuracy: 0.0364 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7321 - val_Label_loss: 1.1201 - val_loss: 1.1307\n",
      "Epoch 78/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8716 - Domain_loss: 0.3611 - Label_accuracy: 0.9269 - Label_loss: 0.1821 - loss: 0.5430 - val_Domain_accuracy: 0.0397 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6428 - val_Label_loss: 1.7634 - val_loss: 1.7868\n",
      "Epoch 79/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8792 - Domain_loss: 0.3575 - Label_accuracy: 0.9292 - Label_loss: 0.1806 - loss: 0.5382 - val_Domain_accuracy: 0.1312 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7166 - val_Label_loss: 1.2135 - val_loss: 1.2255\n",
      "Epoch 80/80\n",
      "239/239 - 8s - 32ms/step - Domain_accuracy: 0.8818 - Domain_loss: 0.3357 - Label_accuracy: 0.9284 - Label_loss: 0.1767 - loss: 0.5122 - val_Domain_accuracy: 0.1114 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7321 - val_Label_loss: 1.1945 - val_loss: 1.1976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #2\n",
      "train_feature shape: (7759, 5, 10, 256)\n",
      "train_targets shape: (7759, 5)\n",
      "train_domin shape: (7759, 9)\n",
      "Epoch 1/80\n",
      "243/243 - 16s - 66ms/step - Domain_accuracy: 0.5082 - Domain_loss: 1.4888 - Label_accuracy: 0.7857 - Label_loss: 0.6609 - loss: 2.1508 - val_Domain_accuracy: 0.4772 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6975 - val_Label_loss: 1.0854 - val_loss: 1.0930\n",
      "Epoch 2/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.6698 - Domain_loss: 0.9620 - Label_accuracy: 0.8877 - Label_loss: 0.3062 - loss: 1.2669 - val_Domain_accuracy: 0.1101 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7696 - val_Label_loss: 0.9463 - val_loss: 0.9582\n",
      "Epoch 3/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.7315 - Domain_loss: 0.8183 - Label_accuracy: 0.9149 - Label_loss: 0.2388 - loss: 1.0577 - val_Domain_accuracy: 0.2304 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7595 - val_Label_loss: 0.9331 - val_loss: 0.9446\n",
      "Epoch 4/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.7527 - Domain_loss: 0.7357 - Label_accuracy: 0.9269 - Label_loss: 0.2037 - loss: 0.9398 - val_Domain_accuracy: 0.1544 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7646 - val_Label_loss: 0.9109 - val_loss: 0.9203\n",
      "Epoch 5/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.7684 - Domain_loss: 0.6772 - Label_accuracy: 0.9363 - Label_loss: 0.1703 - loss: 0.8475 - val_Domain_accuracy: 0.1392 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7582 - val_Label_loss: 1.1686 - val_loss: 1.1833\n",
      "Epoch 6/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.7752 - Domain_loss: 0.6765 - Label_accuracy: 0.9408 - Label_loss: 0.1598 - loss: 0.8358 - val_Domain_accuracy: 0.3608 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7722 - val_Label_loss: 1.0261 - val_loss: 1.0378\n",
      "Epoch 7/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.7995 - Domain_loss: 0.6046 - Label_accuracy: 0.9437 - Label_loss: 0.1477 - loss: 0.7522 - val_Domain_accuracy: 0.2671 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.0562 - val_loss: 1.0696\n",
      "Epoch 8/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.7978 - Domain_loss: 0.5903 - Label_accuracy: 0.9527 - Label_loss: 0.1374 - loss: 0.7274 - val_Domain_accuracy: 0.2278 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7557 - val_Label_loss: 1.3536 - val_loss: 1.3688\n",
      "Epoch 9/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8138 - Domain_loss: 0.5591 - Label_accuracy: 0.9555 - Label_loss: 0.1242 - loss: 0.6837 - val_Domain_accuracy: 0.1797 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7759 - val_Label_loss: 1.0803 - val_loss: 1.0940\n",
      "Epoch 10/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8125 - Domain_loss: 0.5504 - Label_accuracy: 0.9537 - Label_loss: 0.1283 - loss: 0.6791 - val_Domain_accuracy: 0.0734 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7722 - val_Label_loss: 1.1982 - val_loss: 1.2131\n",
      "Epoch 11/80\n",
      "243/243 - 8s - 33ms/step - Domain_accuracy: 0.8185 - Domain_loss: 0.5318 - Label_accuracy: 0.9579 - Label_loss: 0.1167 - loss: 0.6490 - val_Domain_accuracy: 0.2405 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 0.9716 - val_loss: 0.9836\n",
      "Epoch 12/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.8263 - Domain_loss: 0.5133 - Label_accuracy: 0.9625 - Label_loss: 0.1042 - loss: 0.6171 - val_Domain_accuracy: 0.1177 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7304 - val_Label_loss: 1.5900 - val_loss: 1.6100\n",
      "Epoch 13/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.8330 - Domain_loss: 0.4870 - Label_accuracy: 0.9642 - Label_loss: 0.1006 - loss: 0.5875 - val_Domain_accuracy: 0.1329 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7557 - val_Label_loss: 1.3587 - val_loss: 1.3757\n",
      "Epoch 14/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.8145 - Domain_loss: 0.5565 - Label_accuracy: 0.9619 - Label_loss: 0.1084 - loss: 0.6650 - val_Domain_accuracy: 0.2316 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7759 - val_Label_loss: 1.3315 - val_loss: 1.3483\n",
      "Epoch 15/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.8286 - Domain_loss: 0.5106 - Label_accuracy: 0.9687 - Label_loss: 0.0805 - loss: 0.5910 - val_Domain_accuracy: 0.2076 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7633 - val_Label_loss: 1.4519 - val_loss: 1.4702\n",
      "Epoch 16/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8202 - Domain_loss: 0.5332 - Label_accuracy: 0.9665 - Label_loss: 0.0932 - loss: 0.6263 - val_Domain_accuracy: 0.1911 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7785 - val_Label_loss: 1.2844 - val_loss: 1.3006\n",
      "Epoch 17/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8287 - Domain_loss: 0.4962 - Label_accuracy: 0.9733 - Label_loss: 0.0786 - loss: 0.5752 - val_Domain_accuracy: 0.1911 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7797 - val_Label_loss: 1.3988 - val_loss: 1.4165\n",
      "Epoch 18/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8366 - Domain_loss: 0.4751 - Label_accuracy: 0.9710 - Label_loss: 0.0748 - loss: 0.5494 - val_Domain_accuracy: 0.1886 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7646 - val_Label_loss: 1.4377 - val_loss: 1.4559\n",
      "Epoch 19/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8317 - Domain_loss: 0.4864 - Label_accuracy: 0.9722 - Label_loss: 0.0812 - loss: 0.5686 - val_Domain_accuracy: 0.1380 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7722 - val_Label_loss: 1.3280 - val_loss: 1.3447\n",
      "Epoch 20/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8353 - Domain_loss: 0.4968 - Label_accuracy: 0.9688 - Label_loss: 0.0802 - loss: 0.5769 - val_Domain_accuracy: 0.1114 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 1.2216 - val_loss: 1.2370\n",
      "Epoch 21/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.8459 - Domain_loss: 0.4447 - Label_accuracy: 0.9741 - Label_loss: 0.0679 - loss: 0.5130 - val_Domain_accuracy: 0.2038 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.3973 - val_loss: 1.4149\n",
      "Epoch 22/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8420 - Domain_loss: 0.4676 - Label_accuracy: 0.9772 - Label_loss: 0.0658 - loss: 0.5314 - val_Domain_accuracy: 0.2291 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7633 - val_Label_loss: 1.6335 - val_loss: 1.6541\n",
      "Epoch 23/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8394 - Domain_loss: 0.4671 - Label_accuracy: 0.9751 - Label_loss: 0.0661 - loss: 0.5330 - val_Domain_accuracy: 0.1367 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7911 - val_Label_loss: 1.3335 - val_loss: 1.3502\n",
      "Epoch 24/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8451 - Domain_loss: 0.4538 - Label_accuracy: 0.9768 - Label_loss: 0.0613 - loss: 0.5149 - val_Domain_accuracy: 0.2734 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7810 - val_Label_loss: 1.5292 - val_loss: 1.5485\n",
      "Epoch 25/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8464 - Domain_loss: 0.4565 - Label_accuracy: 0.9713 - Label_loss: 0.0734 - loss: 0.5296 - val_Domain_accuracy: 0.2962 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7696 - val_Label_loss: 1.6741 - val_loss: 1.6952\n",
      "Epoch 26/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8389 - Domain_loss: 0.4752 - Label_accuracy: 0.9781 - Label_loss: 0.0615 - loss: 0.5364 - val_Domain_accuracy: 0.2823 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.5494 - val_loss: 1.5691\n",
      "Epoch 27/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8518 - Domain_loss: 0.4172 - Label_accuracy: 0.9771 - Label_loss: 0.0622 - loss: 0.4796 - val_Domain_accuracy: 0.1177 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8025 - val_Label_loss: 1.3829 - val_loss: 1.4004\n",
      "Epoch 28/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8395 - Domain_loss: 0.4788 - Label_accuracy: 0.9774 - Label_loss: 0.0664 - loss: 0.5451 - val_Domain_accuracy: 0.1506 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7886 - val_Label_loss: 1.4849 - val_loss: 1.5037\n",
      "Epoch 29/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8447 - Domain_loss: 0.4666 - Label_accuracy: 0.9729 - Label_loss: 0.0735 - loss: 0.5402 - val_Domain_accuracy: 0.2570 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7646 - val_Label_loss: 1.6577 - val_loss: 1.6787\n",
      "Epoch 30/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8551 - Domain_loss: 0.4283 - Label_accuracy: 0.9820 - Label_loss: 0.0498 - loss: 0.4785 - val_Domain_accuracy: 0.0886 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8013 - val_Label_loss: 1.4237 - val_loss: 1.4417\n",
      "Epoch 31/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8446 - Domain_loss: 0.4638 - Label_accuracy: 0.9792 - Label_loss: 0.0557 - loss: 0.5195 - val_Domain_accuracy: 0.1557 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7595 - val_Label_loss: 1.8402 - val_loss: 1.8634\n",
      "Epoch 32/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8439 - Domain_loss: 0.4573 - Label_accuracy: 0.9822 - Label_loss: 0.0523 - loss: 0.5084 - val_Domain_accuracy: 0.0810 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7759 - val_Label_loss: 1.6228 - val_loss: 1.6434\n",
      "Epoch 33/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8417 - Domain_loss: 0.4682 - Label_accuracy: 0.9807 - Label_loss: 0.0528 - loss: 0.5207 - val_Domain_accuracy: 0.2013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7823 - val_Label_loss: 1.7222 - val_loss: 1.7440\n",
      "Epoch 34/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8421 - Domain_loss: 0.4534 - Label_accuracy: 0.9798 - Label_loss: 0.0586 - loss: 0.5125 - val_Domain_accuracy: 0.0911 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8025 - val_Label_loss: 1.4019 - val_loss: 1.4196\n",
      "Epoch 35/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8375 - Domain_loss: 0.4810 - Label_accuracy: 0.9772 - Label_loss: 0.0659 - loss: 0.5474 - val_Domain_accuracy: 0.0886 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 1.5499 - val_loss: 1.5695\n",
      "Epoch 36/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8466 - Domain_loss: 0.4351 - Label_accuracy: 0.9813 - Label_loss: 0.0521 - loss: 0.4874 - val_Domain_accuracy: 0.1380 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7696 - val_Label_loss: 1.9242 - val_loss: 1.9486\n",
      "Epoch 37/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8541 - Domain_loss: 0.4330 - Label_accuracy: 0.9798 - Label_loss: 0.0538 - loss: 0.4860 - val_Domain_accuracy: 0.1342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7797 - val_Label_loss: 1.5148 - val_loss: 1.5340\n",
      "Epoch 38/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8381 - Domain_loss: 0.4683 - Label_accuracy: 0.9800 - Label_loss: 0.0606 - loss: 0.5282 - val_Domain_accuracy: 0.2000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8101 - val_Label_loss: 1.2697 - val_loss: 1.2858\n",
      "Epoch 39/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8509 - Domain_loss: 0.4343 - Label_accuracy: 0.9834 - Label_loss: 0.0431 - loss: 0.4775 - val_Domain_accuracy: 0.1873 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.6941 - val_loss: 1.7156\n",
      "Epoch 40/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8375 - Domain_loss: 0.4635 - Label_accuracy: 0.9785 - Label_loss: 0.0647 - loss: 0.5281 - val_Domain_accuracy: 0.1557 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8139 - val_Label_loss: 1.4042 - val_loss: 1.4220\n",
      "Epoch 41/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8496 - Domain_loss: 0.4345 - Label_accuracy: 0.9835 - Label_loss: 0.0494 - loss: 0.4838 - val_Domain_accuracy: 0.1506 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7519 - val_Label_loss: 2.3328 - val_loss: 2.3623\n",
      "Epoch 42/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.8395 - Domain_loss: 0.4728 - Label_accuracy: 0.9827 - Label_loss: 0.0479 - loss: 0.5201 - val_Domain_accuracy: 0.1519 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8025 - val_Label_loss: 1.5255 - val_loss: 1.5448\n",
      "Epoch 43/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8555 - Domain_loss: 0.4177 - Label_accuracy: 0.9863 - Label_loss: 0.0389 - loss: 0.4561 - val_Domain_accuracy: 0.1899 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8152 - val_Label_loss: 1.5737 - val_loss: 1.5936\n",
      "Epoch 44/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8531 - Domain_loss: 0.4083 - Label_accuracy: 0.9834 - Label_loss: 0.0485 - loss: 0.4567 - val_Domain_accuracy: 0.2013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7924 - val_Label_loss: 1.6207 - val_loss: 1.6412\n",
      "Epoch 45/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8593 - Domain_loss: 0.4084 - Label_accuracy: 0.9860 - Label_loss: 0.0373 - loss: 0.4459 - val_Domain_accuracy: 0.1747 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7747 - val_Label_loss: 1.8205 - val_loss: 1.8435\n",
      "Epoch 46/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.8569 - Domain_loss: 0.4247 - Label_accuracy: 0.9866 - Label_loss: 0.0394 - loss: 0.4632 - val_Domain_accuracy: 0.1076 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 1.5768 - val_loss: 1.5967\n",
      "Epoch 47/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.8544 - Domain_loss: 0.4194 - Label_accuracy: 0.9817 - Label_loss: 0.0505 - loss: 0.4707 - val_Domain_accuracy: 0.0987 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8038 - val_Label_loss: 1.4374 - val_loss: 1.4555\n",
      "Epoch 48/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8535 - Domain_loss: 0.4344 - Label_accuracy: 0.9827 - Label_loss: 0.0461 - loss: 0.4789 - val_Domain_accuracy: 0.1354 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7886 - val_Label_loss: 1.7783 - val_loss: 1.8008\n",
      "Epoch 49/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8508 - Domain_loss: 0.4353 - Label_accuracy: 0.9867 - Label_loss: 0.0367 - loss: 0.4712 - val_Domain_accuracy: 0.1278 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7962 - val_Label_loss: 1.7381 - val_loss: 1.7601\n",
      "Epoch 50/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8444 - Domain_loss: 0.4529 - Label_accuracy: 0.9838 - Label_loss: 0.0489 - loss: 0.5027 - val_Domain_accuracy: 0.1443 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8165 - val_Label_loss: 1.3990 - val_loss: 1.4167\n",
      "Epoch 51/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8691 - Domain_loss: 0.3811 - Label_accuracy: 0.9905 - Label_loss: 0.0301 - loss: 0.4114 - val_Domain_accuracy: 0.0937 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7975 - val_Label_loss: 1.7543 - val_loss: 1.7765\n",
      "Epoch 52/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8560 - Domain_loss: 0.4150 - Label_accuracy: 0.9844 - Label_loss: 0.0433 - loss: 0.4575 - val_Domain_accuracy: 0.0316 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7911 - val_Label_loss: 1.8531 - val_loss: 1.8765\n",
      "Epoch 53/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8663 - Domain_loss: 0.3984 - Label_accuracy: 0.9847 - Label_loss: 0.0445 - loss: 0.4432 - val_Domain_accuracy: 0.1165 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7810 - val_Label_loss: 1.7988 - val_loss: 1.8215\n",
      "Epoch 54/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8616 - Domain_loss: 0.3985 - Label_accuracy: 0.9866 - Label_loss: 0.0368 - loss: 0.4342 - val_Domain_accuracy: 0.1114 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8013 - val_Label_loss: 1.5793 - val_loss: 1.5993\n",
      "Epoch 55/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8697 - Domain_loss: 0.3713 - Label_accuracy: 0.9899 - Label_loss: 0.0282 - loss: 0.4001 - val_Domain_accuracy: 0.1468 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7734 - val_Label_loss: 1.9995 - val_loss: 2.0248\n",
      "Epoch 56/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8604 - Domain_loss: 0.4010 - Label_accuracy: 0.9879 - Label_loss: 0.0364 - loss: 0.4378 - val_Domain_accuracy: 0.1354 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 2.1033 - val_loss: 2.1299\n",
      "Epoch 57/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8594 - Domain_loss: 0.4164 - Label_accuracy: 0.9871 - Label_loss: 0.0372 - loss: 0.4538 - val_Domain_accuracy: 0.2127 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7608 - val_Label_loss: 2.5146 - val_loss: 2.5446\n",
      "Epoch 58/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8433 - Domain_loss: 0.4522 - Label_accuracy: 0.9841 - Label_loss: 0.0457 - loss: 0.4983 - val_Domain_accuracy: 0.1038 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 1.7550 - val_loss: 1.7772\n",
      "Epoch 59/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8613 - Domain_loss: 0.4029 - Label_accuracy: 0.9901 - Label_loss: 0.0287 - loss: 0.4312 - val_Domain_accuracy: 0.1089 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7747 - val_Label_loss: 2.0878 - val_loss: 2.1142\n",
      "Epoch 60/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8468 - Domain_loss: 0.4395 - Label_accuracy: 0.9861 - Label_loss: 0.0366 - loss: 0.4759 - val_Domain_accuracy: 0.2025 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 2.0085 - val_loss: 2.0339\n",
      "Epoch 61/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8538 - Domain_loss: 0.4176 - Label_accuracy: 0.9870 - Label_loss: 0.0389 - loss: 0.4565 - val_Domain_accuracy: 0.2595 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7582 - val_Label_loss: 2.4053 - val_loss: 2.4357\n",
      "Epoch 62/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8495 - Domain_loss: 0.4460 - Label_accuracy: 0.9852 - Label_loss: 0.0405 - loss: 0.4866 - val_Domain_accuracy: 0.1835 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7962 - val_Label_loss: 1.8769 - val_loss: 1.9007\n",
      "Epoch 63/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8633 - Domain_loss: 0.4009 - Label_accuracy: 0.9883 - Label_loss: 0.0345 - loss: 0.4344 - val_Domain_accuracy: 0.1544 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7911 - val_Label_loss: 1.7357 - val_loss: 1.7577\n",
      "Epoch 64/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8629 - Domain_loss: 0.3943 - Label_accuracy: 0.9912 - Label_loss: 0.0242 - loss: 0.4185 - val_Domain_accuracy: 0.1646 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7987 - val_Label_loss: 1.7595 - val_loss: 1.7818\n",
      "Epoch 65/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8572 - Domain_loss: 0.4179 - Label_accuracy: 0.9874 - Label_loss: 0.0384 - loss: 0.4566 - val_Domain_accuracy: 0.1354 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7886 - val_Label_loss: 1.8296 - val_loss: 1.8528\n",
      "Epoch 66/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8375 - Domain_loss: 0.4758 - Label_accuracy: 0.9881 - Label_loss: 0.0375 - loss: 0.5136 - val_Domain_accuracy: 0.1367 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 1.8211 - val_loss: 1.8442\n",
      "Epoch 67/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8434 - Domain_loss: 0.4666 - Label_accuracy: 0.9874 - Label_loss: 0.0357 - loss: 0.5031 - val_Domain_accuracy: 0.1519 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7759 - val_Label_loss: 1.9718 - val_loss: 1.9968\n",
      "Epoch 68/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.8645 - Domain_loss: 0.3730 - Label_accuracy: 0.9916 - Label_loss: 0.0259 - loss: 0.3985 - val_Domain_accuracy: 0.1203 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8038 - val_Label_loss: 1.8725 - val_loss: 1.8962\n",
      "Epoch 69/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8651 - Domain_loss: 0.3966 - Label_accuracy: 0.9865 - Label_loss: 0.0421 - loss: 0.4388 - val_Domain_accuracy: 0.1962 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8063 - val_Label_loss: 1.6998 - val_loss: 1.7213\n",
      "Epoch 70/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8627 - Domain_loss: 0.4026 - Label_accuracy: 0.9896 - Label_loss: 0.0298 - loss: 0.4319 - val_Domain_accuracy: 0.1291 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7620 - val_Label_loss: 2.2382 - val_loss: 2.2665\n",
      "Epoch 71/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8649 - Domain_loss: 0.3978 - Label_accuracy: 0.9898 - Label_loss: 0.0259 - loss: 0.4225 - val_Domain_accuracy: 0.1101 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7911 - val_Label_loss: 2.2673 - val_loss: 2.2960\n",
      "Epoch 72/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8675 - Domain_loss: 0.3740 - Label_accuracy: 0.9875 - Label_loss: 0.0358 - loss: 0.4107 - val_Domain_accuracy: 0.1000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8038 - val_Label_loss: 2.2272 - val_loss: 2.2554\n",
      "Epoch 73/80\n",
      "243/243 - 8s - 32ms/step - Domain_accuracy: 0.8622 - Domain_loss: 0.4067 - Label_accuracy: 0.9875 - Label_loss: 0.0378 - loss: 0.4444 - val_Domain_accuracy: 0.1089 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7646 - val_Label_loss: 2.4349 - val_loss: 2.4657\n",
      "Epoch 74/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8563 - Domain_loss: 0.4112 - Label_accuracy: 0.9887 - Label_loss: 0.0326 - loss: 0.4441 - val_Domain_accuracy: 0.1494 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7899 - val_Label_loss: 1.9361 - val_loss: 1.9606\n",
      "Epoch 75/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8599 - Domain_loss: 0.4050 - Label_accuracy: 0.9898 - Label_loss: 0.0308 - loss: 0.4361 - val_Domain_accuracy: 0.2304 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7747 - val_Label_loss: 2.3020 - val_loss: 2.3311\n",
      "Epoch 76/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8600 - Domain_loss: 0.3974 - Label_accuracy: 0.9907 - Label_loss: 0.0268 - loss: 0.4249 - val_Domain_accuracy: 0.2101 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7696 - val_Label_loss: 2.4459 - val_loss: 2.4768\n",
      "Epoch 77/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8562 - Domain_loss: 0.4133 - Label_accuracy: 0.9902 - Label_loss: 0.0275 - loss: 0.4399 - val_Domain_accuracy: 0.1329 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8025 - val_Label_loss: 1.9013 - val_loss: 1.9254\n",
      "Epoch 78/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8528 - Domain_loss: 0.4297 - Label_accuracy: 0.9887 - Label_loss: 0.0355 - loss: 0.4643 - val_Domain_accuracy: 0.1190 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7759 - val_Label_loss: 1.8767 - val_loss: 1.9005\n",
      "Epoch 79/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8407 - Domain_loss: 0.4478 - Label_accuracy: 0.9918 - Label_loss: 0.0242 - loss: 0.4725 - val_Domain_accuracy: 0.1367 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8063 - val_Label_loss: 1.7817 - val_loss: 1.8043\n",
      "Epoch 80/80\n",
      "243/243 - 8s - 31ms/step - Domain_accuracy: 0.8495 - Domain_loss: 0.4388 - Label_accuracy: 0.9902 - Label_loss: 0.0288 - loss: 0.4674 - val_Domain_accuracy: 0.1987 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7582 - val_Label_loss: 2.7172 - val_loss: 2.7516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #3\n",
      "train_feature shape: (7789, 5, 10, 256)\n",
      "train_targets shape: (7789, 5)\n",
      "train_domin shape: (7789, 9)\n",
      "Epoch 1/80\n",
      "244/244 - 16s - 66ms/step - Domain_accuracy: 0.5183 - Domain_loss: 1.4784 - Label_accuracy: 0.7749 - Label_loss: 0.6663 - loss: 2.1457 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6684 - val_Label_loss: 1.1071 - val_loss: 1.1175\n",
      "Epoch 2/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.6894 - Domain_loss: 0.9405 - Label_accuracy: 0.8757 - Label_loss: 0.3454 - loss: 1.2843 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7276 - val_Label_loss: 0.9912 - val_loss: 1.0006\n",
      "Epoch 3/80\n",
      "244/244 - 8s - 31ms/step - Domain_accuracy: 0.7034 - Domain_loss: 0.9060 - Label_accuracy: 0.8891 - Label_loss: 0.3034 - loss: 1.2084 - val_Domain_accuracy: 0.0224 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6645 - val_Label_loss: 1.4714 - val_loss: 1.4868\n",
      "Epoch 4/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.7489 - Domain_loss: 0.7403 - Label_accuracy: 0.9042 - Label_loss: 0.2551 - loss: 0.9967 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7474 - val_Label_loss: 0.9538 - val_loss: 0.9632\n",
      "Epoch 5/80\n",
      "244/244 - 8s - 31ms/step - Domain_accuracy: 0.7879 - Domain_loss: 0.6234 - Label_accuracy: 0.9150 - Label_loss: 0.2278 - loss: 0.8522 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7421 - val_Label_loss: 0.9542 - val_loss: 0.9641\n",
      "Epoch 6/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.7956 - Domain_loss: 0.6136 - Label_accuracy: 0.9189 - Label_loss: 0.2111 - loss: 0.8258 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6816 - val_Label_loss: 1.3079 - val_loss: 1.3215\n",
      "Epoch 7/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.7739 - Domain_loss: 0.6848 - Label_accuracy: 0.9268 - Label_loss: 0.1933 - loss: 0.8784 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7329 - val_Label_loss: 1.2841 - val_loss: 1.2974\n",
      "Epoch 8/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8065 - Domain_loss: 0.5751 - Label_accuracy: 0.9303 - Label_loss: 0.1863 - loss: 0.7614 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7276 - val_Label_loss: 1.2029 - val_loss: 1.2152\n",
      "Epoch 9/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8010 - Domain_loss: 0.5690 - Label_accuracy: 0.9350 - Label_loss: 0.1762 - loss: 0.7449 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7224 - val_Label_loss: 1.1272 - val_loss: 1.1390\n",
      "Epoch 10/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8082 - Domain_loss: 0.5549 - Label_accuracy: 0.9371 - Label_loss: 0.1690 - loss: 0.7236 - val_Domain_accuracy: 0.0105 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6566 - val_Label_loss: 1.8287 - val_loss: 1.8480\n",
      "Epoch 11/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8168 - Domain_loss: 0.5259 - Label_accuracy: 0.9444 - Label_loss: 0.1485 - loss: 0.6751 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7355 - val_Label_loss: 1.4341 - val_loss: 1.4492\n",
      "Epoch 12/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8362 - Domain_loss: 0.4828 - Label_accuracy: 0.9438 - Label_loss: 0.1436 - loss: 0.6269 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6947 - val_Label_loss: 1.4630 - val_loss: 1.4783\n",
      "Epoch 13/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8414 - Domain_loss: 0.4655 - Label_accuracy: 0.9476 - Label_loss: 0.1396 - loss: 0.6050 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7211 - val_Label_loss: 1.2362 - val_loss: 1.2491\n",
      "Epoch 14/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8393 - Domain_loss: 0.4716 - Label_accuracy: 0.9465 - Label_loss: 0.1428 - loss: 0.6128 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7329 - val_Label_loss: 1.2726 - val_loss: 1.2858\n",
      "Epoch 15/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8318 - Domain_loss: 0.4886 - Label_accuracy: 0.9480 - Label_loss: 0.1354 - loss: 0.6250 - val_Domain_accuracy: 0.0039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 1.2444 - val_loss: 1.2575\n",
      "Epoch 16/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8493 - Domain_loss: 0.4425 - Label_accuracy: 0.9549 - Label_loss: 0.1194 - loss: 0.5625 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7526 - val_Label_loss: 1.0108 - val_loss: 1.0213\n",
      "Epoch 17/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8490 - Domain_loss: 0.4421 - Label_accuracy: 0.9565 - Label_loss: 0.1190 - loss: 0.5613 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7316 - val_Label_loss: 1.3719 - val_loss: 1.3850\n",
      "Epoch 18/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8467 - Domain_loss: 0.4528 - Label_accuracy: 0.9547 - Label_loss: 0.1192 - loss: 0.5725 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7250 - val_Label_loss: 1.1889 - val_loss: 1.2010\n",
      "Epoch 19/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8530 - Domain_loss: 0.4262 - Label_accuracy: 0.9570 - Label_loss: 0.1188 - loss: 0.5434 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7526 - val_Label_loss: 1.0411 - val_loss: 1.0515\n",
      "Epoch 20/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8583 - Domain_loss: 0.4035 - Label_accuracy: 0.9590 - Label_loss: 0.1064 - loss: 0.5104 - val_Domain_accuracy: 0.0250 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7461 - val_Label_loss: 1.3667 - val_loss: 1.3811\n",
      "Epoch 21/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8384 - Domain_loss: 0.4722 - Label_accuracy: 0.9596 - Label_loss: 0.1094 - loss: 0.5817 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7382 - val_Label_loss: 1.3515 - val_loss: 1.3650\n",
      "Epoch 22/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8493 - Domain_loss: 0.4354 - Label_accuracy: 0.9608 - Label_loss: 0.1069 - loss: 0.5419 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6947 - val_Label_loss: 1.6363 - val_loss: 1.6535\n",
      "Epoch 23/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8732 - Domain_loss: 0.3775 - Label_accuracy: 0.9629 - Label_loss: 0.0986 - loss: 0.4757 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7092 - val_Label_loss: 1.5894 - val_loss: 1.6061\n",
      "Epoch 24/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8705 - Domain_loss: 0.3832 - Label_accuracy: 0.9666 - Label_loss: 0.0908 - loss: 0.4748 - val_Domain_accuracy: 0.0145 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6895 - val_Label_loss: 1.6356 - val_loss: 1.6528\n",
      "Epoch 25/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8606 - Domain_loss: 0.3946 - Label_accuracy: 0.9626 - Label_loss: 0.0963 - loss: 0.4905 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7197 - val_Label_loss: 1.5031 - val_loss: 1.5188\n",
      "Epoch 26/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8597 - Domain_loss: 0.4057 - Label_accuracy: 0.9638 - Label_loss: 0.0968 - loss: 0.5023 - val_Domain_accuracy: 0.0039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6868 - val_Label_loss: 1.7508 - val_loss: 1.7692\n",
      "Epoch 27/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8572 - Domain_loss: 0.4055 - Label_accuracy: 0.9655 - Label_loss: 0.0866 - loss: 0.4929 - val_Domain_accuracy: 0.0105 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7303 - val_Label_loss: 1.8772 - val_loss: 1.8970\n",
      "Epoch 28/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8753 - Domain_loss: 0.3605 - Label_accuracy: 0.9676 - Label_loss: 0.0848 - loss: 0.4441 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7289 - val_Label_loss: 1.6863 - val_loss: 1.7038\n",
      "Epoch 29/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8685 - Domain_loss: 0.3816 - Label_accuracy: 0.9650 - Label_loss: 0.0945 - loss: 0.4762 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7447 - val_Label_loss: 1.5475 - val_loss: 1.5627\n",
      "Epoch 30/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8667 - Domain_loss: 0.3723 - Label_accuracy: 0.9712 - Label_loss: 0.0722 - loss: 0.4437 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7342 - val_Label_loss: 1.6330 - val_loss: 1.6500\n",
      "Epoch 31/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8693 - Domain_loss: 0.3905 - Label_accuracy: 0.9711 - Label_loss: 0.0827 - loss: 0.4728 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7513 - val_Label_loss: 1.7612 - val_loss: 1.7784\n",
      "Epoch 32/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8685 - Domain_loss: 0.3808 - Label_accuracy: 0.9709 - Label_loss: 0.0803 - loss: 0.4619 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7724 - val_Label_loss: 1.7353 - val_loss: 1.7506\n",
      "Epoch 33/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8701 - Domain_loss: 0.3876 - Label_accuracy: 0.9696 - Label_loss: 0.0852 - loss: 0.4738 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7513 - val_Label_loss: 1.2459 - val_loss: 1.2590\n",
      "Epoch 34/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8728 - Domain_loss: 0.3765 - Label_accuracy: 0.9764 - Label_loss: 0.0638 - loss: 0.4399 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7289 - val_Label_loss: 1.6557 - val_loss: 1.6729\n",
      "Epoch 35/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8734 - Domain_loss: 0.3739 - Label_accuracy: 0.9714 - Label_loss: 0.0739 - loss: 0.4478 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7145 - val_Label_loss: 1.6955 - val_loss: 1.7133\n",
      "Epoch 36/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8696 - Domain_loss: 0.3815 - Label_accuracy: 0.9715 - Label_loss: 0.0769 - loss: 0.4593 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6711 - val_Label_loss: 2.0128 - val_loss: 2.0335\n",
      "Epoch 37/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8665 - Domain_loss: 0.3838 - Label_accuracy: 0.9733 - Label_loss: 0.0779 - loss: 0.4621 - val_Domain_accuracy: 0.0105 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7276 - val_Label_loss: 1.5340 - val_loss: 1.5501\n",
      "Epoch 38/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8836 - Domain_loss: 0.3420 - Label_accuracy: 0.9795 - Label_loss: 0.0599 - loss: 0.4020 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7368 - val_Label_loss: 1.8707 - val_loss: 1.8891\n",
      "Epoch 39/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8674 - Domain_loss: 0.3743 - Label_accuracy: 0.9691 - Label_loss: 0.0765 - loss: 0.4510 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6829 - val_Label_loss: 2.2632 - val_loss: 2.2867\n",
      "Epoch 40/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8750 - Domain_loss: 0.3641 - Label_accuracy: 0.9752 - Label_loss: 0.0674 - loss: 0.4309 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7355 - val_Label_loss: 1.7228 - val_loss: 1.7401\n",
      "Epoch 41/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8672 - Domain_loss: 0.3864 - Label_accuracy: 0.9768 - Label_loss: 0.0630 - loss: 0.4497 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7197 - val_Label_loss: 1.8776 - val_loss: 1.8962\n",
      "Epoch 42/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8811 - Domain_loss: 0.3447 - Label_accuracy: 0.9774 - Label_loss: 0.0636 - loss: 0.4074 - val_Domain_accuracy: 0.0211 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6829 - val_Label_loss: 1.9937 - val_loss: 2.0131\n",
      "Epoch 43/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8797 - Domain_loss: 0.3499 - Label_accuracy: 0.9768 - Label_loss: 0.0593 - loss: 0.4090 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7684 - val_Label_loss: 1.5699 - val_loss: 1.5861\n",
      "Epoch 44/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8568 - Domain_loss: 0.4112 - Label_accuracy: 0.9761 - Label_loss: 0.0654 - loss: 0.4774 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7539 - val_Label_loss: 1.5875 - val_loss: 1.6041\n",
      "Epoch 45/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8685 - Domain_loss: 0.3842 - Label_accuracy: 0.9760 - Label_loss: 0.0683 - loss: 0.4530 - val_Domain_accuracy: 0.0039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7566 - val_Label_loss: 1.6334 - val_loss: 1.6503\n",
      "Epoch 46/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8825 - Domain_loss: 0.3496 - Label_accuracy: 0.9810 - Label_loss: 0.0554 - loss: 0.4054 - val_Domain_accuracy: 0.0039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7316 - val_Label_loss: 2.0125 - val_loss: 2.0332\n",
      "Epoch 47/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8783 - Domain_loss: 0.3470 - Label_accuracy: 0.9809 - Label_loss: 0.0482 - loss: 0.3957 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7263 - val_Label_loss: 2.0244 - val_loss: 2.0450\n",
      "Epoch 48/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8825 - Domain_loss: 0.3520 - Label_accuracy: 0.9820 - Label_loss: 0.0509 - loss: 0.4028 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7263 - val_Label_loss: 2.2192 - val_loss: 2.2426\n",
      "Epoch 49/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8622 - Domain_loss: 0.4055 - Label_accuracy: 0.9778 - Label_loss: 0.0639 - loss: 0.4703 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7513 - val_Label_loss: 1.9071 - val_loss: 1.9241\n",
      "Epoch 50/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8712 - Domain_loss: 0.3585 - Label_accuracy: 0.9805 - Label_loss: 0.0524 - loss: 0.4106 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7105 - val_Label_loss: 2.0066 - val_loss: 2.0256\n",
      "Epoch 51/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8637 - Domain_loss: 0.3932 - Label_accuracy: 0.9800 - Label_loss: 0.0555 - loss: 0.4490 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7289 - val_Label_loss: 1.9972 - val_loss: 2.0154\n",
      "Epoch 52/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8802 - Domain_loss: 0.3430 - Label_accuracy: 0.9809 - Label_loss: 0.0559 - loss: 0.3989 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7118 - val_Label_loss: 2.3201 - val_loss: 2.3286\n",
      "Epoch 53/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8883 - Domain_loss: 0.3230 - Label_accuracy: 0.9816 - Label_loss: 0.0516 - loss: 0.3741 - val_Domain_accuracy: 0.0303 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7184 - val_Label_loss: 1.9998 - val_loss: 2.0179\n",
      "Epoch 54/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8744 - Domain_loss: 0.3603 - Label_accuracy: 0.9819 - Label_loss: 0.0479 - loss: 0.4083 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7184 - val_Label_loss: 1.8592 - val_loss: 1.8748\n",
      "Epoch 55/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8699 - Domain_loss: 0.3825 - Label_accuracy: 0.9789 - Label_loss: 0.0589 - loss: 0.4411 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7632 - val_Label_loss: 1.7325 - val_loss: 1.7497\n",
      "Epoch 56/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8728 - Domain_loss: 0.3470 - Label_accuracy: 0.9850 - Label_loss: 0.0392 - loss: 0.3856 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7461 - val_Label_loss: 1.7656 - val_loss: 1.7842\n",
      "Epoch 57/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8624 - Domain_loss: 0.3993 - Label_accuracy: 0.9805 - Label_loss: 0.0468 - loss: 0.4457 - val_Domain_accuracy: 0.0250 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7421 - val_Label_loss: 1.9905 - val_loss: 2.0114\n",
      "Epoch 58/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8567 - Domain_loss: 0.4054 - Label_accuracy: 0.9764 - Label_loss: 0.0626 - loss: 0.4686 - val_Domain_accuracy: 0.0105 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7184 - val_Label_loss: 2.0290 - val_loss: 2.0503\n",
      "Epoch 59/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8616 - Domain_loss: 0.3872 - Label_accuracy: 0.9818 - Label_loss: 0.0548 - loss: 0.4421 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7526 - val_Label_loss: 2.0721 - val_loss: 2.0939\n",
      "Epoch 60/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8637 - Domain_loss: 0.3811 - Label_accuracy: 0.9815 - Label_loss: 0.0531 - loss: 0.4340 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7263 - val_Label_loss: 2.0814 - val_loss: 2.1012\n",
      "Epoch 61/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8702 - Domain_loss: 0.3742 - Label_accuracy: 0.9796 - Label_loss: 0.0558 - loss: 0.4302 - val_Domain_accuracy: 0.0039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7697 - val_Label_loss: 1.6604 - val_loss: 1.6777\n",
      "Epoch 62/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8839 - Domain_loss: 0.3402 - Label_accuracy: 0.9823 - Label_loss: 0.0453 - loss: 0.3847 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7289 - val_Label_loss: 2.3064 - val_loss: 2.3305\n",
      "Epoch 63/80\n",
      "244/244 - 8s - 32ms/step - Domain_accuracy: 0.8766 - Domain_loss: 0.3495 - Label_accuracy: 0.9851 - Label_loss: 0.0439 - loss: 0.3934 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 2.0814 - val_loss: 2.1009\n",
      "Epoch 64/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8760 - Domain_loss: 0.3545 - Label_accuracy: 0.9852 - Label_loss: 0.0386 - loss: 0.3939 - val_Domain_accuracy: 0.0145 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6947 - val_Label_loss: 2.3663 - val_loss: 2.3910\n",
      "Epoch 65/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.8812 - Domain_loss: 0.3342 - Label_accuracy: 0.9827 - Label_loss: 0.0470 - loss: 0.3794 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7211 - val_Label_loss: 2.3867 - val_loss: 2.4113\n",
      "Epoch 66/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8724 - Domain_loss: 0.3778 - Label_accuracy: 0.9837 - Label_loss: 0.0529 - loss: 0.4300 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7526 - val_Label_loss: 2.0371 - val_loss: 2.0537\n",
      "Epoch 67/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8737 - Domain_loss: 0.3602 - Label_accuracy: 0.9834 - Label_loss: 0.0496 - loss: 0.4088 - val_Domain_accuracy: 0.0211 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7092 - val_Label_loss: 2.3311 - val_loss: 2.3548\n",
      "Epoch 68/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.8658 - Domain_loss: 0.3856 - Label_accuracy: 0.9823 - Label_loss: 0.0498 - loss: 0.4341 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7079 - val_Label_loss: 2.4750 - val_loss: 2.5010\n",
      "Epoch 69/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8698 - Domain_loss: 0.3671 - Label_accuracy: 0.9831 - Label_loss: 0.0447 - loss: 0.4108 - val_Domain_accuracy: 0.0145 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7618 - val_Label_loss: 2.1806 - val_loss: 2.2034\n",
      "Epoch 70/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8784 - Domain_loss: 0.3372 - Label_accuracy: 0.9837 - Label_loss: 0.0463 - loss: 0.3831 - val_Domain_accuracy: 0.0250 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6987 - val_Label_loss: 2.5753 - val_loss: 2.6012\n",
      "Epoch 71/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8705 - Domain_loss: 0.3851 - Label_accuracy: 0.9852 - Label_loss: 0.0407 - loss: 0.4261 - val_Domain_accuracy: 0.0145 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7408 - val_Label_loss: 2.2579 - val_loss: 2.2790\n",
      "Epoch 72/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8851 - Domain_loss: 0.3385 - Label_accuracy: 0.9836 - Label_loss: 0.0460 - loss: 0.3847 - val_Domain_accuracy: 0.0224 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7026 - val_Label_loss: 2.5590 - val_loss: 2.5822\n",
      "Epoch 73/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8898 - Domain_loss: 0.3142 - Label_accuracy: 0.9852 - Label_loss: 0.0377 - loss: 0.3508 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7592 - val_Label_loss: 1.8725 - val_loss: 1.8922\n",
      "Epoch 74/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8685 - Domain_loss: 0.3706 - Label_accuracy: 0.9855 - Label_loss: 0.0413 - loss: 0.4127 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7618 - val_Label_loss: 2.1251 - val_loss: 2.1474\n",
      "Epoch 75/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8800 - Domain_loss: 0.3401 - Label_accuracy: 0.9854 - Label_loss: 0.0431 - loss: 0.3825 - val_Domain_accuracy: 0.0237 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7316 - val_Label_loss: 2.2486 - val_loss: 2.2706\n",
      "Epoch 76/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8685 - Domain_loss: 0.3859 - Label_accuracy: 0.9823 - Label_loss: 0.0484 - loss: 0.4343 - val_Domain_accuracy: 0.0224 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7605 - val_Label_loss: 2.0907 - val_loss: 2.1126\n",
      "Epoch 77/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8644 - Domain_loss: 0.3809 - Label_accuracy: 0.9850 - Label_loss: 0.0442 - loss: 0.4246 - val_Domain_accuracy: 0.0211 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7039 - val_Label_loss: 2.5570 - val_loss: 2.5799\n",
      "Epoch 78/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8690 - Domain_loss: 0.3769 - Label_accuracy: 0.9847 - Label_loss: 0.0467 - loss: 0.4241 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7171 - val_Label_loss: 2.3770 - val_loss: 2.3946\n",
      "Epoch 79/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8864 - Domain_loss: 0.3339 - Label_accuracy: 0.9873 - Label_loss: 0.0310 - loss: 0.3643 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7592 - val_Label_loss: 1.9239 - val_loss: 1.9440\n",
      "Epoch 80/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.8836 - Domain_loss: 0.3386 - Label_accuracy: 0.9865 - Label_loss: 0.0363 - loss: 0.3752 - val_Domain_accuracy: 0.0526 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7579 - val_Label_loss: 1.8723 - val_loss: 1.8919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #4\n",
      "train_feature shape: (7639, 5, 10, 256)\n",
      "train_targets shape: (7639, 5)\n",
      "train_domin shape: (7639, 9)\n",
      "Epoch 1/80\n",
      "239/239 - 17s - 72ms/step - Domain_accuracy: 0.5353 - Domain_loss: 1.4024 - Label_accuracy: 0.7881 - Label_loss: 0.6286 - loss: 2.0308 - val_Domain_accuracy: 0.4022 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7956 - val_Label_loss: 0.6284 - val_loss: 0.6337\n",
      "Epoch 2/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.6674 - Domain_loss: 0.9792 - Label_accuracy: 0.8839 - Label_loss: 0.3163 - loss: 1.2945 - val_Domain_accuracy: 0.1264 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7758 - val_Label_loss: 0.8334 - val_loss: 0.8354\n",
      "Epoch 3/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.6806 - Domain_loss: 0.9833 - Label_accuracy: 0.8895 - Label_loss: 0.2873 - loss: 1.2711 - val_Domain_accuracy: 0.2538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7714 - val_Label_loss: 0.8539 - val_loss: 0.8629\n",
      "Epoch 4/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.7415 - Domain_loss: 0.7739 - Label_accuracy: 0.9128 - Label_loss: 0.2313 - loss: 1.0053 - val_Domain_accuracy: 0.2736 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.8605 - val_loss: 0.8632\n",
      "Epoch 5/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.7340 - Domain_loss: 0.8129 - Label_accuracy: 0.9169 - Label_loss: 0.2236 - loss: 1.0366 - val_Domain_accuracy: 0.2978 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7626 - val_Label_loss: 1.0972 - val_loss: 1.1008\n",
      "Epoch 6/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.7606 - Domain_loss: 0.7118 - Label_accuracy: 0.9292 - Label_loss: 0.1865 - loss: 0.8981 - val_Domain_accuracy: 0.2088 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7407 - val_Label_loss: 1.4324 - val_loss: 1.4338\n",
      "Epoch 7/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.7624 - Domain_loss: 0.6894 - Label_accuracy: 0.9297 - Label_loss: 0.1841 - loss: 0.8737 - val_Domain_accuracy: 0.0692 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7330 - val_Label_loss: 1.2689 - val_loss: 1.2602\n",
      "Epoch 8/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.7746 - Domain_loss: 0.6687 - Label_accuracy: 0.9334 - Label_loss: 0.1751 - loss: 0.8440 - val_Domain_accuracy: 0.2956 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7967 - val_Label_loss: 0.9730 - val_loss: 0.9760\n",
      "Epoch 9/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8091 - Domain_loss: 0.5743 - Label_accuracy: 0.9403 - Label_loss: 0.1518 - loss: 0.7261 - val_Domain_accuracy: 0.2110 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8077 - val_Label_loss: 0.8288 - val_loss: 0.8271\n",
      "Epoch 10/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8138 - Domain_loss: 0.5531 - Label_accuracy: 0.9472 - Label_loss: 0.1335 - loss: 0.6868 - val_Domain_accuracy: 0.2791 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7692 - val_Label_loss: 1.1407 - val_loss: 1.1433\n",
      "Epoch 11/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8123 - Domain_loss: 0.5481 - Label_accuracy: 0.9469 - Label_loss: 0.1365 - loss: 0.6844 - val_Domain_accuracy: 0.1989 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7868 - val_Label_loss: 1.0007 - val_loss: 1.0040\n",
      "Epoch 12/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8060 - Domain_loss: 0.5773 - Label_accuracy: 0.9518 - Label_loss: 0.1280 - loss: 0.7056 - val_Domain_accuracy: 0.1703 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7868 - val_Label_loss: 1.1944 - val_loss: 1.1955\n",
      "Epoch 13/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8154 - Domain_loss: 0.5251 - Label_accuracy: 0.9567 - Label_loss: 0.1216 - loss: 0.6466 - val_Domain_accuracy: 0.3198 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7824 - val_Label_loss: 1.0136 - val_loss: 1.0010\n",
      "Epoch 14/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8238 - Domain_loss: 0.5122 - Label_accuracy: 0.9603 - Label_loss: 0.1031 - loss: 0.6153 - val_Domain_accuracy: 0.1121 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 1.1493 - val_loss: 1.1590\n",
      "Epoch 15/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8305 - Domain_loss: 0.4890 - Label_accuracy: 0.9661 - Label_loss: 0.0977 - loss: 0.5866 - val_Domain_accuracy: 0.1956 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 1.0050 - val_loss: 1.0027\n",
      "Epoch 16/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8175 - Domain_loss: 0.5370 - Label_accuracy: 0.9627 - Label_loss: 0.1043 - loss: 0.6412 - val_Domain_accuracy: 0.1703 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 1.0582 - val_loss: 1.0605\n",
      "Epoch 17/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8279 - Domain_loss: 0.5034 - Label_accuracy: 0.9670 - Label_loss: 0.0897 - loss: 0.5933 - val_Domain_accuracy: 0.1670 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7824 - val_Label_loss: 1.1055 - val_loss: 1.0796\n",
      "Epoch 18/80\n",
      "239/239 - 8s - 35ms/step - Domain_accuracy: 0.8209 - Domain_loss: 0.5154 - Label_accuracy: 0.9666 - Label_loss: 0.0934 - loss: 0.6091 - val_Domain_accuracy: 0.2648 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7868 - val_Label_loss: 1.3781 - val_loss: 1.3819\n",
      "Epoch 19/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8444 - Domain_loss: 0.4524 - Label_accuracy: 0.9678 - Label_loss: 0.0858 - loss: 0.5379 - val_Domain_accuracy: 0.2670 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8033 - val_Label_loss: 1.2102 - val_loss: 1.2129\n",
      "Epoch 20/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8224 - Domain_loss: 0.5088 - Label_accuracy: 0.9674 - Label_loss: 0.0882 - loss: 0.5968 - val_Domain_accuracy: 0.3934 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7890 - val_Label_loss: 1.1856 - val_loss: 1.1829\n",
      "Epoch 21/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8385 - Domain_loss: 0.4677 - Label_accuracy: 0.9686 - Label_loss: 0.0819 - loss: 0.5495 - val_Domain_accuracy: 0.2110 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7670 - val_Label_loss: 1.3312 - val_loss: 1.3187\n",
      "Epoch 22/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8591 - Domain_loss: 0.4201 - Label_accuracy: 0.9755 - Label_loss: 0.0661 - loss: 0.4857 - val_Domain_accuracy: 0.2165 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8143 - val_Label_loss: 1.0998 - val_loss: 1.0890\n",
      "Epoch 23/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8449 - Domain_loss: 0.4464 - Label_accuracy: 0.9746 - Label_loss: 0.0742 - loss: 0.5208 - val_Domain_accuracy: 0.1571 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8055 - val_Label_loss: 1.1545 - val_loss: 1.1475\n",
      "Epoch 24/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8560 - Domain_loss: 0.4237 - Label_accuracy: 0.9690 - Label_loss: 0.0805 - loss: 0.5037 - val_Domain_accuracy: 0.2857 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7330 - val_Label_loss: 1.5899 - val_loss: 1.5793\n",
      "Epoch 25/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8512 - Domain_loss: 0.4315 - Label_accuracy: 0.9737 - Label_loss: 0.0737 - loss: 0.5052 - val_Domain_accuracy: 0.1967 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 1.5415 - val_loss: 1.5465\n",
      "Epoch 26/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8620 - Domain_loss: 0.4022 - Label_accuracy: 0.9770 - Label_loss: 0.0622 - loss: 0.4644 - val_Domain_accuracy: 0.2253 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7648 - val_Label_loss: 1.6963 - val_loss: 1.6900\n",
      "Epoch 27/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8624 - Domain_loss: 0.4089 - Label_accuracy: 0.9801 - Label_loss: 0.0556 - loss: 0.4644 - val_Domain_accuracy: 0.1703 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7813 - val_Label_loss: 1.3008 - val_loss: 1.2903\n",
      "Epoch 28/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8462 - Domain_loss: 0.4421 - Label_accuracy: 0.9779 - Label_loss: 0.0621 - loss: 0.5042 - val_Domain_accuracy: 0.1495 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 1.3406 - val_loss: 1.3225\n",
      "Epoch 29/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8569 - Domain_loss: 0.3960 - Label_accuracy: 0.9784 - Label_loss: 0.0584 - loss: 0.4544 - val_Domain_accuracy: 0.1736 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7462 - val_Label_loss: 1.6802 - val_loss: 1.6878\n",
      "Epoch 30/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8533 - Domain_loss: 0.4274 - Label_accuracy: 0.9832 - Label_loss: 0.0488 - loss: 0.4762 - val_Domain_accuracy: 0.2121 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7418 - val_Label_loss: 1.9505 - val_loss: 1.9434\n",
      "Epoch 31/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8678 - Domain_loss: 0.3886 - Label_accuracy: 0.9809 - Label_loss: 0.0536 - loss: 0.4417 - val_Domain_accuracy: 0.1088 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7484 - val_Label_loss: 1.6698 - val_loss: 1.6531\n",
      "Epoch 32/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8419 - Domain_loss: 0.4463 - Label_accuracy: 0.9800 - Label_loss: 0.0549 - loss: 0.5015 - val_Domain_accuracy: 0.1231 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7879 - val_Label_loss: 1.3609 - val_loss: 1.3696\n",
      "Epoch 33/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8474 - Domain_loss: 0.4473 - Label_accuracy: 0.9801 - Label_loss: 0.0531 - loss: 0.5005 - val_Domain_accuracy: 0.3637 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 1.6506 - val_loss: 1.6571\n",
      "Epoch 34/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8438 - Domain_loss: 0.4676 - Label_accuracy: 0.9779 - Label_loss: 0.0634 - loss: 0.5308 - val_Domain_accuracy: 0.0758 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7462 - val_Label_loss: 1.5814 - val_loss: 1.5542\n",
      "Epoch 35/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8498 - Domain_loss: 0.4317 - Label_accuracy: 0.9792 - Label_loss: 0.0563 - loss: 0.4877 - val_Domain_accuracy: 0.1692 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7055 - val_Label_loss: 2.2959 - val_loss: 2.2978\n",
      "Epoch 36/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8419 - Domain_loss: 0.4567 - Label_accuracy: 0.9805 - Label_loss: 0.0535 - loss: 0.5100 - val_Domain_accuracy: 0.1714 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7791 - val_Label_loss: 1.6419 - val_loss: 1.6458\n",
      "Epoch 37/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8574 - Domain_loss: 0.4134 - Label_accuracy: 0.9798 - Label_loss: 0.0605 - loss: 0.4739 - val_Domain_accuracy: 0.2560 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.4586 - val_loss: 1.4622\n",
      "Epoch 38/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8548 - Domain_loss: 0.4055 - Label_accuracy: 0.9815 - Label_loss: 0.0483 - loss: 0.4538 - val_Domain_accuracy: 0.2385 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7956 - val_Label_loss: 1.6456 - val_loss: 1.6456\n",
      "Epoch 39/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8495 - Domain_loss: 0.4299 - Label_accuracy: 0.9776 - Label_loss: 0.0584 - loss: 0.4881 - val_Domain_accuracy: 0.2615 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7571 - val_Label_loss: 2.0998 - val_loss: 2.0966\n",
      "Epoch 40/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8492 - Domain_loss: 0.4421 - Label_accuracy: 0.9823 - Label_loss: 0.0460 - loss: 0.4879 - val_Domain_accuracy: 0.1725 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7758 - val_Label_loss: 1.7801 - val_loss: 1.7666\n",
      "Epoch 41/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8708 - Domain_loss: 0.3783 - Label_accuracy: 0.9866 - Label_loss: 0.0396 - loss: 0.4180 - val_Domain_accuracy: 0.2571 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7000 - val_Label_loss: 3.0437 - val_loss: 3.0173\n",
      "Epoch 42/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8540 - Domain_loss: 0.4081 - Label_accuracy: 0.9844 - Label_loss: 0.0503 - loss: 0.4578 - val_Domain_accuracy: 0.1670 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 1.5779 - val_loss: 1.5649\n",
      "Epoch 43/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8561 - Domain_loss: 0.4159 - Label_accuracy: 0.9821 - Label_loss: 0.0490 - loss: 0.4650 - val_Domain_accuracy: 0.2000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7637 - val_Label_loss: 1.6360 - val_loss: 1.6181\n",
      "Epoch 44/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8538 - Domain_loss: 0.4297 - Label_accuracy: 0.9856 - Label_loss: 0.0425 - loss: 0.4721 - val_Domain_accuracy: 0.2560 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7352 - val_Label_loss: 1.9312 - val_loss: 1.9135\n",
      "Epoch 45/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8584 - Domain_loss: 0.4019 - Label_accuracy: 0.9856 - Label_loss: 0.0395 - loss: 0.4416 - val_Domain_accuracy: 0.2187 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7637 - val_Label_loss: 2.0246 - val_loss: 2.0275\n",
      "Epoch 46/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8632 - Domain_loss: 0.4022 - Label_accuracy: 0.9827 - Label_loss: 0.0444 - loss: 0.4467 - val_Domain_accuracy: 0.2549 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 1.7472 - val_loss: 1.7425\n",
      "Epoch 47/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8683 - Domain_loss: 0.3894 - Label_accuracy: 0.9863 - Label_loss: 0.0406 - loss: 0.4300 - val_Domain_accuracy: 0.1582 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7363 - val_Label_loss: 2.2319 - val_loss: 2.2224\n",
      "Epoch 48/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8631 - Domain_loss: 0.3873 - Label_accuracy: 0.9859 - Label_loss: 0.0393 - loss: 0.4263 - val_Domain_accuracy: 0.1934 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7582 - val_Label_loss: 2.0689 - val_loss: 2.0746\n",
      "Epoch 49/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8428 - Domain_loss: 0.4499 - Label_accuracy: 0.9857 - Label_loss: 0.0397 - loss: 0.4895 - val_Domain_accuracy: 0.1593 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7440 - val_Label_loss: 2.1799 - val_loss: 2.1804\n",
      "Epoch 50/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8489 - Domain_loss: 0.4321 - Label_accuracy: 0.9848 - Label_loss: 0.0479 - loss: 0.4802 - val_Domain_accuracy: 0.1670 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7725 - val_Label_loss: 1.6085 - val_loss: 1.6073\n",
      "Epoch 51/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8677 - Domain_loss: 0.3679 - Label_accuracy: 0.9912 - Label_loss: 0.0252 - loss: 0.3931 - val_Domain_accuracy: 0.2538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7725 - val_Label_loss: 2.1604 - val_loss: 2.1753\n",
      "Epoch 52/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8628 - Domain_loss: 0.3864 - Label_accuracy: 0.9873 - Label_loss: 0.0367 - loss: 0.4233 - val_Domain_accuracy: 0.2879 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7714 - val_Label_loss: 2.0882 - val_loss: 2.0891\n",
      "Epoch 53/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8449 - Domain_loss: 0.4515 - Label_accuracy: 0.9832 - Label_loss: 0.0446 - loss: 0.4963 - val_Domain_accuracy: 0.3495 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.9450 - val_loss: 1.9595\n",
      "Epoch 54/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8459 - Domain_loss: 0.4421 - Label_accuracy: 0.9872 - Label_loss: 0.0371 - loss: 0.4795 - val_Domain_accuracy: 0.1571 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7824 - val_Label_loss: 1.9864 - val_loss: 1.9907\n",
      "Epoch 55/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8665 - Domain_loss: 0.3899 - Label_accuracy: 0.9894 - Label_loss: 0.0278 - loss: 0.4177 - val_Domain_accuracy: 0.1626 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7791 - val_Label_loss: 1.8500 - val_loss: 1.8425\n",
      "Epoch 56/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8607 - Domain_loss: 0.3941 - Label_accuracy: 0.9868 - Label_loss: 0.0372 - loss: 0.4310 - val_Domain_accuracy: 0.1714 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7527 - val_Label_loss: 2.1926 - val_loss: 2.1901\n",
      "Epoch 57/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8392 - Domain_loss: 0.4708 - Label_accuracy: 0.9831 - Label_loss: 0.0444 - loss: 0.5155 - val_Domain_accuracy: 0.1670 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7495 - val_Label_loss: 2.2574 - val_loss: 2.2415\n",
      "Epoch 58/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8544 - Domain_loss: 0.4166 - Label_accuracy: 0.9870 - Label_loss: 0.0416 - loss: 0.4583 - val_Domain_accuracy: 0.2549 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7714 - val_Label_loss: 2.3023 - val_loss: 2.3070\n",
      "Epoch 59/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8444 - Domain_loss: 0.4515 - Label_accuracy: 0.9885 - Label_loss: 0.0310 - loss: 0.4824 - val_Domain_accuracy: 0.3297 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 1.6542 - val_loss: 1.6443\n",
      "Epoch 60/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8585 - Domain_loss: 0.4116 - Label_accuracy: 0.9876 - Label_loss: 0.0344 - loss: 0.4459 - val_Domain_accuracy: 0.1901 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7681 - val_Label_loss: 1.8531 - val_loss: 1.8398\n",
      "Epoch 61/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8637 - Domain_loss: 0.4009 - Label_accuracy: 0.9908 - Label_loss: 0.0249 - loss: 0.4258 - val_Domain_accuracy: 0.1714 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7604 - val_Label_loss: 2.2760 - val_loss: 2.2749\n",
      "Epoch 62/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8441 - Domain_loss: 0.4533 - Label_accuracy: 0.9877 - Label_loss: 0.0362 - loss: 0.4898 - val_Domain_accuracy: 0.1670 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7593 - val_Label_loss: 2.0724 - val_loss: 2.0742\n",
      "Epoch 63/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8526 - Domain_loss: 0.4228 - Label_accuracy: 0.9859 - Label_loss: 0.0403 - loss: 0.4634 - val_Domain_accuracy: 0.2000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8110 - val_Label_loss: 1.6652 - val_loss: 1.6665\n",
      "Epoch 64/80\n",
      "239/239 - 8s - 33ms/step - Domain_accuracy: 0.8417 - Domain_loss: 0.4432 - Label_accuracy: 0.9855 - Label_loss: 0.0450 - loss: 0.4885 - val_Domain_accuracy: 0.2429 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7681 - val_Label_loss: 2.5478 - val_loss: 2.5552\n",
      "Epoch 65/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8656 - Domain_loss: 0.3968 - Label_accuracy: 0.9883 - Label_loss: 0.0337 - loss: 0.4302 - val_Domain_accuracy: 0.2407 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.8606 - val_loss: 1.8565\n",
      "Epoch 66/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8536 - Domain_loss: 0.4071 - Label_accuracy: 0.9873 - Label_loss: 0.0403 - loss: 0.4475 - val_Domain_accuracy: 0.1945 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7319 - val_Label_loss: 2.3118 - val_loss: 2.2903\n",
      "Epoch 67/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8670 - Domain_loss: 0.3760 - Label_accuracy: 0.9891 - Label_loss: 0.0324 - loss: 0.4085 - val_Domain_accuracy: 0.2440 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8055 - val_Label_loss: 1.6799 - val_loss: 1.6763\n",
      "Epoch 68/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8525 - Domain_loss: 0.4273 - Label_accuracy: 0.9882 - Label_loss: 0.0348 - loss: 0.4624 - val_Domain_accuracy: 0.1956 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 2.2757 - val_loss: 2.2815\n",
      "Epoch 69/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8512 - Domain_loss: 0.4264 - Label_accuracy: 0.9895 - Label_loss: 0.0249 - loss: 0.4517 - val_Domain_accuracy: 0.1824 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 2.0686 - val_loss: 2.0796\n",
      "Epoch 70/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8632 - Domain_loss: 0.3947 - Label_accuracy: 0.9882 - Label_loss: 0.0312 - loss: 0.4252 - val_Domain_accuracy: 0.1923 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7626 - val_Label_loss: 2.5168 - val_loss: 2.5070\n",
      "Epoch 71/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8572 - Domain_loss: 0.4137 - Label_accuracy: 0.9881 - Label_loss: 0.0390 - loss: 0.4522 - val_Domain_accuracy: 0.3582 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7538 - val_Label_loss: 2.8018 - val_loss: 2.8253\n",
      "Epoch 72/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8375 - Domain_loss: 0.4787 - Label_accuracy: 0.9863 - Label_loss: 0.0412 - loss: 0.5201 - val_Domain_accuracy: 0.1473 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7659 - val_Label_loss: 2.0704 - val_loss: 2.0549\n",
      "Epoch 73/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8767 - Domain_loss: 0.3445 - Label_accuracy: 0.9918 - Label_loss: 0.0260 - loss: 0.3709 - val_Domain_accuracy: 0.2945 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7780 - val_Label_loss: 2.2018 - val_loss: 2.2024\n",
      "Epoch 74/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8653 - Domain_loss: 0.3874 - Label_accuracy: 0.9873 - Label_loss: 0.0390 - loss: 0.4264 - val_Domain_accuracy: 0.3363 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7868 - val_Label_loss: 2.0479 - val_loss: 2.0544\n",
      "Epoch 75/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8606 - Domain_loss: 0.3924 - Label_accuracy: 0.9894 - Label_loss: 0.0329 - loss: 0.4254 - val_Domain_accuracy: 0.1989 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7890 - val_Label_loss: 1.8204 - val_loss: 1.8200\n",
      "Epoch 76/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8459 - Domain_loss: 0.4472 - Label_accuracy: 0.9894 - Label_loss: 0.0346 - loss: 0.4814 - val_Domain_accuracy: 0.2088 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7604 - val_Label_loss: 2.7346 - val_loss: 2.7543\n",
      "Epoch 77/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8437 - Domain_loss: 0.4540 - Label_accuracy: 0.9901 - Label_loss: 0.0275 - loss: 0.4815 - val_Domain_accuracy: 0.2516 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8209 - val_Label_loss: 1.4537 - val_loss: 1.4469\n",
      "Epoch 78/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8574 - Domain_loss: 0.4133 - Label_accuracy: 0.9891 - Label_loss: 0.0291 - loss: 0.4425 - val_Domain_accuracy: 0.2363 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7604 - val_Label_loss: 2.3847 - val_loss: 2.3758\n",
      "Epoch 79/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8598 - Domain_loss: 0.3965 - Label_accuracy: 0.9885 - Label_loss: 0.0302 - loss: 0.4269 - val_Domain_accuracy: 0.1890 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7648 - val_Label_loss: 2.4278 - val_loss: 2.4263\n",
      "Epoch 80/80\n",
      "239/239 - 8s - 34ms/step - Domain_accuracy: 0.8660 - Domain_loss: 0.3788 - Label_accuracy: 0.9918 - Label_loss: 0.0230 - loss: 0.4017 - val_Domain_accuracy: 0.2505 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7692 - val_Label_loss: 2.6273 - val_loss: 2.6208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #5\n",
      "train_feature shape: (7730, 5, 10, 256)\n",
      "train_targets shape: (7730, 5)\n",
      "train_domin shape: (7730, 9)\n",
      "Epoch 1/80\n",
      "242/242 - 17s - 71ms/step - Domain_accuracy: 0.4197 - Domain_loss: 1.7429 - Label_accuracy: 0.6539 - Label_loss: 1.0799 - loss: 2.8246 - val_Domain_accuracy: 0.1453 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7033 - val_Label_loss: 0.7308 - val_loss: 0.7334\n",
      "Epoch 2/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.5704 - Domain_loss: 1.2300 - Label_accuracy: 0.7546 - Label_loss: 0.6274 - loss: 1.8572 - val_Domain_accuracy: 0.1429 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8046 - val_Label_loss: 0.5066 - val_loss: 0.5074\n",
      "Epoch 3/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.6000 - Domain_loss: 1.1978 - Label_accuracy: 0.7815 - Label_loss: 0.5562 - loss: 1.7552 - val_Domain_accuracy: 0.0904 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8059 - val_Label_loss: 0.5014 - val_loss: 0.5020\n",
      "Epoch 4/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.6294 - Domain_loss: 1.0872 - Label_accuracy: 0.7977 - Label_loss: 0.5235 - loss: 1.6109 - val_Domain_accuracy: 0.1905 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 0.5267 - val_loss: 0.5278\n",
      "Epoch 5/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.6671 - Domain_loss: 1.0025 - Label_accuracy: 0.8132 - Label_loss: 0.4861 - loss: 1.4884 - val_Domain_accuracy: 0.3040 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7888 - val_Label_loss: 0.5082 - val_loss: 0.5090\n",
      "Epoch 6/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.6695 - Domain_loss: 0.9904 - Label_accuracy: 0.8096 - Label_loss: 0.4806 - loss: 1.4711 - val_Domain_accuracy: 0.1245 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7766 - val_Label_loss: 0.5680 - val_loss: 0.5668\n",
      "Epoch 7/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.6516 - Domain_loss: 1.0408 - Label_accuracy: 0.8135 - Label_loss: 0.4706 - loss: 1.5124 - val_Domain_accuracy: 0.1917 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7851 - val_Label_loss: 0.4945 - val_loss: 0.4948\n",
      "Epoch 8/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.6671 - Domain_loss: 0.9694 - Label_accuracy: 0.8171 - Label_loss: 0.4598 - loss: 1.4292 - val_Domain_accuracy: 0.1001 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7863 - val_Label_loss: 0.5175 - val_loss: 0.5193\n",
      "Epoch 9/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7116 - Domain_loss: 0.8464 - Label_accuracy: 0.8263 - Label_loss: 0.4335 - loss: 1.2793 - val_Domain_accuracy: 0.1087 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7888 - val_Label_loss: 0.5180 - val_loss: 0.5186\n",
      "Epoch 10/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7088 - Domain_loss: 0.8582 - Label_accuracy: 0.8331 - Label_loss: 0.4299 - loss: 1.2871 - val_Domain_accuracy: 0.3504 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7656 - val_Label_loss: 0.5611 - val_loss: 0.5632\n",
      "Epoch 11/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7018 - Domain_loss: 0.8580 - Label_accuracy: 0.8233 - Label_loss: 0.4395 - loss: 1.2975 - val_Domain_accuracy: 0.1966 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7998 - val_Label_loss: 0.5367 - val_loss: 0.5355\n",
      "Epoch 12/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7199 - Domain_loss: 0.8322 - Label_accuracy: 0.8361 - Label_loss: 0.4075 - loss: 1.2399 - val_Domain_accuracy: 0.0317 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7643 - val_Label_loss: 0.6275 - val_loss: 0.6280\n",
      "Epoch 13/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7292 - Domain_loss: 0.7924 - Label_accuracy: 0.8415 - Label_loss: 0.4109 - loss: 1.2028 - val_Domain_accuracy: 0.1502 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 0.5111 - val_loss: 0.5119\n",
      "Epoch 14/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7277 - Domain_loss: 0.8012 - Label_accuracy: 0.8362 - Label_loss: 0.3954 - loss: 1.1965 - val_Domain_accuracy: 0.5360 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7717 - val_Label_loss: 0.5423 - val_loss: 0.5418\n",
      "Epoch 15/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7451 - Domain_loss: 0.7535 - Label_accuracy: 0.8428 - Label_loss: 0.3928 - loss: 1.1464 - val_Domain_accuracy: 0.1197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7753 - val_Label_loss: 0.5363 - val_loss: 0.5363\n",
      "Epoch 16/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7419 - Domain_loss: 0.7605 - Label_accuracy: 0.8472 - Label_loss: 0.3850 - loss: 1.1462 - val_Domain_accuracy: 0.1673 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7766 - val_Label_loss: 0.5389 - val_loss: 0.5404\n",
      "Epoch 17/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7511 - Domain_loss: 0.7394 - Label_accuracy: 0.8488 - Label_loss: 0.3811 - loss: 1.1194 - val_Domain_accuracy: 0.2808 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 0.5326 - val_loss: 0.5337\n",
      "Epoch 18/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7718 - Domain_loss: 0.6760 - Label_accuracy: 0.8529 - Label_loss: 0.3721 - loss: 1.0481 - val_Domain_accuracy: 0.3028 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7558 - val_Label_loss: 0.5874 - val_loss: 0.5896\n",
      "Epoch 19/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7543 - Domain_loss: 0.7273 - Label_accuracy: 0.8451 - Label_loss: 0.3875 - loss: 1.1143 - val_Domain_accuracy: 0.4945 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7643 - val_Label_loss: 0.5878 - val_loss: 0.5898\n",
      "Epoch 20/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7549 - Domain_loss: 0.7167 - Label_accuracy: 0.8507 - Label_loss: 0.3735 - loss: 1.0891 - val_Domain_accuracy: 0.1490 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7973 - val_Label_loss: 0.5149 - val_loss: 0.5157\n",
      "Epoch 21/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7721 - Domain_loss: 0.6568 - Label_accuracy: 0.8609 - Label_loss: 0.3569 - loss: 1.0142 - val_Domain_accuracy: 0.3639 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7497 - val_Label_loss: 0.6023 - val_loss: 0.6038\n",
      "Epoch 22/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7630 - Domain_loss: 0.7014 - Label_accuracy: 0.8582 - Label_loss: 0.3617 - loss: 1.0629 - val_Domain_accuracy: 0.1661 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7656 - val_Label_loss: 0.5825 - val_loss: 0.5843\n",
      "Epoch 23/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7748 - Domain_loss: 0.6543 - Label_accuracy: 0.8590 - Label_loss: 0.3594 - loss: 1.0139 - val_Domain_accuracy: 0.2149 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7668 - val_Label_loss: 0.5849 - val_loss: 0.5858\n",
      "Epoch 24/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7812 - Domain_loss: 0.6202 - Label_accuracy: 0.8638 - Label_loss: 0.3418 - loss: 0.9628 - val_Domain_accuracy: 0.0806 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7998 - val_Label_loss: 0.5580 - val_loss: 0.5582\n",
      "Epoch 25/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7739 - Domain_loss: 0.6704 - Label_accuracy: 0.8599 - Label_loss: 0.3534 - loss: 1.0231 - val_Domain_accuracy: 0.2479 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7766 - val_Label_loss: 0.5309 - val_loss: 0.5308\n",
      "Epoch 26/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7834 - Domain_loss: 0.6460 - Label_accuracy: 0.8643 - Label_loss: 0.3390 - loss: 0.9850 - val_Domain_accuracy: 0.0659 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7778 - val_Label_loss: 0.5467 - val_loss: 0.5473\n",
      "Epoch 27/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7788 - Domain_loss: 0.6317 - Label_accuracy: 0.8719 - Label_loss: 0.3188 - loss: 0.9505 - val_Domain_accuracy: 0.4872 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7692 - val_Label_loss: 0.6452 - val_loss: 0.6473\n",
      "Epoch 28/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7661 - Domain_loss: 0.6783 - Label_accuracy: 0.8723 - Label_loss: 0.3325 - loss: 1.0106 - val_Domain_accuracy: 0.1832 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7460 - val_Label_loss: 0.6084 - val_loss: 0.6094\n",
      "Epoch 29/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7987 - Domain_loss: 0.5752 - Label_accuracy: 0.8688 - Label_loss: 0.3238 - loss: 0.8980 - val_Domain_accuracy: 0.2723 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7680 - val_Label_loss: 0.5832 - val_loss: 0.5845\n",
      "Epoch 30/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7946 - Domain_loss: 0.5919 - Label_accuracy: 0.8670 - Label_loss: 0.3311 - loss: 0.9224 - val_Domain_accuracy: 0.0647 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7607 - val_Label_loss: 0.5996 - val_loss: 0.6012\n",
      "Epoch 31/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8115 - Domain_loss: 0.5623 - Label_accuracy: 0.8788 - Label_loss: 0.3094 - loss: 0.8712 - val_Domain_accuracy: 0.1355 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7668 - val_Label_loss: 0.6588 - val_loss: 0.6603\n",
      "Epoch 32/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7939 - Domain_loss: 0.6182 - Label_accuracy: 0.8789 - Label_loss: 0.3121 - loss: 0.9302 - val_Domain_accuracy: 0.0513 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7570 - val_Label_loss: 0.6499 - val_loss: 0.6513\n",
      "Epoch 33/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7827 - Domain_loss: 0.6402 - Label_accuracy: 0.8699 - Label_loss: 0.3241 - loss: 0.9646 - val_Domain_accuracy: 0.2503 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7839 - val_Label_loss: 0.5691 - val_loss: 0.5681\n",
      "Epoch 34/80\n",
      "242/242 - 8s - 35ms/step - Domain_accuracy: 0.8000 - Domain_loss: 0.5831 - Label_accuracy: 0.8793 - Label_loss: 0.2997 - loss: 0.8837 - val_Domain_accuracy: 0.3053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8022 - val_Label_loss: 0.5406 - val_loss: 0.5417\n",
      "Epoch 35/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8041 - Domain_loss: 0.5637 - Label_accuracy: 0.8777 - Label_loss: 0.3040 - loss: 0.8672 - val_Domain_accuracy: 0.3834 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7961 - val_Label_loss: 0.5488 - val_loss: 0.5487\n",
      "Epoch 36/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8092 - Domain_loss: 0.5623 - Label_accuracy: 0.8765 - Label_loss: 0.3077 - loss: 0.8692 - val_Domain_accuracy: 0.2698 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7961 - val_Label_loss: 0.5651 - val_loss: 0.5647\n",
      "Epoch 37/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8144 - Domain_loss: 0.5506 - Label_accuracy: 0.8860 - Label_loss: 0.2939 - loss: 0.8450 - val_Domain_accuracy: 0.1978 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8022 - val_Label_loss: 0.5486 - val_loss: 0.5492\n",
      "Epoch 38/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.7940 - Domain_loss: 0.6069 - Label_accuracy: 0.8846 - Label_loss: 0.2942 - loss: 0.9011 - val_Domain_accuracy: 0.3944 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7839 - val_Label_loss: 0.5675 - val_loss: 0.5680\n",
      "Epoch 39/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8106 - Domain_loss: 0.5593 - Label_accuracy: 0.8790 - Label_loss: 0.3005 - loss: 0.8593 - val_Domain_accuracy: 0.0830 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7827 - val_Label_loss: 0.5694 - val_loss: 0.5699\n",
      "Epoch 40/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8221 - Domain_loss: 0.5178 - Label_accuracy: 0.8865 - Label_loss: 0.2853 - loss: 0.8034 - val_Domain_accuracy: 0.1648 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 0.5700 - val_loss: 0.5708\n",
      "Epoch 41/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8113 - Domain_loss: 0.5410 - Label_accuracy: 0.8891 - Label_loss: 0.2834 - loss: 0.8236 - val_Domain_accuracy: 0.2039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 0.5978 - val_loss: 0.5979\n",
      "Epoch 42/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8138 - Domain_loss: 0.5327 - Label_accuracy: 0.8935 - Label_loss: 0.2735 - loss: 0.8064 - val_Domain_accuracy: 0.2344 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7851 - val_Label_loss: 0.5938 - val_loss: 0.5937\n",
      "Epoch 43/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8141 - Domain_loss: 0.5487 - Label_accuracy: 0.8911 - Label_loss: 0.2830 - loss: 0.8320 - val_Domain_accuracy: 0.4383 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7827 - val_Label_loss: 0.5952 - val_loss: 0.5975\n",
      "Epoch 44/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8111 - Domain_loss: 0.5479 - Label_accuracy: 0.8873 - Label_loss: 0.2757 - loss: 0.8241 - val_Domain_accuracy: 0.1624 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7863 - val_Label_loss: 0.6096 - val_loss: 0.6104\n",
      "Epoch 45/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8167 - Domain_loss: 0.5260 - Label_accuracy: 0.8926 - Label_loss: 0.2608 - loss: 0.7876 - val_Domain_accuracy: 0.2039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7717 - val_Label_loss: 0.6340 - val_loss: 0.6346\n",
      "Epoch 46/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8263 - Domain_loss: 0.5022 - Label_accuracy: 0.8957 - Label_loss: 0.2589 - loss: 0.7607 - val_Domain_accuracy: 0.4176 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7680 - val_Label_loss: 0.6597 - val_loss: 0.6632\n",
      "Epoch 47/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8274 - Domain_loss: 0.5069 - Label_accuracy: 0.8959 - Label_loss: 0.2650 - loss: 0.7722 - val_Domain_accuracy: 0.1038 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7888 - val_Label_loss: 0.5797 - val_loss: 0.5809\n",
      "Epoch 48/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8094 - Domain_loss: 0.5494 - Label_accuracy: 0.9010 - Label_loss: 0.2518 - loss: 0.8020 - val_Domain_accuracy: 0.2088 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7729 - val_Label_loss: 0.6385 - val_loss: 0.6434\n",
      "Epoch 49/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8173 - Domain_loss: 0.5375 - Label_accuracy: 0.8940 - Label_loss: 0.2673 - loss: 0.8046 - val_Domain_accuracy: 0.1893 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7668 - val_Label_loss: 0.6018 - val_loss: 0.6016\n",
      "Epoch 50/80\n",
      "242/242 - 8s - 35ms/step - Domain_accuracy: 0.8032 - Domain_loss: 0.5697 - Label_accuracy: 0.8990 - Label_loss: 0.2508 - loss: 0.8202 - val_Domain_accuracy: 0.1538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 0.5921 - val_loss: 0.5945\n",
      "Epoch 51/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8062 - Domain_loss: 0.5541 - Label_accuracy: 0.9032 - Label_loss: 0.2600 - loss: 0.8139 - val_Domain_accuracy: 0.1648 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7729 - val_Label_loss: 0.6493 - val_loss: 0.6523\n",
      "Epoch 52/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8190 - Domain_loss: 0.5252 - Label_accuracy: 0.8982 - Label_loss: 0.2525 - loss: 0.7781 - val_Domain_accuracy: 0.1929 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7888 - val_Label_loss: 0.6206 - val_loss: 0.6214\n",
      "Epoch 53/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8286 - Domain_loss: 0.5058 - Label_accuracy: 0.9003 - Label_loss: 0.2442 - loss: 0.7499 - val_Domain_accuracy: 0.3309 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7619 - val_Label_loss: 0.6487 - val_loss: 0.6505\n",
      "Epoch 54/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8120 - Domain_loss: 0.5417 - Label_accuracy: 0.9003 - Label_loss: 0.2504 - loss: 0.7925 - val_Domain_accuracy: 0.1123 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 0.7848 - val_loss: 0.7857\n",
      "Epoch 55/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8216 - Domain_loss: 0.4998 - Label_accuracy: 0.9069 - Label_loss: 0.2412 - loss: 0.7409 - val_Domain_accuracy: 0.2735 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7863 - val_Label_loss: 0.6376 - val_loss: 0.6378\n",
      "Epoch 56/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8301 - Domain_loss: 0.5036 - Label_accuracy: 0.9025 - Label_loss: 0.2485 - loss: 0.7525 - val_Domain_accuracy: 0.2222 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7790 - val_Label_loss: 0.6572 - val_loss: 0.6580\n",
      "Epoch 57/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8194 - Domain_loss: 0.5230 - Label_accuracy: 0.8997 - Label_loss: 0.2489 - loss: 0.7725 - val_Domain_accuracy: 0.2173 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 0.6493 - val_loss: 0.6494\n",
      "Epoch 58/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8369 - Domain_loss: 0.4821 - Label_accuracy: 0.9023 - Label_loss: 0.2473 - loss: 0.7298 - val_Domain_accuracy: 0.2955 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7607 - val_Label_loss: 0.6901 - val_loss: 0.6955\n",
      "Epoch 59/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8313 - Domain_loss: 0.4953 - Label_accuracy: 0.9083 - Label_loss: 0.2322 - loss: 0.7277 - val_Domain_accuracy: 0.1087 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7888 - val_Label_loss: 0.6051 - val_loss: 0.6087\n",
      "Epoch 60/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8286 - Domain_loss: 0.5014 - Label_accuracy: 0.9056 - Label_loss: 0.2465 - loss: 0.7468 - val_Domain_accuracy: 0.2002 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7863 - val_Label_loss: 0.6175 - val_loss: 0.6196\n",
      "Epoch 61/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8266 - Domain_loss: 0.5240 - Label_accuracy: 0.9035 - Label_loss: 0.2315 - loss: 0.7554 - val_Domain_accuracy: 0.2540 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7692 - val_Label_loss: 0.7007 - val_loss: 0.7038\n",
      "Epoch 62/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8301 - Domain_loss: 0.4889 - Label_accuracy: 0.9069 - Label_loss: 0.2413 - loss: 0.7298 - val_Domain_accuracy: 0.1477 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 0.5937 - val_loss: 0.5966\n",
      "Epoch 63/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8281 - Domain_loss: 0.5021 - Label_accuracy: 0.9048 - Label_loss: 0.2396 - loss: 0.7407 - val_Domain_accuracy: 0.0720 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7436 - val_Label_loss: 0.8284 - val_loss: 0.8337\n",
      "Epoch 64/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8329 - Domain_loss: 0.4970 - Label_accuracy: 0.9067 - Label_loss: 0.2317 - loss: 0.7288 - val_Domain_accuracy: 0.1685 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7729 - val_Label_loss: 0.7556 - val_loss: 0.7580\n",
      "Epoch 65/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8245 - Domain_loss: 0.5100 - Label_accuracy: 0.9129 - Label_loss: 0.2269 - loss: 0.7369 - val_Domain_accuracy: 0.1294 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7631 - val_Label_loss: 0.6615 - val_loss: 0.6642\n",
      "Epoch 66/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8283 - Domain_loss: 0.5157 - Label_accuracy: 0.9124 - Label_loss: 0.2236 - loss: 0.7394 - val_Domain_accuracy: 0.2442 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7839 - val_Label_loss: 0.6663 - val_loss: 0.6684\n",
      "Epoch 67/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8278 - Domain_loss: 0.5033 - Label_accuracy: 0.9142 - Label_loss: 0.2140 - loss: 0.7173 - val_Domain_accuracy: 0.0781 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 0.6577 - val_loss: 0.6591\n",
      "Epoch 68/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8226 - Domain_loss: 0.5150 - Label_accuracy: 0.9127 - Label_loss: 0.2214 - loss: 0.7363 - val_Domain_accuracy: 0.1587 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7692 - val_Label_loss: 0.7862 - val_loss: 0.7896\n",
      "Epoch 69/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8365 - Domain_loss: 0.4845 - Label_accuracy: 0.9118 - Label_loss: 0.2228 - loss: 0.7070 - val_Domain_accuracy: 0.1966 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7863 - val_Label_loss: 0.6610 - val_loss: 0.6619\n",
      "Epoch 70/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8367 - Domain_loss: 0.4703 - Label_accuracy: 0.9159 - Label_loss: 0.2181 - loss: 0.6885 - val_Domain_accuracy: 0.1453 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7460 - val_Label_loss: 0.7105 - val_loss: 0.7127\n",
      "Epoch 71/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8413 - Domain_loss: 0.4650 - Label_accuracy: 0.9153 - Label_loss: 0.2133 - loss: 0.6789 - val_Domain_accuracy: 0.1013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 0.7373 - val_loss: 0.7381\n",
      "Epoch 72/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8335 - Domain_loss: 0.4774 - Label_accuracy: 0.9173 - Label_loss: 0.2080 - loss: 0.6852 - val_Domain_accuracy: 0.1160 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7839 - val_Label_loss: 0.6503 - val_loss: 0.6545\n",
      "Epoch 73/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8203 - Domain_loss: 0.5266 - Label_accuracy: 0.9163 - Label_loss: 0.2150 - loss: 0.7416 - val_Domain_accuracy: 0.2125 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7851 - val_Label_loss: 0.6482 - val_loss: 0.6502\n",
      "Epoch 74/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8317 - Domain_loss: 0.5012 - Label_accuracy: 0.9105 - Label_loss: 0.2299 - loss: 0.7319 - val_Domain_accuracy: 0.2027 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7961 - val_Label_loss: 0.7111 - val_loss: 0.7148\n",
      "Epoch 75/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8274 - Domain_loss: 0.5035 - Label_accuracy: 0.9080 - Label_loss: 0.2224 - loss: 0.7256 - val_Domain_accuracy: 0.1087 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8083 - val_Label_loss: 0.6126 - val_loss: 0.6135\n",
      "Epoch 76/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8448 - Domain_loss: 0.4582 - Label_accuracy: 0.9210 - Label_loss: 0.2046 - loss: 0.6630 - val_Domain_accuracy: 0.0708 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 0.6662 - val_loss: 0.6675\n",
      "Epoch 77/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8393 - Domain_loss: 0.4583 - Label_accuracy: 0.9190 - Label_loss: 0.2092 - loss: 0.6670 - val_Domain_accuracy: 0.1856 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7790 - val_Label_loss: 0.6701 - val_loss: 0.6738\n",
      "Epoch 78/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8409 - Domain_loss: 0.4617 - Label_accuracy: 0.9213 - Label_loss: 0.2011 - loss: 0.6633 - val_Domain_accuracy: 0.0305 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7790 - val_Label_loss: 0.8819 - val_loss: 0.8825\n",
      "Epoch 79/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8343 - Domain_loss: 0.4932 - Label_accuracy: 0.9188 - Label_loss: 0.2107 - loss: 0.7040 - val_Domain_accuracy: 0.1441 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7741 - val_Label_loss: 0.7658 - val_loss: 0.7683\n",
      "Epoch 80/80\n",
      "242/242 - 8s - 34ms/step - Domain_accuracy: 0.8354 - Domain_loss: 0.4790 - Label_accuracy: 0.9166 - Label_loss: 0.2092 - loss: 0.6881 - val_Domain_accuracy: 0.1013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 0.6744 - val_loss: 0.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #6\n",
      "train_feature shape: (7769, 5, 10, 256)\n",
      "train_targets shape: (7769, 5)\n",
      "train_domin shape: (7769, 9)\n",
      "Epoch 1/80\n",
      "243/243 - 17s - 71ms/step - Domain_accuracy: 0.5326 - Domain_loss: 1.4191 - Label_accuracy: 0.7659 - Label_loss: 0.6857 - loss: 2.1054 - val_Domain_accuracy: 0.1256 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7013 - val_Label_loss: 1.0827 - val_loss: 1.0371\n",
      "Epoch 2/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.7031 - Domain_loss: 0.8947 - Label_accuracy: 0.8530 - Label_loss: 0.3859 - loss: 1.2805 - val_Domain_accuracy: 0.5756 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7205 - val_Label_loss: 0.8973 - val_loss: 0.8853\n",
      "Epoch 3/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.7554 - Domain_loss: 0.7244 - Label_accuracy: 0.8977 - Label_loss: 0.2780 - loss: 1.0025 - val_Domain_accuracy: 0.6538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7423 - val_Label_loss: 0.8719 - val_loss: 0.8391\n",
      "Epoch 4/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.7787 - Domain_loss: 0.6451 - Label_accuracy: 0.9057 - Label_loss: 0.2504 - loss: 0.8954 - val_Domain_accuracy: 0.4654 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7795 - val_Label_loss: 0.9087 - val_loss: 0.8920\n",
      "Epoch 5/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8073 - Domain_loss: 0.5811 - Label_accuracy: 0.9127 - Label_loss: 0.2295 - loss: 0.8109 - val_Domain_accuracy: 0.4423 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7808 - val_Label_loss: 0.8308 - val_loss: 0.8204\n",
      "Epoch 6/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8153 - Domain_loss: 0.5439 - Label_accuracy: 0.9217 - Label_loss: 0.2023 - loss: 0.7465 - val_Domain_accuracy: 0.5128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6949 - val_Label_loss: 1.6316 - val_loss: 1.6218\n",
      "Epoch 7/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8354 - Domain_loss: 0.4841 - Label_accuracy: 0.9228 - Label_loss: 0.2029 - loss: 0.6871 - val_Domain_accuracy: 0.6218 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7821 - val_Label_loss: 0.9927 - val_loss: 0.9790\n",
      "Epoch 8/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8521 - Domain_loss: 0.4319 - Label_accuracy: 0.9296 - Label_loss: 0.1715 - loss: 0.6034 - val_Domain_accuracy: 0.5115 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7910 - val_Label_loss: 0.9306 - val_loss: 0.9233\n",
      "Epoch 9/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8279 - Domain_loss: 0.4917 - Label_accuracy: 0.9395 - Label_loss: 0.1576 - loss: 0.6496 - val_Domain_accuracy: 0.2936 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7782 - val_Label_loss: 1.1940 - val_loss: 1.1765\n",
      "Epoch 10/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8453 - Domain_loss: 0.4498 - Label_accuracy: 0.9422 - Label_loss: 0.1536 - loss: 0.6033 - val_Domain_accuracy: 0.2872 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7859 - val_Label_loss: 0.8737 - val_loss: 0.8596\n",
      "Epoch 11/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8534 - Domain_loss: 0.4237 - Label_accuracy: 0.9493 - Label_loss: 0.1398 - loss: 0.5638 - val_Domain_accuracy: 0.5141 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7910 - val_Label_loss: 1.1150 - val_loss: 1.1042\n",
      "Epoch 12/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8555 - Domain_loss: 0.4138 - Label_accuracy: 0.9476 - Label_loss: 0.1368 - loss: 0.5508 - val_Domain_accuracy: 0.5564 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7782 - val_Label_loss: 1.1117 - val_loss: 1.1033\n",
      "Epoch 13/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8511 - Domain_loss: 0.4236 - Label_accuracy: 0.9480 - Label_loss: 0.1383 - loss: 0.5618 - val_Domain_accuracy: 0.2051 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7923 - val_Label_loss: 1.0239 - val_loss: 1.0080\n",
      "Epoch 14/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8500 - Domain_loss: 0.4322 - Label_accuracy: 0.9489 - Label_loss: 0.1355 - loss: 0.5680 - val_Domain_accuracy: 0.5756 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7974 - val_Label_loss: 0.9654 - val_loss: 0.9655\n",
      "Epoch 15/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8606 - Domain_loss: 0.4039 - Label_accuracy: 0.9488 - Label_loss: 0.1367 - loss: 0.5403 - val_Domain_accuracy: 0.2859 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8013 - val_Label_loss: 0.8430 - val_loss: 0.8377\n",
      "Epoch 16/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8549 - Domain_loss: 0.4194 - Label_accuracy: 0.9522 - Label_loss: 0.1275 - loss: 0.5468 - val_Domain_accuracy: 0.5000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8013 - val_Label_loss: 0.9339 - val_loss: 0.9135\n",
      "Epoch 17/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8651 - Domain_loss: 0.3911 - Label_accuracy: 0.9535 - Label_loss: 0.1220 - loss: 0.5129 - val_Domain_accuracy: 0.5679 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6949 - val_Label_loss: 2.0313 - val_loss: 1.9657\n",
      "Epoch 18/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8593 - Domain_loss: 0.4089 - Label_accuracy: 0.9600 - Label_loss: 0.1082 - loss: 0.5171 - val_Domain_accuracy: 0.4795 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8115 - val_Label_loss: 0.9592 - val_loss: 0.9492\n",
      "Epoch 19/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8668 - Domain_loss: 0.3709 - Label_accuracy: 0.9619 - Label_loss: 0.1054 - loss: 0.4761 - val_Domain_accuracy: 0.6026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7833 - val_Label_loss: 0.9848 - val_loss: 0.9730\n",
      "Epoch 20/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8769 - Domain_loss: 0.3583 - Label_accuracy: 0.9658 - Label_loss: 0.0938 - loss: 0.4521 - val_Domain_accuracy: 0.5321 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7795 - val_Label_loss: 1.2401 - val_loss: 1.2174\n",
      "Epoch 21/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8705 - Domain_loss: 0.3687 - Label_accuracy: 0.9615 - Label_loss: 0.0988 - loss: 0.4677 - val_Domain_accuracy: 0.6449 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7859 - val_Label_loss: 1.0841 - val_loss: 1.0859\n",
      "Epoch 22/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8589 - Domain_loss: 0.3985 - Label_accuracy: 0.9595 - Label_loss: 0.1097 - loss: 0.5085 - val_Domain_accuracy: 0.4218 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 1.1118 - val_loss: 1.1129\n",
      "Epoch 23/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8731 - Domain_loss: 0.3753 - Label_accuracy: 0.9614 - Label_loss: 0.0980 - loss: 0.4734 - val_Domain_accuracy: 0.3949 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 1.3731 - val_loss: 1.3736\n",
      "Epoch 24/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8652 - Domain_loss: 0.3827 - Label_accuracy: 0.9661 - Label_loss: 0.0952 - loss: 0.4775 - val_Domain_accuracy: 0.4821 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7897 - val_Label_loss: 1.0676 - val_loss: 1.0623\n",
      "Epoch 25/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8614 - Domain_loss: 0.4027 - Label_accuracy: 0.9674 - Label_loss: 0.0845 - loss: 0.4871 - val_Domain_accuracy: 0.5731 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7731 - val_Label_loss: 1.5305 - val_loss: 1.5205\n",
      "Epoch 26/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8870 - Domain_loss: 0.3264 - Label_accuracy: 0.9714 - Label_loss: 0.0755 - loss: 0.4021 - val_Domain_accuracy: 0.3821 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7769 - val_Label_loss: 1.3255 - val_loss: 1.3166\n",
      "Epoch 27/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8760 - Domain_loss: 0.3603 - Label_accuracy: 0.9696 - Label_loss: 0.0767 - loss: 0.4369 - val_Domain_accuracy: 0.5256 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7654 - val_Label_loss: 1.4230 - val_loss: 1.4030\n",
      "Epoch 28/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8642 - Domain_loss: 0.3902 - Label_accuracy: 0.9668 - Label_loss: 0.0934 - loss: 0.4836 - val_Domain_accuracy: 0.6269 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7897 - val_Label_loss: 1.3376 - val_loss: 1.3242\n",
      "Epoch 29/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8746 - Domain_loss: 0.3669 - Label_accuracy: 0.9704 - Label_loss: 0.0765 - loss: 0.4433 - val_Domain_accuracy: 0.4397 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7654 - val_Label_loss: 1.8432 - val_loss: 1.7984\n",
      "Epoch 30/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8772 - Domain_loss: 0.3549 - Label_accuracy: 0.9699 - Label_loss: 0.0780 - loss: 0.4331 - val_Domain_accuracy: 0.3705 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8090 - val_Label_loss: 1.2058 - val_loss: 1.1956\n",
      "Epoch 31/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8735 - Domain_loss: 0.3664 - Label_accuracy: 0.9722 - Label_loss: 0.0783 - loss: 0.4447 - val_Domain_accuracy: 0.5321 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7744 - val_Label_loss: 1.8125 - val_loss: 1.7971\n",
      "Epoch 32/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8742 - Domain_loss: 0.3528 - Label_accuracy: 0.9728 - Label_loss: 0.0740 - loss: 0.4267 - val_Domain_accuracy: 0.4603 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7526 - val_Label_loss: 1.7465 - val_loss: 1.7169\n",
      "Epoch 33/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8755 - Domain_loss: 0.3530 - Label_accuracy: 0.9753 - Label_loss: 0.0713 - loss: 0.4241 - val_Domain_accuracy: 0.5551 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7782 - val_Label_loss: 1.6284 - val_loss: 1.6157\n",
      "Epoch 34/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8778 - Domain_loss: 0.3584 - Label_accuracy: 0.9676 - Label_loss: 0.0850 - loss: 0.4436 - val_Domain_accuracy: 0.3833 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 1.4280 - val_loss: 1.4323\n",
      "Epoch 35/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8863 - Domain_loss: 0.3336 - Label_accuracy: 0.9727 - Label_loss: 0.0706 - loss: 0.4043 - val_Domain_accuracy: 0.5436 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7987 - val_Label_loss: 1.5454 - val_loss: 1.5475\n",
      "Epoch 36/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8862 - Domain_loss: 0.3279 - Label_accuracy: 0.9784 - Label_loss: 0.0611 - loss: 0.3892 - val_Domain_accuracy: 0.6205 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 1.5040 - val_loss: 1.4627\n",
      "Epoch 37/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8777 - Domain_loss: 0.3592 - Label_accuracy: 0.9759 - Label_loss: 0.0700 - loss: 0.4294 - val_Domain_accuracy: 0.4115 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7821 - val_Label_loss: 1.5333 - val_loss: 1.5374\n",
      "Epoch 38/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8629 - Domain_loss: 0.3968 - Label_accuracy: 0.9764 - Label_loss: 0.0624 - loss: 0.4593 - val_Domain_accuracy: 0.5090 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7833 - val_Label_loss: 1.7462 - val_loss: 1.7562\n",
      "Epoch 39/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8759 - Domain_loss: 0.3653 - Label_accuracy: 0.9784 - Label_loss: 0.0596 - loss: 0.4248 - val_Domain_accuracy: 0.5244 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7795 - val_Label_loss: 1.5564 - val_loss: 1.5289\n",
      "Epoch 40/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8806 - Domain_loss: 0.3383 - Label_accuracy: 0.9790 - Label_loss: 0.0621 - loss: 0.4003 - val_Domain_accuracy: 0.5744 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 1.4291 - val_loss: 1.4078\n",
      "Epoch 41/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8695 - Domain_loss: 0.3733 - Label_accuracy: 0.9725 - Label_loss: 0.0684 - loss: 0.4415 - val_Domain_accuracy: 0.4756 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7679 - val_Label_loss: 2.0374 - val_loss: 2.0208\n",
      "Epoch 42/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8650 - Domain_loss: 0.3939 - Label_accuracy: 0.9743 - Label_loss: 0.0645 - loss: 0.4586 - val_Domain_accuracy: 0.4962 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7859 - val_Label_loss: 2.1252 - val_loss: 2.1184\n",
      "Epoch 43/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8793 - Domain_loss: 0.3434 - Label_accuracy: 0.9789 - Label_loss: 0.0592 - loss: 0.4023 - val_Domain_accuracy: 0.5654 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7667 - val_Label_loss: 1.8705 - val_loss: 1.8565\n",
      "Epoch 44/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8721 - Domain_loss: 0.3625 - Label_accuracy: 0.9771 - Label_loss: 0.0626 - loss: 0.4254 - val_Domain_accuracy: 0.6872 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7718 - val_Label_loss: 1.9412 - val_loss: 1.9413\n",
      "Epoch 45/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8615 - Domain_loss: 0.3971 - Label_accuracy: 0.9761 - Label_loss: 0.0624 - loss: 0.4596 - val_Domain_accuracy: 0.5923 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7897 - val_Label_loss: 1.6181 - val_loss: 1.5904\n",
      "Epoch 46/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8820 - Domain_loss: 0.3327 - Label_accuracy: 0.9772 - Label_loss: 0.0616 - loss: 0.3943 - val_Domain_accuracy: 0.6218 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7718 - val_Label_loss: 2.0939 - val_loss: 2.0193\n",
      "Epoch 47/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8785 - Domain_loss: 0.3467 - Label_accuracy: 0.9829 - Label_loss: 0.0457 - loss: 0.3919 - val_Domain_accuracy: 0.3769 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7692 - val_Label_loss: 2.0177 - val_loss: 2.0167\n",
      "Epoch 48/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8748 - Domain_loss: 0.3700 - Label_accuracy: 0.9770 - Label_loss: 0.0638 - loss: 0.4338 - val_Domain_accuracy: 0.5846 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7962 - val_Label_loss: 1.4780 - val_loss: 1.4510\n",
      "Epoch 49/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8946 - Domain_loss: 0.3129 - Label_accuracy: 0.9815 - Label_loss: 0.0519 - loss: 0.3650 - val_Domain_accuracy: 0.6641 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7923 - val_Label_loss: 1.8018 - val_loss: 1.7815\n",
      "Epoch 50/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8746 - Domain_loss: 0.3548 - Label_accuracy: 0.9776 - Label_loss: 0.0631 - loss: 0.4180 - val_Domain_accuracy: 0.5333 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 1.6237 - val_loss: 1.6161\n",
      "Epoch 51/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8820 - Domain_loss: 0.3429 - Label_accuracy: 0.9799 - Label_loss: 0.0600 - loss: 0.4026 - val_Domain_accuracy: 0.5923 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8026 - val_Label_loss: 1.4228 - val_loss: 1.3901\n",
      "Epoch 52/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8839 - Domain_loss: 0.3385 - Label_accuracy: 0.9807 - Label_loss: 0.0555 - loss: 0.3941 - val_Domain_accuracy: 0.5346 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7808 - val_Label_loss: 2.1654 - val_loss: 2.1501\n",
      "Epoch 53/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8910 - Domain_loss: 0.3193 - Label_accuracy: 0.9831 - Label_loss: 0.0532 - loss: 0.3727 - val_Domain_accuracy: 0.5282 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7718 - val_Label_loss: 2.1424 - val_loss: 2.1180\n",
      "Epoch 54/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8768 - Domain_loss: 0.3469 - Label_accuracy: 0.9835 - Label_loss: 0.0510 - loss: 0.3981 - val_Domain_accuracy: 0.5410 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7718 - val_Label_loss: 1.8510 - val_loss: 1.8273\n",
      "Epoch 55/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8956 - Domain_loss: 0.3018 - Label_accuracy: 0.9833 - Label_loss: 0.0458 - loss: 0.3475 - val_Domain_accuracy: 0.4410 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7769 - val_Label_loss: 2.0627 - val_loss: 2.0552\n",
      "Epoch 56/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8938 - Domain_loss: 0.3014 - Label_accuracy: 0.9852 - Label_loss: 0.0403 - loss: 0.3417 - val_Domain_accuracy: 0.5244 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 1.7820 - val_loss: 1.7435\n",
      "Epoch 57/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8912 - Domain_loss: 0.3013 - Label_accuracy: 0.9809 - Label_loss: 0.0537 - loss: 0.3550 - val_Domain_accuracy: 0.5346 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8013 - val_Label_loss: 1.6831 - val_loss: 1.6534\n",
      "Epoch 58/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8907 - Domain_loss: 0.3093 - Label_accuracy: 0.9834 - Label_loss: 0.0471 - loss: 0.3563 - val_Domain_accuracy: 0.6231 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7897 - val_Label_loss: 1.6473 - val_loss: 1.6090\n",
      "Epoch 59/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8878 - Domain_loss: 0.3155 - Label_accuracy: 0.9848 - Label_loss: 0.0421 - loss: 0.3571 - val_Domain_accuracy: 0.4103 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 2.0952 - val_loss: 2.0711\n",
      "Epoch 60/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8722 - Domain_loss: 0.3602 - Label_accuracy: 0.9804 - Label_loss: 0.0501 - loss: 0.4104 - val_Domain_accuracy: 0.6038 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7859 - val_Label_loss: 2.0488 - val_loss: 2.0078\n",
      "Epoch 61/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8896 - Domain_loss: 0.3004 - Label_accuracy: 0.9842 - Label_loss: 0.0433 - loss: 0.3434 - val_Domain_accuracy: 0.5462 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7885 - val_Label_loss: 2.5307 - val_loss: 2.5019\n",
      "Epoch 62/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8829 - Domain_loss: 0.3467 - Label_accuracy: 0.9820 - Label_loss: 0.0555 - loss: 0.4023 - val_Domain_accuracy: 0.6282 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7923 - val_Label_loss: 1.8452 - val_loss: 1.8082\n",
      "Epoch 63/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8763 - Domain_loss: 0.3580 - Label_accuracy: 0.9815 - Label_loss: 0.0525 - loss: 0.4105 - val_Domain_accuracy: 0.4038 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7897 - val_Label_loss: 1.8942 - val_loss: 1.8546\n",
      "Epoch 64/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8845 - Domain_loss: 0.3253 - Label_accuracy: 0.9817 - Label_loss: 0.0513 - loss: 0.3767 - val_Domain_accuracy: 0.4526 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7449 - val_Label_loss: 3.2132 - val_loss: 3.1615\n",
      "Epoch 65/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8854 - Domain_loss: 0.3334 - Label_accuracy: 0.9817 - Label_loss: 0.0484 - loss: 0.3821 - val_Domain_accuracy: 0.4833 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8128 - val_Label_loss: 1.7131 - val_loss: 1.6820\n",
      "Epoch 66/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8999 - Domain_loss: 0.2895 - Label_accuracy: 0.9824 - Label_loss: 0.0511 - loss: 0.3400 - val_Domain_accuracy: 0.5962 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8141 - val_Label_loss: 1.6745 - val_loss: 1.6524\n",
      "Epoch 67/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8905 - Domain_loss: 0.3121 - Label_accuracy: 0.9835 - Label_loss: 0.0473 - loss: 0.3596 - val_Domain_accuracy: 0.5615 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7897 - val_Label_loss: 2.0819 - val_loss: 2.0450\n",
      "Epoch 68/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8992 - Domain_loss: 0.2728 - Label_accuracy: 0.9873 - Label_loss: 0.0368 - loss: 0.3097 - val_Domain_accuracy: 0.5359 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7897 - val_Label_loss: 2.2818 - val_loss: 2.2763\n",
      "Epoch 69/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8892 - Domain_loss: 0.3208 - Label_accuracy: 0.9843 - Label_loss: 0.0448 - loss: 0.3657 - val_Domain_accuracy: 0.6064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7744 - val_Label_loss: 2.1090 - val_loss: 2.0545\n",
      "Epoch 70/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8890 - Domain_loss: 0.3197 - Label_accuracy: 0.9861 - Label_loss: 0.0375 - loss: 0.3573 - val_Domain_accuracy: 0.6090 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8154 - val_Label_loss: 1.7446 - val_loss: 1.7471\n",
      "Epoch 71/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8939 - Domain_loss: 0.3089 - Label_accuracy: 0.9880 - Label_loss: 0.0365 - loss: 0.3453 - val_Domain_accuracy: 0.6013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7756 - val_Label_loss: 2.6135 - val_loss: 2.6041\n",
      "Epoch 72/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8936 - Domain_loss: 0.3007 - Label_accuracy: 0.9876 - Label_loss: 0.0343 - loss: 0.3348 - val_Domain_accuracy: 0.5000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7833 - val_Label_loss: 2.3341 - val_loss: 2.3208\n",
      "Epoch 73/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8863 - Domain_loss: 0.3126 - Label_accuracy: 0.9852 - Label_loss: 0.0431 - loss: 0.3556 - val_Domain_accuracy: 0.5526 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7615 - val_Label_loss: 3.2901 - val_loss: 3.2785\n",
      "Epoch 74/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8808 - Domain_loss: 0.3444 - Label_accuracy: 0.9812 - Label_loss: 0.0627 - loss: 0.4071 - val_Domain_accuracy: 0.4910 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 1.9342 - val_loss: 1.9408\n",
      "Epoch 75/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8911 - Domain_loss: 0.3182 - Label_accuracy: 0.9864 - Label_loss: 0.0407 - loss: 0.3584 - val_Domain_accuracy: 0.4808 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7923 - val_Label_loss: 1.9670 - val_loss: 1.9558\n",
      "Epoch 76/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8961 - Domain_loss: 0.3098 - Label_accuracy: 0.9842 - Label_loss: 0.0438 - loss: 0.3533 - val_Domain_accuracy: 0.6679 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8128 - val_Label_loss: 1.7666 - val_loss: 1.7581\n",
      "Epoch 77/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8941 - Domain_loss: 0.3063 - Label_accuracy: 0.9866 - Label_loss: 0.0417 - loss: 0.3479 - val_Domain_accuracy: 0.6385 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7910 - val_Label_loss: 1.8258 - val_loss: 1.8195\n",
      "Epoch 78/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8917 - Domain_loss: 0.3154 - Label_accuracy: 0.9878 - Label_loss: 0.0370 - loss: 0.3525 - val_Domain_accuracy: 0.6179 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 2.0917 - val_loss: 2.0872\n",
      "Epoch 79/80\n",
      "243/243 - 8s - 34ms/step - Domain_accuracy: 0.8759 - Domain_loss: 0.3551 - Label_accuracy: 0.9830 - Label_loss: 0.0457 - loss: 0.4009 - val_Domain_accuracy: 0.6359 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7833 - val_Label_loss: 2.1271 - val_loss: 2.1093\n",
      "Epoch 80/80\n",
      "243/243 - 9s - 35ms/step - Domain_accuracy: 0.8876 - Domain_loss: 0.3300 - Label_accuracy: 0.9839 - Label_loss: 0.0487 - loss: 0.3787 - val_Domain_accuracy: 0.5051 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8051 - val_Label_loss: 1.7620 - val_loss: 1.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #7\n",
      "train_feature shape: (7583, 5, 10, 256)\n",
      "train_targets shape: (7583, 5)\n",
      "train_domin shape: (7583, 9)\n",
      "Epoch 1/80\n",
      "237/237 - 17s - 74ms/step - Domain_accuracy: 0.4376 - Domain_loss: 1.8199 - Label_accuracy: 0.6992 - Label_loss: 0.9857 - loss: 2.8058 - val_Domain_accuracy: 0.1201 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8427 - val_Label_loss: 0.4140 - val_loss: 0.4243\n",
      "Epoch 2/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.5709 - Domain_loss: 1.2717 - Label_accuracy: 0.7841 - Label_loss: 0.5731 - loss: 1.8448 - val_Domain_accuracy: 0.4234 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8157 - val_Label_loss: 0.3770 - val_loss: 0.3845\n",
      "Epoch 3/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.6441 - Domain_loss: 1.0961 - Label_accuracy: 0.8051 - Label_loss: 0.5100 - loss: 1.6061 - val_Domain_accuracy: 0.2257 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8820 - val_Label_loss: 0.3361 - val_loss: 0.3423\n",
      "Epoch 4/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.6853 - Domain_loss: 0.9452 - Label_accuracy: 0.8131 - Label_loss: 0.4798 - loss: 1.4251 - val_Domain_accuracy: 0.3012 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8872 - val_Label_loss: 0.2747 - val_loss: 0.2805\n",
      "Epoch 5/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.7295 - Domain_loss: 0.8224 - Label_accuracy: 0.8205 - Label_loss: 0.4487 - loss: 1.2710 - val_Domain_accuracy: 0.3137 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8799 - val_Label_loss: 0.2886 - val_loss: 0.2963\n",
      "Epoch 6/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.7348 - Domain_loss: 0.8013 - Label_accuracy: 0.8272 - Label_loss: 0.4405 - loss: 1.2419 - val_Domain_accuracy: 0.3696 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8696 - val_Label_loss: 0.3325 - val_loss: 0.3400\n",
      "Epoch 7/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.7546 - Domain_loss: 0.7234 - Label_accuracy: 0.8383 - Label_loss: 0.4083 - loss: 1.1318 - val_Domain_accuracy: 0.3644 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8851 - val_Label_loss: 0.2979 - val_loss: 0.3034\n",
      "Epoch 8/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.7775 - Domain_loss: 0.6694 - Label_accuracy: 0.8344 - Label_loss: 0.4188 - loss: 1.0882 - val_Domain_accuracy: 0.3685 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8903 - val_Label_loss: 0.3006 - val_loss: 0.3078\n",
      "Epoch 9/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.7807 - Domain_loss: 0.6536 - Label_accuracy: 0.8427 - Label_loss: 0.3988 - loss: 1.0524 - val_Domain_accuracy: 0.0259 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8975 - val_Label_loss: 0.2732 - val_loss: 0.2778\n",
      "Epoch 10/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.7861 - Domain_loss: 0.6549 - Label_accuracy: 0.8466 - Label_loss: 0.3862 - loss: 1.0411 - val_Domain_accuracy: 0.3954 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8799 - val_Label_loss: 0.2898 - val_loss: 0.2943\n",
      "Epoch 11/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8154 - Domain_loss: 0.5883 - Label_accuracy: 0.8458 - Label_loss: 0.3882 - loss: 0.9765 - val_Domain_accuracy: 0.0952 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9006 - val_Label_loss: 0.2484 - val_loss: 0.2536\n",
      "Epoch 12/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8057 - Domain_loss: 0.5875 - Label_accuracy: 0.8485 - Label_loss: 0.3834 - loss: 0.9709 - val_Domain_accuracy: 0.1408 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8810 - val_Label_loss: 0.3037 - val_loss: 0.3117\n",
      "Epoch 13/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8192 - Domain_loss: 0.5489 - Label_accuracy: 0.8594 - Label_loss: 0.3595 - loss: 0.9083 - val_Domain_accuracy: 0.1884 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8986 - val_Label_loss: 0.2742 - val_loss: 0.2801\n",
      "Epoch 14/80\n",
      "237/237 - 8s - 34ms/step - Domain_accuracy: 0.8261 - Domain_loss: 0.5248 - Label_accuracy: 0.8555 - Label_loss: 0.3602 - loss: 0.8850 - val_Domain_accuracy: 0.2329 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8706 - val_Label_loss: 0.3242 - val_loss: 0.3326\n",
      "Epoch 15/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8311 - Domain_loss: 0.5225 - Label_accuracy: 0.8621 - Label_loss: 0.3480 - loss: 0.8705 - val_Domain_accuracy: 0.0611 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9027 - val_Label_loss: 0.2592 - val_loss: 0.2656\n",
      "Epoch 16/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8353 - Domain_loss: 0.5062 - Label_accuracy: 0.8630 - Label_loss: 0.3425 - loss: 0.8487 - val_Domain_accuracy: 0.1014 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9006 - val_Label_loss: 0.2457 - val_loss: 0.2513\n",
      "Epoch 17/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8357 - Domain_loss: 0.4810 - Label_accuracy: 0.8664 - Label_loss: 0.3313 - loss: 0.8124 - val_Domain_accuracy: 0.1573 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8975 - val_Label_loss: 0.2670 - val_loss: 0.2735\n",
      "Epoch 18/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8354 - Domain_loss: 0.5037 - Label_accuracy: 0.8675 - Label_loss: 0.3324 - loss: 0.8361 - val_Domain_accuracy: 0.1170 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8965 - val_Label_loss: 0.2925 - val_loss: 0.2992\n",
      "Epoch 19/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8464 - Domain_loss: 0.4616 - Label_accuracy: 0.8664 - Label_loss: 0.3366 - loss: 0.7981 - val_Domain_accuracy: 0.0828 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8830 - val_Label_loss: 0.2761 - val_loss: 0.2832\n",
      "Epoch 20/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8445 - Domain_loss: 0.4669 - Label_accuracy: 0.8729 - Label_loss: 0.3209 - loss: 0.7878 - val_Domain_accuracy: 0.3313 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8872 - val_Label_loss: 0.2980 - val_loss: 0.3035\n",
      "Epoch 21/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8466 - Domain_loss: 0.4733 - Label_accuracy: 0.8685 - Label_loss: 0.3265 - loss: 0.7998 - val_Domain_accuracy: 0.0839 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8841 - val_Label_loss: 0.2846 - val_loss: 0.2897\n",
      "Epoch 22/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8375 - Domain_loss: 0.4998 - Label_accuracy: 0.8713 - Label_loss: 0.3168 - loss: 0.8166 - val_Domain_accuracy: 0.1553 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9048 - val_Label_loss: 0.2649 - val_loss: 0.2706\n",
      "Epoch 23/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8631 - Domain_loss: 0.4102 - Label_accuracy: 0.8818 - Label_loss: 0.2984 - loss: 0.7086 - val_Domain_accuracy: 0.1749 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9017 - val_Label_loss: 0.2654 - val_loss: 0.2717\n",
      "Epoch 24/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8603 - Domain_loss: 0.4207 - Label_accuracy: 0.8828 - Label_loss: 0.2987 - loss: 0.7194 - val_Domain_accuracy: 0.0818 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8861 - val_Label_loss: 0.2868 - val_loss: 0.2940\n",
      "Epoch 25/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8646 - Domain_loss: 0.4100 - Label_accuracy: 0.8793 - Label_loss: 0.3055 - loss: 0.7155 - val_Domain_accuracy: 0.2671 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8892 - val_Label_loss: 0.2706 - val_loss: 0.2767\n",
      "Epoch 26/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8690 - Domain_loss: 0.3889 - Label_accuracy: 0.8870 - Label_loss: 0.2782 - loss: 0.6671 - val_Domain_accuracy: 0.1553 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8892 - val_Label_loss: 0.2783 - val_loss: 0.2846\n",
      "Epoch 27/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8737 - Domain_loss: 0.3765 - Label_accuracy: 0.8890 - Label_loss: 0.2752 - loss: 0.6517 - val_Domain_accuracy: 0.1356 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8903 - val_Label_loss: 0.2681 - val_loss: 0.2746\n",
      "Epoch 28/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8577 - Domain_loss: 0.4171 - Label_accuracy: 0.8867 - Label_loss: 0.2803 - loss: 0.6974 - val_Domain_accuracy: 0.1222 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8696 - val_Label_loss: 0.3337 - val_loss: 0.3398\n",
      "Epoch 29/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8481 - Domain_loss: 0.4440 - Label_accuracy: 0.8874 - Label_loss: 0.2930 - loss: 0.7370 - val_Domain_accuracy: 0.1356 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8934 - val_Label_loss: 0.2747 - val_loss: 0.2814\n",
      "Epoch 30/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8723 - Domain_loss: 0.3809 - Label_accuracy: 0.8994 - Label_loss: 0.2642 - loss: 0.6451 - val_Domain_accuracy: 0.3095 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8509 - val_Label_loss: 0.4095 - val_loss: 0.4185\n",
      "Epoch 31/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8627 - Domain_loss: 0.4022 - Label_accuracy: 0.8920 - Label_loss: 0.2685 - loss: 0.6707 - val_Domain_accuracy: 0.1439 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8923 - val_Label_loss: 0.2633 - val_loss: 0.2691\n",
      "Epoch 32/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8716 - Domain_loss: 0.3943 - Label_accuracy: 0.8969 - Label_loss: 0.2619 - loss: 0.6562 - val_Domain_accuracy: 0.1108 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8996 - val_Label_loss: 0.2496 - val_loss: 0.2553\n",
      "Epoch 33/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8690 - Domain_loss: 0.4017 - Label_accuracy: 0.8909 - Label_loss: 0.2637 - loss: 0.6654 - val_Domain_accuracy: 0.1605 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8851 - val_Label_loss: 0.3240 - val_loss: 0.3323\n",
      "Epoch 34/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8756 - Domain_loss: 0.3806 - Label_accuracy: 0.8986 - Label_loss: 0.2522 - loss: 0.6328 - val_Domain_accuracy: 0.1242 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8665 - val_Label_loss: 0.3868 - val_loss: 0.3936\n",
      "Epoch 35/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8690 - Domain_loss: 0.3918 - Label_accuracy: 0.9015 - Label_loss: 0.2457 - loss: 0.6375 - val_Domain_accuracy: 0.1532 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8996 - val_Label_loss: 0.2492 - val_loss: 0.2558\n",
      "Epoch 36/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8727 - Domain_loss: 0.3737 - Label_accuracy: 0.9065 - Label_loss: 0.2425 - loss: 0.6162 - val_Domain_accuracy: 0.0963 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8810 - val_Label_loss: 0.3041 - val_loss: 0.3112\n",
      "Epoch 37/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8621 - Domain_loss: 0.4153 - Label_accuracy: 0.9004 - Label_loss: 0.2454 - loss: 0.6607 - val_Domain_accuracy: 0.2950 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8892 - val_Label_loss: 0.2742 - val_loss: 0.2805\n",
      "Epoch 38/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8660 - Domain_loss: 0.3957 - Label_accuracy: 0.9035 - Label_loss: 0.2500 - loss: 0.6457 - val_Domain_accuracy: 0.1159 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8810 - val_Label_loss: 0.3247 - val_loss: 0.3323\n",
      "Epoch 39/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8768 - Domain_loss: 0.3708 - Label_accuracy: 0.9040 - Label_loss: 0.2433 - loss: 0.6141 - val_Domain_accuracy: 0.1159 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8747 - val_Label_loss: 0.3148 - val_loss: 0.3228\n",
      "Epoch 40/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8830 - Domain_loss: 0.3543 - Label_accuracy: 0.9130 - Label_loss: 0.2237 - loss: 0.5779 - val_Domain_accuracy: 0.0311 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8986 - val_Label_loss: 0.2586 - val_loss: 0.2652\n",
      "Epoch 41/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8714 - Domain_loss: 0.3762 - Label_accuracy: 0.9049 - Label_loss: 0.2374 - loss: 0.6135 - val_Domain_accuracy: 0.0704 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8799 - val_Label_loss: 0.3440 - val_loss: 0.3527\n",
      "Epoch 42/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8763 - Domain_loss: 0.3742 - Label_accuracy: 0.9066 - Label_loss: 0.2239 - loss: 0.5981 - val_Domain_accuracy: 0.0611 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8768 - val_Label_loss: 0.3461 - val_loss: 0.3552\n",
      "Epoch 43/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8838 - Domain_loss: 0.3537 - Label_accuracy: 0.9157 - Label_loss: 0.2181 - loss: 0.5718 - val_Domain_accuracy: 0.1739 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9058 - val_Label_loss: 0.2502 - val_loss: 0.2563\n",
      "Epoch 44/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8705 - Domain_loss: 0.3873 - Label_accuracy: 0.9080 - Label_loss: 0.2289 - loss: 0.6162 - val_Domain_accuracy: 0.0787 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8830 - val_Label_loss: 0.3220 - val_loss: 0.3298\n",
      "Epoch 45/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8833 - Domain_loss: 0.3447 - Label_accuracy: 0.9130 - Label_loss: 0.2177 - loss: 0.5623 - val_Domain_accuracy: 0.2246 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8820 - val_Label_loss: 0.3152 - val_loss: 0.3235\n",
      "Epoch 46/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8746 - Domain_loss: 0.3723 - Label_accuracy: 0.9115 - Label_loss: 0.2199 - loss: 0.5922 - val_Domain_accuracy: 0.0518 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8892 - val_Label_loss: 0.2831 - val_loss: 0.2907\n",
      "Epoch 47/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8847 - Domain_loss: 0.3407 - Label_accuracy: 0.9142 - Label_loss: 0.2176 - loss: 0.5583 - val_Domain_accuracy: 0.0983 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8861 - val_Label_loss: 0.3000 - val_loss: 0.3073\n",
      "Epoch 48/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8771 - Domain_loss: 0.3615 - Label_accuracy: 0.9171 - Label_loss: 0.2136 - loss: 0.5751 - val_Domain_accuracy: 0.3064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8861 - val_Label_loss: 0.3285 - val_loss: 0.3368\n",
      "Epoch 49/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8743 - Domain_loss: 0.3714 - Label_accuracy: 0.9202 - Label_loss: 0.2023 - loss: 0.5737 - val_Domain_accuracy: 0.0228 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8944 - val_Label_loss: 0.3158 - val_loss: 0.3242\n",
      "Epoch 50/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8809 - Domain_loss: 0.3468 - Label_accuracy: 0.9148 - Label_loss: 0.2176 - loss: 0.5645 - val_Domain_accuracy: 0.0259 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8903 - val_Label_loss: 0.2831 - val_loss: 0.2907\n",
      "Epoch 51/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8884 - Domain_loss: 0.3312 - Label_accuracy: 0.9250 - Label_loss: 0.1884 - loss: 0.5196 - val_Domain_accuracy: 0.2588 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8892 - val_Label_loss: 0.3083 - val_loss: 0.3163\n",
      "Epoch 52/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8872 - Domain_loss: 0.3379 - Label_accuracy: 0.9206 - Label_loss: 0.2010 - loss: 0.5390 - val_Domain_accuracy: 0.2422 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8778 - val_Label_loss: 0.3627 - val_loss: 0.3719\n",
      "Epoch 53/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8816 - Domain_loss: 0.3524 - Label_accuracy: 0.9298 - Label_loss: 0.1826 - loss: 0.5350 - val_Domain_accuracy: 0.0435 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8975 - val_Label_loss: 0.2953 - val_loss: 0.3032\n",
      "Epoch 54/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8845 - Domain_loss: 0.3409 - Label_accuracy: 0.9263 - Label_loss: 0.1969 - loss: 0.5377 - val_Domain_accuracy: 0.0994 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8872 - val_Label_loss: 0.3339 - val_loss: 0.3405\n",
      "Epoch 55/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8758 - Domain_loss: 0.3774 - Label_accuracy: 0.9200 - Label_loss: 0.2071 - loss: 0.5845 - val_Domain_accuracy: 0.1863 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8716 - val_Label_loss: 0.3757 - val_loss: 0.3853\n",
      "Epoch 56/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8879 - Domain_loss: 0.3335 - Label_accuracy: 0.9230 - Label_loss: 0.1885 - loss: 0.5220 - val_Domain_accuracy: 0.0901 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8820 - val_Label_loss: 0.3176 - val_loss: 0.3255\n",
      "Epoch 57/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8808 - Domain_loss: 0.3526 - Label_accuracy: 0.9265 - Label_loss: 0.1876 - loss: 0.5402 - val_Domain_accuracy: 0.1542 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8830 - val_Label_loss: 0.3742 - val_loss: 0.3838\n",
      "Epoch 58/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8755 - Domain_loss: 0.3862 - Label_accuracy: 0.9213 - Label_loss: 0.2037 - loss: 0.5899 - val_Domain_accuracy: 0.2899 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8965 - val_Label_loss: 0.2712 - val_loss: 0.2778\n",
      "Epoch 59/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8837 - Domain_loss: 0.3408 - Label_accuracy: 0.9275 - Label_loss: 0.1852 - loss: 0.5260 - val_Domain_accuracy: 0.1946 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8986 - val_Label_loss: 0.2888 - val_loss: 0.2964\n",
      "Epoch 60/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8888 - Domain_loss: 0.3276 - Label_accuracy: 0.9291 - Label_loss: 0.1776 - loss: 0.5052 - val_Domain_accuracy: 0.2340 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8934 - val_Label_loss: 0.3211 - val_loss: 0.3295\n",
      "Epoch 61/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8766 - Domain_loss: 0.3660 - Label_accuracy: 0.9264 - Label_loss: 0.1893 - loss: 0.5553 - val_Domain_accuracy: 0.0559 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8913 - val_Label_loss: 0.3265 - val_loss: 0.3350\n",
      "Epoch 62/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8825 - Domain_loss: 0.3396 - Label_accuracy: 0.9285 - Label_loss: 0.1773 - loss: 0.5170 - val_Domain_accuracy: 0.0528 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8861 - val_Label_loss: 0.3363 - val_loss: 0.3451\n",
      "Epoch 63/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8940 - Domain_loss: 0.3130 - Label_accuracy: 0.9331 - Label_loss: 0.1714 - loss: 0.4844 - val_Domain_accuracy: 0.1149 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8851 - val_Label_loss: 0.3589 - val_loss: 0.3683\n",
      "Epoch 64/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8865 - Domain_loss: 0.3417 - Label_accuracy: 0.9298 - Label_loss: 0.1795 - loss: 0.5212 - val_Domain_accuracy: 0.0538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9017 - val_Label_loss: 0.3137 - val_loss: 0.3221\n",
      "Epoch 65/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8854 - Domain_loss: 0.3528 - Label_accuracy: 0.9363 - Label_loss: 0.1752 - loss: 0.5280 - val_Domain_accuracy: 0.1253 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8954 - val_Label_loss: 0.3263 - val_loss: 0.3329\n",
      "Epoch 66/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8905 - Domain_loss: 0.3149 - Label_accuracy: 0.9284 - Label_loss: 0.1733 - loss: 0.4883 - val_Domain_accuracy: 0.0859 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8996 - val_Label_loss: 0.3123 - val_loss: 0.3200\n",
      "Epoch 67/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8763 - Domain_loss: 0.3634 - Label_accuracy: 0.9312 - Label_loss: 0.1730 - loss: 0.5365 - val_Domain_accuracy: 0.0290 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8934 - val_Label_loss: 0.2954 - val_loss: 0.3032\n",
      "Epoch 68/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8776 - Domain_loss: 0.3641 - Label_accuracy: 0.9318 - Label_loss: 0.1816 - loss: 0.5457 - val_Domain_accuracy: 0.1201 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8685 - val_Label_loss: 0.3664 - val_loss: 0.3731\n",
      "Epoch 69/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8879 - Domain_loss: 0.3447 - Label_accuracy: 0.9352 - Label_loss: 0.1772 - loss: 0.5219 - val_Domain_accuracy: 0.2826 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8913 - val_Label_loss: 0.3146 - val_loss: 0.3227\n",
      "Epoch 70/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8867 - Domain_loss: 0.3313 - Label_accuracy: 0.9331 - Label_loss: 0.1758 - loss: 0.5071 - val_Domain_accuracy: 0.0663 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8861 - val_Label_loss: 0.2977 - val_loss: 0.3055\n",
      "Epoch 71/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8957 - Domain_loss: 0.2978 - Label_accuracy: 0.9388 - Label_loss: 0.1608 - loss: 0.4586 - val_Domain_accuracy: 0.1718 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8986 - val_Label_loss: 0.3112 - val_loss: 0.3185\n",
      "Epoch 72/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8912 - Domain_loss: 0.3254 - Label_accuracy: 0.9350 - Label_loss: 0.1693 - loss: 0.4947 - val_Domain_accuracy: 0.2919 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8923 - val_Label_loss: 0.2964 - val_loss: 0.3040\n",
      "Epoch 73/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8855 - Domain_loss: 0.3359 - Label_accuracy: 0.9318 - Label_loss: 0.1692 - loss: 0.5051 - val_Domain_accuracy: 0.0921 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8810 - val_Label_loss: 0.3630 - val_loss: 0.3701\n",
      "Epoch 74/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8866 - Domain_loss: 0.3345 - Label_accuracy: 0.9337 - Label_loss: 0.1694 - loss: 0.5039 - val_Domain_accuracy: 0.1760 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8613 - val_Label_loss: 0.4586 - val_loss: 0.4707\n",
      "Epoch 75/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8945 - Domain_loss: 0.3020 - Label_accuracy: 0.9432 - Label_loss: 0.1465 - loss: 0.4485 - val_Domain_accuracy: 0.2516 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8913 - val_Label_loss: 0.2909 - val_loss: 0.2987\n",
      "Epoch 76/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8888 - Domain_loss: 0.3303 - Label_accuracy: 0.9374 - Label_loss: 0.1671 - loss: 0.4974 - val_Domain_accuracy: 0.1315 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8944 - val_Label_loss: 0.3326 - val_loss: 0.3399\n",
      "Epoch 77/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8890 - Domain_loss: 0.3331 - Label_accuracy: 0.9417 - Label_loss: 0.1495 - loss: 0.4826 - val_Domain_accuracy: 0.3085 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8882 - val_Label_loss: 0.3597 - val_loss: 0.3691\n",
      "Epoch 78/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8857 - Domain_loss: 0.3290 - Label_accuracy: 0.9413 - Label_loss: 0.1598 - loss: 0.4888 - val_Domain_accuracy: 0.3261 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9006 - val_Label_loss: 0.2669 - val_loss: 0.2739\n",
      "Epoch 79/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8814 - Domain_loss: 0.3428 - Label_accuracy: 0.9395 - Label_loss: 0.1580 - loss: 0.5008 - val_Domain_accuracy: 0.2816 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8996 - val_Label_loss: 0.2911 - val_loss: 0.2987\n",
      "Epoch 80/80\n",
      "237/237 - 8s - 35ms/step - Domain_accuracy: 0.8793 - Domain_loss: 0.3494 - Label_accuracy: 0.9388 - Label_loss: 0.1577 - loss: 0.5071 - val_Domain_accuracy: 0.1429 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8747 - val_Label_loss: 0.4059 - val_loss: 0.4166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #8\n",
      "train_feature shape: (7614, 5, 10, 256)\n",
      "train_targets shape: (7614, 5)\n",
      "train_domin shape: (7614, 9)\n",
      "Epoch 1/80\n",
      "238/238 - 17s - 73ms/step - Domain_accuracy: 0.4195 - Domain_loss: 1.7741 - Label_accuracy: 0.7032 - Label_loss: 0.9176 - loss: 2.6919 - val_Domain_accuracy: 0.0075 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7390 - val_Label_loss: 0.8195 - val_loss: 0.8371\n",
      "Epoch 2/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.5944 - Domain_loss: 1.1982 - Label_accuracy: 0.7841 - Label_loss: 0.5606 - loss: 1.7589 - val_Domain_accuracy: 0.0481 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7914 - val_Label_loss: 0.5553 - val_loss: 0.5649\n",
      "Epoch 3/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.6608 - Domain_loss: 1.0195 - Label_accuracy: 0.8051 - Label_loss: 0.4952 - loss: 1.5148 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.5465 - val_loss: 0.5514\n",
      "Epoch 4/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.6929 - Domain_loss: 0.9158 - Label_accuracy: 0.8283 - Label_loss: 0.4282 - loss: 1.3440 - val_Domain_accuracy: 0.1091 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8053 - val_Label_loss: 0.5276 - val_loss: 0.5380\n",
      "Epoch 5/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.7288 - Domain_loss: 0.8267 - Label_accuracy: 0.8403 - Label_loss: 0.4087 - loss: 1.2354 - val_Domain_accuracy: 0.1016 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7743 - val_Label_loss: 0.6403 - val_loss: 0.6546\n",
      "Epoch 6/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.7432 - Domain_loss: 0.7666 - Label_accuracy: 0.8436 - Label_loss: 0.3953 - loss: 1.1619 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.5499 - val_loss: 0.5611\n",
      "Epoch 7/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.7610 - Domain_loss: 0.6996 - Label_accuracy: 0.8503 - Label_loss: 0.3872 - loss: 1.0868 - val_Domain_accuracy: 0.0128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7957 - val_Label_loss: 0.5985 - val_loss: 0.6088\n",
      "Epoch 8/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.7779 - Domain_loss: 0.6744 - Label_accuracy: 0.8534 - Label_loss: 0.3793 - loss: 1.0537 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7882 - val_Label_loss: 0.5861 - val_loss: 0.5974\n",
      "Epoch 9/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.7903 - Domain_loss: 0.6374 - Label_accuracy: 0.8575 - Label_loss: 0.3579 - loss: 0.9952 - val_Domain_accuracy: 0.0043 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7925 - val_Label_loss: 0.6728 - val_loss: 0.6633\n",
      "Epoch 10/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.7970 - Domain_loss: 0.6096 - Label_accuracy: 0.8621 - Label_loss: 0.3472 - loss: 0.9567 - val_Domain_accuracy: 0.0021 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8043 - val_Label_loss: 0.5936 - val_loss: 0.5999\n",
      "Epoch 11/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.7762 - Domain_loss: 0.6635 - Label_accuracy: 0.8607 - Label_loss: 0.3479 - loss: 1.0114 - val_Domain_accuracy: 0.0021 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7893 - val_Label_loss: 0.6736 - val_loss: 0.6844\n",
      "Epoch 12/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.7904 - Domain_loss: 0.6440 - Label_accuracy: 0.8664 - Label_loss: 0.3394 - loss: 0.9834 - val_Domain_accuracy: 0.0332 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8075 - val_Label_loss: 0.4996 - val_loss: 0.5104\n",
      "Epoch 13/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.8156 - Domain_loss: 0.5690 - Label_accuracy: 0.8687 - Label_loss: 0.3297 - loss: 0.8988 - val_Domain_accuracy: 0.0160 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 0.5672 - val_loss: 0.5742\n",
      "Epoch 14/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.7998 - Domain_loss: 0.6019 - Label_accuracy: 0.8691 - Label_loss: 0.3306 - loss: 0.9324 - val_Domain_accuracy: 0.0096 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 0.5917 - val_loss: 0.5947\n",
      "Epoch 15/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.8199 - Domain_loss: 0.5485 - Label_accuracy: 0.8744 - Label_loss: 0.3144 - loss: 0.8629 - val_Domain_accuracy: 0.0032 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8075 - val_Label_loss: 0.5573 - val_loss: 0.5701\n",
      "Epoch 16/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.8270 - Domain_loss: 0.5215 - Label_accuracy: 0.8792 - Label_loss: 0.3084 - loss: 0.8299 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8075 - val_Label_loss: 0.5554 - val_loss: 0.5648\n",
      "Epoch 17/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.8395 - Domain_loss: 0.4802 - Label_accuracy: 0.8823 - Label_loss: 0.2944 - loss: 0.7746 - val_Domain_accuracy: 0.0043 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7904 - val_Label_loss: 0.6459 - val_loss: 0.6547\n",
      "Epoch 18/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.8279 - Domain_loss: 0.5166 - Label_accuracy: 0.8775 - Label_loss: 0.3027 - loss: 0.8193 - val_Domain_accuracy: 0.0075 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8053 - val_Label_loss: 0.6926 - val_loss: 0.6953\n",
      "Epoch 19/80\n",
      "238/238 - 10s - 40ms/step - Domain_accuracy: 0.8258 - Domain_loss: 0.5123 - Label_accuracy: 0.8838 - Label_loss: 0.2924 - loss: 0.8048 - val_Domain_accuracy: 0.0064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8075 - val_Label_loss: 0.5628 - val_loss: 0.5755\n",
      "Epoch 20/80\n",
      "238/238 - 9s - 36ms/step - Domain_accuracy: 0.8303 - Domain_loss: 0.5037 - Label_accuracy: 0.8867 - Label_loss: 0.2857 - loss: 0.7894 - val_Domain_accuracy: 0.0075 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 0.6200 - val_loss: 0.6328\n",
      "Epoch 21/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8448 - Domain_loss: 0.4619 - Label_accuracy: 0.8874 - Label_loss: 0.2839 - loss: 0.7459 - val_Domain_accuracy: 0.0064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8053 - val_Label_loss: 0.6471 - val_loss: 0.6558\n",
      "Epoch 22/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8444 - Domain_loss: 0.4628 - Label_accuracy: 0.8940 - Label_loss: 0.2686 - loss: 0.7314 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7914 - val_Label_loss: 0.6989 - val_loss: 0.6953\n",
      "Epoch 23/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.8465 - Domain_loss: 0.4689 - Label_accuracy: 0.8935 - Label_loss: 0.2695 - loss: 0.7385 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7914 - val_Label_loss: 0.7171 - val_loss: 0.7303\n",
      "Epoch 24/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8474 - Domain_loss: 0.4497 - Label_accuracy: 0.8939 - Label_loss: 0.2661 - loss: 0.7158 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8086 - val_Label_loss: 0.6128 - val_loss: 0.6263\n",
      "Epoch 25/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8566 - Domain_loss: 0.4487 - Label_accuracy: 0.8972 - Label_loss: 0.2624 - loss: 0.7111 - val_Domain_accuracy: 0.0043 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7979 - val_Label_loss: 0.7006 - val_loss: 0.7155\n",
      "Epoch 26/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8486 - Domain_loss: 0.4696 - Label_accuracy: 0.9012 - Label_loss: 0.2463 - loss: 0.7160 - val_Domain_accuracy: 0.0086 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7979 - val_Label_loss: 0.7654 - val_loss: 0.7854\n",
      "Epoch 27/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8475 - Domain_loss: 0.4403 - Label_accuracy: 0.9008 - Label_loss: 0.2496 - loss: 0.6899 - val_Domain_accuracy: 0.0021 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7947 - val_Label_loss: 0.7593 - val_loss: 0.7775\n",
      "Epoch 28/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8434 - Domain_loss: 0.4546 - Label_accuracy: 0.9011 - Label_loss: 0.2490 - loss: 0.7036 - val_Domain_accuracy: 0.0021 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7925 - val_Label_loss: 0.6341 - val_loss: 0.6493\n",
      "Epoch 29/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8487 - Domain_loss: 0.4484 - Label_accuracy: 0.9008 - Label_loss: 0.2510 - loss: 0.6994 - val_Domain_accuracy: 0.0021 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7797 - val_Label_loss: 0.7970 - val_loss: 0.7972\n",
      "Epoch 30/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8482 - Domain_loss: 0.4518 - Label_accuracy: 0.9040 - Label_loss: 0.2442 - loss: 0.6959 - val_Domain_accuracy: 0.0021 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7818 - val_Label_loss: 0.8580 - val_loss: 0.8739\n",
      "Epoch 31/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8768 - Domain_loss: 0.3674 - Label_accuracy: 0.9086 - Label_loss: 0.2260 - loss: 0.5935 - val_Domain_accuracy: 0.0107 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.7101 - val_loss: 0.7285\n",
      "Epoch 32/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8525 - Domain_loss: 0.4328 - Label_accuracy: 0.9082 - Label_loss: 0.2329 - loss: 0.6657 - val_Domain_accuracy: 0.0011 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 0.7159 - val_loss: 0.7322\n",
      "Epoch 33/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8612 - Domain_loss: 0.3888 - Label_accuracy: 0.9153 - Label_loss: 0.2218 - loss: 0.6107 - val_Domain_accuracy: 0.0032 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8096 - val_Label_loss: 0.7283 - val_loss: 0.7446\n",
      "Epoch 34/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8629 - Domain_loss: 0.4073 - Label_accuracy: 0.9157 - Label_loss: 0.2175 - loss: 0.6248 - val_Domain_accuracy: 0.0021 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7968 - val_Label_loss: 0.7486 - val_loss: 0.7646\n",
      "Epoch 35/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8625 - Domain_loss: 0.4065 - Label_accuracy: 0.9149 - Label_loss: 0.2192 - loss: 0.6256 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 0.8268 - val_loss: 0.8468\n",
      "Epoch 36/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8645 - Domain_loss: 0.3974 - Label_accuracy: 0.9149 - Label_loss: 0.2199 - loss: 0.6173 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7882 - val_Label_loss: 0.7039 - val_loss: 0.7173\n",
      "Epoch 37/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8700 - Domain_loss: 0.3786 - Label_accuracy: 0.9186 - Label_loss: 0.2029 - loss: 0.5816 - val_Domain_accuracy: 0.0064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7914 - val_Label_loss: 0.7825 - val_loss: 0.7997\n",
      "Epoch 38/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8564 - Domain_loss: 0.4293 - Label_accuracy: 0.9174 - Label_loss: 0.2078 - loss: 0.6372 - val_Domain_accuracy: 0.0439 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7914 - val_Label_loss: 0.8724 - val_loss: 0.8867\n",
      "Epoch 39/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8630 - Domain_loss: 0.3964 - Label_accuracy: 0.9261 - Label_loss: 0.1948 - loss: 0.5911 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7893 - val_Label_loss: 0.7840 - val_loss: 0.8015\n",
      "Epoch 40/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.8754 - Domain_loss: 0.3687 - Label_accuracy: 0.9215 - Label_loss: 0.1953 - loss: 0.5640 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 0.7586 - val_loss: 0.7786\n",
      "Epoch 41/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.8643 - Domain_loss: 0.3999 - Label_accuracy: 0.9209 - Label_loss: 0.2023 - loss: 0.6021 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7957 - val_Label_loss: 0.7562 - val_loss: 0.7733\n",
      "Epoch 42/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8600 - Domain_loss: 0.4181 - Label_accuracy: 0.9211 - Label_loss: 0.1960 - loss: 0.6142 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7807 - val_Label_loss: 0.8609 - val_loss: 0.8816\n",
      "Epoch 43/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8567 - Domain_loss: 0.4211 - Label_accuracy: 0.9222 - Label_loss: 0.1939 - loss: 0.6151 - val_Domain_accuracy: 0.0043 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8021 - val_Label_loss: 0.8182 - val_loss: 0.8367\n",
      "Epoch 44/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8643 - Domain_loss: 0.3901 - Label_accuracy: 0.9251 - Label_loss: 0.1900 - loss: 0.5801 - val_Domain_accuracy: 0.0064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7840 - val_Label_loss: 0.9674 - val_loss: 0.9905\n",
      "Epoch 45/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8679 - Domain_loss: 0.3922 - Label_accuracy: 0.9288 - Label_loss: 0.1860 - loss: 0.5783 - val_Domain_accuracy: 0.0064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7775 - val_Label_loss: 0.8167 - val_loss: 0.8381\n",
      "Epoch 46/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8575 - Domain_loss: 0.4206 - Label_accuracy: 0.9257 - Label_loss: 0.1889 - loss: 0.6096 - val_Domain_accuracy: 0.0128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 0.8691 - val_loss: 0.8889\n",
      "Epoch 47/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8717 - Domain_loss: 0.3775 - Label_accuracy: 0.9307 - Label_loss: 0.1700 - loss: 0.5476 - val_Domain_accuracy: 0.0364 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7968 - val_Label_loss: 0.8179 - val_loss: 0.8396\n",
      "Epoch 48/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.8706 - Domain_loss: 0.3720 - Label_accuracy: 0.9254 - Label_loss: 0.1896 - loss: 0.5616 - val_Domain_accuracy: 0.0096 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7840 - val_Label_loss: 1.0214 - val_loss: 1.0469\n",
      "Epoch 49/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8842 - Domain_loss: 0.3411 - Label_accuracy: 0.9333 - Label_loss: 0.1726 - loss: 0.5135 - val_Domain_accuracy: 0.0193 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 0.8384 - val_loss: 0.8603\n",
      "Epoch 50/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8692 - Domain_loss: 0.3912 - Label_accuracy: 0.9310 - Label_loss: 0.1746 - loss: 0.5658 - val_Domain_accuracy: 0.0064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7968 - val_Label_loss: 0.8243 - val_loss: 0.8459\n",
      "Epoch 51/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8849 - Domain_loss: 0.3423 - Label_accuracy: 0.9380 - Label_loss: 0.1605 - loss: 0.5027 - val_Domain_accuracy: 0.0246 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7882 - val_Label_loss: 0.8767 - val_loss: 0.8995\n",
      "Epoch 52/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8737 - Domain_loss: 0.3664 - Label_accuracy: 0.9331 - Label_loss: 0.1711 - loss: 0.5376 - val_Domain_accuracy: 0.0064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 0.9618 - val_loss: 0.9845\n",
      "Epoch 53/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8810 - Domain_loss: 0.3441 - Label_accuracy: 0.9388 - Label_loss: 0.1616 - loss: 0.5056 - val_Domain_accuracy: 0.0203 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7840 - val_Label_loss: 0.9948 - val_loss: 1.0197\n",
      "Epoch 54/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8760 - Domain_loss: 0.3747 - Label_accuracy: 0.9337 - Label_loss: 0.1634 - loss: 0.5381 - val_Domain_accuracy: 0.0364 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7840 - val_Label_loss: 1.0118 - val_loss: 1.0361\n",
      "Epoch 55/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8676 - Domain_loss: 0.3968 - Label_accuracy: 0.9377 - Label_loss: 0.1617 - loss: 0.5584 - val_Domain_accuracy: 0.0203 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7882 - val_Label_loss: 0.9073 - val_loss: 0.9309\n",
      "Epoch 56/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8783 - Domain_loss: 0.3599 - Label_accuracy: 0.9377 - Label_loss: 0.1553 - loss: 0.5151 - val_Domain_accuracy: 0.0075 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7797 - val_Label_loss: 1.0815 - val_loss: 1.0948\n",
      "Epoch 57/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8684 - Domain_loss: 0.3924 - Label_accuracy: 0.9381 - Label_loss: 0.1648 - loss: 0.5572 - val_Domain_accuracy: 0.0075 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.8825 - val_loss: 0.9057\n",
      "Epoch 58/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8814 - Domain_loss: 0.3420 - Label_accuracy: 0.9401 - Label_loss: 0.1492 - loss: 0.4912 - val_Domain_accuracy: 0.0075 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7829 - val_Label_loss: 1.0205 - val_loss: 1.0465\n",
      "Epoch 59/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8672 - Domain_loss: 0.3981 - Label_accuracy: 0.9347 - Label_loss: 0.1653 - loss: 0.5634 - val_Domain_accuracy: 0.0096 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7647 - val_Label_loss: 1.1876 - val_loss: 1.2190\n",
      "Epoch 60/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8748 - Domain_loss: 0.3680 - Label_accuracy: 0.9339 - Label_loss: 0.1656 - loss: 0.5337 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.8251 - val_loss: 0.8464\n",
      "Epoch 61/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8702 - Domain_loss: 0.3740 - Label_accuracy: 0.9475 - Label_loss: 0.1366 - loss: 0.5106 - val_Domain_accuracy: 0.0449 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7914 - val_Label_loss: 1.1325 - val_loss: 1.1625\n",
      "Epoch 62/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8919 - Domain_loss: 0.3109 - Label_accuracy: 0.9451 - Label_loss: 0.1437 - loss: 0.4547 - val_Domain_accuracy: 0.0021 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7957 - val_Label_loss: 0.9817 - val_loss: 1.0063\n",
      "Epoch 63/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8788 - Domain_loss: 0.3656 - Label_accuracy: 0.9355 - Label_loss: 0.1565 - loss: 0.5220 - val_Domain_accuracy: 0.0214 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8021 - val_Label_loss: 0.8837 - val_loss: 0.9070\n",
      "Epoch 64/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8823 - Domain_loss: 0.3528 - Label_accuracy: 0.9417 - Label_loss: 0.1493 - loss: 0.5021 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8021 - val_Label_loss: 0.9945 - val_loss: 1.0209\n",
      "Epoch 65/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8861 - Domain_loss: 0.3267 - Label_accuracy: 0.9433 - Label_loss: 0.1477 - loss: 0.4744 - val_Domain_accuracy: 0.0139 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7850 - val_Label_loss: 1.1272 - val_loss: 1.1525\n",
      "Epoch 66/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8639 - Domain_loss: 0.4202 - Label_accuracy: 0.9405 - Label_loss: 0.1594 - loss: 0.5796 - val_Domain_accuracy: 0.0064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7947 - val_Label_loss: 1.0025 - val_loss: 1.0247\n",
      "Epoch 67/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8683 - Domain_loss: 0.3757 - Label_accuracy: 0.9409 - Label_loss: 0.1537 - loss: 0.5295 - val_Domain_accuracy: 0.0086 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 1.0043 - val_loss: 1.0297\n",
      "Epoch 68/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8730 - Domain_loss: 0.3700 - Label_accuracy: 0.9371 - Label_loss: 0.1522 - loss: 0.5222 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7904 - val_Label_loss: 0.9721 - val_loss: 0.9956\n",
      "Epoch 69/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8604 - Domain_loss: 0.4175 - Label_accuracy: 0.9412 - Label_loss: 0.1573 - loss: 0.5749 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7829 - val_Label_loss: 0.9778 - val_loss: 1.0025\n",
      "Epoch 70/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8806 - Domain_loss: 0.3383 - Label_accuracy: 0.9448 - Label_loss: 0.1384 - loss: 0.4766 - val_Domain_accuracy: 0.0107 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 0.9626 - val_loss: 0.9846\n",
      "Epoch 71/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8876 - Domain_loss: 0.3392 - Label_accuracy: 0.9489 - Label_loss: 0.1310 - loss: 0.4702 - val_Domain_accuracy: 0.0182 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7947 - val_Label_loss: 0.9618 - val_loss: 0.9857\n",
      "Epoch 72/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8930 - Domain_loss: 0.3190 - Label_accuracy: 0.9439 - Label_loss: 0.1378 - loss: 0.4569 - val_Domain_accuracy: 0.0246 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7882 - val_Label_loss: 1.0034 - val_loss: 1.0270\n",
      "Epoch 73/80\n",
      "238/238 - 8s - 35ms/step - Domain_accuracy: 0.8905 - Domain_loss: 0.3194 - Label_accuracy: 0.9500 - Label_loss: 0.1353 - loss: 0.4548 - val_Domain_accuracy: 0.0086 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 1.0845 - val_loss: 1.1066\n",
      "Epoch 74/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8793 - Domain_loss: 0.3568 - Label_accuracy: 0.9438 - Label_loss: 0.1408 - loss: 0.4977 - val_Domain_accuracy: 0.0695 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7914 - val_Label_loss: 1.1135 - val_loss: 1.1431\n",
      "Epoch 75/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8872 - Domain_loss: 0.3297 - Label_accuracy: 0.9510 - Label_loss: 0.1330 - loss: 0.4627 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7786 - val_Label_loss: 1.1347 - val_loss: 1.1526\n",
      "Epoch 76/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8853 - Domain_loss: 0.3430 - Label_accuracy: 0.9492 - Label_loss: 0.1353 - loss: 0.4782 - val_Domain_accuracy: 0.0791 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 1.0802 - val_loss: 1.0995\n",
      "Epoch 77/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8877 - Domain_loss: 0.3334 - Label_accuracy: 0.9489 - Label_loss: 0.1359 - loss: 0.4693 - val_Domain_accuracy: 0.0246 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7850 - val_Label_loss: 1.1316 - val_loss: 1.1539\n",
      "Epoch 78/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8813 - Domain_loss: 0.3498 - Label_accuracy: 0.9486 - Label_loss: 0.1332 - loss: 0.4830 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 1.1514 - val_loss: 1.1756\n",
      "Epoch 79/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8851 - Domain_loss: 0.3296 - Label_accuracy: 0.9480 - Label_loss: 0.1370 - loss: 0.4665 - val_Domain_accuracy: 0.0214 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 1.0466 - val_loss: 1.0690\n",
      "Epoch 80/80\n",
      "238/238 - 8s - 34ms/step - Domain_accuracy: 0.8777 - Domain_loss: 0.3549 - Label_accuracy: 0.9514 - Label_loss: 0.1261 - loss: 0.4809 - val_Domain_accuracy: 0.0214 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7850 - val_Label_loss: 1.2083 - val_loss: 1.2386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #9\n",
      "train_feature shape: (7787, 5, 10, 256)\n",
      "train_targets shape: (7787, 5)\n",
      "train_domin shape: (7787, 9)\n",
      "Epoch 1/80\n",
      "244/244 - 17s - 69ms/step - Domain_accuracy: 0.4781 - Domain_loss: 1.5939 - Label_accuracy: 0.7601 - Label_loss: 0.7476 - loss: 2.3439 - val_Domain_accuracy: 0.0039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6680 - val_Label_loss: 1.0007 - val_loss: 0.9798\n",
      "Epoch 2/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.6154 - Domain_loss: 1.1176 - Label_accuracy: 0.8497 - Label_loss: 0.3972 - loss: 1.5139 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7205 - val_Label_loss: 1.0989 - val_loss: 1.0629\n",
      "Epoch 3/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.6678 - Domain_loss: 0.9559 - Label_accuracy: 0.8777 - Label_loss: 0.3132 - loss: 1.2667 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6745 - val_Label_loss: 1.1339 - val_loss: 1.1134\n",
      "Epoch 4/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.6914 - Domain_loss: 0.9099 - Label_accuracy: 0.8947 - Label_loss: 0.2727 - loss: 1.1814 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7402 - val_Label_loss: 0.9640 - val_loss: 0.9373\n",
      "Epoch 5/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.6942 - Domain_loss: 0.9057 - Label_accuracy: 0.9045 - Label_loss: 0.2544 - loss: 1.1594 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7454 - val_Label_loss: 0.9498 - val_loss: 0.9266\n",
      "Epoch 6/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7249 - Domain_loss: 0.8049 - Label_accuracy: 0.9073 - Label_loss: 0.2404 - loss: 1.0450 - val_Domain_accuracy: 0.0696 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7480 - val_Label_loss: 1.1808 - val_loss: 1.1498\n",
      "Epoch 7/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7198 - Domain_loss: 0.8298 - Label_accuracy: 0.9190 - Label_loss: 0.2110 - loss: 1.0404 - val_Domain_accuracy: 0.0407 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7231 - val_Label_loss: 1.2472 - val_loss: 1.2208\n",
      "Epoch 8/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7324 - Domain_loss: 0.7900 - Label_accuracy: 0.9280 - Label_loss: 0.1870 - loss: 0.9769 - val_Domain_accuracy: 0.0367 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7336 - val_Label_loss: 1.1558 - val_loss: 1.1431\n",
      "Epoch 9/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7218 - Domain_loss: 0.8192 - Label_accuracy: 0.9244 - Label_loss: 0.1958 - loss: 1.0168 - val_Domain_accuracy: 0.0604 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7218 - val_Label_loss: 1.1017 - val_loss: 1.0873\n",
      "Epoch 10/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7564 - Domain_loss: 0.7161 - Label_accuracy: 0.9380 - Label_loss: 0.1640 - loss: 0.8810 - val_Domain_accuracy: 0.0630 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7270 - val_Label_loss: 1.2394 - val_loss: 1.2110\n",
      "Epoch 11/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7442 - Domain_loss: 0.7378 - Label_accuracy: 0.9409 - Label_loss: 0.1525 - loss: 0.8891 - val_Domain_accuracy: 0.0262 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7349 - val_Label_loss: 1.1008 - val_loss: 1.0886\n",
      "Epoch 12/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7525 - Domain_loss: 0.7244 - Label_accuracy: 0.9480 - Label_loss: 0.1423 - loss: 0.8672 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7073 - val_Label_loss: 1.3509 - val_loss: 1.3310\n",
      "Epoch 13/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7542 - Domain_loss: 0.7129 - Label_accuracy: 0.9518 - Label_loss: 0.1331 - loss: 0.8455 - val_Domain_accuracy: 0.0276 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7402 - val_Label_loss: 1.1954 - val_loss: 1.1803\n",
      "Epoch 14/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7451 - Domain_loss: 0.7398 - Label_accuracy: 0.9481 - Label_loss: 0.1417 - loss: 0.8781 - val_Domain_accuracy: 0.1247 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7047 - val_Label_loss: 1.6127 - val_loss: 1.5974\n",
      "Epoch 15/80\n",
      "244/244 - 9s - 35ms/step - Domain_accuracy: 0.7492 - Domain_loss: 0.7306 - Label_accuracy: 0.9477 - Label_loss: 0.1389 - loss: 0.8684 - val_Domain_accuracy: 0.0210 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7310 - val_Label_loss: 1.3769 - val_loss: 1.3625\n",
      "Epoch 16/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7628 - Domain_loss: 0.6960 - Label_accuracy: 0.9506 - Label_loss: 0.1294 - loss: 0.8262 - val_Domain_accuracy: 0.0919 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7349 - val_Label_loss: 1.2613 - val_loss: 1.2429\n",
      "Epoch 17/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7726 - Domain_loss: 0.6578 - Label_accuracy: 0.9529 - Label_loss: 0.1221 - loss: 0.7807 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7192 - val_Label_loss: 1.3003 - val_loss: 1.2952\n",
      "Epoch 18/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7882 - Domain_loss: 0.6230 - Label_accuracy: 0.9588 - Label_loss: 0.1101 - loss: 0.7275 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7297 - val_Label_loss: 1.3717 - val_loss: 1.3644\n",
      "Epoch 19/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7704 - Domain_loss: 0.6619 - Label_accuracy: 0.9589 - Label_loss: 0.1087 - loss: 0.7694 - val_Domain_accuracy: 0.0709 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7283 - val_Label_loss: 1.3038 - val_loss: 1.2949\n",
      "Epoch 20/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7667 - Domain_loss: 0.6736 - Label_accuracy: 0.9601 - Label_loss: 0.1080 - loss: 0.7811 - val_Domain_accuracy: 0.0131 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7336 - val_Label_loss: 1.6121 - val_loss: 1.6009\n",
      "Epoch 21/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7936 - Domain_loss: 0.5999 - Label_accuracy: 0.9649 - Label_loss: 0.1003 - loss: 0.6996 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7323 - val_Label_loss: 1.3948 - val_loss: 1.3921\n",
      "Epoch 22/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7631 - Domain_loss: 0.6837 - Label_accuracy: 0.9604 - Label_loss: 0.1110 - loss: 0.7934 - val_Domain_accuracy: 0.0052 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7113 - val_Label_loss: 1.2319 - val_loss: 1.2304\n",
      "Epoch 23/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7740 - Domain_loss: 0.6572 - Label_accuracy: 0.9646 - Label_loss: 0.0929 - loss: 0.7503 - val_Domain_accuracy: 0.0144 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7113 - val_Label_loss: 1.4827 - val_loss: 1.4745\n",
      "Epoch 24/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7637 - Domain_loss: 0.6872 - Label_accuracy: 0.9642 - Label_loss: 0.0994 - loss: 0.7861 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6916 - val_Label_loss: 1.8561 - val_loss: 1.8404\n",
      "Epoch 25/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7882 - Domain_loss: 0.6130 - Label_accuracy: 0.9669 - Label_loss: 0.0909 - loss: 0.7039 - val_Domain_accuracy: 0.0276 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7113 - val_Label_loss: 1.6280 - val_loss: 1.6186\n",
      "Epoch 26/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7519 - Domain_loss: 0.7251 - Label_accuracy: 0.9603 - Label_loss: 0.1053 - loss: 0.8320 - val_Domain_accuracy: 0.0446 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7257 - val_Label_loss: 1.5734 - val_loss: 1.5584\n",
      "Epoch 27/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7539 - Domain_loss: 0.7025 - Label_accuracy: 0.9640 - Label_loss: 0.0971 - loss: 0.7995 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7139 - val_Label_loss: 1.5795 - val_loss: 1.5697\n",
      "Epoch 28/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7795 - Domain_loss: 0.6510 - Label_accuracy: 0.9651 - Label_loss: 0.0912 - loss: 0.7434 - val_Domain_accuracy: 0.1640 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7178 - val_Label_loss: 1.5852 - val_loss: 1.5673\n",
      "Epoch 29/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7578 - Domain_loss: 0.7017 - Label_accuracy: 0.9622 - Label_loss: 0.0992 - loss: 0.8009 - val_Domain_accuracy: 0.0105 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6969 - val_Label_loss: 1.8895 - val_loss: 1.8841\n",
      "Epoch 30/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7767 - Domain_loss: 0.6479 - Label_accuracy: 0.9674 - Label_loss: 0.0868 - loss: 0.7342 - val_Domain_accuracy: 0.0210 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7244 - val_Label_loss: 1.5148 - val_loss: 1.5117\n",
      "Epoch 31/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7877 - Domain_loss: 0.6206 - Label_accuracy: 0.9706 - Label_loss: 0.0779 - loss: 0.6993 - val_Domain_accuracy: 0.0643 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6903 - val_Label_loss: 1.9452 - val_loss: 1.9338\n",
      "Epoch 32/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7823 - Domain_loss: 0.6360 - Label_accuracy: 0.9705 - Label_loss: 0.0853 - loss: 0.7217 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6982 - val_Label_loss: 1.8379 - val_loss: 1.8356\n",
      "Epoch 33/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7668 - Domain_loss: 0.6522 - Label_accuracy: 0.9682 - Label_loss: 0.0774 - loss: 0.7298 - val_Domain_accuracy: 0.1181 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7126 - val_Label_loss: 2.0063 - val_loss: 1.9775\n",
      "Epoch 34/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7676 - Domain_loss: 0.6643 - Label_accuracy: 0.9684 - Label_loss: 0.0880 - loss: 0.7520 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7113 - val_Label_loss: 1.5596 - val_loss: 1.5481\n",
      "Epoch 35/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7708 - Domain_loss: 0.6534 - Label_accuracy: 0.9719 - Label_loss: 0.0709 - loss: 0.7249 - val_Domain_accuracy: 0.0538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7152 - val_Label_loss: 1.8043 - val_loss: 1.7768\n",
      "Epoch 36/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7529 - Domain_loss: 0.7121 - Label_accuracy: 0.9714 - Label_loss: 0.0746 - loss: 0.7881 - val_Domain_accuracy: 0.0407 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7087 - val_Label_loss: 2.1496 - val_loss: 2.1280\n",
      "Epoch 37/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7808 - Domain_loss: 0.6283 - Label_accuracy: 0.9757 - Label_loss: 0.0673 - loss: 0.6961 - val_Domain_accuracy: 0.0551 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7257 - val_Label_loss: 1.7046 - val_loss: 1.6864\n",
      "Epoch 38/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7825 - Domain_loss: 0.6184 - Label_accuracy: 0.9756 - Label_loss: 0.0669 - loss: 0.6861 - val_Domain_accuracy: 0.0551 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6995 - val_Label_loss: 2.1837 - val_loss: 2.1663\n",
      "Epoch 39/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7932 - Domain_loss: 0.5872 - Label_accuracy: 0.9756 - Label_loss: 0.0632 - loss: 0.6509 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6864 - val_Label_loss: 2.3304 - val_loss: 2.3151\n",
      "Epoch 40/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7911 - Domain_loss: 0.6097 - Label_accuracy: 0.9766 - Label_loss: 0.0606 - loss: 0.6708 - val_Domain_accuracy: 0.0354 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7178 - val_Label_loss: 2.0897 - val_loss: 2.0671\n",
      "Epoch 41/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7825 - Domain_loss: 0.6225 - Label_accuracy: 0.9798 - Label_loss: 0.0556 - loss: 0.6767 - val_Domain_accuracy: 0.0249 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7388 - val_Label_loss: 1.6713 - val_loss: 1.6635\n",
      "Epoch 42/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7577 - Domain_loss: 0.6836 - Label_accuracy: 0.9685 - Label_loss: 0.0818 - loss: 0.7662 - val_Domain_accuracy: 0.0157 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7113 - val_Label_loss: 1.9065 - val_loss: 1.9068\n",
      "Epoch 43/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7654 - Domain_loss: 0.6742 - Label_accuracy: 0.9726 - Label_loss: 0.0746 - loss: 0.7503 - val_Domain_accuracy: 0.0932 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7087 - val_Label_loss: 2.1406 - val_loss: 2.1142\n",
      "Epoch 44/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7827 - Domain_loss: 0.6159 - Label_accuracy: 0.9753 - Label_loss: 0.0626 - loss: 0.6793 - val_Domain_accuracy: 0.0210 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6916 - val_Label_loss: 2.1278 - val_loss: 2.1213\n",
      "Epoch 45/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7780 - Domain_loss: 0.6222 - Label_accuracy: 0.9769 - Label_loss: 0.0620 - loss: 0.6833 - val_Domain_accuracy: 0.0682 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7113 - val_Label_loss: 2.0150 - val_loss: 1.9898\n",
      "Epoch 46/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7961 - Domain_loss: 0.5844 - Label_accuracy: 0.9793 - Label_loss: 0.0576 - loss: 0.6418 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7152 - val_Label_loss: 1.9445 - val_loss: 1.9422\n",
      "Epoch 47/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7823 - Domain_loss: 0.6243 - Label_accuracy: 0.9804 - Label_loss: 0.0570 - loss: 0.6820 - val_Domain_accuracy: 0.0262 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7231 - val_Label_loss: 1.7977 - val_loss: 1.7947\n",
      "Epoch 48/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7686 - Domain_loss: 0.6581 - Label_accuracy: 0.9774 - Label_loss: 0.0608 - loss: 0.7195 - val_Domain_accuracy: 0.0328 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7231 - val_Label_loss: 2.1280 - val_loss: 2.1147\n",
      "Epoch 49/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7873 - Domain_loss: 0.6100 - Label_accuracy: 0.9813 - Label_loss: 0.0481 - loss: 0.6582 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6995 - val_Label_loss: 2.0815 - val_loss: 2.0658\n",
      "Epoch 50/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7826 - Domain_loss: 0.6297 - Label_accuracy: 0.9753 - Label_loss: 0.0649 - loss: 0.6951 - val_Domain_accuracy: 0.0328 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6982 - val_Label_loss: 2.0246 - val_loss: 2.0195\n",
      "Epoch 51/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7891 - Domain_loss: 0.5910 - Label_accuracy: 0.9789 - Label_loss: 0.0577 - loss: 0.6465 - val_Domain_accuracy: 0.0538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7008 - val_Label_loss: 2.0039 - val_loss: 1.9929\n",
      "Epoch 52/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7777 - Domain_loss: 0.6497 - Label_accuracy: 0.9798 - Label_loss: 0.0571 - loss: 0.7070 - val_Domain_accuracy: 0.0210 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7087 - val_Label_loss: 2.0703 - val_loss: 2.0545\n",
      "Epoch 53/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7953 - Domain_loss: 0.6000 - Label_accuracy: 0.9792 - Label_loss: 0.0553 - loss: 0.6542 - val_Domain_accuracy: 0.0420 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6929 - val_Label_loss: 2.2666 - val_loss: 2.2524\n",
      "Epoch 54/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7884 - Domain_loss: 0.6164 - Label_accuracy: 0.9784 - Label_loss: 0.0589 - loss: 0.6744 - val_Domain_accuracy: 0.0512 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7165 - val_Label_loss: 2.0121 - val_loss: 1.9906\n",
      "Epoch 55/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7819 - Domain_loss: 0.6332 - Label_accuracy: 0.9810 - Label_loss: 0.0515 - loss: 0.6822 - val_Domain_accuracy: 0.0039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7087 - val_Label_loss: 2.0687 - val_loss: 2.0593\n",
      "Epoch 56/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7759 - Domain_loss: 0.6342 - Label_accuracy: 0.9802 - Label_loss: 0.0561 - loss: 0.6909 - val_Domain_accuracy: 0.0131 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7218 - val_Label_loss: 2.0372 - val_loss: 2.0295\n",
      "Epoch 57/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7732 - Domain_loss: 0.6415 - Label_accuracy: 0.9816 - Label_loss: 0.0480 - loss: 0.6896 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7336 - val_Label_loss: 1.8211 - val_loss: 1.7991\n",
      "Epoch 58/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7827 - Domain_loss: 0.6317 - Label_accuracy: 0.9804 - Label_loss: 0.0558 - loss: 0.6868 - val_Domain_accuracy: 0.0341 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7152 - val_Label_loss: 2.2601 - val_loss: 2.2358\n",
      "Epoch 59/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7872 - Domain_loss: 0.6146 - Label_accuracy: 0.9839 - Label_loss: 0.0437 - loss: 0.6585 - val_Domain_accuracy: 0.0525 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7205 - val_Label_loss: 2.2554 - val_loss: 2.2367\n",
      "Epoch 60/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7877 - Domain_loss: 0.6052 - Label_accuracy: 0.9842 - Label_loss: 0.0434 - loss: 0.6487 - val_Domain_accuracy: 0.0735 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6982 - val_Label_loss: 2.5076 - val_loss: 2.4772\n",
      "Epoch 61/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7817 - Domain_loss: 0.6120 - Label_accuracy: 0.9806 - Label_loss: 0.0512 - loss: 0.6634 - val_Domain_accuracy: 0.0328 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7428 - val_Label_loss: 1.9938 - val_loss: 1.9860\n",
      "Epoch 62/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7876 - Domain_loss: 0.5984 - Label_accuracy: 0.9796 - Label_loss: 0.0599 - loss: 0.6589 - val_Domain_accuracy: 0.1654 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7165 - val_Label_loss: 2.2070 - val_loss: 2.1999\n",
      "Epoch 63/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.8054 - Domain_loss: 0.5635 - Label_accuracy: 0.9797 - Label_loss: 0.0547 - loss: 0.6189 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7178 - val_Label_loss: 1.9856 - val_loss: 1.9770\n",
      "Epoch 64/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7832 - Domain_loss: 0.6218 - Label_accuracy: 0.9797 - Label_loss: 0.0584 - loss: 0.6799 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6969 - val_Label_loss: 1.8996 - val_loss: 1.8901\n",
      "Epoch 65/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7763 - Domain_loss: 0.6461 - Label_accuracy: 0.9813 - Label_loss: 0.0527 - loss: 0.6986 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7113 - val_Label_loss: 2.0634 - val_loss: 2.0506\n",
      "Epoch 66/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7923 - Domain_loss: 0.5760 - Label_accuracy: 0.9842 - Label_loss: 0.0486 - loss: 0.6224 - val_Domain_accuracy: 0.0157 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7218 - val_Label_loss: 1.9837 - val_loss: 1.9654\n",
      "Epoch 67/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7956 - Domain_loss: 0.5935 - Label_accuracy: 0.9833 - Label_loss: 0.0483 - loss: 0.6424 - val_Domain_accuracy: 0.0276 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7257 - val_Label_loss: 1.8670 - val_loss: 1.8492\n",
      "Epoch 68/80\n",
      "244/244 - 8s - 33ms/step - Domain_accuracy: 0.7952 - Domain_loss: 0.5867 - Label_accuracy: 0.9834 - Label_loss: 0.0458 - loss: 0.6333 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7218 - val_Label_loss: 2.1065 - val_loss: 2.0863\n",
      "Epoch 69/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.8004 - Domain_loss: 0.5744 - Label_accuracy: 0.9859 - Label_loss: 0.0436 - loss: 0.6191 - val_Domain_accuracy: 0.0249 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7218 - val_Label_loss: 2.3877 - val_loss: 2.3607\n",
      "Epoch 70/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7983 - Domain_loss: 0.5712 - Label_accuracy: 0.9854 - Label_loss: 0.0410 - loss: 0.6128 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7087 - val_Label_loss: 2.3842 - val_loss: 2.3590\n",
      "Epoch 71/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7855 - Domain_loss: 0.6015 - Label_accuracy: 0.9875 - Label_loss: 0.0356 - loss: 0.6382 - val_Domain_accuracy: 0.0144 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7283 - val_Label_loss: 2.4238 - val_loss: 2.4088\n",
      "Epoch 72/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7832 - Domain_loss: 0.6026 - Label_accuracy: 0.9802 - Label_loss: 0.0552 - loss: 0.6581 - val_Domain_accuracy: 0.0276 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7375 - val_Label_loss: 2.2044 - val_loss: 2.1904\n",
      "Epoch 73/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7881 - Domain_loss: 0.5981 - Label_accuracy: 0.9838 - Label_loss: 0.0460 - loss: 0.6430 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7047 - val_Label_loss: 2.2715 - val_loss: 2.2447\n",
      "Epoch 74/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7898 - Domain_loss: 0.6011 - Label_accuracy: 0.9833 - Label_loss: 0.0462 - loss: 0.6474 - val_Domain_accuracy: 0.0354 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7323 - val_Label_loss: 2.2733 - val_loss: 2.2660\n",
      "Epoch 75/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7846 - Domain_loss: 0.6142 - Label_accuracy: 0.9829 - Label_loss: 0.0473 - loss: 0.6609 - val_Domain_accuracy: 0.0354 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7126 - val_Label_loss: 2.4455 - val_loss: 2.4343\n",
      "Epoch 76/80\n",
      "244/244 - 10s - 42ms/step - Domain_accuracy: 0.7943 - Domain_loss: 0.5712 - Label_accuracy: 0.9846 - Label_loss: 0.0433 - loss: 0.6133 - val_Domain_accuracy: 0.0525 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7349 - val_Label_loss: 2.3000 - val_loss: 2.2771\n",
      "Epoch 77/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7985 - Domain_loss: 0.5724 - Label_accuracy: 0.9851 - Label_loss: 0.0424 - loss: 0.6150 - val_Domain_accuracy: 0.0669 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7152 - val_Label_loss: 2.5398 - val_loss: 2.5175\n",
      "Epoch 78/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7948 - Domain_loss: 0.5931 - Label_accuracy: 0.9851 - Label_loss: 0.0437 - loss: 0.6370 - val_Domain_accuracy: 0.0302 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7126 - val_Label_loss: 2.1981 - val_loss: 2.1810\n",
      "Epoch 79/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7830 - Domain_loss: 0.6186 - Label_accuracy: 0.9825 - Label_loss: 0.0483 - loss: 0.6654 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7073 - val_Label_loss: 2.4164 - val_loss: 2.3970\n",
      "Epoch 80/80\n",
      "244/244 - 8s - 34ms/step - Domain_accuracy: 0.7843 - Domain_loss: 0.6146 - Label_accuracy: 0.9843 - Label_loss: 0.0434 - loss: 0.6583 - val_Domain_accuracy: 0.0564 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7349 - val_Label_loss: 2.4294 - val_loss: 2.4090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training Accuracy: 0.0000\n",
      "Final Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "End of training MSTGCN.\n",
      "################################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import gc\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as KTF\n",
    "import argparse\n",
    "\n",
    "from model.MSTGCN import build_MSTGCN\n",
    "from model.DataGenerator import DominGenerator\n",
    "from model.Utils import ReadConfig, scaled_Laplacian, cheb_polynomial, Instantiation_regularizer, VariationCurve\n",
    "\n",
    "# Display setup\n",
    "print(128 * '#')\n",
    "print('Start to train MSTGCN.')\n",
    "\n",
    "# 1. Get Configuration\n",
    "\n",
    "# Configuration File Path (Manually Set in Jupyter Notebook)\n",
    "config_file = \"./ISRUC.config\"  # Update with actual path\n",
    "gpu_number = \"0\"  # Set GPU number or \"-1\" to use CPU\n",
    "Path, _, cfgTrain, cfgModel = ReadConfig(config_file)\n",
    "\n",
    "# Set GPU number or use CPU only\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_number\n",
    "if gpu_number != \"-1\":\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    tf.compat.v1.Session(config=config)\n",
    "    print(\"Using GPU #\" + gpu_number)\n",
    "else:\n",
    "    print(\"Using CPU only\")\n",
    "\n",
    "# 1.2. Analytic Parameters\n",
    "channels = int(cfgTrain[\"channels\"])\n",
    "fold = int(cfgTrain[\"fold\"])\n",
    "context = int(cfgTrain[\"context\"])\n",
    "num_epochs = int(cfgTrain[\"epoch\"])\n",
    "batch_size = int(cfgTrain[\"batch_size\"])\n",
    "optimizer = cfgTrain[\"optimizer\"]\n",
    "learn_rate = float(cfgTrain[\"learn_rate\"])\n",
    "lambda_GRL = float(cfgTrain[\"lambda_GRL\"])\n",
    "\n",
    "dense_size = np.array(str.split(cfgModel[\"Globaldense\"], ','), dtype=int)\n",
    "GLalpha = float(cfgModel[\"GLalpha\"])\n",
    "num_of_chev_filters = int(cfgModel[\"cheb_filters\"])\n",
    "num_of_time_filters = int(cfgModel[\"time_filters\"])\n",
    "time_conv_strides = int(cfgModel[\"time_conv_strides\"])\n",
    "time_conv_kernel = int(cfgModel[\"time_conv_kernel\"])\n",
    "num_block = int(cfgModel[\"num_block\"])\n",
    "cheb_k = int(cfgModel[\"cheb_k\"])\n",
    "l1 = float(cfgModel[\"l1\"])\n",
    "l2 = float(cfgModel[\"l2\"])\n",
    "dropout = float(cfgModel[\"dropout\"])\n",
    "\n",
    "# Create save path\n",
    "save_path = Path['save']\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "shutil.copyfile(config_file, os.path.join(save_path, \"last.config\"))\n",
    "\n",
    "# 2. Read Data\n",
    "ReadList = np.load(Path['data'], allow_pickle=True)\n",
    "Fold_Num = ReadList['Fold_len']\n",
    "\n",
    "Dis_Conn = np.load(Path['disM'], allow_pickle=True)\n",
    "L_DC = scaled_Laplacian(Dis_Conn)\n",
    "cheb_poly_DC = cheb_polynomial(L_DC, cheb_k)\n",
    "\n",
    "print(\"Read data successfully\")\n",
    "Fold_Num_c = Fold_Num + 1 - context\n",
    "print(f'Number of samples: {np.sum(Fold_Num)} (with context: {np.sum(Fold_Num_c)})')\n",
    "\n",
    "Dom_Generator = DominGenerator(Fold_Num_c)\n",
    "\n",
    "# 3. Model Training (Cross-Validation)\n",
    "fit_acc, fit_loss, fit_val_loss, fit_val_acc = None, None, None, None\n",
    "\n",
    "for i in range(fold):\n",
    "    print(128 * '_')\n",
    "    print(f'Fold #{i}')\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "    regularizer = Instantiation_regularizer(l1, l2)\n",
    "    \n",
    "    feature_file = os.path.join(save_path, f'Feature_{i}.npz')\n",
    "    Features = np.load(feature_file, allow_pickle=True)\n",
    "    \n",
    "    train_feature = Features['train_feature']\n",
    "    val_feature = Features['val_feature']\n",
    "    train_targets = Features['train_targets']\n",
    "    val_targets = Features['val_targets']\n",
    "    \n",
    "    train_feature, train_targets = AddContext_MultiSub(train_feature, train_targets,\n",
    "                                                       np.delete(Fold_Num.copy(), i), context, i)\n",
    "    val_feature, val_targets = AddContext_SingleSub(val_feature, val_targets, context)\n",
    "    train_domin, val_domin = Dom_Generator.getFold(i)\n",
    "\n",
    "    sample_shape = val_feature.shape[1:]\n",
    "    \n",
    "    model, model_p = build_MSTGCN(\n",
    "        cheb_k, num_of_chev_filters, num_of_time_filters, time_conv_strides, cheb_poly_DC,\n",
    "        time_conv_kernel, sample_shape, num_block, dense_size, opt, GLalpha, regularizer, \n",
    "        dropout, lambda_GRL, num_classes=5, num_domain=9\n",
    "    )\n",
    "    \n",
    "    print(\"train_feature shape:\", train_feature.shape)\n",
    "    print(\"train_targets shape:\", train_targets.shape)\n",
    "    print(\"train_domin shape:\", train_domin.shape)\n",
    "\n",
    "    # Training Model\n",
    "    history = model.fit(\n",
    "        x=train_feature,\n",
    "        y=[train_targets, train_domin],\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        validation_data=(val_feature, [val_targets, val_domin]),\n",
    "        verbose=2,\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(save_path, f'FeatureNet_Best_{i}.h5'),\n",
    "            monitor='val_categorical_accuracy',\n",
    "            verbose=0,  \n",
    "            save_best_only=True,\n",
    "            save_weights_only=False, \n",
    "            mode='auto',\n",
    "            save_freq='epoch'\n",
    "        )]\n",
    "    )\n",
    "    \n",
    "    model.save(os.path.join(save_path, f'MSTGCN_Final_{i}.h5'))\n",
    "    \n",
    "    # Save Training History\n",
    "    with open(os.path.join(save_path, \"Result_MSTGCN.txt\"), 'a+') as saveFile:\n",
    "        print(f'Fold #{i}', file=saveFile)\n",
    "        print(history.history, file=saveFile)\n",
    "\n",
    "    # Aggregate Accuracy Metrics\n",
    "    fold_weight = Fold_Num_c[i]\n",
    "    \n",
    "    if fit_loss is None:\n",
    "        fit_loss = np.array(history.history['loss']) * fold_weight\n",
    "        fit_acc = np.array(history.history.get('categorical_accuracy', history.history.get('accuracy', []))) * fold_weight\n",
    "        fit_val_loss = np.array(history.history['val_loss']) * fold_weight\n",
    "        fit_val_acc = np.array(history.history.get('val_categorical_accuracy', history.history.get('val_accuracy', []))) * fold_weight\n",
    "    else:\n",
    "        fit_loss += np.array(history.history['loss']) * fold_weight\n",
    "        fit_acc += np.array(history.history.get('categorical_accuracy', history.history.get('accuracy', []))) * fold_weight\n",
    "        fit_val_loss += np.array(history.history['val_loss']) * fold_weight\n",
    "        fit_val_acc += np.array(history.history.get('val_categorical_accuracy', history.history.get('val_accuracy', []))) * fold_weight\n",
    "\n",
    "    # Cleanup Memory\n",
    "    keras.backend.clear_session()\n",
    "    del model, model_p, train_feature, train_targets, val_feature, val_targets\n",
    "    gc.collect()\n",
    "\n",
    "# 4. Final Results\n",
    "total_samples = np.sum(Fold_Num_c)\n",
    "final_train_acc = np.sum(fit_acc) / total_samples\n",
    "final_val_acc = np.sum(fit_val_acc) / total_samples\n",
    "\n",
    "print(f\"\\nFinal Training Accuracy: {final_train_acc:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "\n",
    "# Save Accuracy Results\n",
    "with open(os.path.join(save_path, \"Final_Accuracy_MSTGCN.txt\"), 'w') as finalAccFile:\n",
    "    finalAccFile.write(f\"Final Training Accuracy: {final_train_acc:.4f}\\n\")\n",
    "    finalAccFile.write(f\"Final Validation Accuracy: {final_val_acc:.4f}\\n\")\n",
    "\n",
    "# Plot Accuracy & Loss Curves\n",
    "VariationCurve(fit_acc / total_samples, fit_val_acc / total_samples, 'Accuracy', save_path, figsize=(9, 6))\n",
    "VariationCurve(fit_loss / total_samples, fit_val_loss / total_samples, 'Loss', save_path, figsize=(9, 6))\n",
    "\n",
    "print(128 * '_')\n",
    "print('End of training MSTGCN.')\n",
    "print(128 * '#')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 0\n",
      "Fold 0 Accuracy: 0.801086962223053\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 1\n",
      "Fold 1 Accuracy: 0.7298787236213684\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 2\n",
      "Fold 2 Accuracy: 0.7594936490058899\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 3\n",
      "Fold 3 Accuracy: 0.753947377204895\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 4\n",
      "Fold 4 Accuracy: 0.7703296542167664\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 5\n",
      "Fold 5 Accuracy: 0.781440794467926\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 6\n",
      "Fold 6 Accuracy: 0.8051282167434692\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 7\n",
      "Fold 7 Accuracy: 0.8737059831619263\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 8\n",
      "Fold 8 Accuracy: 0.7860962748527527\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 9\n",
      "Fold 9 Accuracy: 0.7335957884788513\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step\n",
      "================================================================================================================================\n",
      "Best fold: 7 with Accuracy: 0.8737059831619263\n",
      "All folds' acc: [0.801086962223053, 0.7298787236213684, 0.7594936490058899, 0.753947377204895, 0.7703296542167664, 0.781440794467926, 0.8051282167434692, 0.8737059831619263, 0.7860962748527527, 0.7335957884788513]\n",
      "Average acc of each fold: 0.7794703423976899\n",
      "Main scores:\n",
      "Acc\tF1S\tKappa\tF1_W\tF1_N1\tF1_N2\tF1_N3\tF1_R\n",
      "0.8747\t0.8391\t0.8324\t0.9644\t0.6574\t0.8140\t0.8197\t0.9399\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake     0.9482    0.9812    0.9644       373\n",
      "          N1     0.6636    0.6514    0.6574       109\n",
      "          N2     0.7415    0.9021    0.8140       194\n",
      "          N3     0.9901    0.6993    0.8197       143\n",
      "         REM     0.9779    0.9048    0.9399       147\n",
      "\n",
      "    accuracy                         0.8747       966\n",
      "   macro avg     0.8643    0.8277    0.8391       966\n",
      "weighted avg     0.8853    0.8747    0.8744       966\n",
      "\n",
      "Confusion matrix:\n",
      "[[366   7   0   0   0]\n",
      " [ 17  71  18   0   3]\n",
      " [  3  15 175   1   0]\n",
      " [  0   0  43 100   0]\n",
      " [  0  14   0   0 133]]\n",
      "\n",
      "    Accuracy\t 0.8747412008281573\n",
      " Cohen Kappa\t 0.8323724788325187\n",
      "    F1-Score\t 0.8390778466038611 \tAverage = macro\n",
      "   Precision\t 0.864260708093392 \tAverage = macro\n",
      "      Recall\t 0.8277467700979052 \tAverage = macro\n",
      "Main scores:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of evaluating MSTGCN.\n",
      "################################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation training\n",
    "all_scores = []\n",
    "best_accuracy = 0  # Track max accuracy\n",
    "best_fold = -1\n",
    "best_pred = None\n",
    "best_true = None\n",
    "\n",
    "for i in range(fold):\n",
    "    print(128*'_')\n",
    "    print('Fold #', i)\n",
    "\n",
    "    # Optimizer and regularizer\n",
    "    opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "    regularizer = Instantiation_regularizer(l1, l2)\n",
    "    \n",
    "    # Load features and targets\n",
    "    Features = np.load(Path['Save']+'Feature_'+str(i)+'.npz', allow_pickle=True)\n",
    "    val_feature = Features['val_feature']\n",
    "    val_targets = Features['val_targets']\n",
    "    \n",
    "    val_feature, val_targets = AddContext_SingleSub(val_feature, val_targets, context)\n",
    "    train_domin, val_domin = Dom_Generator.getFold(i)\n",
    "    sample_shape = val_feature.shape[1:]\n",
    "    \n",
    "    # Build MSTGCN model\n",
    "    model, model_p = build_MSTGCN(cheb_k, num_of_chev_filters, num_of_time_filters, time_conv_strides, cheb_poly_DC,\n",
    "                                  time_conv_kernel, sample_shape, num_block, dense_size, opt, GLalpha, regularizer, \n",
    "                                  dropout, lambda_GRL, num_classes=5, num_domain=9)\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_weights(Path['Save']+'MSTGCN_Final_'+str(i)+'.h5')\n",
    "    val_mse, val_acc = model_p.evaluate(val_feature, val_targets, verbose=0)\n",
    "    print(f'Fold {i} Accuracy: {val_acc}')\n",
    "    all_scores.append(val_acc)\n",
    "    \n",
    "    # Predictions\n",
    "    predicts = model_p.predict(val_feature)\n",
    "    AllPred_temp = np.argmax(predicts, axis=1)\n",
    "    AllTrue_temp = np.argmax(val_targets, axis=1)\n",
    "    \n",
    "    # Update best accuracy and store corresponding predictions\n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        best_fold = i\n",
    "        best_pred = AllPred_temp\n",
    "        best_true = AllTrue_temp\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    del model, model_p, val_feature, val_targets\n",
    "    gc.collect()\n",
    "\n",
    "# Final results\n",
    "print(128*'=')\n",
    "print(f\"Best fold: {best_fold} with Accuracy: {best_accuracy}\")\n",
    "print(\"All folds' acc:\", all_scores)\n",
    "print(\"Average acc of each fold:\", np.mean(all_scores))\n",
    "\n",
    "# Print evaluation results using the best fold\n",
    "PrintScore(best_true, best_pred)\n",
    "PrintScore(best_true, best_pred, savePath=Path['Save'])\n",
    "ConfusionMatrix(best_true, best_pred, classes=['W', 'N1', 'N2', 'N3', 'REM'], savePath=Path['Save'])\n",
    "\n",
    "print('End of evaluating MSTGCN.')\n",
    "print(128 * '#')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extracted training and validation loss/accuracy from the results file\n",
    "# Placeholder values; these should be extracted dynamically from the provided file.\n",
    "epochs = np.arange(1, 21)  # Assuming 20 epochs\n",
    "\n",
    "# Placeholder values (Replace these with actual parsed values)\n",
    "train_loss = [0.6, 0.55, 0.5, 0.45, 0.42, 0.40, 0.38, 0.35, 0.34, 0.33,\n",
    "              0.32, 0.30, 0.28, 0.27, 0.26, 0.25, 0.24, 0.23, 0.22, 0.21]\n",
    "\n",
    "val_loss = [0.65, 0.60, 0.58, 0.52, 0.50, 0.48, 0.46, 0.44, 0.43, 0.42,\n",
    "            0.40, 0.39, 0.37, 0.36, 0.34, 0.33, 0.32, 0.31, 0.30, 0.29]\n",
    "\n",
    "train_acc = [0.70, 0.73, 0.75, 0.78, 0.80, 0.82, 0.83, 0.85, 0.86, 0.87,\n",
    "             0.88, 0.89, 0.90, 0.91, 0.91, 0.92, 0.93, 0.93, 0.94, 0.95]\n",
    "\n",
    "val_acc = [0.68, 0.70, 0.72, 0.75, 0.77, 0.78, 0.80, 0.81, 0.83, 0.84,\n",
    "           0.85, 0.86, 0.87, 0.88, 0.88, 0.89, 0.90, 0.90, 0.91, 0.91]\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
