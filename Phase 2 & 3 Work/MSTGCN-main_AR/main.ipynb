{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read subject 1\n",
      "Subject 1 : (924,) (924, 10, 3000)\n",
      "Read subject 2\n",
      "Subject 2 : (911,) (911, 10, 3000)\n",
      "Read subject 3\n",
      "Subject 3 : (794,) (794, 10, 3000)\n",
      "Read subject 4\n",
      "Subject 4 : (764,) (764, 10, 3000)\n",
      "Read subject 5\n",
      "Subject 5 : (914,) (914, 10, 3000)\n",
      "Read subject 6\n",
      "Subject 6 : (823,) (823, 10, 3000)\n",
      "Read subject 7\n",
      "Subject 7 : (784,) (784, 10, 3000)\n",
      "Read subject 8\n",
      "Subject 8 : (970,) (970, 10, 3000)\n",
      "Read subject 9\n",
      "Subject 9 : (939,) (939, 10, 3000)\n",
      "Read subject 10\n",
      "Subject 10 : (766,) (766, 10, 3000)\n",
      "Preprocess over.\n",
      "Saved to D:/Python/Major_Project/data\\ISRUC_S3.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "from os import path\n",
    "from scipy import signal\n",
    "import os\n",
    "\n",
    "path_Extracted = 'D:/Python/Major_Project/dataset/mat_data/ISRUC_S3_mat'\n",
    "path_RawData   = 'D:/Python/Major_Project/data/ISRUC_S3/RawData/RawData'\n",
    "path_output    = 'D:/Python/Major_Project/data'\n",
    "channels = ['C3_A2', 'C4_A1', 'F3_A2', 'F4_A1', 'O1_A2', 'O2_A1',\n",
    "            'LOC_A2', 'ROC_A1', 'X1', 'X2']\n",
    "\n",
    "def read_psg(path_Extracted, sub_id, channels, resample=3000):\n",
    "    psg = scio.loadmat(path.join(path_Extracted, 'subject%d.mat' % (sub_id)))\n",
    "    psg_use = []\n",
    "    for c in channels:\n",
    "        psg_use.append(\n",
    "            np.expand_dims(signal.resample(psg[c], resample, axis=-1), 1))\n",
    "    psg_use = np.concatenate(psg_use, axis=1)\n",
    "    return psg_use\n",
    "\n",
    "def read_label(path_RawData, sub_id, ignore=30):\n",
    "    label = []\n",
    "    with open(path.join(path_RawData, '%d/%d_1.txt' % (sub_id, sub_id))) as f:\n",
    "        s = f.readline()\n",
    "        while True:\n",
    "            a = s.replace('\\n', '')\n",
    "            label.append(int(a))\n",
    "            s = f.readline()\n",
    "            if s == '' or s == '\\n':\n",
    "                break\n",
    "    return np.array(label[:-ignore])\n",
    "\n",
    "fold_label = []\n",
    "fold_psg = []\n",
    "fold_len = []\n",
    "\n",
    "for sub in range(1, 11):\n",
    "    print('Read subject', sub)\n",
    "    labels = read_label(path_RawData, sub)\n",
    "    psg = read_psg(path_Extracted, sub, channels)\n",
    "    print('Subject', sub, ':', labels.shape, psg.shape)\n",
    "    assert len(labels) == len(psg)\n",
    "\n",
    "    # Label Mapping\n",
    "    apnea_labels = np.copy(labels)\n",
    "    apnea_labels[np.isin(labels, [0, 2, 3])] = 0  # Normal: W, N2, N3\n",
    "    apnea_labels[np.isin(labels, [1])] = 1  # OSA: N1\n",
    "    apnea_labels[np.isin(labels, [5])] = 2  # CSA: REM\n",
    "\n",
    "    fold_label.append(np.eye(3)[apnea_labels])  # One-hot encoding with 3 classes\n",
    "    fold_psg.append(psg)\n",
    "    fold_len.append(len(labels))\n",
    "\n",
    "print('Preprocess over.')\n",
    "\n",
    "os.makedirs(path_output, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "np.savez(os.path.join(path_output, 'ISRUC_S3.npz'),\n",
    "    Fold_data=np.array(fold_psg, dtype=object),  \n",
    "    Fold_label=np.array(fold_label, dtype=object),  \n",
    "    Fold_len=np.array(fold_len)  \n",
    ")\n",
    "\n",
    "print('Saved to', os.path.join(path_output, 'ISRUC_S3.npz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################################################################\n",
      "Start to train FeatureNet.\n",
      "Config:  ./ISRUC.config\n",
      "Use CPU only\n",
      "Read data successfully\n",
      "Number of samples: 8589\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 0\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 40s - 330ms/step - acc: 0.5335 - loss: 1.7178 - val_acc: 0.4913 - val_loss: 1.7494\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 20s - 171ms/step - acc: 0.6474 - loss: 1.0818 - val_acc: 0.5032 - val_loss: 1.9444\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 22s - 182ms/step - acc: 0.6958 - loss: 0.8818 - val_acc: 0.5184 - val_loss: 2.4017\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 173ms/step - acc: 0.7268 - loss: 0.7647 - val_acc: 0.5844 - val_loss: 2.3561\n",
      "Epoch 5/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.7365 - loss: 0.7074 - val_acc: 0.5195 - val_loss: 2.8759\n",
      "Epoch 6/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.7515 - loss: 0.6554 - val_acc: 0.5379 - val_loss: 2.7085\n",
      "Epoch 7/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.7546 - loss: 0.6464 - val_acc: 0.5563 - val_loss: 2.9628\n",
      "Epoch 8/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.7605 - loss: 0.6098 - val_acc: 0.5509 - val_loss: 3.0794\n",
      "Epoch 9/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.7739 - loss: 0.5890 - val_acc: 0.5747 - val_loss: 3.0077\n",
      "Epoch 10/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.7846 - loss: 0.5622 - val_acc: 0.5639 - val_loss: 2.7865\n",
      "Epoch 11/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.7838 - loss: 0.5435 - val_acc: 0.5498 - val_loss: 2.8174\n",
      "Epoch 12/80\n",
      "120/120 - 20s - 171ms/step - acc: 0.7958 - loss: 0.5368 - val_acc: 0.4924 - val_loss: 3.2985\n",
      "Epoch 13/80\n",
      "120/120 - 21s - 174ms/step - acc: 0.7958 - loss: 0.5264 - val_acc: 0.5281 - val_loss: 3.2846\n",
      "Epoch 14/80\n",
      "120/120 - 21s - 174ms/step - acc: 0.7971 - loss: 0.5159 - val_acc: 0.5238 - val_loss: 2.9815\n",
      "Epoch 15/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.7973 - loss: 0.5153 - val_acc: 0.5465 - val_loss: 2.6905\n",
      "Epoch 16/80\n",
      "120/120 - 21s - 174ms/step - acc: 0.8043 - loss: 0.5049 - val_acc: 0.5498 - val_loss: 2.6091\n",
      "Epoch 17/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.8098 - loss: 0.4904 - val_acc: 0.5065 - val_loss: 2.8322\n",
      "Epoch 18/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8076 - loss: 0.4785 - val_acc: 0.4675 - val_loss: 3.0380\n",
      "Epoch 19/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8068 - loss: 0.4830 - val_acc: 0.5595 - val_loss: 2.6232\n",
      "Epoch 20/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8117 - loss: 0.4689 - val_acc: 0.5260 - val_loss: 3.0638\n",
      "Epoch 21/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8146 - loss: 0.4645 - val_acc: 0.5011 - val_loss: 3.0678\n",
      "Epoch 22/80\n",
      "120/120 - 22s - 181ms/step - acc: 0.8217 - loss: 0.4522 - val_acc: 0.4253 - val_loss: 3.3181\n",
      "Epoch 23/80\n",
      "120/120 - 21s - 176ms/step - acc: 0.8271 - loss: 0.4435 - val_acc: 0.4080 - val_loss: 3.3428\n",
      "Epoch 24/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8292 - loss: 0.4304 - val_acc: 0.3918 - val_loss: 3.7054\n",
      "Epoch 25/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8348 - loss: 0.4285 - val_acc: 0.5097 - val_loss: 2.9554\n",
      "Epoch 26/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8241 - loss: 0.4485 - val_acc: 0.4372 - val_loss: 3.2488\n",
      "Epoch 27/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8292 - loss: 0.4266 - val_acc: 0.4816 - val_loss: 3.4005\n",
      "Epoch 28/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8374 - loss: 0.4207 - val_acc: 0.4989 - val_loss: 3.4156\n",
      "Epoch 29/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8377 - loss: 0.4049 - val_acc: 0.4275 - val_loss: 3.1055\n",
      "Epoch 30/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8374 - loss: 0.4087 - val_acc: 0.5292 - val_loss: 3.1043\n",
      "Epoch 31/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8454 - loss: 0.3944 - val_acc: 0.4361 - val_loss: 3.7978\n",
      "Epoch 32/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8470 - loss: 0.3906 - val_acc: 0.5076 - val_loss: 2.8571\n",
      "Epoch 33/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8480 - loss: 0.3965 - val_acc: 0.4838 - val_loss: 2.9546\n",
      "Epoch 34/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8466 - loss: 0.3885 - val_acc: 0.4632 - val_loss: 3.1922\n",
      "Epoch 35/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8492 - loss: 0.3836 - val_acc: 0.4848 - val_loss: 3.5041\n",
      "Epoch 36/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8571 - loss: 0.3606 - val_acc: 0.4870 - val_loss: 3.3772\n",
      "Epoch 37/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8560 - loss: 0.3671 - val_acc: 0.4502 - val_loss: 3.3757\n",
      "Epoch 38/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8581 - loss: 0.3498 - val_acc: 0.4351 - val_loss: 3.8938\n",
      "Epoch 39/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8671 - loss: 0.3422 - val_acc: 0.4827 - val_loss: 3.4948\n",
      "Epoch 40/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8659 - loss: 0.3461 - val_acc: 0.3929 - val_loss: 3.7112\n",
      "Epoch 41/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8686 - loss: 0.3372 - val_acc: 0.4232 - val_loss: 3.9741\n",
      "Epoch 42/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8684 - loss: 0.3296 - val_acc: 0.4903 - val_loss: 3.3831\n",
      "Epoch 43/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8727 - loss: 0.3300 - val_acc: 0.4481 - val_loss: 3.7565\n",
      "Epoch 44/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8723 - loss: 0.3292 - val_acc: 0.4838 - val_loss: 3.3008\n",
      "Epoch 45/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8802 - loss: 0.3127 - val_acc: 0.3983 - val_loss: 4.2930\n",
      "Epoch 46/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8768 - loss: 0.3212 - val_acc: 0.4058 - val_loss: 3.9186\n",
      "Epoch 47/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8836 - loss: 0.3021 - val_acc: 0.4654 - val_loss: 3.7848\n",
      "Epoch 48/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8813 - loss: 0.3103 - val_acc: 0.5227 - val_loss: 3.5699\n",
      "Epoch 49/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8916 - loss: 0.2856 - val_acc: 0.4199 - val_loss: 3.8606\n",
      "Epoch 50/80\n",
      "120/120 - 20s - 168ms/step - acc: 0.8862 - loss: 0.2963 - val_acc: 0.4329 - val_loss: 4.0595\n",
      "Epoch 51/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8905 - loss: 0.2804 - val_acc: 0.4978 - val_loss: 3.3720\n",
      "Epoch 52/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8954 - loss: 0.2799 - val_acc: 0.5032 - val_loss: 3.3734\n",
      "Epoch 53/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.8985 - loss: 0.2702 - val_acc: 0.4394 - val_loss: 3.8389\n",
      "Epoch 54/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9031 - loss: 0.2585 - val_acc: 0.4264 - val_loss: 4.2897\n",
      "Epoch 55/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9001 - loss: 0.2659 - val_acc: 0.3658 - val_loss: 4.5871\n",
      "Epoch 56/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8984 - loss: 0.2648 - val_acc: 0.4091 - val_loss: 4.2127\n",
      "Epoch 57/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.8989 - loss: 0.2654 - val_acc: 0.5400 - val_loss: 3.2971\n",
      "Epoch 58/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9007 - loss: 0.2566 - val_acc: 0.4502 - val_loss: 4.1542\n",
      "Epoch 59/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9037 - loss: 0.2537 - val_acc: 0.4773 - val_loss: 3.4356\n",
      "Epoch 60/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9040 - loss: 0.2567 - val_acc: 0.3918 - val_loss: 4.3184\n",
      "Epoch 61/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9068 - loss: 0.2490 - val_acc: 0.4015 - val_loss: 4.3719\n",
      "Epoch 62/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9063 - loss: 0.2505 - val_acc: 0.4848 - val_loss: 3.8430\n",
      "Epoch 63/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9088 - loss: 0.2423 - val_acc: 0.3874 - val_loss: 4.3091\n",
      "Epoch 64/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9129 - loss: 0.2333 - val_acc: 0.4481 - val_loss: 3.8641\n",
      "Epoch 65/80\n",
      "120/120 - 20s - 171ms/step - acc: 0.9140 - loss: 0.2392 - val_acc: 0.4437 - val_loss: 4.0991\n",
      "Epoch 66/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.9122 - loss: 0.2323 - val_acc: 0.4838 - val_loss: 3.8649\n",
      "Epoch 67/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9219 - loss: 0.2144 - val_acc: 0.4903 - val_loss: 3.7955\n",
      "Epoch 68/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9208 - loss: 0.2086 - val_acc: 0.3874 - val_loss: 4.9799\n",
      "Epoch 69/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9189 - loss: 0.2121 - val_acc: 0.4654 - val_loss: 4.4211\n",
      "Epoch 70/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.9215 - loss: 0.2137 - val_acc: 0.4610 - val_loss: 4.4477\n",
      "Epoch 71/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9190 - loss: 0.2245 - val_acc: 0.4773 - val_loss: 4.0372\n",
      "Epoch 72/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9213 - loss: 0.2096 - val_acc: 0.4232 - val_loss: 4.4150\n",
      "Epoch 73/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.9194 - loss: 0.2173 - val_acc: 0.5022 - val_loss: 3.4996\n",
      "Epoch 74/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.9247 - loss: 0.2048 - val_acc: 0.4665 - val_loss: 3.8541\n",
      "Epoch 75/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.9290 - loss: 0.1998 - val_acc: 0.4600 - val_loss: 3.9857\n",
      "Epoch 76/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9267 - loss: 0.1965 - val_acc: 0.4545 - val_loss: 4.1416\n",
      "Epoch 77/80\n",
      "120/120 - 20s - 170ms/step - acc: 0.9258 - loss: 0.2068 - val_acc: 0.4459 - val_loss: 4.0283\n",
      "Epoch 78/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9286 - loss: 0.1899 - val_acc: 0.5249 - val_loss: 3.3228\n",
      "Epoch 79/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9224 - loss: 0.2083 - val_acc: 0.5465 - val_loss: 3.5387\n",
      "Epoch 80/80\n",
      "120/120 - 20s - 169ms/step - acc: 0.9322 - loss: 0.1823 - val_acc: 0.4297 - val_loss: 4.1171\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Save feature of Fold #0 to ./output/Feature_0.npz\n",
      "WARNING:tensorflow:From c:\\Users\\Victus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Victus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 1\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 40s - 334ms/step - acc: 0.5197 - loss: 1.9053 - val_acc: 0.4555 - val_loss: 1.3253\n",
      "Epoch 2/80\n",
      "120/120 - 21s - 174ms/step - acc: 0.6392 - loss: 1.1450 - val_acc: 0.4424 - val_loss: 1.7835\n",
      "Epoch 3/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.6948 - loss: 0.9014 - val_acc: 0.3985 - val_loss: 2.2648\n",
      "Epoch 4/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.7244 - loss: 0.7862 - val_acc: 0.3974 - val_loss: 2.6657\n",
      "Epoch 5/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.7417 - loss: 0.7250 - val_acc: 0.3908 - val_loss: 2.9454\n",
      "Epoch 6/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.7481 - loss: 0.6771 - val_acc: 0.3831 - val_loss: 3.3913\n",
      "Epoch 7/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.7609 - loss: 0.6436 - val_acc: 0.4325 - val_loss: 2.4656\n",
      "Epoch 8/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.7693 - loss: 0.6208 - val_acc: 0.4347 - val_loss: 2.6745\n",
      "Epoch 9/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 173ms/step - acc: 0.7828 - loss: 0.5800 - val_acc: 0.4742 - val_loss: 2.6405\n",
      "Epoch 10/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.7886 - loss: 0.5631 - val_acc: 0.4292 - val_loss: 2.5286\n",
      "Epoch 11/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.7848 - loss: 0.5629 - val_acc: 0.4358 - val_loss: 2.9010\n",
      "Epoch 12/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 173ms/step - acc: 0.7887 - loss: 0.5519 - val_acc: 0.5477 - val_loss: 2.4723\n",
      "Epoch 13/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.7970 - loss: 0.5325 - val_acc: 0.4907 - val_loss: 2.7306\n",
      "Epoch 14/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8027 - loss: 0.5142 - val_acc: 0.4523 - val_loss: 2.6547\n",
      "Epoch 15/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8065 - loss: 0.5028 - val_acc: 0.4369 - val_loss: 2.8379\n",
      "Epoch 16/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8117 - loss: 0.4969 - val_acc: 0.4512 - val_loss: 2.7106\n",
      "Epoch 17/80\n",
      "120/120 - 21s - 174ms/step - acc: 0.8050 - loss: 0.4891 - val_acc: 0.4951 - val_loss: 2.5864\n",
      "Epoch 18/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8165 - loss: 0.4667 - val_acc: 0.4237 - val_loss: 3.1633\n",
      "Epoch 19/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.8246 - loss: 0.4571 - val_acc: 0.4424 - val_loss: 2.6479\n",
      "Epoch 20/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8239 - loss: 0.4619 - val_acc: 0.4127 - val_loss: 3.4302\n",
      "Epoch 21/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8277 - loss: 0.4482 - val_acc: 0.4347 - val_loss: 3.1210\n",
      "Epoch 22/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8295 - loss: 0.4451 - val_acc: 0.4215 - val_loss: 3.2370\n",
      "Epoch 23/80\n",
      "120/120 - 22s - 180ms/step - acc: 0.8242 - loss: 0.4542 - val_acc: 0.4479 - val_loss: 3.0965\n",
      "Epoch 24/80\n",
      "120/120 - 21s - 174ms/step - acc: 0.8312 - loss: 0.4291 - val_acc: 0.5203 - val_loss: 2.5634\n",
      "Epoch 25/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.8399 - loss: 0.4157 - val_acc: 0.4610 - val_loss: 3.1424\n",
      "Epoch 26/80\n",
      "120/120 - 21s - 174ms/step - acc: 0.8281 - loss: 0.4349 - val_acc: 0.3996 - val_loss: 3.8201\n",
      "Epoch 27/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8393 - loss: 0.4130 - val_acc: 0.4270 - val_loss: 3.4910\n",
      "Epoch 28/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8401 - loss: 0.4042 - val_acc: 0.4281 - val_loss: 3.5328\n",
      "Epoch 29/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8474 - loss: 0.3941 - val_acc: 0.4182 - val_loss: 3.7434\n",
      "Epoch 30/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8501 - loss: 0.3906 - val_acc: 0.4764 - val_loss: 3.1330\n",
      "Epoch 31/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8451 - loss: 0.3786 - val_acc: 0.4336 - val_loss: 3.3535\n",
      "Epoch 32/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.8509 - loss: 0.3780 - val_acc: 0.4907 - val_loss: 3.1041\n",
      "Epoch 33/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8544 - loss: 0.3731 - val_acc: 0.4018 - val_loss: 4.0656\n",
      "Epoch 34/80\n",
      "120/120 - 21s - 174ms/step - acc: 0.8614 - loss: 0.3623 - val_acc: 0.4138 - val_loss: 4.2189\n",
      "Epoch 35/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.8613 - loss: 0.3577 - val_acc: 0.4555 - val_loss: 3.3274\n",
      "Epoch 36/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8643 - loss: 0.3526 - val_acc: 0.4018 - val_loss: 4.4468\n",
      "Epoch 37/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8642 - loss: 0.3454 - val_acc: 0.4270 - val_loss: 3.8084\n",
      "Epoch 38/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 21s - 174ms/step - acc: 0.8661 - loss: 0.3343 - val_acc: 0.5510 - val_loss: 3.4284\n",
      "Epoch 39/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.8629 - loss: 0.3419 - val_acc: 0.4171 - val_loss: 3.8866\n",
      "Epoch 40/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.8748 - loss: 0.3138 - val_acc: 0.4490 - val_loss: 3.5621\n",
      "Epoch 41/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.8803 - loss: 0.3126 - val_acc: 0.4863 - val_loss: 3.5441\n",
      "Epoch 42/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.8774 - loss: 0.3149 - val_acc: 0.3974 - val_loss: 5.1028\n",
      "Epoch 43/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.8794 - loss: 0.3066 - val_acc: 0.4523 - val_loss: 3.8809\n",
      "Epoch 44/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.8786 - loss: 0.3062 - val_acc: 0.4226 - val_loss: 4.8147\n",
      "Epoch 45/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.8856 - loss: 0.2988 - val_acc: 0.4007 - val_loss: 4.8964\n",
      "Epoch 46/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.8897 - loss: 0.2897 - val_acc: 0.4182 - val_loss: 4.9226\n",
      "Epoch 47/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.8883 - loss: 0.2904 - val_acc: 0.3930 - val_loss: 5.0238\n",
      "Epoch 48/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.8896 - loss: 0.2832 - val_acc: 0.4226 - val_loss: 4.2248\n",
      "Epoch 49/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.8980 - loss: 0.2718 - val_acc: 0.4116 - val_loss: 4.7916\n",
      "Epoch 50/80\n",
      "120/120 - 20s - 171ms/step - acc: 0.8942 - loss: 0.2748 - val_acc: 0.3897 - val_loss: 4.3995\n",
      "Epoch 51/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.8967 - loss: 0.2703 - val_acc: 0.4083 - val_loss: 4.4594\n",
      "Epoch 52/80\n",
      "120/120 - 21s - 173ms/step - acc: 0.8984 - loss: 0.2707 - val_acc: 0.4303 - val_loss: 4.5328\n",
      "Epoch 53/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.9011 - loss: 0.2577 - val_acc: 0.4490 - val_loss: 4.1051\n",
      "Epoch 54/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.9038 - loss: 0.2446 - val_acc: 0.4369 - val_loss: 4.5226\n",
      "Epoch 55/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9052 - loss: 0.2481 - val_acc: 0.4962 - val_loss: 3.7122\n",
      "Epoch 56/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9044 - loss: 0.2488 - val_acc: 0.4391 - val_loss: 4.7231\n",
      "Epoch 57/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9032 - loss: 0.2550 - val_acc: 0.4764 - val_loss: 3.9813\n",
      "Epoch 58/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9121 - loss: 0.2391 - val_acc: 0.4676 - val_loss: 3.8847\n",
      "Epoch 59/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9094 - loss: 0.2336 - val_acc: 0.4248 - val_loss: 4.4992\n",
      "Epoch 60/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.9169 - loss: 0.2197 - val_acc: 0.4116 - val_loss: 5.0469\n",
      "Epoch 61/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9056 - loss: 0.2418 - val_acc: 0.4621 - val_loss: 4.3944\n",
      "Epoch 62/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9082 - loss: 0.2388 - val_acc: 0.4314 - val_loss: 4.4777\n",
      "Epoch 63/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9138 - loss: 0.2296 - val_acc: 0.4105 - val_loss: 4.9038\n",
      "Epoch 64/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.9209 - loss: 0.2131 - val_acc: 0.4544 - val_loss: 4.4284\n",
      "Epoch 65/80\n",
      "120/120 - 21s - 174ms/step - acc: 0.9174 - loss: 0.2165 - val_acc: 0.4435 - val_loss: 4.3324\n",
      "Epoch 66/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.9164 - loss: 0.2187 - val_acc: 0.4566 - val_loss: 4.2650\n",
      "Epoch 67/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9241 - loss: 0.2079 - val_acc: 0.4116 - val_loss: 4.9548\n",
      "Epoch 68/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.9219 - loss: 0.2069 - val_acc: 0.4577 - val_loss: 4.6170\n",
      "Epoch 69/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9229 - loss: 0.2061 - val_acc: 0.3985 - val_loss: 5.3585\n",
      "Epoch 70/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9269 - loss: 0.2040 - val_acc: 0.4973 - val_loss: 3.8899\n",
      "Epoch 71/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9282 - loss: 0.2002 - val_acc: 0.4281 - val_loss: 4.7978\n",
      "Epoch 72/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9268 - loss: 0.1998 - val_acc: 0.4029 - val_loss: 4.8087\n",
      "Epoch 73/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.9251 - loss: 0.1978 - val_acc: 0.4446 - val_loss: 4.1229\n",
      "Epoch 74/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.9341 - loss: 0.1801 - val_acc: 0.4490 - val_loss: 4.4663\n",
      "Epoch 75/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9333 - loss: 0.1818 - val_acc: 0.4007 - val_loss: 5.4405\n",
      "Epoch 76/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9361 - loss: 0.1821 - val_acc: 0.4369 - val_loss: 4.8405\n",
      "Epoch 77/80\n",
      "120/120 - 21s - 172ms/step - acc: 0.9329 - loss: 0.1877 - val_acc: 0.4512 - val_loss: 4.5018\n",
      "Epoch 78/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9333 - loss: 0.1862 - val_acc: 0.4204 - val_loss: 4.7968\n",
      "Epoch 79/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9293 - loss: 0.1930 - val_acc: 0.4577 - val_loss: 4.4988\n",
      "Epoch 80/80\n",
      "120/120 - 21s - 171ms/step - acc: 0.9364 - loss: 0.1782 - val_acc: 0.4314 - val_loss: 5.1233\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Save feature of Fold #1 to ./output/Feature_1.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 2\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 43s - 353ms/step - acc: 0.5042 - loss: 1.8402 - val_acc: 0.4458 - val_loss: 1.5783\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 23s - 186ms/step - acc: 0.6575 - loss: 1.0671 - val_acc: 0.5038 - val_loss: 1.8505\n",
      "Epoch 3/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.7098 - loss: 0.8496 - val_acc: 0.4912 - val_loss: 2.1307\n",
      "Epoch 4/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.7284 - loss: 0.7773 - val_acc: 0.5013 - val_loss: 2.4377\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 23s - 186ms/step - acc: 0.7430 - loss: 0.7001 - val_acc: 0.5076 - val_loss: 2.4159\n",
      "Epoch 6/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.7646 - loss: 0.6419 - val_acc: 0.5000 - val_loss: 2.0737\n",
      "Epoch 7/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.7566 - loss: 0.6548 - val_acc: 0.4597 - val_loss: 2.8950\n",
      "Epoch 8/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.7754 - loss: 0.5950 - val_acc: 0.4987 - val_loss: 2.4393\n",
      "Epoch 9/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.7745 - loss: 0.5857 - val_acc: 0.5038 - val_loss: 2.2519\n",
      "Epoch 10/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 23s - 189ms/step - acc: 0.7746 - loss: 0.5667 - val_acc: 0.5176 - val_loss: 2.6058\n",
      "Epoch 11/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 23s - 186ms/step - acc: 0.7820 - loss: 0.5738 - val_acc: 0.5252 - val_loss: 2.2430\n",
      "Epoch 12/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 23s - 187ms/step - acc: 0.7917 - loss: 0.5364 - val_acc: 0.5340 - val_loss: 2.5885\n",
      "Epoch 13/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.7946 - loss: 0.5287 - val_acc: 0.5315 - val_loss: 2.5884\n",
      "Epoch 14/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.7994 - loss: 0.5171 - val_acc: 0.5000 - val_loss: 2.7547\n",
      "Epoch 15/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 23s - 185ms/step - acc: 0.8041 - loss: 0.5000 - val_acc: 0.5479 - val_loss: 2.5383\n",
      "Epoch 16/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 23s - 186ms/step - acc: 0.8062 - loss: 0.4919 - val_acc: 0.5579 - val_loss: 2.5421\n",
      "Epoch 17/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.8069 - loss: 0.4787 - val_acc: 0.5353 - val_loss: 2.8611\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 23s - 185ms/step - acc: 0.8158 - loss: 0.4721 - val_acc: 0.5705 - val_loss: 2.4008\n",
      "Epoch 19/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8162 - loss: 0.4612 - val_acc: 0.5680 - val_loss: 2.4153\n",
      "Epoch 20/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.8204 - loss: 0.4582 - val_acc: 0.5428 - val_loss: 2.7295\n",
      "Epoch 21/80\n",
      "122/122 - 23s - 190ms/step - acc: 0.8263 - loss: 0.4495 - val_acc: 0.5504 - val_loss: 2.4913\n",
      "Epoch 22/80\n",
      "122/122 - 24s - 200ms/step - acc: 0.8287 - loss: 0.4369 - val_acc: 0.5693 - val_loss: 2.4508\n",
      "Epoch 23/80\n",
      "122/122 - 24s - 199ms/step - acc: 0.8204 - loss: 0.4472 - val_acc: 0.5491 - val_loss: 2.5525\n",
      "Epoch 24/80\n",
      "122/122 - 23s - 190ms/step - acc: 0.8272 - loss: 0.4421 - val_acc: 0.5403 - val_loss: 2.5622\n",
      "Epoch 25/80\n",
      "122/122 - 23s - 188ms/step - acc: 0.8310 - loss: 0.4257 - val_acc: 0.5239 - val_loss: 2.8152\n",
      "Epoch 26/80\n",
      "122/122 - 23s - 184ms/step - acc: 0.8301 - loss: 0.4366 - val_acc: 0.5441 - val_loss: 2.6338\n",
      "Epoch 27/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 23s - 186ms/step - acc: 0.8345 - loss: 0.4205 - val_acc: 0.5844 - val_loss: 2.1663\n",
      "Epoch 28/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8350 - loss: 0.4174 - val_acc: 0.5781 - val_loss: 2.4328\n",
      "Epoch 29/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.8434 - loss: 0.4096 - val_acc: 0.5592 - val_loss: 2.4962\n",
      "Epoch 30/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.8417 - loss: 0.4101 - val_acc: 0.5567 - val_loss: 2.4023\n",
      "Epoch 31/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8500 - loss: 0.3924 - val_acc: 0.5416 - val_loss: 2.7324\n",
      "Epoch 32/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.8479 - loss: 0.3925 - val_acc: 0.5793 - val_loss: 2.2468\n",
      "Epoch 33/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.8481 - loss: 0.3723 - val_acc: 0.5529 - val_loss: 2.6051\n",
      "Epoch 34/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 23s - 186ms/step - acc: 0.8564 - loss: 0.3698 - val_acc: 0.5982 - val_loss: 2.1570\n",
      "Epoch 35/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.8585 - loss: 0.3631 - val_acc: 0.5579 - val_loss: 2.4930\n",
      "Epoch 36/80\n",
      "122/122 - 23s - 188ms/step - acc: 0.8547 - loss: 0.3597 - val_acc: 0.5831 - val_loss: 2.5747\n",
      "Epoch 37/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.8618 - loss: 0.3523 - val_acc: 0.5189 - val_loss: 2.9905\n",
      "Epoch 38/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8640 - loss: 0.3542 - val_acc: 0.5693 - val_loss: 2.4961\n",
      "Epoch 39/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8659 - loss: 0.3508 - val_acc: 0.5567 - val_loss: 2.5029\n",
      "Epoch 40/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8725 - loss: 0.3304 - val_acc: 0.5831 - val_loss: 2.4919\n",
      "Epoch 41/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8721 - loss: 0.3303 - val_acc: 0.5907 - val_loss: 2.3098\n",
      "Epoch 42/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.8658 - loss: 0.3353 - val_acc: 0.5516 - val_loss: 2.7185\n",
      "Epoch 43/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.8797 - loss: 0.3205 - val_acc: 0.5718 - val_loss: 2.6197\n",
      "Epoch 44/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8771 - loss: 0.3185 - val_acc: 0.5781 - val_loss: 2.4575\n",
      "Epoch 45/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8825 - loss: 0.3119 - val_acc: 0.5655 - val_loss: 2.7669\n",
      "Epoch 46/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8753 - loss: 0.3226 - val_acc: 0.5718 - val_loss: 2.8384\n",
      "Epoch 47/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8818 - loss: 0.3051 - val_acc: 0.5264 - val_loss: 3.3510\n",
      "Epoch 48/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.8858 - loss: 0.2919 - val_acc: 0.5793 - val_loss: 2.7379\n",
      "Epoch 49/80\n",
      "122/122 - 23s - 188ms/step - acc: 0.8783 - loss: 0.3111 - val_acc: 0.5050 - val_loss: 3.4164\n",
      "Epoch 50/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.8883 - loss: 0.2903 - val_acc: 0.5605 - val_loss: 2.8465\n",
      "Epoch 51/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8897 - loss: 0.2879 - val_acc: 0.5277 - val_loss: 3.2279\n",
      "Epoch 52/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.8922 - loss: 0.2801 - val_acc: 0.5479 - val_loss: 3.1591\n",
      "Epoch 53/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.8943 - loss: 0.2745 - val_acc: 0.4849 - val_loss: 3.5951\n",
      "Epoch 54/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.8935 - loss: 0.2827 - val_acc: 0.5403 - val_loss: 3.3221\n",
      "Epoch 55/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8979 - loss: 0.2760 - val_acc: 0.5302 - val_loss: 3.4258\n",
      "Epoch 56/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.9011 - loss: 0.2554 - val_acc: 0.5277 - val_loss: 3.7260\n",
      "Epoch 57/80\n",
      "122/122 - 23s - 187ms/step - acc: 0.8984 - loss: 0.2680 - val_acc: 0.5290 - val_loss: 3.5968\n",
      "Epoch 58/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.8990 - loss: 0.2710 - val_acc: 0.5479 - val_loss: 2.9968\n",
      "Epoch 59/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9078 - loss: 0.2474 - val_acc: 0.5479 - val_loss: 3.1277\n",
      "Epoch 60/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.9037 - loss: 0.2609 - val_acc: 0.5542 - val_loss: 2.9756\n",
      "Epoch 61/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.9053 - loss: 0.2515 - val_acc: 0.5453 - val_loss: 3.0797\n",
      "Epoch 62/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.9146 - loss: 0.2315 - val_acc: 0.5302 - val_loss: 3.5262\n",
      "Epoch 63/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9039 - loss: 0.2479 - val_acc: 0.5655 - val_loss: 2.9200\n",
      "Epoch 64/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.9098 - loss: 0.2432 - val_acc: 0.5277 - val_loss: 3.3342\n",
      "Epoch 65/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.9134 - loss: 0.2294 - val_acc: 0.5403 - val_loss: 3.1647\n",
      "Epoch 66/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.9120 - loss: 0.2350 - val_acc: 0.5567 - val_loss: 3.7611\n",
      "Epoch 67/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.9157 - loss: 0.2160 - val_acc: 0.5441 - val_loss: 3.5930\n",
      "Epoch 68/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9108 - loss: 0.2426 - val_acc: 0.5592 - val_loss: 3.2838\n",
      "Epoch 69/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9174 - loss: 0.2243 - val_acc: 0.5756 - val_loss: 2.9292\n",
      "Epoch 70/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.9206 - loss: 0.2228 - val_acc: 0.5718 - val_loss: 2.9768\n",
      "Epoch 71/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.9151 - loss: 0.2196 - val_acc: 0.5730 - val_loss: 3.1062\n",
      "Epoch 72/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.9220 - loss: 0.2134 - val_acc: 0.5113 - val_loss: 3.7830\n",
      "Epoch 73/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9167 - loss: 0.2219 - val_acc: 0.5113 - val_loss: 3.7364\n",
      "Epoch 74/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.9221 - loss: 0.2089 - val_acc: 0.5705 - val_loss: 2.8745\n",
      "Epoch 75/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9248 - loss: 0.2052 - val_acc: 0.5479 - val_loss: 3.0090\n",
      "Epoch 76/80\n",
      "122/122 - 22s - 184ms/step - acc: 0.9173 - loss: 0.2242 - val_acc: 0.5730 - val_loss: 3.1310\n",
      "Epoch 77/80\n",
      "122/122 - 23s - 188ms/step - acc: 0.9241 - loss: 0.2057 - val_acc: 0.5743 - val_loss: 3.2125\n",
      "Epoch 78/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.9296 - loss: 0.1999 - val_acc: 0.5605 - val_loss: 3.1135\n",
      "Epoch 79/80\n",
      "122/122 - 23s - 186ms/step - acc: 0.9339 - loss: 0.1886 - val_acc: 0.5290 - val_loss: 3.6098\n",
      "Epoch 80/80\n",
      "122/122 - 23s - 185ms/step - acc: 0.9243 - loss: 0.2085 - val_acc: 0.5441 - val_loss: 3.7417\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "Save feature of Fold #2 to ./output/Feature_2.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 3\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 44s - 361ms/step - acc: 0.5187 - loss: 1.8516 - val_acc: 0.2657 - val_loss: 2.0902\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 196ms/step - acc: 0.6422 - loss: 1.1632 - val_acc: 0.3770 - val_loss: 1.7765\n",
      "Epoch 3/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.7013 - loss: 0.8798 - val_acc: 0.2487 - val_loss: 2.3050\n",
      "Epoch 4/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.7270 - loss: 0.7899 - val_acc: 0.2369 - val_loss: 2.7839\n",
      "Epoch 5/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.7445 - loss: 0.7016 - val_acc: 0.2552 - val_loss: 3.0683\n",
      "Epoch 6/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.7615 - loss: 0.6509 - val_acc: 0.1702 - val_loss: 3.7134\n",
      "Epoch 7/80\n",
      "123/123 - 24s - 196ms/step - acc: 0.7693 - loss: 0.6354 - val_acc: 0.2343 - val_loss: 3.5102\n",
      "Epoch 8/80\n",
      "123/123 - 25s - 203ms/step - acc: 0.7721 - loss: 0.6254 - val_acc: 0.2736 - val_loss: 3.1705\n",
      "Epoch 9/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.7816 - loss: 0.5772 - val_acc: 0.2094 - val_loss: 3.2424\n",
      "Epoch 10/80\n",
      "123/123 - 24s - 196ms/step - acc: 0.7854 - loss: 0.5716 - val_acc: 0.2147 - val_loss: 2.9668\n",
      "Epoch 11/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.7881 - loss: 0.5519 - val_acc: 0.2644 - val_loss: 2.3136\n",
      "Epoch 12/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.7937 - loss: 0.5438 - val_acc: 0.1885 - val_loss: 3.4851\n",
      "Epoch 13/80\n",
      "123/123 - 24s - 196ms/step - acc: 0.7995 - loss: 0.5194 - val_acc: 0.1780 - val_loss: 3.5413\n",
      "Epoch 14/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8028 - loss: 0.4998 - val_acc: 0.2814 - val_loss: 2.4365\n",
      "Epoch 15/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.8095 - loss: 0.5026 - val_acc: 0.3298 - val_loss: 2.2574\n",
      "Epoch 16/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8081 - loss: 0.4853 - val_acc: 0.3298 - val_loss: 2.0631\n",
      "Epoch 17/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8096 - loss: 0.4806 - val_acc: 0.2552 - val_loss: 2.7486\n",
      "Epoch 18/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8120 - loss: 0.4834 - val_acc: 0.2631 - val_loss: 2.8478\n",
      "Epoch 19/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.8215 - loss: 0.4624 - val_acc: 0.3429 - val_loss: 2.1841\n",
      "Epoch 20/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8212 - loss: 0.4678 - val_acc: 0.3089 - val_loss: 2.0973\n",
      "Epoch 21/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8244 - loss: 0.4406 - val_acc: 0.2880 - val_loss: 2.3588\n",
      "Epoch 22/80\n",
      "123/123 - 24s - 198ms/step - acc: 0.8284 - loss: 0.4391 - val_acc: 0.2827 - val_loss: 2.7808\n",
      "Epoch 23/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 198ms/step - acc: 0.8341 - loss: 0.4337 - val_acc: 0.4123 - val_loss: 2.0708\n",
      "Epoch 24/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8318 - loss: 0.4248 - val_acc: 0.3927 - val_loss: 1.9023\n",
      "Epoch 25/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.8296 - loss: 0.4216 - val_acc: 0.3521 - val_loss: 2.2678\n",
      "Epoch 26/80\n",
      "123/123 - 24s - 192ms/step - acc: 0.8417 - loss: 0.4111 - val_acc: 0.3547 - val_loss: 2.1923\n",
      "Epoch 27/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.8353 - loss: 0.4189 - val_acc: 0.3665 - val_loss: 2.2132\n",
      "Epoch 28/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 197ms/step - acc: 0.8367 - loss: 0.4144 - val_acc: 0.5301 - val_loss: 1.8182\n",
      "Epoch 29/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8502 - loss: 0.3881 - val_acc: 0.4241 - val_loss: 2.0553\n",
      "Epoch 30/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8537 - loss: 0.3760 - val_acc: 0.3953 - val_loss: 2.1188\n",
      "Epoch 31/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.8534 - loss: 0.3676 - val_acc: 0.3953 - val_loss: 2.1567\n",
      "Epoch 32/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.8528 - loss: 0.3655 - val_acc: 0.4725 - val_loss: 2.0612\n",
      "Epoch 33/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8529 - loss: 0.3792 - val_acc: 0.4293 - val_loss: 2.1145\n",
      "Epoch 34/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.8593 - loss: 0.3609 - val_acc: 0.5183 - val_loss: 2.1801\n",
      "Epoch 35/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.8579 - loss: 0.3692 - val_acc: 0.4516 - val_loss: 2.1852\n",
      "Epoch 36/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.8585 - loss: 0.3622 - val_acc: 0.4490 - val_loss: 2.0465\n",
      "Epoch 37/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.8611 - loss: 0.3496 - val_acc: 0.4162 - val_loss: 2.2209\n",
      "Epoch 38/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.8619 - loss: 0.3557 - val_acc: 0.3927 - val_loss: 2.2585\n",
      "Epoch 39/80\n",
      "123/123 - 24s - 197ms/step - acc: 0.8626 - loss: 0.3451 - val_acc: 0.4751 - val_loss: 1.7506\n",
      "Epoch 40/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8731 - loss: 0.3353 - val_acc: 0.5013 - val_loss: 2.0502\n",
      "Epoch 41/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8702 - loss: 0.3365 - val_acc: 0.5236 - val_loss: 1.9375\n",
      "Epoch 42/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8709 - loss: 0.3228 - val_acc: 0.5026 - val_loss: 1.8576\n",
      "Epoch 43/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8846 - loss: 0.3051 - val_acc: 0.4948 - val_loss: 1.8000\n",
      "Epoch 44/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 25s - 200ms/step - acc: 0.8805 - loss: 0.3143 - val_acc: 0.5484 - val_loss: 1.7550\n",
      "Epoch 45/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.8783 - loss: 0.3112 - val_acc: 0.5314 - val_loss: 1.8581\n",
      "Epoch 46/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 193ms/step - acc: 0.8872 - loss: 0.2971 - val_acc: 0.5681 - val_loss: 1.5817\n",
      "Epoch 47/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8879 - loss: 0.2979 - val_acc: 0.5144 - val_loss: 1.8254\n",
      "Epoch 48/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8860 - loss: 0.2980 - val_acc: 0.4869 - val_loss: 1.8617\n",
      "Epoch 49/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8896 - loss: 0.2977 - val_acc: 0.4699 - val_loss: 2.2825\n",
      "Epoch 50/80\n",
      "123/123 - 24s - 196ms/step - acc: 0.8932 - loss: 0.2883 - val_acc: 0.5497 - val_loss: 1.7298\n",
      "Epoch 51/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 24s - 194ms/step - acc: 0.8861 - loss: 0.2919 - val_acc: 0.5916 - val_loss: 1.7830\n",
      "Epoch 52/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8939 - loss: 0.2726 - val_acc: 0.5851 - val_loss: 1.6639\n",
      "Epoch 53/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8950 - loss: 0.2820 - val_acc: 0.5209 - val_loss: 1.9909\n",
      "Epoch 54/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8973 - loss: 0.2774 - val_acc: 0.5065 - val_loss: 1.9744\n",
      "Epoch 55/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.8992 - loss: 0.2564 - val_acc: 0.5628 - val_loss: 1.7278\n",
      "Epoch 56/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.9042 - loss: 0.2497 - val_acc: 0.5484 - val_loss: 1.7553\n",
      "Epoch 57/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.9029 - loss: 0.2549 - val_acc: 0.5013 - val_loss: 1.7982\n",
      "Epoch 58/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.9040 - loss: 0.2568 - val_acc: 0.5196 - val_loss: 1.9311\n",
      "Epoch 59/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.9096 - loss: 0.2483 - val_acc: 0.5314 - val_loss: 1.7643\n",
      "Epoch 60/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.9036 - loss: 0.2513 - val_acc: 0.4634 - val_loss: 2.2154\n",
      "Epoch 61/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.9057 - loss: 0.2409 - val_acc: 0.5236 - val_loss: 1.8594\n",
      "Epoch 62/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.9089 - loss: 0.2412 - val_acc: 0.5144 - val_loss: 1.7962\n",
      "Epoch 63/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.9111 - loss: 0.2305 - val_acc: 0.4961 - val_loss: 1.9038\n",
      "Epoch 64/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.9119 - loss: 0.2285 - val_acc: 0.4843 - val_loss: 2.1724\n",
      "Epoch 65/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.9139 - loss: 0.2313 - val_acc: 0.4974 - val_loss: 2.1722\n",
      "Epoch 66/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.9183 - loss: 0.2248 - val_acc: 0.4817 - val_loss: 2.4934\n",
      "Epoch 67/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.9169 - loss: 0.2267 - val_acc: 0.4725 - val_loss: 2.2958\n",
      "Epoch 68/80\n",
      "123/123 - 24s - 192ms/step - acc: 0.9140 - loss: 0.2295 - val_acc: 0.5170 - val_loss: 1.7604\n",
      "Epoch 69/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.9165 - loss: 0.2223 - val_acc: 0.4777 - val_loss: 2.1624\n",
      "Epoch 70/80\n",
      "123/123 - 24s - 197ms/step - acc: 0.9165 - loss: 0.2222 - val_acc: 0.4411 - val_loss: 2.6163\n",
      "Epoch 71/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.9165 - loss: 0.2234 - val_acc: 0.4660 - val_loss: 1.8495\n",
      "Epoch 72/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.9277 - loss: 0.2036 - val_acc: 0.5079 - val_loss: 1.9631\n",
      "Epoch 73/80\n",
      "123/123 - 24s - 196ms/step - acc: 0.9256 - loss: 0.2046 - val_acc: 0.4686 - val_loss: 2.1918\n",
      "Epoch 74/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.9291 - loss: 0.1971 - val_acc: 0.5105 - val_loss: 1.9496\n",
      "Epoch 75/80\n",
      "123/123 - 24s - 195ms/step - acc: 0.9277 - loss: 0.1985 - val_acc: 0.4974 - val_loss: 2.2506\n",
      "Epoch 76/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.9295 - loss: 0.1942 - val_acc: 0.4804 - val_loss: 2.2137\n",
      "Epoch 77/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.9278 - loss: 0.1934 - val_acc: 0.5131 - val_loss: 1.9155\n",
      "Epoch 78/80\n",
      "123/123 - 24s - 193ms/step - acc: 0.9316 - loss: 0.1904 - val_acc: 0.5576 - val_loss: 1.9822\n",
      "Epoch 79/80\n",
      "123/123 - 24s - 194ms/step - acc: 0.9297 - loss: 0.1977 - val_acc: 0.5236 - val_loss: 2.1971\n",
      "Epoch 80/80\n",
      "123/123 - 24s - 196ms/step - acc: 0.9307 - loss: 0.1848 - val_acc: 0.5759 - val_loss: 1.6961\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "Save feature of Fold #3 to ./output/Feature_3.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 4\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 45s - 373ms/step - acc: 0.5164 - loss: 1.8562 - val_acc: 0.1499 - val_loss: 2.5862\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 208ms/step - acc: 0.6326 - loss: 1.1781 - val_acc: 0.2495 - val_loss: 1.9888\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 209ms/step - acc: 0.6874 - loss: 0.9164 - val_acc: 0.2757 - val_loss: 2.3586\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 209ms/step - acc: 0.7183 - loss: 0.7744 - val_acc: 0.3118 - val_loss: 2.7441\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 209ms/step - acc: 0.7408 - loss: 0.7035 - val_acc: 0.3621 - val_loss: 2.6252\n",
      "Epoch 6/80\n",
      "120/120 - 25s - 210ms/step - acc: 0.7547 - loss: 0.6693 - val_acc: 0.3042 - val_loss: 3.4869\n",
      "Epoch 7/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.7627 - loss: 0.6227 - val_acc: 0.3501 - val_loss: 3.0577\n",
      "Epoch 8/80\n",
      "120/120 - 25s - 205ms/step - acc: 0.7689 - loss: 0.6031 - val_acc: 0.3228 - val_loss: 3.5034\n",
      "Epoch 9/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 207ms/step - acc: 0.7850 - loss: 0.5813 - val_acc: 0.3862 - val_loss: 3.3669\n",
      "Epoch 10/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.7878 - loss: 0.5639 - val_acc: 0.3282 - val_loss: 4.0646\n",
      "Epoch 11/80\n",
      "120/120 - 25s - 208ms/step - acc: 0.7861 - loss: 0.5626 - val_acc: 0.3501 - val_loss: 3.1728\n",
      "Epoch 12/80\n",
      "120/120 - 25s - 208ms/step - acc: 0.7821 - loss: 0.5610 - val_acc: 0.3381 - val_loss: 3.6465\n",
      "Epoch 13/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.7874 - loss: 0.5449 - val_acc: 0.3665 - val_loss: 3.4498\n",
      "Epoch 14/80\n",
      "120/120 - 25s - 210ms/step - acc: 0.7940 - loss: 0.5202 - val_acc: 0.3501 - val_loss: 3.6767\n",
      "Epoch 15/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 208ms/step - acc: 0.7982 - loss: 0.5127 - val_acc: 0.3906 - val_loss: 3.7367\n",
      "Epoch 16/80\n",
      "120/120 - 25s - 209ms/step - acc: 0.8051 - loss: 0.4983 - val_acc: 0.3676 - val_loss: 3.7998\n",
      "Epoch 17/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.8038 - loss: 0.4972 - val_acc: 0.3359 - val_loss: 4.1210\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 207ms/step - acc: 0.8056 - loss: 0.5023 - val_acc: 0.4070 - val_loss: 3.7972\n",
      "Epoch 19/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 208ms/step - acc: 0.8137 - loss: 0.4733 - val_acc: 0.4278 - val_loss: 3.4687\n",
      "Epoch 20/80\n",
      "120/120 - 25s - 208ms/step - acc: 0.8099 - loss: 0.4869 - val_acc: 0.4048 - val_loss: 4.1338\n",
      "Epoch 21/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.8190 - loss: 0.4751 - val_acc: 0.4114 - val_loss: 3.5587\n",
      "Epoch 22/80\n",
      "120/120 - 25s - 208ms/step - acc: 0.8137 - loss: 0.4764 - val_acc: 0.3818 - val_loss: 3.8141\n",
      "Epoch 23/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 207ms/step - acc: 0.8182 - loss: 0.4659 - val_acc: 0.4508 - val_loss: 3.3164\n",
      "Epoch 24/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8323 - loss: 0.4456 - val_acc: 0.4497 - val_loss: 3.8923\n",
      "Epoch 25/80\n",
      "120/120 - 25s - 208ms/step - acc: 0.8258 - loss: 0.4499 - val_acc: 0.4453 - val_loss: 3.4812\n",
      "Epoch 26/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8360 - loss: 0.4203 - val_acc: 0.4234 - val_loss: 3.6856\n",
      "Epoch 27/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8271 - loss: 0.4434 - val_acc: 0.4420 - val_loss: 3.1474\n",
      "Epoch 28/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8327 - loss: 0.4323 - val_acc: 0.4453 - val_loss: 3.7228\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 207ms/step - acc: 0.8358 - loss: 0.4225 - val_acc: 0.4562 - val_loss: 3.3623\n",
      "Epoch 30/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.8421 - loss: 0.4042 - val_acc: 0.4168 - val_loss: 4.2258\n",
      "Epoch 31/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8366 - loss: 0.4072 - val_acc: 0.4190 - val_loss: 3.8350\n",
      "Epoch 32/80\n",
      "120/120 - 25s - 205ms/step - acc: 0.8396 - loss: 0.4024 - val_acc: 0.4190 - val_loss: 3.6688\n",
      "Epoch 33/80\n",
      "120/120 - 25s - 205ms/step - acc: 0.8447 - loss: 0.3958 - val_acc: 0.4256 - val_loss: 4.0093\n",
      "Epoch 34/80\n",
      "120/120 - 25s - 204ms/step - acc: 0.8493 - loss: 0.3879 - val_acc: 0.4530 - val_loss: 3.6953\n",
      "Epoch 35/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 206ms/step - acc: 0.8511 - loss: 0.3845 - val_acc: 0.4584 - val_loss: 3.6566\n",
      "Epoch 36/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.8601 - loss: 0.3678 - val_acc: 0.4365 - val_loss: 3.6351\n",
      "Epoch 37/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.8538 - loss: 0.3725 - val_acc: 0.4387 - val_loss: 3.6384\n",
      "Epoch 38/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8558 - loss: 0.3734 - val_acc: 0.4267 - val_loss: 3.5605\n",
      "Epoch 39/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8559 - loss: 0.3739 - val_acc: 0.4442 - val_loss: 3.3092\n",
      "Epoch 40/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8667 - loss: 0.3529 - val_acc: 0.4354 - val_loss: 3.9524\n",
      "Epoch 41/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8633 - loss: 0.3425 - val_acc: 0.4070 - val_loss: 3.6624\n",
      "Epoch 42/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8711 - loss: 0.3388 - val_acc: 0.4278 - val_loss: 3.7933\n",
      "Epoch 43/80\n",
      "120/120 - 25s - 205ms/step - acc: 0.8701 - loss: 0.3390 - val_acc: 0.4322 - val_loss: 4.0504\n",
      "Epoch 44/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8668 - loss: 0.3444 - val_acc: 0.4059 - val_loss: 4.3548\n",
      "Epoch 45/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8747 - loss: 0.3174 - val_acc: 0.4190 - val_loss: 4.3942\n",
      "Epoch 46/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8769 - loss: 0.3200 - val_acc: 0.4070 - val_loss: 3.7486\n",
      "Epoch 47/80\n",
      "120/120 - 25s - 208ms/step - acc: 0.8817 - loss: 0.3119 - val_acc: 0.4081 - val_loss: 4.6345\n",
      "Epoch 48/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.8787 - loss: 0.3089 - val_acc: 0.3939 - val_loss: 4.6099\n",
      "Epoch 49/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.8803 - loss: 0.3084 - val_acc: 0.3578 - val_loss: 4.8829\n",
      "Epoch 50/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.8861 - loss: 0.2923 - val_acc: 0.4212 - val_loss: 4.3463\n",
      "Epoch 51/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.8860 - loss: 0.2989 - val_acc: 0.3676 - val_loss: 4.9047\n",
      "Epoch 52/80\n",
      "120/120 - 25s - 208ms/step - acc: 0.8855 - loss: 0.2990 - val_acc: 0.4190 - val_loss: 4.2681\n",
      "Epoch 53/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.8952 - loss: 0.2800 - val_acc: 0.4354 - val_loss: 4.2333\n",
      "Epoch 54/80\n",
      "120/120 - 25s - 208ms/step - acc: 0.8933 - loss: 0.2820 - val_acc: 0.3786 - val_loss: 4.7124\n",
      "Epoch 55/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8924 - loss: 0.2781 - val_acc: 0.4333 - val_loss: 4.5783\n",
      "Epoch 56/80\n",
      "120/120 - 25s - 208ms/step - acc: 0.8962 - loss: 0.2738 - val_acc: 0.4037 - val_loss: 4.3578\n",
      "Epoch 57/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.8976 - loss: 0.2715 - val_acc: 0.3829 - val_loss: 4.8533\n",
      "Epoch 58/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.9020 - loss: 0.2695 - val_acc: 0.3632 - val_loss: 5.1606\n",
      "Epoch 59/80\n",
      "120/120 - 25s - 205ms/step - acc: 0.9091 - loss: 0.2380 - val_acc: 0.3928 - val_loss: 4.8381\n",
      "Epoch 60/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.9042 - loss: 0.2518 - val_acc: 0.3961 - val_loss: 4.7168\n",
      "Epoch 61/80\n",
      "120/120 - 25s - 208ms/step - acc: 0.9080 - loss: 0.2474 - val_acc: 0.4125 - val_loss: 4.4081\n",
      "Epoch 62/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.9076 - loss: 0.2484 - val_acc: 0.3961 - val_loss: 4.9253\n",
      "Epoch 63/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.9111 - loss: 0.2371 - val_acc: 0.4245 - val_loss: 4.9644\n",
      "Epoch 64/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.9166 - loss: 0.2245 - val_acc: 0.3611 - val_loss: 5.3716\n",
      "Epoch 65/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.9100 - loss: 0.2363 - val_acc: 0.3917 - val_loss: 5.2272\n",
      "Epoch 66/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.9096 - loss: 0.2361 - val_acc: 0.3895 - val_loss: 4.8564\n",
      "Epoch 67/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.9165 - loss: 0.2303 - val_acc: 0.3851 - val_loss: 4.8355\n",
      "Epoch 68/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.9193 - loss: 0.2257 - val_acc: 0.4398 - val_loss: 4.2751\n",
      "Epoch 69/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.9213 - loss: 0.2153 - val_acc: 0.4026 - val_loss: 4.8415\n",
      "Epoch 70/80\n",
      "120/120 - 25s - 204ms/step - acc: 0.9175 - loss: 0.2271 - val_acc: 0.4278 - val_loss: 4.8953\n",
      "Epoch 71/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.9191 - loss: 0.2223 - val_acc: 0.3982 - val_loss: 4.5357\n",
      "Epoch 72/80\n",
      "120/120 - 25s - 205ms/step - acc: 0.9205 - loss: 0.2086 - val_acc: 0.4037 - val_loss: 4.8100\n",
      "Epoch 73/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.9252 - loss: 0.2074 - val_acc: 0.4004 - val_loss: 4.7925\n",
      "Epoch 74/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.9266 - loss: 0.2035 - val_acc: 0.4223 - val_loss: 4.6588\n",
      "Epoch 75/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.9243 - loss: 0.2043 - val_acc: 0.4037 - val_loss: 4.6943\n",
      "Epoch 76/80\n",
      "120/120 - 25s - 205ms/step - acc: 0.9253 - loss: 0.2014 - val_acc: 0.4168 - val_loss: 4.6522\n",
      "Epoch 77/80\n",
      "120/120 - 25s - 207ms/step - acc: 0.9255 - loss: 0.1998 - val_acc: 0.4322 - val_loss: 4.5040\n",
      "Epoch 78/80\n",
      "120/120 - 25s - 205ms/step - acc: 0.9295 - loss: 0.1928 - val_acc: 0.4114 - val_loss: 4.8633\n",
      "Epoch 79/80\n",
      "120/120 - 25s - 206ms/step - acc: 0.9300 - loss: 0.2014 - val_acc: 0.3414 - val_loss: 5.4252\n",
      "Epoch 80/80\n",
      "120/120 - 25s - 205ms/step - acc: 0.9256 - loss: 0.2020 - val_acc: 0.3720 - val_loss: 4.9262\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "Save feature of Fold #4 to ./output/Feature_4.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 5\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 46s - 377ms/step - acc: 0.5299 - loss: 1.7496 - val_acc: 0.5140 - val_loss: 1.1807\n",
      "Epoch 2/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.6427 - loss: 1.1032 - val_acc: 0.4216 - val_loss: 1.5983\n",
      "Epoch 3/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.6942 - loss: 0.8695 - val_acc: 0.3876 - val_loss: 2.4979\n",
      "Epoch 4/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.7273 - loss: 0.7642 - val_acc: 0.3876 - val_loss: 2.9884\n",
      "Epoch 5/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.7559 - loss: 0.6787 - val_acc: 0.3998 - val_loss: 3.1195\n",
      "Epoch 6/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.7604 - loss: 0.6508 - val_acc: 0.3913 - val_loss: 3.0947\n",
      "Epoch 7/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.7712 - loss: 0.6157 - val_acc: 0.4034 - val_loss: 3.1248\n",
      "Epoch 8/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.7798 - loss: 0.6042 - val_acc: 0.3876 - val_loss: 3.2454\n",
      "Epoch 9/80\n",
      "122/122 - 25s - 205ms/step - acc: 0.7785 - loss: 0.5766 - val_acc: 0.4010 - val_loss: 2.8748\n",
      "Epoch 10/80\n",
      "122/122 - 25s - 205ms/step - acc: 0.7856 - loss: 0.5510 - val_acc: 0.3985 - val_loss: 3.1257\n",
      "Epoch 11/80\n",
      "122/122 - 25s - 205ms/step - acc: 0.7956 - loss: 0.5361 - val_acc: 0.3973 - val_loss: 3.1587\n",
      "Epoch 12/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.8022 - loss: 0.5262 - val_acc: 0.4168 - val_loss: 2.7955\n",
      "Epoch 13/80\n",
      "122/122 - 25s - 205ms/step - acc: 0.8057 - loss: 0.5042 - val_acc: 0.4557 - val_loss: 2.2903\n",
      "Epoch 14/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8014 - loss: 0.5045 - val_acc: 0.4447 - val_loss: 2.4077\n",
      "Epoch 15/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8031 - loss: 0.5052 - val_acc: 0.4265 - val_loss: 2.7353\n",
      "Epoch 16/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.8151 - loss: 0.4849 - val_acc: 0.4885 - val_loss: 2.1839\n",
      "Epoch 17/80\n",
      "122/122 - 25s - 205ms/step - acc: 0.8183 - loss: 0.4701 - val_acc: 0.4228 - val_loss: 2.7718\n",
      "Epoch 18/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.8204 - loss: 0.4671 - val_acc: 0.4471 - val_loss: 2.7121\n",
      "Epoch 19/80\n",
      "122/122 - 25s - 205ms/step - acc: 0.8222 - loss: 0.4677 - val_acc: 0.4824 - val_loss: 2.2369\n",
      "Epoch 20/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.8211 - loss: 0.4527 - val_acc: 0.4544 - val_loss: 2.4191\n",
      "Epoch 21/80\n",
      "122/122 - 25s - 205ms/step - acc: 0.8218 - loss: 0.4554 - val_acc: 0.4326 - val_loss: 2.8103\n",
      "Epoch 22/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8282 - loss: 0.4449 - val_acc: 0.4690 - val_loss: 2.4478\n",
      "Epoch 23/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.8341 - loss: 0.4298 - val_acc: 0.5103 - val_loss: 2.0089\n",
      "Epoch 24/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8344 - loss: 0.4200 - val_acc: 0.4277 - val_loss: 2.8451\n",
      "Epoch 25/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.8405 - loss: 0.4085 - val_acc: 0.4860 - val_loss: 2.1237\n",
      "Epoch 26/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 25s - 207ms/step - acc: 0.8411 - loss: 0.4134 - val_acc: 0.5565 - val_loss: 2.0554\n",
      "Epoch 27/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8375 - loss: 0.4103 - val_acc: 0.4739 - val_loss: 2.6451\n",
      "Epoch 28/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.8408 - loss: 0.4077 - val_acc: 0.4520 - val_loss: 2.8608\n",
      "Epoch 29/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8497 - loss: 0.3917 - val_acc: 0.4690 - val_loss: 2.5919\n",
      "Epoch 30/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8509 - loss: 0.3896 - val_acc: 0.4994 - val_loss: 2.3520\n",
      "Epoch 31/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8546 - loss: 0.3711 - val_acc: 0.4909 - val_loss: 2.4979\n",
      "Epoch 32/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8557 - loss: 0.3687 - val_acc: 0.4654 - val_loss: 2.7395\n",
      "Epoch 33/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8607 - loss: 0.3583 - val_acc: 0.4642 - val_loss: 2.9774\n",
      "Epoch 34/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8657 - loss: 0.3644 - val_acc: 0.4836 - val_loss: 2.6537\n",
      "Epoch 35/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8644 - loss: 0.3547 - val_acc: 0.4678 - val_loss: 2.8688\n",
      "Epoch 36/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.8642 - loss: 0.3502 - val_acc: 0.5018 - val_loss: 2.3893\n",
      "Epoch 37/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8692 - loss: 0.3329 - val_acc: 0.4921 - val_loss: 2.5921\n",
      "Epoch 38/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.8684 - loss: 0.3376 - val_acc: 0.4690 - val_loss: 2.8492\n",
      "Epoch 39/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8670 - loss: 0.3372 - val_acc: 0.4605 - val_loss: 3.3074\n",
      "Epoch 40/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8738 - loss: 0.3221 - val_acc: 0.4666 - val_loss: 2.4858\n",
      "Epoch 41/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8710 - loss: 0.3320 - val_acc: 0.4994 - val_loss: 2.5819\n",
      "Epoch 42/80\n",
      "122/122 - 25s - 209ms/step - acc: 0.8801 - loss: 0.3110 - val_acc: 0.5128 - val_loss: 2.2138\n",
      "Epoch 43/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8862 - loss: 0.3017 - val_acc: 0.4666 - val_loss: 3.0342\n",
      "Epoch 44/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8876 - loss: 0.2985 - val_acc: 0.4921 - val_loss: 2.5715\n",
      "Epoch 45/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8854 - loss: 0.2982 - val_acc: 0.4532 - val_loss: 3.4455\n",
      "Epoch 46/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8864 - loss: 0.2955 - val_acc: 0.4957 - val_loss: 2.7703\n",
      "Epoch 47/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8914 - loss: 0.2988 - val_acc: 0.4787 - val_loss: 2.8427\n",
      "Epoch 48/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8875 - loss: 0.2868 - val_acc: 0.4860 - val_loss: 2.8512\n",
      "Epoch 49/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8972 - loss: 0.2747 - val_acc: 0.4714 - val_loss: 2.9538\n",
      "Epoch 50/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8958 - loss: 0.2753 - val_acc: 0.4824 - val_loss: 2.8158\n",
      "Epoch 51/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8984 - loss: 0.2752 - val_acc: 0.4751 - val_loss: 3.0615\n",
      "Epoch 52/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8909 - loss: 0.2719 - val_acc: 0.4520 - val_loss: 3.5294\n",
      "Epoch 53/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9008 - loss: 0.2596 - val_acc: 0.4496 - val_loss: 3.5214\n",
      "Epoch 54/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9030 - loss: 0.2641 - val_acc: 0.4654 - val_loss: 3.2433\n",
      "Epoch 55/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8935 - loss: 0.2748 - val_acc: 0.4921 - val_loss: 2.7439\n",
      "Epoch 56/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9074 - loss: 0.2477 - val_acc: 0.4763 - val_loss: 3.3551\n",
      "Epoch 57/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9034 - loss: 0.2538 - val_acc: 0.4702 - val_loss: 3.6551\n",
      "Epoch 58/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.9095 - loss: 0.2510 - val_acc: 0.5407 - val_loss: 2.3164\n",
      "Epoch 59/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.9099 - loss: 0.2460 - val_acc: 0.4945 - val_loss: 2.8577\n",
      "Epoch 60/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9087 - loss: 0.2377 - val_acc: 0.4824 - val_loss: 3.0916\n",
      "Epoch 61/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9136 - loss: 0.2337 - val_acc: 0.4629 - val_loss: 3.9701\n",
      "Epoch 62/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.9119 - loss: 0.2350 - val_acc: 0.4800 - val_loss: 3.2285\n",
      "Epoch 63/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9149 - loss: 0.2298 - val_acc: 0.4982 - val_loss: 3.0462\n",
      "Epoch 64/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9149 - loss: 0.2263 - val_acc: 0.4836 - val_loss: 3.1099\n",
      "Epoch 65/80\n",
      "122/122 - 25s - 209ms/step - acc: 0.9182 - loss: 0.2209 - val_acc: 0.4994 - val_loss: 2.7905\n",
      "Epoch 66/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9216 - loss: 0.2149 - val_acc: 0.5249 - val_loss: 2.4064\n",
      "Epoch 67/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9262 - loss: 0.2058 - val_acc: 0.4970 - val_loss: 3.0077\n",
      "Epoch 68/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9193 - loss: 0.2149 - val_acc: 0.4860 - val_loss: 3.2584\n",
      "Epoch 69/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9257 - loss: 0.2073 - val_acc: 0.5140 - val_loss: 2.6984\n",
      "Epoch 70/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9222 - loss: 0.2128 - val_acc: 0.4800 - val_loss: 3.4686\n",
      "Epoch 71/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9247 - loss: 0.2105 - val_acc: 0.4824 - val_loss: 3.2575\n",
      "Epoch 72/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9248 - loss: 0.2084 - val_acc: 0.5115 - val_loss: 2.7546\n",
      "Epoch 73/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.9266 - loss: 0.1982 - val_acc: 0.4982 - val_loss: 3.0771\n",
      "Epoch 74/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9244 - loss: 0.2096 - val_acc: 0.4885 - val_loss: 3.2407\n",
      "Epoch 75/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.9260 - loss: 0.1989 - val_acc: 0.4751 - val_loss: 3.5290\n",
      "Epoch 76/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9314 - loss: 0.1899 - val_acc: 0.4933 - val_loss: 3.7013\n",
      "Epoch 77/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9267 - loss: 0.2014 - val_acc: 0.4787 - val_loss: 3.6750\n",
      "Epoch 78/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9297 - loss: 0.1883 - val_acc: 0.4933 - val_loss: 3.2823\n",
      "Epoch 79/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9294 - loss: 0.1936 - val_acc: 0.5055 - val_loss: 3.1642\n",
      "Epoch 80/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9311 - loss: 0.1891 - val_acc: 0.4909 - val_loss: 3.3063\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "Save feature of Fold #5 to ./output/Feature_5.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 6\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 47s - 382ms/step - acc: 0.5362 - loss: 1.6740 - val_acc: 0.4885 - val_loss: 1.3995\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 26s - 209ms/step - acc: 0.6537 - loss: 1.0874 - val_acc: 0.5013 - val_loss: 2.1677\n",
      "Epoch 3/80\n",
      "122/122 - 25s - 209ms/step - acc: 0.6962 - loss: 0.8597 - val_acc: 0.4082 - val_loss: 3.4747\n",
      "Epoch 4/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.7313 - loss: 0.7475 - val_acc: 0.3801 - val_loss: 3.9729\n",
      "Epoch 5/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.7502 - loss: 0.6996 - val_acc: 0.4209 - val_loss: 4.2241\n",
      "Epoch 6/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.7594 - loss: 0.6437 - val_acc: 0.4503 - val_loss: 4.2656\n",
      "Epoch 7/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.7776 - loss: 0.5965 - val_acc: 0.4362 - val_loss: 4.5739\n",
      "Epoch 8/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.7819 - loss: 0.5830 - val_acc: 0.4694 - val_loss: 4.2593\n",
      "Epoch 9/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.7871 - loss: 0.5612 - val_acc: 0.4490 - val_loss: 4.2437\n",
      "Epoch 10/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.7919 - loss: 0.5538 - val_acc: 0.4630 - val_loss: 4.5230\n",
      "Epoch 11/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.7858 - loss: 0.5492 - val_acc: 0.4758 - val_loss: 4.5519\n",
      "Epoch 12/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8012 - loss: 0.5168 - val_acc: 0.4707 - val_loss: 4.0424\n",
      "Epoch 13/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8024 - loss: 0.5093 - val_acc: 0.4617 - val_loss: 4.8117\n",
      "Epoch 14/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8015 - loss: 0.5155 - val_acc: 0.4643 - val_loss: 4.1413\n",
      "Epoch 15/80\n",
      "122/122 - 25s - 206ms/step - acc: 0.8124 - loss: 0.4879 - val_acc: 0.4719 - val_loss: 4.5280\n",
      "Epoch 16/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8127 - loss: 0.4860 - val_acc: 0.4758 - val_loss: 3.9499\n",
      "Epoch 17/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8150 - loss: 0.4747 - val_acc: 0.4426 - val_loss: 4.5368\n",
      "Epoch 18/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8182 - loss: 0.4665 - val_acc: 0.4796 - val_loss: 4.3365\n",
      "Epoch 19/80\n",
      "122/122 - 25s - 209ms/step - acc: 0.8252 - loss: 0.4567 - val_acc: 0.4566 - val_loss: 4.4522\n",
      "Epoch 20/80\n",
      "122/122 - 26s - 211ms/step - acc: 0.8215 - loss: 0.4566 - val_acc: 0.4528 - val_loss: 5.1507\n",
      "Epoch 21/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8200 - loss: 0.4567 - val_acc: 0.4643 - val_loss: 4.6094\n",
      "Epoch 22/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8236 - loss: 0.4465 - val_acc: 0.4796 - val_loss: 4.1988\n",
      "Epoch 23/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.8332 - loss: 0.4359 - val_acc: 0.4681 - val_loss: 4.3107\n",
      "Epoch 24/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.8282 - loss: 0.4311 - val_acc: 0.4668 - val_loss: 4.4494\n",
      "Epoch 25/80\n",
      "122/122 - 25s - 209ms/step - acc: 0.8309 - loss: 0.4288 - val_acc: 0.4643 - val_loss: 4.8501\n",
      "Epoch 26/80\n",
      "122/122 - 25s - 209ms/step - acc: 0.8361 - loss: 0.4271 - val_acc: 0.4732 - val_loss: 4.5658\n",
      "Epoch 27/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.8419 - loss: 0.4074 - val_acc: 0.4566 - val_loss: 4.1467\n",
      "Epoch 28/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8360 - loss: 0.4173 - val_acc: 0.4528 - val_loss: 4.6715\n",
      "Epoch 29/80\n",
      "122/122 - 25s - 209ms/step - acc: 0.8382 - loss: 0.4097 - val_acc: 0.4809 - val_loss: 3.8113\n",
      "Epoch 30/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8484 - loss: 0.3896 - val_acc: 0.4974 - val_loss: 3.9226\n",
      "Epoch 31/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.8402 - loss: 0.4051 - val_acc: 0.4885 - val_loss: 3.9675\n",
      "Epoch 32/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.8488 - loss: 0.3862 - val_acc: 0.4796 - val_loss: 3.9205\n",
      "Epoch 33/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.8515 - loss: 0.3829 - val_acc: 0.4758 - val_loss: 4.3026\n",
      "Epoch 34/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.8532 - loss: 0.3766 - val_acc: 0.4974 - val_loss: 3.9387\n",
      "Epoch 35/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.8582 - loss: 0.3675 - val_acc: 0.4885 - val_loss: 4.1807\n",
      "Epoch 36/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 26s - 210ms/step - acc: 0.8605 - loss: 0.3622 - val_acc: 0.5038 - val_loss: 3.5462\n",
      "Epoch 37/80\n",
      "122/122 - 26s - 209ms/step - acc: 0.8561 - loss: 0.3648 - val_acc: 0.4758 - val_loss: 4.5525\n",
      "Epoch 38/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 26s - 209ms/step - acc: 0.8597 - loss: 0.3594 - val_acc: 0.5128 - val_loss: 3.2985\n",
      "Epoch 39/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.8676 - loss: 0.3411 - val_acc: 0.5064 - val_loss: 3.3635\n",
      "Epoch 40/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 26s - 210ms/step - acc: 0.8619 - loss: 0.3583 - val_acc: 0.5281 - val_loss: 3.2582\n",
      "Epoch 41/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.8660 - loss: 0.3449 - val_acc: 0.4911 - val_loss: 3.4206\n",
      "Epoch 42/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.8633 - loss: 0.3525 - val_acc: 0.4962 - val_loss: 3.4221\n",
      "Epoch 43/80\n",
      "122/122 - 26s - 212ms/step - acc: 0.8728 - loss: 0.3270 - val_acc: 0.5102 - val_loss: 3.3494\n",
      "Epoch 44/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.8669 - loss: 0.3284 - val_acc: 0.5230 - val_loss: 3.2001\n",
      "Epoch 45/80\n",
      "122/122 - 26s - 212ms/step - acc: 0.8780 - loss: 0.3218 - val_acc: 0.4936 - val_loss: 3.7155\n",
      "Epoch 46/80\n",
      "122/122 - 26s - 211ms/step - acc: 0.8719 - loss: 0.3243 - val_acc: 0.5013 - val_loss: 3.5171\n",
      "Epoch 47/80\n",
      "122/122 - 26s - 211ms/step - acc: 0.8869 - loss: 0.3021 - val_acc: 0.5051 - val_loss: 3.3577\n",
      "Epoch 48/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 26s - 211ms/step - acc: 0.8835 - loss: 0.3002 - val_acc: 0.5306 - val_loss: 3.1188\n",
      "Epoch 49/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8862 - loss: 0.2946 - val_acc: 0.5179 - val_loss: 3.2947\n",
      "Epoch 50/80\n",
      "122/122 - 26s - 209ms/step - acc: 0.8865 - loss: 0.2953 - val_acc: 0.4911 - val_loss: 3.4222\n",
      "Epoch 51/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8894 - loss: 0.2918 - val_acc: 0.5000 - val_loss: 3.4282\n",
      "Epoch 52/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.8933 - loss: 0.2800 - val_acc: 0.5128 - val_loss: 3.3547\n",
      "Epoch 53/80\n",
      "122/122 - 26s - 209ms/step - acc: 0.8887 - loss: 0.2870 - val_acc: 0.5000 - val_loss: 3.3579\n",
      "Epoch 54/80\n",
      "122/122 - 26s - 209ms/step - acc: 0.8915 - loss: 0.2832 - val_acc: 0.5038 - val_loss: 3.1491\n",
      "Epoch 55/80\n",
      "122/122 - 26s - 211ms/step - acc: 0.8998 - loss: 0.2677 - val_acc: 0.5051 - val_loss: 3.3952\n",
      "Epoch 56/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.8983 - loss: 0.2772 - val_acc: 0.5179 - val_loss: 3.2663\n",
      "Epoch 57/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 26s - 214ms/step - acc: 0.9040 - loss: 0.2577 - val_acc: 0.5523 - val_loss: 2.8169\n",
      "Epoch 58/80\n",
      "122/122 - 26s - 209ms/step - acc: 0.9031 - loss: 0.2526 - val_acc: 0.5191 - val_loss: 3.2182\n",
      "Epoch 59/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9061 - loss: 0.2571 - val_acc: 0.4911 - val_loss: 3.6339\n",
      "Epoch 60/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9061 - loss: 0.2504 - val_acc: 0.5255 - val_loss: 3.0074\n",
      "Epoch 61/80\n",
      "122/122 - 26s - 211ms/step - acc: 0.9048 - loss: 0.2530 - val_acc: 0.5089 - val_loss: 3.2568\n",
      "Epoch 62/80\n",
      "122/122 - 25s - 209ms/step - acc: 0.9065 - loss: 0.2429 - val_acc: 0.5485 - val_loss: 3.0497\n",
      "Epoch 63/80\n",
      "122/122 - 25s - 209ms/step - acc: 0.9119 - loss: 0.2318 - val_acc: 0.5255 - val_loss: 3.1835\n",
      "Epoch 64/80\n",
      "122/122 - 26s - 209ms/step - acc: 0.9121 - loss: 0.2365 - val_acc: 0.5268 - val_loss: 3.1407\n",
      "Epoch 65/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.9103 - loss: 0.2396 - val_acc: 0.5179 - val_loss: 3.1565\n",
      "Epoch 66/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9135 - loss: 0.2338 - val_acc: 0.5089 - val_loss: 3.6287\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 - 26s - 210ms/step - acc: 0.9145 - loss: 0.2317 - val_acc: 0.5651 - val_loss: 2.7826\n",
      "Epoch 68/80\n",
      "122/122 - 26s - 211ms/step - acc: 0.9174 - loss: 0.2231 - val_acc: 0.5344 - val_loss: 3.2092\n",
      "Epoch 69/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.9161 - loss: 0.2276 - val_acc: 0.5319 - val_loss: 3.3040\n",
      "Epoch 70/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9202 - loss: 0.2167 - val_acc: 0.5370 - val_loss: 3.1448\n",
      "Epoch 71/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9156 - loss: 0.2253 - val_acc: 0.5089 - val_loss: 3.5659\n",
      "Epoch 72/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9158 - loss: 0.2266 - val_acc: 0.5166 - val_loss: 3.1816\n",
      "Epoch 73/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9254 - loss: 0.2007 - val_acc: 0.5281 - val_loss: 3.1331\n",
      "Epoch 74/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9250 - loss: 0.2064 - val_acc: 0.5230 - val_loss: 3.1928\n",
      "Epoch 75/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9233 - loss: 0.2115 - val_acc: 0.5472 - val_loss: 3.1215\n",
      "Epoch 76/80\n",
      "122/122 - 26s - 210ms/step - acc: 0.9236 - loss: 0.2032 - val_acc: 0.5230 - val_loss: 3.2868\n",
      "Epoch 77/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9256 - loss: 0.2020 - val_acc: 0.5064 - val_loss: 3.5643\n",
      "Epoch 78/80\n",
      "122/122 - 25s - 207ms/step - acc: 0.9286 - loss: 0.1986 - val_acc: 0.5013 - val_loss: 3.5115\n",
      "Epoch 79/80\n",
      "122/122 - 25s - 209ms/step - acc: 0.9284 - loss: 0.1962 - val_acc: 0.5472 - val_loss: 3.0514\n",
      "Epoch 80/80\n",
      "122/122 - 25s - 208ms/step - acc: 0.9286 - loss: 0.1963 - val_acc: 0.5089 - val_loss: 3.4560\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "Save feature of Fold #6 to ./output/Feature_6.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 7\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 46s - 383ms/step - acc: 0.4976 - loss: 1.9346 - val_acc: 0.2278 - val_loss: 3.3642\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 213ms/step - acc: 0.6144 - loss: 1.2438 - val_acc: 0.2474 - val_loss: 1.9594\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 212ms/step - acc: 0.6695 - loss: 1.0045 - val_acc: 0.5186 - val_loss: 1.4707\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 212ms/step - acc: 0.7044 - loss: 0.8504 - val_acc: 0.5206 - val_loss: 1.6941\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 212ms/step - acc: 0.7194 - loss: 0.7840 - val_acc: 0.5412 - val_loss: 1.8367\n",
      "Epoch 6/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 212ms/step - acc: 0.7464 - loss: 0.7020 - val_acc: 0.5619 - val_loss: 1.6694\n",
      "Epoch 7/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.7494 - loss: 0.6781 - val_acc: 0.5041 - val_loss: 2.3076\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 212ms/step - acc: 0.7529 - loss: 0.6603 - val_acc: 0.5753 - val_loss: 1.7896\n",
      "Epoch 9/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.7651 - loss: 0.6326 - val_acc: 0.5577 - val_loss: 1.8458\n",
      "Epoch 10/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.7634 - loss: 0.6200 - val_acc: 0.4876 - val_loss: 2.4685\n",
      "Epoch 11/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 212ms/step - acc: 0.7719 - loss: 0.6152 - val_acc: 0.5876 - val_loss: 1.7292\n",
      "Epoch 12/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.7823 - loss: 0.5813 - val_acc: 0.5588 - val_loss: 1.8068\n",
      "Epoch 13/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.7773 - loss: 0.5776 - val_acc: 0.5124 - val_loss: 2.4496\n",
      "Epoch 14/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.7854 - loss: 0.5614 - val_acc: 0.5649 - val_loss: 2.1601\n",
      "Epoch 15/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.7854 - loss: 0.5605 - val_acc: 0.5237 - val_loss: 2.4708\n",
      "Epoch 16/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.7907 - loss: 0.5524 - val_acc: 0.5835 - val_loss: 2.0934\n",
      "Epoch 17/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.7913 - loss: 0.5451 - val_acc: 0.4990 - val_loss: 2.8088\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 213ms/step - acc: 0.7882 - loss: 0.5346 - val_acc: 0.5948 - val_loss: 1.8458\n",
      "Epoch 19/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.8017 - loss: 0.5161 - val_acc: 0.5814 - val_loss: 1.8774\n",
      "Epoch 20/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.8050 - loss: 0.5077 - val_acc: 0.5649 - val_loss: 2.1720\n",
      "Epoch 21/80\n",
      "120/120 - 25s - 210ms/step - acc: 0.7960 - loss: 0.5157 - val_acc: 0.4763 - val_loss: 2.9889\n",
      "Epoch 22/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 211ms/step - acc: 0.7934 - loss: 0.5273 - val_acc: 0.6052 - val_loss: 1.7343\n",
      "Epoch 23/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8113 - loss: 0.4885 - val_acc: 0.5474 - val_loss: 2.1807\n",
      "Epoch 24/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8089 - loss: 0.4815 - val_acc: 0.5629 - val_loss: 2.2179\n",
      "Epoch 25/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8199 - loss: 0.4739 - val_acc: 0.5619 - val_loss: 2.0604\n",
      "Epoch 26/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.8107 - loss: 0.4938 - val_acc: 0.5072 - val_loss: 2.5633\n",
      "Epoch 27/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.8185 - loss: 0.4684 - val_acc: 0.5113 - val_loss: 2.6777\n",
      "Epoch 28/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8135 - loss: 0.4719 - val_acc: 0.5515 - val_loss: 2.3702\n",
      "Epoch 29/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.8214 - loss: 0.4522 - val_acc: 0.5258 - val_loss: 2.7462\n",
      "Epoch 30/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 25s - 212ms/step - acc: 0.8241 - loss: 0.4408 - val_acc: 0.6381 - val_loss: 1.9394\n",
      "Epoch 31/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8235 - loss: 0.4381 - val_acc: 0.5835 - val_loss: 2.2013\n",
      "Epoch 32/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.8287 - loss: 0.4301 - val_acc: 0.5773 - val_loss: 2.0558\n",
      "Epoch 33/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.8266 - loss: 0.4388 - val_acc: 0.5608 - val_loss: 2.3850\n",
      "Epoch 34/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8304 - loss: 0.4303 - val_acc: 0.5299 - val_loss: 2.3745\n",
      "Epoch 35/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.8319 - loss: 0.4322 - val_acc: 0.5351 - val_loss: 2.5674\n",
      "Epoch 36/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.8439 - loss: 0.4024 - val_acc: 0.4330 - val_loss: 3.4024\n",
      "Epoch 37/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8470 - loss: 0.3946 - val_acc: 0.4660 - val_loss: 3.0102\n",
      "Epoch 38/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8439 - loss: 0.3946 - val_acc: 0.4804 - val_loss: 2.8501\n",
      "Epoch 39/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8362 - loss: 0.4238 - val_acc: 0.5206 - val_loss: 2.8656\n",
      "Epoch 40/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8493 - loss: 0.3998 - val_acc: 0.5505 - val_loss: 2.5242\n",
      "Epoch 41/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8475 - loss: 0.3907 - val_acc: 0.4196 - val_loss: 3.2678\n",
      "Epoch 42/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8458 - loss: 0.3836 - val_acc: 0.5021 - val_loss: 3.2097\n",
      "Epoch 43/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8518 - loss: 0.3788 - val_acc: 0.5268 - val_loss: 2.6126\n",
      "Epoch 44/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8517 - loss: 0.3886 - val_acc: 0.5392 - val_loss: 2.6240\n",
      "Epoch 45/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8540 - loss: 0.3723 - val_acc: 0.5701 - val_loss: 2.5078\n",
      "Epoch 46/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8598 - loss: 0.3604 - val_acc: 0.5216 - val_loss: 2.8589\n",
      "Epoch 47/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8647 - loss: 0.3531 - val_acc: 0.5588 - val_loss: 2.9031\n",
      "Epoch 48/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.8681 - loss: 0.3371 - val_acc: 0.6175 - val_loss: 2.1394\n",
      "Epoch 49/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8628 - loss: 0.3538 - val_acc: 0.5443 - val_loss: 2.6124\n",
      "Epoch 50/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8669 - loss: 0.3515 - val_acc: 0.6041 - val_loss: 2.2083\n",
      "Epoch 51/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8691 - loss: 0.3436 - val_acc: 0.5670 - val_loss: 2.3688\n",
      "Epoch 52/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8674 - loss: 0.3369 - val_acc: 0.5948 - val_loss: 2.2749\n",
      "Epoch 53/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8705 - loss: 0.3388 - val_acc: 0.5464 - val_loss: 2.7538\n",
      "Epoch 54/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8711 - loss: 0.3408 - val_acc: 0.5361 - val_loss: 2.8891\n",
      "Epoch 55/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8737 - loss: 0.3288 - val_acc: 0.4938 - val_loss: 3.0893\n",
      "Epoch 56/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8678 - loss: 0.3345 - val_acc: 0.5825 - val_loss: 2.2986\n",
      "Epoch 57/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8779 - loss: 0.3205 - val_acc: 0.5258 - val_loss: 2.8635\n",
      "Epoch 58/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8786 - loss: 0.3159 - val_acc: 0.5866 - val_loss: 2.3093\n",
      "Epoch 59/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8750 - loss: 0.3304 - val_acc: 0.5794 - val_loss: 2.4070\n",
      "Epoch 60/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8786 - loss: 0.3113 - val_acc: 0.5856 - val_loss: 2.4845\n",
      "Epoch 61/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8749 - loss: 0.3264 - val_acc: 0.5536 - val_loss: 2.4853\n",
      "Epoch 62/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8876 - loss: 0.2960 - val_acc: 0.5474 - val_loss: 2.6450\n",
      "Epoch 63/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8845 - loss: 0.2990 - val_acc: 0.5701 - val_loss: 2.7498\n",
      "Epoch 64/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8904 - loss: 0.2930 - val_acc: 0.6216 - val_loss: 2.0636\n",
      "Epoch 65/80\n",
      "120/120 - 26s - 214ms/step - acc: 0.8888 - loss: 0.2931 - val_acc: 0.6021 - val_loss: 2.3110\n",
      "Epoch 66/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8911 - loss: 0.2885 - val_acc: 0.5784 - val_loss: 2.4265\n",
      "Epoch 67/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8901 - loss: 0.2941 - val_acc: 0.5938 - val_loss: 2.4572\n",
      "Epoch 68/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8811 - loss: 0.3063 - val_acc: 0.5959 - val_loss: 2.1344\n",
      "Epoch 69/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8925 - loss: 0.2821 - val_acc: 0.5897 - val_loss: 2.2935\n",
      "Epoch 70/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8874 - loss: 0.2874 - val_acc: 0.5515 - val_loss: 2.6225\n",
      "Epoch 71/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8925 - loss: 0.2765 - val_acc: 0.6052 - val_loss: 2.4578\n",
      "Epoch 72/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.8909 - loss: 0.2836 - val_acc: 0.6072 - val_loss: 2.2720\n",
      "Epoch 73/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.9006 - loss: 0.2608 - val_acc: 0.5845 - val_loss: 2.4130\n",
      "Epoch 74/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.9079 - loss: 0.2477 - val_acc: 0.6196 - val_loss: 1.9474\n",
      "Epoch 75/80\n",
      "120/120 - 26s - 213ms/step - acc: 0.9096 - loss: 0.2467 - val_acc: 0.6000 - val_loss: 2.3023\n",
      "Epoch 76/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.9086 - loss: 0.2462 - val_acc: 0.6052 - val_loss: 2.3823\n",
      "Epoch 77/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.9026 - loss: 0.2559 - val_acc: 0.5979 - val_loss: 2.3183\n",
      "Epoch 78/80\n",
      "120/120 - 25s - 211ms/step - acc: 0.8995 - loss: 0.2680 - val_acc: 0.5485 - val_loss: 2.7832\n",
      "Epoch 79/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.8964 - loss: 0.2866 - val_acc: 0.5938 - val_loss: 2.3866\n",
      "Epoch 80/80\n",
      "120/120 - 25s - 212ms/step - acc: 0.9079 - loss: 0.2476 - val_acc: 0.6196 - val_loss: 2.1018\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "Save feature of Fold #7 to ./output/Feature_7.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 8\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 46s - 386ms/step - acc: 0.5227 - loss: 1.7612 - val_acc: 0.3429 - val_loss: 1.8072\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 215ms/step - acc: 0.6556 - loss: 1.0481 - val_acc: 0.3834 - val_loss: 1.9177\n",
      "Epoch 3/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.7005 - loss: 0.8392 - val_acc: 0.3557 - val_loss: 2.5038\n",
      "Epoch 4/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.7246 - loss: 0.7647 - val_acc: 0.3131 - val_loss: 3.3140\n",
      "Epoch 5/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.7493 - loss: 0.6814 - val_acc: 0.3749 - val_loss: 2.8703\n",
      "Epoch 6/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.7616 - loss: 0.6396 - val_acc: 0.3131 - val_loss: 3.1969\n",
      "Epoch 7/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 218ms/step - acc: 0.7627 - loss: 0.6504 - val_acc: 0.4164 - val_loss: 3.0064\n",
      "Epoch 8/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.7731 - loss: 0.5968 - val_acc: 0.3504 - val_loss: 3.4933\n",
      "Epoch 9/80\n",
      "120/120 - 27s - 221ms/step - acc: 0.7791 - loss: 0.5762 - val_acc: 0.3600 - val_loss: 3.2279\n",
      "Epoch 10/80\n",
      "120/120 - 26s - 219ms/step - acc: 0.7761 - loss: 0.5727 - val_acc: 0.3994 - val_loss: 3.1360\n",
      "Epoch 11/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.7877 - loss: 0.5609 - val_acc: 0.3568 - val_loss: 3.3887\n",
      "Epoch 12/80\n",
      "120/120 - 26s - 219ms/step - acc: 0.7835 - loss: 0.5451 - val_acc: 0.4153 - val_loss: 3.2044\n",
      "Epoch 13/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 218ms/step - acc: 0.7889 - loss: 0.5410 - val_acc: 0.4398 - val_loss: 3.2793\n",
      "Epoch 14/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 26s - 218ms/step - acc: 0.8044 - loss: 0.5009 - val_acc: 0.4665 - val_loss: 3.3217\n",
      "Epoch 15/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8072 - loss: 0.4943 - val_acc: 0.3866 - val_loss: 3.8290\n",
      "Epoch 16/80\n",
      "120/120 - 26s - 220ms/step - acc: 0.8029 - loss: 0.4979 - val_acc: 0.4185 - val_loss: 3.5095\n",
      "Epoch 17/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8078 - loss: 0.4938 - val_acc: 0.4302 - val_loss: 3.4048\n",
      "Epoch 18/80\n",
      "120/120 - 26s - 219ms/step - acc: 0.8084 - loss: 0.4867 - val_acc: 0.4079 - val_loss: 3.4149\n",
      "Epoch 19/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8152 - loss: 0.4671 - val_acc: 0.3706 - val_loss: 3.6384\n",
      "Epoch 20/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8247 - loss: 0.4572 - val_acc: 0.4164 - val_loss: 3.6073\n",
      "Epoch 21/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8237 - loss: 0.4517 - val_acc: 0.3876 - val_loss: 3.6770\n",
      "Epoch 22/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8238 - loss: 0.4492 - val_acc: 0.3866 - val_loss: 3.7643\n",
      "Epoch 23/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8261 - loss: 0.4481 - val_acc: 0.4036 - val_loss: 3.5284\n",
      "Epoch 24/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8332 - loss: 0.4346 - val_acc: 0.3653 - val_loss: 3.6824\n",
      "Epoch 25/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8303 - loss: 0.4255 - val_acc: 0.4068 - val_loss: 3.6433\n",
      "Epoch 26/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8258 - loss: 0.4361 - val_acc: 0.3834 - val_loss: 3.3645\n",
      "Epoch 27/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8352 - loss: 0.4241 - val_acc: 0.3845 - val_loss: 3.6114\n",
      "Epoch 28/80\n",
      "120/120 - 28s - 237ms/step - acc: 0.8344 - loss: 0.4195 - val_acc: 0.3781 - val_loss: 3.8252\n",
      "Epoch 29/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8353 - loss: 0.4135 - val_acc: 0.3685 - val_loss: 3.4579\n",
      "Epoch 30/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8430 - loss: 0.3990 - val_acc: 0.3355 - val_loss: 4.1184\n",
      "Epoch 31/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.8455 - loss: 0.3968 - val_acc: 0.3472 - val_loss: 4.1111\n",
      "Epoch 32/80\n",
      "120/120 - 26s - 219ms/step - acc: 0.8484 - loss: 0.3945 - val_acc: 0.3653 - val_loss: 3.9832\n",
      "Epoch 33/80\n",
      "120/120 - 26s - 220ms/step - acc: 0.8471 - loss: 0.3854 - val_acc: 0.3632 - val_loss: 3.8933\n",
      "Epoch 34/80\n",
      "120/120 - 26s - 219ms/step - acc: 0.8503 - loss: 0.3810 - val_acc: 0.3749 - val_loss: 3.8706\n",
      "Epoch 35/80\n",
      "120/120 - 26s - 219ms/step - acc: 0.8608 - loss: 0.3629 - val_acc: 0.3568 - val_loss: 4.3407\n",
      "Epoch 36/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8596 - loss: 0.3639 - val_acc: 0.3365 - val_loss: 4.3731\n",
      "Epoch 37/80\n",
      "120/120 - 26s - 220ms/step - acc: 0.8635 - loss: 0.3572 - val_acc: 0.3269 - val_loss: 4.7136\n",
      "Epoch 38/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8579 - loss: 0.3616 - val_acc: 0.3536 - val_loss: 4.2818\n",
      "Epoch 39/80\n",
      "120/120 - 26s - 220ms/step - acc: 0.8643 - loss: 0.3648 - val_acc: 0.3504 - val_loss: 4.2269\n",
      "Epoch 40/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8639 - loss: 0.3425 - val_acc: 0.3610 - val_loss: 4.1307\n",
      "Epoch 41/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8736 - loss: 0.3262 - val_acc: 0.3344 - val_loss: 4.4808\n",
      "Epoch 42/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8681 - loss: 0.3317 - val_acc: 0.3749 - val_loss: 4.2292\n",
      "Epoch 43/80\n",
      "120/120 - 26s - 215ms/step - acc: 0.8724 - loss: 0.3335 - val_acc: 0.3600 - val_loss: 4.3160\n",
      "Epoch 44/80\n",
      "120/120 - 26s - 219ms/step - acc: 0.8733 - loss: 0.3359 - val_acc: 0.3429 - val_loss: 4.3555\n",
      "Epoch 45/80\n",
      "120/120 - 26s - 219ms/step - acc: 0.8705 - loss: 0.3286 - val_acc: 0.3738 - val_loss: 3.9582\n",
      "Epoch 46/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8728 - loss: 0.3246 - val_acc: 0.4345 - val_loss: 3.5387\n",
      "Epoch 47/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8814 - loss: 0.3224 - val_acc: 0.3717 - val_loss: 4.4181\n",
      "Epoch 48/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8864 - loss: 0.3027 - val_acc: 0.3738 - val_loss: 4.0631\n",
      "Epoch 49/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8893 - loss: 0.2945 - val_acc: 0.3514 - val_loss: 5.0480\n",
      "Epoch 50/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8885 - loss: 0.2890 - val_acc: 0.3514 - val_loss: 4.2336\n",
      "Epoch 51/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8974 - loss: 0.2829 - val_acc: 0.3876 - val_loss: 4.3335\n",
      "Epoch 52/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8903 - loss: 0.2951 - val_acc: 0.3770 - val_loss: 4.1483\n",
      "Epoch 53/80\n",
      "120/120 - 26s - 219ms/step - acc: 0.8877 - loss: 0.2908 - val_acc: 0.3525 - val_loss: 4.5973\n",
      "Epoch 54/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8916 - loss: 0.2738 - val_acc: 0.4036 - val_loss: 4.2167\n",
      "Epoch 55/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.8881 - loss: 0.2895 - val_acc: 0.3706 - val_loss: 4.2477\n",
      "Epoch 56/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9034 - loss: 0.2630 - val_acc: 0.3738 - val_loss: 4.6427\n",
      "Epoch 57/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.9014 - loss: 0.2662 - val_acc: 0.3589 - val_loss: 4.4501\n",
      "Epoch 58/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.8999 - loss: 0.2615 - val_acc: 0.4143 - val_loss: 4.2271\n",
      "Epoch 59/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9005 - loss: 0.2624 - val_acc: 0.3727 - val_loss: 4.0627\n",
      "Epoch 60/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9031 - loss: 0.2520 - val_acc: 0.3802 - val_loss: 4.7434\n",
      "Epoch 61/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.9013 - loss: 0.2589 - val_acc: 0.3717 - val_loss: 4.3951\n",
      "Epoch 62/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9076 - loss: 0.2513 - val_acc: 0.3461 - val_loss: 5.2124\n",
      "Epoch 63/80\n",
      "120/120 - 27s - 222ms/step - acc: 0.9118 - loss: 0.2441 - val_acc: 0.3493 - val_loss: 4.9572\n",
      "Epoch 64/80\n",
      "120/120 - 28s - 234ms/step - acc: 0.9127 - loss: 0.2467 - val_acc: 0.3568 - val_loss: 5.2433\n",
      "Epoch 65/80\n",
      "120/120 - 28s - 234ms/step - acc: 0.9094 - loss: 0.2441 - val_acc: 0.4047 - val_loss: 3.9008\n",
      "Epoch 66/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9131 - loss: 0.2308 - val_acc: 0.3440 - val_loss: 5.0649\n",
      "Epoch 67/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9135 - loss: 0.2352 - val_acc: 0.3568 - val_loss: 4.8652\n",
      "Epoch 68/80\n",
      "120/120 - 26s - 219ms/step - acc: 0.9180 - loss: 0.2263 - val_acc: 0.3717 - val_loss: 4.3903\n",
      "Epoch 69/80\n",
      "120/120 - 26s - 216ms/step - acc: 0.9170 - loss: 0.2219 - val_acc: 0.3845 - val_loss: 4.5960\n",
      "Epoch 70/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9200 - loss: 0.2139 - val_acc: 0.3514 - val_loss: 4.6342\n",
      "Epoch 71/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.9213 - loss: 0.2203 - val_acc: 0.3536 - val_loss: 4.9884\n",
      "Epoch 72/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.9207 - loss: 0.2100 - val_acc: 0.3962 - val_loss: 4.1521\n",
      "Epoch 73/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9191 - loss: 0.2169 - val_acc: 0.3376 - val_loss: 5.1739\n",
      "Epoch 74/80\n",
      "120/120 - 26s - 219ms/step - acc: 0.9187 - loss: 0.2186 - val_acc: 0.3749 - val_loss: 4.4506\n",
      "Epoch 75/80\n",
      "120/120 - 26s - 219ms/step - acc: 0.9248 - loss: 0.2153 - val_acc: 0.3845 - val_loss: 4.3751\n",
      "Epoch 76/80\n",
      "120/120 - 27s - 221ms/step - acc: 0.9205 - loss: 0.2119 - val_acc: 0.4260 - val_loss: 3.9507\n",
      "Epoch 77/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.9273 - loss: 0.2019 - val_acc: 0.4026 - val_loss: 4.4578\n",
      "Epoch 78/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.9258 - loss: 0.2068 - val_acc: 0.3536 - val_loss: 4.9007\n",
      "Epoch 79/80\n",
      "120/120 - 26s - 217ms/step - acc: 0.9312 - loss: 0.1922 - val_acc: 0.3706 - val_loss: 4.8935\n",
      "Epoch 80/80\n",
      "120/120 - 26s - 218ms/step - acc: 0.9312 - loss: 0.1948 - val_acc: 0.3685 - val_loss: 4.8948\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "Save feature of Fold #8 to ./output/Feature_8.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 9\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 - 48s - 388ms/step - acc: 0.5183 - loss: 1.8292 - val_acc: 0.3969 - val_loss: 1.4749\n",
      "Epoch 2/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.6494 - loss: 1.0693 - val_acc: 0.3277 - val_loss: 1.9374\n",
      "Epoch 3/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.7138 - loss: 0.8431 - val_acc: 0.3211 - val_loss: 2.3721\n",
      "Epoch 4/80\n",
      "123/123 - 27s - 219ms/step - acc: 0.7302 - loss: 0.7749 - val_acc: 0.3198 - val_loss: 2.7657\n",
      "Epoch 5/80\n",
      "123/123 - 27s - 219ms/step - acc: 0.7487 - loss: 0.7029 - val_acc: 0.3094 - val_loss: 3.6526\n",
      "Epoch 6/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.7541 - loss: 0.6523 - val_acc: 0.3094 - val_loss: 2.9594\n",
      "Epoch 7/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.7685 - loss: 0.6277 - val_acc: 0.3107 - val_loss: 3.2559\n",
      "Epoch 8/80\n",
      "123/123 - 27s - 223ms/step - acc: 0.7675 - loss: 0.6280 - val_acc: 0.3107 - val_loss: 3.2092\n",
      "Epoch 9/80\n",
      "123/123 - 27s - 223ms/step - acc: 0.7718 - loss: 0.5902 - val_acc: 0.3055 - val_loss: 3.1613\n",
      "Epoch 10/80\n",
      "123/123 - 27s - 223ms/step - acc: 0.7916 - loss: 0.5542 - val_acc: 0.3159 - val_loss: 2.8542\n",
      "Epoch 11/80\n",
      "123/123 - 27s - 223ms/step - acc: 0.7874 - loss: 0.5553 - val_acc: 0.3042 - val_loss: 3.4989\n",
      "Epoch 12/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.7887 - loss: 0.5444 - val_acc: 0.3172 - val_loss: 3.2291\n",
      "Epoch 13/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.7960 - loss: 0.5309 - val_acc: 0.3185 - val_loss: 3.8719\n",
      "Epoch 14/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.7985 - loss: 0.5133 - val_acc: 0.3120 - val_loss: 3.2157\n",
      "Epoch 15/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.7991 - loss: 0.5123 - val_acc: 0.3264 - val_loss: 2.9982\n",
      "Epoch 16/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.8058 - loss: 0.4958 - val_acc: 0.3290 - val_loss: 3.0434\n",
      "Epoch 17/80\n",
      "123/123 - 27s - 223ms/step - acc: 0.8138 - loss: 0.4948 - val_acc: 0.3198 - val_loss: 3.5414\n",
      "Epoch 18/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.8139 - loss: 0.4739 - val_acc: 0.3251 - val_loss: 3.3875\n",
      "Epoch 19/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8141 - loss: 0.4769 - val_acc: 0.3394 - val_loss: 3.0818\n",
      "Epoch 20/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.8111 - loss: 0.4754 - val_acc: 0.3185 - val_loss: 3.6597\n",
      "Epoch 21/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8195 - loss: 0.4638 - val_acc: 0.3394 - val_loss: 3.6958\n",
      "Epoch 22/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.8245 - loss: 0.4462 - val_acc: 0.3211 - val_loss: 3.7767\n",
      "Epoch 23/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.8267 - loss: 0.4425 - val_acc: 0.3290 - val_loss: 3.6982\n",
      "Epoch 24/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8278 - loss: 0.4320 - val_acc: 0.3329 - val_loss: 3.1095\n",
      "Epoch 25/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8334 - loss: 0.4253 - val_acc: 0.3420 - val_loss: 3.2941\n",
      "Epoch 26/80\n",
      "123/123 - 27s - 223ms/step - acc: 0.8350 - loss: 0.4251 - val_acc: 0.3433 - val_loss: 3.1887\n",
      "Epoch 27/80\n",
      "123/123 - 27s - 223ms/step - acc: 0.8357 - loss: 0.4162 - val_acc: 0.3316 - val_loss: 3.2007\n",
      "Epoch 28/80\n",
      "123/123 - 28s - 224ms/step - acc: 0.8348 - loss: 0.4137 - val_acc: 0.3342 - val_loss: 3.1043\n",
      "Epoch 29/80\n",
      "123/123 - 27s - 223ms/step - acc: 0.8419 - loss: 0.4012 - val_acc: 0.3512 - val_loss: 3.0549\n",
      "Epoch 30/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.8386 - loss: 0.4009 - val_acc: 0.3251 - val_loss: 3.6525\n",
      "Epoch 31/80\n",
      "123/123 - 27s - 223ms/step - acc: 0.8442 - loss: 0.3995 - val_acc: 0.3460 - val_loss: 3.2454\n",
      "Epoch 32/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8544 - loss: 0.3769 - val_acc: 0.3146 - val_loss: 3.7817\n",
      "Epoch 33/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8503 - loss: 0.3750 - val_acc: 0.3329 - val_loss: 3.0904\n",
      "Epoch 34/80\n",
      "123/123 - 27s - 223ms/step - acc: 0.8562 - loss: 0.3699 - val_acc: 0.3433 - val_loss: 3.3901\n",
      "Epoch 35/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8585 - loss: 0.3678 - val_acc: 0.3277 - val_loss: 3.9101\n",
      "Epoch 36/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8605 - loss: 0.3643 - val_acc: 0.3277 - val_loss: 3.8610\n",
      "Epoch 37/80\n",
      "123/123 - 27s - 219ms/step - acc: 0.8651 - loss: 0.3476 - val_acc: 0.3303 - val_loss: 3.7810\n",
      "Epoch 38/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.8687 - loss: 0.3409 - val_acc: 0.3734 - val_loss: 3.0396\n",
      "Epoch 39/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.8641 - loss: 0.3529 - val_acc: 0.3172 - val_loss: 3.8763\n",
      "Epoch 40/80\n",
      "123/123 - 27s - 219ms/step - acc: 0.8626 - loss: 0.3550 - val_acc: 0.3120 - val_loss: 3.9132\n",
      "Epoch 41/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.8688 - loss: 0.3343 - val_acc: 0.3146 - val_loss: 3.7272\n",
      "Epoch 42/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8671 - loss: 0.3348 - val_acc: 0.3211 - val_loss: 3.7896\n",
      "Epoch 43/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.8774 - loss: 0.3192 - val_acc: 0.3564 - val_loss: 3.0882\n",
      "Epoch 44/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.8731 - loss: 0.3274 - val_acc: 0.3081 - val_loss: 4.6100\n",
      "Epoch 45/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.8759 - loss: 0.3301 - val_acc: 0.3251 - val_loss: 4.1862\n",
      "Epoch 46/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.8787 - loss: 0.3238 - val_acc: 0.3277 - val_loss: 3.6965\n",
      "Epoch 47/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.8796 - loss: 0.3040 - val_acc: 0.3264 - val_loss: 4.0580\n",
      "Epoch 48/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.8905 - loss: 0.2990 - val_acc: 0.3316 - val_loss: 3.9265\n",
      "Epoch 49/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.8844 - loss: 0.2985 - val_acc: 0.3003 - val_loss: 4.2152\n",
      "Epoch 50/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8866 - loss: 0.2956 - val_acc: 0.3198 - val_loss: 3.6965\n",
      "Epoch 51/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8953 - loss: 0.2753 - val_acc: 0.3198 - val_loss: 4.3788\n",
      "Epoch 52/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8925 - loss: 0.2763 - val_acc: 0.3303 - val_loss: 4.1171\n",
      "Epoch 53/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9013 - loss: 0.2670 - val_acc: 0.3264 - val_loss: 4.5362\n",
      "Epoch 54/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.8977 - loss: 0.2721 - val_acc: 0.3525 - val_loss: 3.7401\n",
      "Epoch 55/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9032 - loss: 0.2685 - val_acc: 0.3198 - val_loss: 4.3439\n",
      "Epoch 56/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.8953 - loss: 0.2666 - val_acc: 0.3290 - val_loss: 3.8308\n",
      "Epoch 57/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9031 - loss: 0.2539 - val_acc: 0.3172 - val_loss: 4.4896\n",
      "Epoch 58/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.8974 - loss: 0.2679 - val_acc: 0.3159 - val_loss: 4.0688\n",
      "Epoch 59/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9046 - loss: 0.2493 - val_acc: 0.3290 - val_loss: 4.1789\n",
      "Epoch 60/80\n",
      "123/123 - 27s - 223ms/step - acc: 0.9016 - loss: 0.2537 - val_acc: 0.3107 - val_loss: 3.9844\n",
      "Epoch 61/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.9076 - loss: 0.2396 - val_acc: 0.3211 - val_loss: 4.5185\n",
      "Epoch 62/80\n",
      "123/123 - 28s - 224ms/step - acc: 0.9083 - loss: 0.2480 - val_acc: 0.3055 - val_loss: 4.2495\n",
      "Epoch 63/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9128 - loss: 0.2319 - val_acc: 0.3055 - val_loss: 4.4479\n",
      "Epoch 64/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.9144 - loss: 0.2341 - val_acc: 0.3211 - val_loss: 4.3591\n",
      "Epoch 65/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9127 - loss: 0.2414 - val_acc: 0.2990 - val_loss: 4.5118\n",
      "Epoch 66/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.9132 - loss: 0.2294 - val_acc: 0.3081 - val_loss: 4.5481\n",
      "Epoch 67/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9117 - loss: 0.2321 - val_acc: 0.3225 - val_loss: 3.9966\n",
      "Epoch 68/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9174 - loss: 0.2261 - val_acc: 0.2911 - val_loss: 5.2190\n",
      "Epoch 69/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9188 - loss: 0.2222 - val_acc: 0.3120 - val_loss: 4.7321\n",
      "Epoch 70/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9219 - loss: 0.2081 - val_acc: 0.3107 - val_loss: 4.5993\n",
      "Epoch 71/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.9146 - loss: 0.2257 - val_acc: 0.3120 - val_loss: 4.7346\n",
      "Epoch 72/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.9216 - loss: 0.2101 - val_acc: 0.3068 - val_loss: 4.6373\n",
      "Epoch 73/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9223 - loss: 0.2082 - val_acc: 0.3146 - val_loss: 4.2593\n",
      "Epoch 74/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9251 - loss: 0.2004 - val_acc: 0.2950 - val_loss: 5.4598\n",
      "Epoch 75/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9223 - loss: 0.2068 - val_acc: 0.3133 - val_loss: 4.6139\n",
      "Epoch 76/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.9229 - loss: 0.2089 - val_acc: 0.3225 - val_loss: 4.2782\n",
      "Epoch 77/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9294 - loss: 0.1976 - val_acc: 0.3159 - val_loss: 4.3567\n",
      "Epoch 78/80\n",
      "123/123 - 27s - 220ms/step - acc: 0.9241 - loss: 0.2055 - val_acc: 0.3029 - val_loss: 4.8619\n",
      "Epoch 79/80\n",
      "123/123 - 27s - 221ms/step - acc: 0.9297 - loss: 0.1931 - val_acc: 0.3094 - val_loss: 5.1475\n",
      "Epoch 80/80\n",
      "123/123 - 27s - 222ms/step - acc: 0.9268 - loss: 0.1936 - val_acc: 0.2924 - val_loss: 5.5915\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "Save feature of Fold #9 to ./output/Feature_9.npz\n",
      "________________________________________________________________________________________________________________________________\n",
      "End of training FeatureNet.\n",
      "################################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import shutil\n",
    "import gc\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as KTF\n",
    "\n",
    "from model.FeatureNet import build_FeatureNet\n",
    "from model.DataGenerator import kFoldGenerator\n",
    "from model.Utils import ReadConfig\n",
    "\n",
    "# Display a header\n",
    "print(128 * '#')\n",
    "print('Start to train FeatureNet.')\n",
    "\n",
    "# Configuration Setup\n",
    "parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"-c\", type=str, help=\"Configuration file\", required=True)\n",
    "# parser.add_argument(\"-g\", type=str, help=\"GPU number to use, set '-1' to use CPU\", required=True)\n",
    "# args = parser.parse_args()\n",
    "args = lambda: None\n",
    "args.c = \"./ISRUC.config\"  # Update with your actual path\n",
    "args.g = \"-1\"  # Change this based on whether you want to use a GPU or CPU\n",
    "\n",
    "Path, cfgFeature, _, _ = ReadConfig(args.c)\n",
    "\n",
    "# Set GPU or CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.g\n",
    "if args.g != \"-1\":\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "    print(\"Use GPU #\" + args.g)\n",
    "else:\n",
    "    print(\"Use CPU only\")\n",
    "\n",
    "# Training Parameters\n",
    "channels = int(cfgFeature[\"channels\"])\n",
    "fold = int(cfgFeature[\"fold\"])\n",
    "num_epochs_f = int(cfgFeature[\"epoch_f\"])\n",
    "batch_size_f = int(cfgFeature[\"batch_size_f\"])\n",
    "optimizer_f = cfgFeature[\"optimizer_f\"]\n",
    "learn_rate_f = float(cfgFeature[\"learn_rate_f\"])\n",
    "\n",
    "# Create save path\n",
    "# if not os.path.exists(Path['Save']):\n",
    "#     os.makedirs(Path['Save'])\n",
    "# shutil.copyfile(args.c, Path['Save'] + \"last.config\")\n",
    "if not os.path.exists(Path['save']):  # Use lowercase keys\n",
    "    os.makedirs(Path['save'])\n",
    "shutil.copyfile(args.c, os.path.join(Path['save'], \"last.config\"))\n",
    "\n",
    "\n",
    "# Load Data\n",
    "ReadList = np.load(Path['data'], allow_pickle=True)\n",
    "Fold_Num = ReadList['Fold_len']  # Number of samples in each fold\n",
    "Fold_Data = ReadList['Fold_data']  # Data per fold\n",
    "Fold_Label = ReadList['Fold_label']  # Labels per fold\n",
    "\n",
    "print(\"Read data successfully\")\n",
    "print(\"Number of samples:\", np.sum(Fold_Num))\n",
    "\n",
    "# Create kFoldGenerator\n",
    "DataGenerator = kFoldGenerator(Fold_Data, Fold_Label)\n",
    "\n",
    "# Training with k-Fold Cross-Validation\n",
    "all_scores = []\n",
    "for i in range(fold):\n",
    "    print(128 * '_')\n",
    "    print('Fold #', i)\n",
    "    \n",
    "    # Initialize Optimizer\n",
    "    opt_f = keras.optimizers.Adam(learning_rate=learn_rate_f)\n",
    "    \n",
    "    # Fetch Fold Data\n",
    "    train_data, train_targets, val_data, val_targets = DataGenerator.getFold(i)\n",
    "    \n",
    "    # Build FeatureNet\n",
    "    featureNet, featureNet_p = build_FeatureNet(opt_f, channels)\n",
    "    history_fea = featureNet.fit(\n",
    "        x=train_data,\n",
    "        y=train_targets,\n",
    "        epochs=num_epochs_f,\n",
    "        batch_size=batch_size_f,\n",
    "        shuffle=True,\n",
    "        validation_data=(val_data, val_targets),\n",
    "        verbose=2,\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint(\n",
    "            Path['Save'] + 'FeatureNet_Best_' + str(i) + '.h5',\n",
    "            monitor='val_acc',\n",
    "            verbose=0,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='auto',\n",
    "            save_freq='epoch'\n",
    "        )]\n",
    "    )\n",
    "    \n",
    "    # Aggregate Training Information\n",
    "    if i == 0:\n",
    "        fit_loss = np.array(history_fea.history['loss']) * Fold_Num[i]\n",
    "        fit_acc = np.array(history_fea.history['acc']) * Fold_Num[i]\n",
    "        fit_val_loss = np.array(history_fea.history['val_loss']) * Fold_Num[i]\n",
    "        fit_val_acc = np.array(history_fea.history['val_acc']) * Fold_Num[i]\n",
    "    else:\n",
    "        fit_loss += np.array(history_fea.history['loss']) * Fold_Num[i]\n",
    "        fit_acc += np.array(history_fea.history['acc']) * Fold_Num[i]\n",
    "        fit_val_loss += np.array(history_fea.history['val_loss']) * Fold_Num[i]\n",
    "        fit_val_acc += np.array(history_fea.history['val_acc']) * Fold_Num[i]\n",
    "    \n",
    "    # Load Best Weights\n",
    "    featureNet.load_weights(Path['Save'] + 'FeatureNet_Best_' + str(i) + '.h5')\n",
    "    \n",
    "    # Extract and Save Features\n",
    "    train_feature = featureNet_p.predict(train_data)\n",
    "    val_feature = featureNet_p.predict(val_data)\n",
    "    print('Save feature of Fold #' + str(i) + ' to ' + Path['Save'] + 'Feature_' + str(i) + '.npz')\n",
    "    np.savez(Path['Save'] + 'Feature_' + str(i) + '.npz',\n",
    "             train_feature=train_feature,\n",
    "             val_feature=val_feature,\n",
    "             train_targets=train_targets,\n",
    "             val_targets=val_targets)\n",
    "    \n",
    "    # Log Results\n",
    "    with open(Path['Save'] + \"Result_FeatureNet.txt\", 'a+') as saveFile:\n",
    "        print('Fold #'+str(i), file=saveFile)\n",
    "        print(history_fea.history, file=saveFile)\n",
    "    \n",
    "    # Cleanup Memory\n",
    "    keras.backend.clear_session()\n",
    "    del featureNet, featureNet_p, train_data, train_targets, val_data, val_targets, train_feature, val_feature\n",
    "    gc.collect()\n",
    "\n",
    "print(128 * '_')\n",
    "print('End of training FeatureNet.')\n",
    "print(128 * '#')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import shutil\n",
    "# import gc\n",
    "# import keras\n",
    "# import tensorflow as tf\n",
    "# from keras import backend as KTF\n",
    "# import argparse\n",
    "\n",
    "# from model.MSTGCN import build_MSTGCN\n",
    "# from model.DataGenerator import DominGenerator\n",
    "# from model.Utils import *\n",
    "\n",
    "# # Display setup\n",
    "# print(128 * '#')\n",
    "# print('Start to train MSTGCN.')\n",
    "\n",
    "# # 1. Get Configuration\n",
    "\n",
    "# # Configuration File Path (Manually Set in Jupyter Notebook)\n",
    "# config_file = \"./ISRUC.config\"  # Update with actual path\n",
    "# gpu_number = \"0\"  # Set GPU number or \"-1\" to use CPU\n",
    "# Path, _, cfgTrain, cfgModel = ReadConfig(config_file)\n",
    "\n",
    "# # Set GPU number or use CPU only\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_number\n",
    "# if gpu_number != \"-1\":\n",
    "#     config = tf.compat.v1.ConfigProto()\n",
    "#     config.gpu_options.allow_growth = True\n",
    "#     sess = tf.compat.v1.Session(config=config)\n",
    "#     print(\"Use GPU #\" + gpu_number)\n",
    "# else:\n",
    "#     print(\"Use CPU only\")\n",
    "\n",
    "# # 1.2. Analytic Parameters\n",
    "# channels = int(cfgTrain[\"channels\"])\n",
    "# fold = int(cfgTrain[\"fold\"])\n",
    "# context = int(cfgTrain[\"context\"])\n",
    "# num_epochs = int(cfgTrain[\"epoch\"])\n",
    "# batch_size = int(cfgTrain[\"batch_size\"])\n",
    "# optimizer = cfgTrain[\"optimizer\"]\n",
    "# learn_rate = float(cfgTrain[\"learn_rate\"])\n",
    "# lambda_GRL = float(cfgTrain[\"lambda_GRL\"])\n",
    "\n",
    "# dense_size = np.array(str.split(cfgModel[\"Globaldense\"], ','), dtype=int)\n",
    "# GLalpha = float(cfgModel[\"GLalpha\"])\n",
    "# num_of_chev_filters = int(cfgModel[\"cheb_filters\"])\n",
    "# num_of_time_filters = int(cfgModel[\"time_filters\"])\n",
    "# time_conv_strides = int(cfgModel[\"time_conv_strides\"])\n",
    "# time_conv_kernel = int(cfgModel[\"time_conv_kernel\"])\n",
    "# num_block = int(cfgModel[\"num_block\"])\n",
    "# cheb_k = int(cfgModel[\"cheb_k\"])\n",
    "# l1 = float(cfgModel[\"l1\"])\n",
    "# l2 = float(cfgModel[\"l2\"])\n",
    "# dropout = float(cfgModel[\"dropout\"])\n",
    "\n",
    "# # Create save path\n",
    "# if not os.path.exists(Path['Save']):\n",
    "#     os.makedirs(Path['Save'])\n",
    "# shutil.copyfile(config_file, Path['Save'] + \"last.config\")\n",
    "\n",
    "# # 2. Read Data\n",
    "# ReadList = np.load(Path['data'], allow_pickle=True)\n",
    "# Fold_Num = ReadList['Fold_len']\n",
    "\n",
    "# Dis_Conn = np.load(Path['disM'], allow_pickle=True)\n",
    "# L_DC = scaled_Laplacian(Dis_Conn)\n",
    "# cheb_poly_DC = cheb_polynomial(L_DC, cheb_k)\n",
    "\n",
    "# print(\"Read data successfully\")\n",
    "# Fold_Num_c = Fold_Num + 1 - context\n",
    "# print('Number of samples:', np.sum(Fold_Num), '(with context:', np.sum(Fold_Num_c), ')')\n",
    "\n",
    "# Dom_Generator = DominGenerator(Fold_Num_c)\n",
    "\n",
    "# # 3. Model Training (Cross-Validation)\n",
    "# all_scores = []\n",
    "# for i in range(fold):\n",
    "#     print(128 * '_')\n",
    "#     print('Fold #', i)\n",
    "    \n",
    "#     opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "#     regularizer = Instantiation_regularizer(l1, l2)\n",
    "    \n",
    "#     Features = np.load(Path['Save']+'Feature_'+str(i)+'.npz', allow_pickle=True)\n",
    "#     train_feature = Features['train_feature']\n",
    "#     val_feature = Features['val_feature']\n",
    "#     train_targets = Features['train_targets']\n",
    "#     val_targets = Features['val_targets']\n",
    "    \n",
    "#     train_feature, train_targets = AddContext_MultiSub(train_feature, train_targets,\n",
    "#                                                        np.delete(Fold_Num.copy(), i), context, i)\n",
    "#     val_feature, val_targets = AddContext_SingleSub(val_feature, val_targets, context)\n",
    "#     train_domin, val_domin = Dom_Generator.getFold(i)\n",
    "\n",
    "#     sample_shape = (val_feature.shape[1:])\n",
    "    \n",
    "#     model, model_p = build_MSTGCN(cheb_k, num_of_chev_filters, num_of_time_filters, time_conv_strides, cheb_poly_DC,\n",
    "#                                   time_conv_kernel, sample_shape, num_block, dense_size, opt, GLalpha, regularizer, \n",
    "#                                   dropout, lambda_GRL, num_classes=5, num_domain=9)\n",
    "    \n",
    "#     print(\"train_feature shape:\", train_feature.shape)\n",
    "#     print(\"train_targets shape:\", train_targets.shape)\n",
    "#     print(\"train_domin shape:\", train_domin.shape)\n",
    "\n",
    "#     history = model.fit(\n",
    "#         x=train_feature,\n",
    "#         y=[train_targets, train_domin],\n",
    "#         epochs=num_epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=True,\n",
    "#         validation_data=(val_feature, [val_targets, val_domin]),\n",
    "#         verbose=2,\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint(Path['Save']+'FeatureNet_Best_'+str(i)+'.h5',\n",
    "#                                            monitor='val_Label_acc',\n",
    "#                                            verbose=0,  \n",
    "#                                            save_best_only=True,\n",
    "#                                            save_weights_only=False, \n",
    "#                                            mode='auto',\n",
    "#                                            save_freq='epoch')] )\n",
    "    \n",
    "#     model.save(Path['Save']+'MSTGCN_Final_'+str(i)+'.h5')\n",
    "    \n",
    "#     saveFile = open(Path['Save'] + \"Result_MSTGCN.txt\", 'a+')\n",
    "#     print('Fold #'+str(i), file=saveFile)\n",
    "#     print(history.history, file=saveFile)\n",
    "#     saveFile.close()\n",
    "    \n",
    "#     keras.backend.clear_session()\n",
    "#     del model, model_p, train_feature, train_targets, val_feature, val_targets\n",
    "#     gc.collect()\n",
    "\n",
    "# # 4. Final Results\n",
    "\n",
    "# fit_acc = fit_acc / np.sum(Fold_Num_c)\n",
    "# fit_loss = fit_loss / np.sum(Fold_Num_c)\n",
    "# fit_val_loss = fit_val_loss / np.sum(Fold_Num_c)\n",
    "# fit_val_acc = fit_val_acc / np.sum(Fold_Num_c)\n",
    "\n",
    "# VariationCurve(fit_acc, fit_val_acc, 'Acc', Path['Save'], figsize=(9, 6))\n",
    "# VariationCurve(fit_loss, fit_val_loss, 'Loss', Path['Save'], figsize=(9, 6))\n",
    "\n",
    "# saveFile = open(Path['Save'] + \"Result_MSTGCN.txt\", 'a+')\n",
    "# print(history.history, file=saveFile)\n",
    "# saveFile.close()\n",
    "\n",
    "# print(128 * '_')\n",
    "# print('End of training MSTGCN.')\n",
    "# print(128 * '#')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_acc = 0.0\n",
    "# fit_loss = 0.0\n",
    "# fit_val_loss = 0.0\n",
    "# fit_val_acc = 0.0\n",
    "\n",
    "# fit_acc = fit_acc / np.sum(Fold_Num_c)\n",
    "# fit_loss = fit_loss / np.sum(Fold_Num_c)\n",
    "# fit_val_loss = fit_val_loss / np.sum(Fold_Num_c)\n",
    "# fit_val_acc = fit_val_acc / np.sum(Fold_Num_c)\n",
    "\n",
    "# VariationCurve(fit_acc, fit_val_acc, 'Acc', Path['Save'], figsize=(9, 6))\n",
    "# VariationCurve(fit_loss, fit_val_loss, 'Loss', Path['Save'], figsize=(9, 6))\n",
    "\n",
    "# saveFile = open(Path['Save'] + \"Result_MSTGCN.txt\", 'a+')\n",
    "# print(history.history, file=saveFile)\n",
    "# saveFile.close()\n",
    "\n",
    "# print(128 * '_')\n",
    "# print('End of training MSTGCN.')\n",
    "# print(128 * '#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################################################################\n",
      "Start to train MSTGCN.\n",
      "Config:  ./ISRUC.config\n",
      "Using GPU #0\n",
      "Read data successfully\n",
      "Number of samples: 8589 (with context: 8549)\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold #0\n",
      "train_feature shape: (7629, 5, 10, 256)\n",
      "train_targets shape: (7629, 5)\n",
      "train_domin shape: (7629, 9)\n",
      "Epoch 1/80\n",
      "239/239 - 19s - 82ms/step - Domain_accuracy: 0.4500 - Domain_loss: 1.6632 - Label_accuracy: 0.6697 - Label_loss: 1.0103 - loss: 2.6746 - val_Domain_accuracy: 0.1315 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7935 - val_Label_loss: 0.5389 - val_loss: 0.5415\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Victus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:209: UserWarning: Can save best model only with val_categorical_accuracy available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.5767 - Domain_loss: 1.1944 - Label_accuracy: 0.7540 - Label_loss: 0.6281 - loss: 1.8224 - val_Domain_accuracy: 0.1663 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8326 - val_Label_loss: 0.5206 - val_loss: 0.5248\n",
      "Epoch 3/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.6402 - Domain_loss: 1.0237 - Label_accuracy: 0.7787 - Label_loss: 0.5619 - loss: 1.5860 - val_Domain_accuracy: 0.2696 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8022 - val_Label_loss: 0.5134 - val_loss: 0.5167\n",
      "Epoch 4/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.6838 - Domain_loss: 0.8947 - Label_accuracy: 0.7926 - Label_loss: 0.5271 - loss: 1.4205 - val_Domain_accuracy: 0.1772 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.4750 - val_loss: 0.4777\n",
      "Epoch 5/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.7010 - Domain_loss: 0.8614 - Label_accuracy: 0.7979 - Label_loss: 0.5078 - loss: 1.3688 - val_Domain_accuracy: 0.2359 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8359 - val_Label_loss: 0.4497 - val_loss: 0.4529\n",
      "Epoch 6/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.7234 - Domain_loss: 0.7951 - Label_accuracy: 0.8097 - Label_loss: 0.4808 - loss: 1.2766 - val_Domain_accuracy: 0.1217 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8228 - val_Label_loss: 0.4712 - val_loss: 0.4712\n",
      "Epoch 7/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.7310 - Domain_loss: 0.8022 - Label_accuracy: 0.8139 - Label_loss: 0.4680 - loss: 1.2706 - val_Domain_accuracy: 0.1826 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8326 - val_Label_loss: 0.4319 - val_loss: 0.4350\n",
      "Epoch 8/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.7355 - Domain_loss: 0.7850 - Label_accuracy: 0.8188 - Label_loss: 0.4635 - loss: 1.2477 - val_Domain_accuracy: 0.2402 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8087 - val_Label_loss: 0.5075 - val_loss: 0.5083\n",
      "Epoch 9/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.7610 - Domain_loss: 0.7045 - Label_accuracy: 0.8306 - Label_loss: 0.4431 - loss: 1.1465 - val_Domain_accuracy: 0.1587 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8402 - val_Label_loss: 0.4051 - val_loss: 0.4078\n",
      "Epoch 10/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.7800 - Domain_loss: 0.6451 - Label_accuracy: 0.8280 - Label_loss: 0.4369 - loss: 1.0829 - val_Domain_accuracy: 0.1717 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7967 - val_Label_loss: 0.5615 - val_loss: 0.5639\n",
      "Epoch 11/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.7968 - Domain_loss: 0.6235 - Label_accuracy: 0.8306 - Label_loss: 0.4242 - loss: 1.0476 - val_Domain_accuracy: 0.3000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8272 - val_Label_loss: 0.4741 - val_loss: 0.4769\n",
      "Epoch 12/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.7997 - Domain_loss: 0.5969 - Label_accuracy: 0.8283 - Label_loss: 0.4216 - loss: 1.0186 - val_Domain_accuracy: 0.2913 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8152 - val_Label_loss: 0.4772 - val_loss: 0.4786\n",
      "Epoch 13/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.8174 - Domain_loss: 0.5383 - Label_accuracy: 0.8438 - Label_loss: 0.3990 - loss: 0.9368 - val_Domain_accuracy: 0.2576 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8293 - val_Label_loss: 0.4568 - val_loss: 0.4572\n",
      "Epoch 14/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.7998 - Domain_loss: 0.6010 - Label_accuracy: 0.8381 - Label_loss: 0.4039 - loss: 1.0044 - val_Domain_accuracy: 0.2457 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8228 - val_Label_loss: 0.4237 - val_loss: 0.4264\n",
      "Epoch 15/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.8233 - Domain_loss: 0.5254 - Label_accuracy: 0.8432 - Label_loss: 0.3933 - loss: 0.9183 - val_Domain_accuracy: 0.4043 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8467 - val_Label_loss: 0.4043 - val_loss: 0.4073\n",
      "Epoch 16/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.8285 - Domain_loss: 0.5161 - Label_accuracy: 0.8521 - Label_loss: 0.3823 - loss: 0.8988 - val_Domain_accuracy: 0.3880 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8054 - val_Label_loss: 0.4924 - val_loss: 0.4927\n",
      "Epoch 17/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8228 - Domain_loss: 0.5160 - Label_accuracy: 0.8486 - Label_loss: 0.3810 - loss: 0.8980 - val_Domain_accuracy: 0.3761 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8196 - val_Label_loss: 0.4927 - val_loss: 0.4959\n",
      "Epoch 18/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8304 - Domain_loss: 0.5164 - Label_accuracy: 0.8494 - Label_loss: 0.3785 - loss: 0.8955 - val_Domain_accuracy: 0.3685 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8261 - val_Label_loss: 0.5346 - val_loss: 0.5381\n",
      "Epoch 19/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8190 - Domain_loss: 0.5165 - Label_accuracy: 0.8517 - Label_loss: 0.3697 - loss: 0.8866 - val_Domain_accuracy: 0.2641 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8446 - val_Label_loss: 0.4564 - val_loss: 0.4581\n",
      "Epoch 20/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8289 - Domain_loss: 0.4966 - Label_accuracy: 0.8510 - Label_loss: 0.3649 - loss: 0.8605 - val_Domain_accuracy: 0.3761 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8359 - val_Label_loss: 0.4525 - val_loss: 0.4540\n",
      "Epoch 21/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8373 - Domain_loss: 0.4817 - Label_accuracy: 0.8548 - Label_loss: 0.3540 - loss: 0.8352 - val_Domain_accuracy: 0.5272 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8217 - val_Label_loss: 0.4665 - val_loss: 0.4688\n",
      "Epoch 22/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8443 - Domain_loss: 0.4559 - Label_accuracy: 0.8579 - Label_loss: 0.3568 - loss: 0.8125 - val_Domain_accuracy: 0.1891 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 0.5472 - val_loss: 0.5495\n",
      "Epoch 23/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8305 - Domain_loss: 0.5025 - Label_accuracy: 0.8579 - Label_loss: 0.3533 - loss: 0.8561 - val_Domain_accuracy: 0.3891 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8261 - val_Label_loss: 0.4643 - val_loss: 0.4672\n",
      "Epoch 24/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8413 - Domain_loss: 0.4667 - Label_accuracy: 0.8611 - Label_loss: 0.3502 - loss: 0.8156 - val_Domain_accuracy: 0.3293 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8120 - val_Label_loss: 0.5463 - val_loss: 0.5482\n",
      "Epoch 25/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8468 - Domain_loss: 0.4666 - Label_accuracy: 0.8706 - Label_loss: 0.3298 - loss: 0.7969 - val_Domain_accuracy: 0.3489 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8337 - val_Label_loss: 0.4727 - val_loss: 0.4739\n",
      "Epoch 26/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8432 - Domain_loss: 0.4636 - Label_accuracy: 0.8675 - Label_loss: 0.3330 - loss: 0.7970 - val_Domain_accuracy: 0.2641 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8065 - val_Label_loss: 0.5407 - val_loss: 0.5446\n",
      "Epoch 27/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8466 - Domain_loss: 0.4684 - Label_accuracy: 0.8658 - Label_loss: 0.3344 - loss: 0.8019 - val_Domain_accuracy: 0.2848 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8141 - val_Label_loss: 0.5064 - val_loss: 0.5077\n",
      "Epoch 28/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8521 - Domain_loss: 0.4423 - Label_accuracy: 0.8713 - Label_loss: 0.3260 - loss: 0.7676 - val_Domain_accuracy: 0.3022 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8239 - val_Label_loss: 0.5553 - val_loss: 0.5588\n",
      "Epoch 29/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8499 - Domain_loss: 0.4369 - Label_accuracy: 0.8709 - Label_loss: 0.3188 - loss: 0.7560 - val_Domain_accuracy: 0.2717 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8120 - val_Label_loss: 0.6641 - val_loss: 0.6695\n",
      "Epoch 30/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8482 - Domain_loss: 0.4556 - Label_accuracy: 0.8714 - Label_loss: 0.3224 - loss: 0.7778 - val_Domain_accuracy: 0.1902 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7728 - val_Label_loss: 0.6815 - val_loss: 0.6833\n",
      "Epoch 31/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8548 - Domain_loss: 0.4372 - Label_accuracy: 0.8666 - Label_loss: 0.3233 - loss: 0.7588 - val_Domain_accuracy: 0.3424 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7935 - val_Label_loss: 0.6565 - val_loss: 0.6614\n",
      "Epoch 32/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8512 - Domain_loss: 0.4309 - Label_accuracy: 0.8739 - Label_loss: 0.3167 - loss: 0.7470 - val_Domain_accuracy: 0.2641 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8239 - val_Label_loss: 0.5254 - val_loss: 0.5270\n",
      "Epoch 33/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8460 - Domain_loss: 0.4623 - Label_accuracy: 0.8793 - Label_loss: 0.3091 - loss: 0.7723 - val_Domain_accuracy: 0.1880 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.5642 - val_loss: 0.5657\n",
      "Epoch 34/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8508 - Domain_loss: 0.4308 - Label_accuracy: 0.8776 - Label_loss: 0.3059 - loss: 0.7360 - val_Domain_accuracy: 0.2967 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8402 - val_Label_loss: 0.4621 - val_loss: 0.4650\n",
      "Epoch 35/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8473 - Domain_loss: 0.4497 - Label_accuracy: 0.8788 - Label_loss: 0.3011 - loss: 0.7516 - val_Domain_accuracy: 0.2500 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7946 - val_Label_loss: 0.6924 - val_loss: 0.6942\n",
      "Epoch 36/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8414 - Domain_loss: 0.4567 - Label_accuracy: 0.8761 - Label_loss: 0.3057 - loss: 0.7626 - val_Domain_accuracy: 0.2717 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8283 - val_Label_loss: 0.5385 - val_loss: 0.5414\n",
      "Epoch 37/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8504 - Domain_loss: 0.4322 - Label_accuracy: 0.8768 - Label_loss: 0.2963 - loss: 0.7296 - val_Domain_accuracy: 0.3152 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8326 - val_Label_loss: 0.5320 - val_loss: 0.5353\n",
      "Epoch 38/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8594 - Domain_loss: 0.4279 - Label_accuracy: 0.8867 - Label_loss: 0.2816 - loss: 0.7087 - val_Domain_accuracy: 0.1891 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8120 - val_Label_loss: 0.5918 - val_loss: 0.5929\n",
      "Epoch 39/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8493 - Domain_loss: 0.4363 - Label_accuracy: 0.8843 - Label_loss: 0.2891 - loss: 0.7253 - val_Domain_accuracy: 0.2663 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8065 - val_Label_loss: 0.6630 - val_loss: 0.6679\n",
      "Epoch 40/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8508 - Domain_loss: 0.4631 - Label_accuracy: 0.8841 - Label_loss: 0.2887 - loss: 0.7531 - val_Domain_accuracy: 0.2652 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8239 - val_Label_loss: 0.6407 - val_loss: 0.6443\n",
      "Epoch 41/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8499 - Domain_loss: 0.4342 - Label_accuracy: 0.8853 - Label_loss: 0.2872 - loss: 0.7230 - val_Domain_accuracy: 0.2141 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8250 - val_Label_loss: 0.5211 - val_loss: 0.5250\n",
      "Epoch 42/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8545 - Domain_loss: 0.4198 - Label_accuracy: 0.8912 - Label_loss: 0.2753 - loss: 0.6961 - val_Domain_accuracy: 0.3109 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8261 - val_Label_loss: 0.6012 - val_loss: 0.6048\n",
      "Epoch 43/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8441 - Domain_loss: 0.4541 - Label_accuracy: 0.8887 - Label_loss: 0.2804 - loss: 0.7339 - val_Domain_accuracy: 0.2826 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8261 - val_Label_loss: 0.6010 - val_loss: 0.6045\n",
      "Epoch 44/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8453 - Domain_loss: 0.4629 - Label_accuracy: 0.8921 - Label_loss: 0.2754 - loss: 0.7375 - val_Domain_accuracy: 0.2761 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7913 - val_Label_loss: 0.7296 - val_loss: 0.7332\n",
      "Epoch 45/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.8453 - Domain_loss: 0.4601 - Label_accuracy: 0.8923 - Label_loss: 0.2690 - loss: 0.7279 - val_Domain_accuracy: 0.3391 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7696 - val_Label_loss: 0.7719 - val_loss: 0.7709\n",
      "Epoch 46/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8422 - Domain_loss: 0.4695 - Label_accuracy: 0.8895 - Label_loss: 0.2826 - loss: 0.7527 - val_Domain_accuracy: 0.2935 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8239 - val_Label_loss: 0.5717 - val_loss: 0.5737\n",
      "Epoch 47/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8688 - Domain_loss: 0.3982 - Label_accuracy: 0.8985 - Label_loss: 0.2603 - loss: 0.6584 - val_Domain_accuracy: 0.3217 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8261 - val_Label_loss: 0.6145 - val_loss: 0.6182\n",
      "Epoch 48/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8487 - Domain_loss: 0.4451 - Label_accuracy: 0.9021 - Label_loss: 0.2553 - loss: 0.7004 - val_Domain_accuracy: 0.2739 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8076 - val_Label_loss: 0.6516 - val_loss: 0.6550\n",
      "Epoch 49/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8599 - Domain_loss: 0.4160 - Label_accuracy: 0.8984 - Label_loss: 0.2519 - loss: 0.6675 - val_Domain_accuracy: 0.1522 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7902 - val_Label_loss: 0.6346 - val_loss: 0.6373\n",
      "Epoch 50/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8479 - Domain_loss: 0.4471 - Label_accuracy: 0.8934 - Label_loss: 0.2709 - loss: 0.7178 - val_Domain_accuracy: 0.2000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7326 - val_Label_loss: 0.8416 - val_loss: 0.8409\n",
      "Epoch 51/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8592 - Domain_loss: 0.4203 - Label_accuracy: 0.8980 - Label_loss: 0.2572 - loss: 0.6770 - val_Domain_accuracy: 0.2054 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7967 - val_Label_loss: 0.6519 - val_loss: 0.6542\n",
      "Epoch 52/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8476 - Domain_loss: 0.4507 - Label_accuracy: 0.9013 - Label_loss: 0.2493 - loss: 0.6996 - val_Domain_accuracy: 0.0957 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8087 - val_Label_loss: 0.7126 - val_loss: 0.7173\n",
      "Epoch 53/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8586 - Domain_loss: 0.4187 - Label_accuracy: 0.9001 - Label_loss: 0.2566 - loss: 0.6760 - val_Domain_accuracy: 0.1859 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8043 - val_Label_loss: 0.6213 - val_loss: 0.6217\n",
      "Epoch 54/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8521 - Domain_loss: 0.4379 - Label_accuracy: 0.9030 - Label_loss: 0.2435 - loss: 0.6812 - val_Domain_accuracy: 0.3337 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8120 - val_Label_loss: 0.6806 - val_loss: 0.6840\n",
      "Epoch 55/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8423 - Domain_loss: 0.4546 - Label_accuracy: 0.8959 - Label_loss: 0.2534 - loss: 0.7083 - val_Domain_accuracy: 0.3000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8033 - val_Label_loss: 0.7709 - val_loss: 0.7758\n",
      "Epoch 56/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8476 - Domain_loss: 0.4427 - Label_accuracy: 0.9029 - Label_loss: 0.2517 - loss: 0.6942 - val_Domain_accuracy: 0.2761 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.7879 - val_loss: 0.7892\n",
      "Epoch 57/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8611 - Domain_loss: 0.4108 - Label_accuracy: 0.9010 - Label_loss: 0.2415 - loss: 0.6524 - val_Domain_accuracy: 0.3065 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8315 - val_Label_loss: 0.5787 - val_loss: 0.5819\n",
      "Epoch 58/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8456 - Domain_loss: 0.4398 - Label_accuracy: 0.9050 - Label_loss: 0.2420 - loss: 0.6831 - val_Domain_accuracy: 0.1750 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8033 - val_Label_loss: 0.7919 - val_loss: 0.7964\n",
      "Epoch 59/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8544 - Domain_loss: 0.4226 - Label_accuracy: 0.9105 - Label_loss: 0.2379 - loss: 0.6601 - val_Domain_accuracy: 0.1957 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8228 - val_Label_loss: 0.5710 - val_loss: 0.5742\n",
      "Epoch 60/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8554 - Domain_loss: 0.4259 - Label_accuracy: 0.9034 - Label_loss: 0.2422 - loss: 0.6671 - val_Domain_accuracy: 0.3696 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8217 - val_Label_loss: 0.6477 - val_loss: 0.6490\n",
      "Epoch 61/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8379 - Domain_loss: 0.4660 - Label_accuracy: 0.9008 - Label_loss: 0.2508 - loss: 0.7174 - val_Domain_accuracy: 0.1815 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8163 - val_Label_loss: 0.6774 - val_loss: 0.6805\n",
      "Epoch 62/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8470 - Domain_loss: 0.4444 - Label_accuracy: 0.9034 - Label_loss: 0.2369 - loss: 0.6818 - val_Domain_accuracy: 0.1935 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8098 - val_Label_loss: 0.6381 - val_loss: 0.6411\n",
      "Epoch 63/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8641 - Domain_loss: 0.4061 - Label_accuracy: 0.9127 - Label_loss: 0.2213 - loss: 0.6265 - val_Domain_accuracy: 0.3446 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8141 - val_Label_loss: 0.7673 - val_loss: 0.7703\n",
      "Epoch 64/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8528 - Domain_loss: 0.4337 - Label_accuracy: 0.9099 - Label_loss: 0.2238 - loss: 0.6587 - val_Domain_accuracy: 0.2272 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8065 - val_Label_loss: 0.7345 - val_loss: 0.7384\n",
      "Epoch 65/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8487 - Domain_loss: 0.4298 - Label_accuracy: 0.9061 - Label_loss: 0.2360 - loss: 0.6648 - val_Domain_accuracy: 0.2641 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8043 - val_Label_loss: 0.7497 - val_loss: 0.7507\n",
      "Epoch 66/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8491 - Domain_loss: 0.4401 - Label_accuracy: 0.9094 - Label_loss: 0.2257 - loss: 0.6660 - val_Domain_accuracy: 0.2315 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8207 - val_Label_loss: 0.6659 - val_loss: 0.6694\n",
      "Epoch 67/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8613 - Domain_loss: 0.3932 - Label_accuracy: 0.9132 - Label_loss: 0.2186 - loss: 0.6114 - val_Domain_accuracy: 0.3120 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8228 - val_Label_loss: 0.6534 - val_loss: 0.6568\n",
      "Epoch 68/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8557 - Domain_loss: 0.4214 - Label_accuracy: 0.9114 - Label_loss: 0.2229 - loss: 0.6439 - val_Domain_accuracy: 0.1478 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7848 - val_Label_loss: 0.7958 - val_loss: 0.7951\n",
      "Epoch 69/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8389 - Domain_loss: 0.4715 - Label_accuracy: 0.9102 - Label_loss: 0.2387 - loss: 0.7100 - val_Domain_accuracy: 0.2402 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8185 - val_Label_loss: 0.6441 - val_loss: 0.6487\n",
      "Epoch 70/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8486 - Domain_loss: 0.4345 - Label_accuracy: 0.9164 - Label_loss: 0.2150 - loss: 0.6480 - val_Domain_accuracy: 0.1772 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7957 - val_Label_loss: 0.7239 - val_loss: 0.7238\n",
      "Epoch 71/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8580 - Domain_loss: 0.4094 - Label_accuracy: 0.9145 - Label_loss: 0.2165 - loss: 0.6257 - val_Domain_accuracy: 0.3076 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8228 - val_Label_loss: 0.6487 - val_loss: 0.6519\n",
      "Epoch 72/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8620 - Domain_loss: 0.4036 - Label_accuracy: 0.9090 - Label_loss: 0.2319 - loss: 0.6331 - val_Domain_accuracy: 0.1402 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7793 - val_Label_loss: 0.7374 - val_loss: 0.7379\n",
      "Epoch 73/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8558 - Domain_loss: 0.4194 - Label_accuracy: 0.9157 - Label_loss: 0.2166 - loss: 0.6367 - val_Domain_accuracy: 0.1685 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8207 - val_Label_loss: 0.6672 - val_loss: 0.6709\n",
      "Epoch 74/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8601 - Domain_loss: 0.4053 - Label_accuracy: 0.9148 - Label_loss: 0.2165 - loss: 0.6229 - val_Domain_accuracy: 0.3576 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8098 - val_Label_loss: 0.8106 - val_loss: 0.8151\n",
      "Epoch 75/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8586 - Domain_loss: 0.3998 - Label_accuracy: 0.9151 - Label_loss: 0.2084 - loss: 0.6077 - val_Domain_accuracy: 0.1630 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8130 - val_Label_loss: 0.7380 - val_loss: 0.7421\n",
      "Epoch 76/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8525 - Domain_loss: 0.4474 - Label_accuracy: 0.9130 - Label_loss: 0.2162 - loss: 0.6642 - val_Domain_accuracy: 0.2772 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 0.7539 - val_loss: 0.7559\n",
      "Epoch 77/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8549 - Domain_loss: 0.4140 - Label_accuracy: 0.9149 - Label_loss: 0.2152 - loss: 0.6303 - val_Domain_accuracy: 0.1870 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8207 - val_Label_loss: 0.6724 - val_loss: 0.6762\n",
      "Epoch 78/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8595 - Domain_loss: 0.4029 - Label_accuracy: 0.9181 - Label_loss: 0.2021 - loss: 0.6053 - val_Domain_accuracy: 0.3054 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8250 - val_Label_loss: 0.7203 - val_loss: 0.7248\n",
      "Epoch 79/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8583 - Domain_loss: 0.4103 - Label_accuracy: 0.9164 - Label_loss: 0.2056 - loss: 0.6142 - val_Domain_accuracy: 0.2174 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7935 - val_Label_loss: 0.7386 - val_loss: 0.7422\n",
      "Epoch 80/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8626 - Domain_loss: 0.3992 - Label_accuracy: 0.9182 - Label_loss: 0.2072 - loss: 0.6054 - val_Domain_accuracy: 0.2098 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7891 - val_Label_loss: 0.8132 - val_loss: 0.8158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #1\n",
      "train_feature shape: (7642, 5, 10, 256)\n",
      "train_targets shape: (7642, 5)\n",
      "train_domin shape: (7642, 9)\n",
      "Epoch 1/80\n",
      "239/239 - 18s - 77ms/step - Domain_accuracy: 0.4508 - Domain_loss: 1.7235 - Label_accuracy: 0.7448 - Label_loss: 0.7996 - loss: 2.5238 - val_Domain_accuracy: 0.3186 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6759 - val_Label_loss: 0.8699 - val_loss: 0.8830\n",
      "Epoch 2/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.6437 - Domain_loss: 1.0388 - Label_accuracy: 0.8338 - Label_loss: 0.4361 - loss: 1.4745 - val_Domain_accuracy: 0.2139 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6417 - val_Label_loss: 1.2406 - val_loss: 1.2529\n",
      "Epoch 3/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.6858 - Domain_loss: 0.9395 - Label_accuracy: 0.8633 - Label_loss: 0.3706 - loss: 1.3100 - val_Domain_accuracy: 0.0981 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6538 - val_Label_loss: 1.0992 - val_loss: 1.1105\n",
      "Epoch 4/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.7261 - Domain_loss: 0.8228 - Label_accuracy: 0.8756 - Label_loss: 0.3228 - loss: 1.1456 - val_Domain_accuracy: 0.1918 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6549 - val_Label_loss: 1.2631 - val_loss: 1.2734\n",
      "Epoch 5/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.7484 - Domain_loss: 0.7530 - Label_accuracy: 0.8879 - Label_loss: 0.2943 - loss: 1.0470 - val_Domain_accuracy: 0.0540 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7299 - val_Label_loss: 0.8591 - val_loss: 0.8641\n",
      "Epoch 6/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.7359 - Domain_loss: 0.7780 - Label_accuracy: 0.8979 - Label_loss: 0.2591 - loss: 1.0373 - val_Domain_accuracy: 0.2007 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7398 - val_Label_loss: 1.0260 - val_loss: 1.0251\n",
      "Epoch 7/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.7741 - Domain_loss: 0.6625 - Label_accuracy: 0.9008 - Label_loss: 0.2598 - loss: 0.9225 - val_Domain_accuracy: 0.1929 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7398 - val_Label_loss: 0.8297 - val_loss: 0.8247\n",
      "Epoch 8/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.7676 - Domain_loss: 0.6683 - Label_accuracy: 0.9087 - Label_loss: 0.2366 - loss: 0.9050 - val_Domain_accuracy: 0.0992 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7332 - val_Label_loss: 1.0349 - val_loss: 1.0362\n",
      "Epoch 9/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.7745 - Domain_loss: 0.6587 - Label_accuracy: 0.9146 - Label_loss: 0.2256 - loss: 0.8843 - val_Domain_accuracy: 0.0485 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7773 - val_Label_loss: 0.7232 - val_loss: 0.7220\n",
      "Epoch 10/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.7834 - Domain_loss: 0.6259 - Label_accuracy: 0.9197 - Label_loss: 0.2062 - loss: 0.8324 - val_Domain_accuracy: 0.2690 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6946 - val_Label_loss: 1.2089 - val_loss: 1.2108\n",
      "Epoch 11/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8028 - Domain_loss: 0.5860 - Label_accuracy: 0.9293 - Label_loss: 0.1911 - loss: 0.7770 - val_Domain_accuracy: 0.2889 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7519 - val_Label_loss: 1.0361 - val_loss: 1.0409\n",
      "Epoch 12/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.7963 - Domain_loss: 0.5941 - Label_accuracy: 0.9293 - Label_loss: 0.1894 - loss: 0.7836 - val_Domain_accuracy: 0.0981 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7067 - val_Label_loss: 1.0630 - val_loss: 1.0643\n",
      "Epoch 13/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8024 - Domain_loss: 0.5661 - Label_accuracy: 0.9317 - Label_loss: 0.1816 - loss: 0.7479 - val_Domain_accuracy: 0.1389 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7585 - val_Label_loss: 1.0498 - val_loss: 1.0437\n",
      "Epoch 14/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8074 - Domain_loss: 0.5471 - Label_accuracy: 0.9333 - Label_loss: 0.1732 - loss: 0.7203 - val_Domain_accuracy: 0.1841 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7100 - val_Label_loss: 1.3783 - val_loss: 1.3817\n",
      "Epoch 15/80\n",
      "239/239 - 9s - 39ms/step - Domain_accuracy: 0.8118 - Domain_loss: 0.5569 - Label_accuracy: 0.9335 - Label_loss: 0.1724 - loss: 0.7292 - val_Domain_accuracy: 0.1510 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6858 - val_Label_loss: 1.1470 - val_loss: 1.1465\n",
      "Epoch 16/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8114 - Domain_loss: 0.5417 - Label_accuracy: 0.9354 - Label_loss: 0.1662 - loss: 0.7077 - val_Domain_accuracy: 0.0474 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7530 - val_Label_loss: 0.9426 - val_loss: 0.9388\n",
      "Epoch 17/80\n",
      "239/239 - 9s - 39ms/step - Domain_accuracy: 0.8086 - Domain_loss: 0.5567 - Label_accuracy: 0.9360 - Label_loss: 0.1649 - loss: 0.7209 - val_Domain_accuracy: 0.2117 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7464 - val_Label_loss: 1.0890 - val_loss: 1.0849\n",
      "Epoch 18/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8245 - Domain_loss: 0.5109 - Label_accuracy: 0.9437 - Label_loss: 0.1457 - loss: 0.6563 - val_Domain_accuracy: 0.0617 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7122 - val_Label_loss: 1.2023 - val_loss: 1.1923\n",
      "Epoch 19/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8193 - Domain_loss: 0.5325 - Label_accuracy: 0.9477 - Label_loss: 0.1398 - loss: 0.6719 - val_Domain_accuracy: 0.1036 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6891 - val_Label_loss: 1.3417 - val_loss: 1.3413\n",
      "Epoch 20/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8360 - Domain_loss: 0.4747 - Label_accuracy: 0.9501 - Label_loss: 0.1346 - loss: 0.6094 - val_Domain_accuracy: 0.1323 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7751 - val_Label_loss: 1.1224 - val_loss: 1.1156\n",
      "Epoch 21/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8304 - Domain_loss: 0.4759 - Label_accuracy: 0.9460 - Label_loss: 0.1394 - loss: 0.6151 - val_Domain_accuracy: 0.1533 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7277 - val_Label_loss: 1.5689 - val_loss: 1.5634\n",
      "Epoch 22/80\n",
      "239/239 - 9s - 39ms/step - Domain_accuracy: 0.8305 - Domain_loss: 0.4882 - Label_accuracy: 0.9478 - Label_loss: 0.1360 - loss: 0.6240 - val_Domain_accuracy: 0.0386 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7552 - val_Label_loss: 1.0391 - val_loss: 1.0251\n",
      "Epoch 23/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8274 - Domain_loss: 0.5000 - Label_accuracy: 0.9525 - Label_loss: 0.1254 - loss: 0.6254 - val_Domain_accuracy: 0.0849 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7310 - val_Label_loss: 1.2611 - val_loss: 1.2520\n",
      "Epoch 24/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8376 - Domain_loss: 0.4609 - Label_accuracy: 0.9546 - Label_loss: 0.1181 - loss: 0.5789 - val_Domain_accuracy: 0.1279 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7585 - val_Label_loss: 1.1465 - val_loss: 1.1397\n",
      "Epoch 25/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8286 - Domain_loss: 0.4980 - Label_accuracy: 0.9509 - Label_loss: 0.1301 - loss: 0.6282 - val_Domain_accuracy: 0.1235 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7630 - val_Label_loss: 1.0175 - val_loss: 1.0148\n",
      "Epoch 26/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8486 - Domain_loss: 0.4368 - Label_accuracy: 0.9537 - Label_loss: 0.1197 - loss: 0.5564 - val_Domain_accuracy: 0.0342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7178 - val_Label_loss: 1.2211 - val_loss: 1.2170\n",
      "Epoch 27/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8405 - Domain_loss: 0.4703 - Label_accuracy: 0.9541 - Label_loss: 0.1204 - loss: 0.5903 - val_Domain_accuracy: 0.1169 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7100 - val_Label_loss: 1.2479 - val_loss: 1.2343\n",
      "Epoch 28/80\n",
      "239/239 - 9s - 39ms/step - Domain_accuracy: 0.8353 - Domain_loss: 0.4744 - Label_accuracy: 0.9555 - Label_loss: 0.1209 - loss: 0.5954 - val_Domain_accuracy: 0.1422 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7266 - val_Label_loss: 1.3170 - val_loss: 1.3170\n",
      "Epoch 29/80\n",
      "239/239 - 9s - 39ms/step - Domain_accuracy: 0.8371 - Domain_loss: 0.4852 - Label_accuracy: 0.9543 - Label_loss: 0.1152 - loss: 0.6005 - val_Domain_accuracy: 0.0463 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6736 - val_Label_loss: 1.5215 - val_loss: 1.5198\n",
      "Epoch 30/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8503 - Domain_loss: 0.4328 - Label_accuracy: 0.9562 - Label_loss: 0.1096 - loss: 0.5425 - val_Domain_accuracy: 0.1323 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7288 - val_Label_loss: 1.2306 - val_loss: 1.2294\n",
      "Epoch 31/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8292 - Domain_loss: 0.4888 - Label_accuracy: 0.9579 - Label_loss: 0.1078 - loss: 0.5967 - val_Domain_accuracy: 0.2470 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7067 - val_Label_loss: 1.3555 - val_loss: 1.3433\n",
      "Epoch 32/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8346 - Domain_loss: 0.4822 - Label_accuracy: 0.9615 - Label_loss: 0.1026 - loss: 0.5849 - val_Domain_accuracy: 0.0816 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7012 - val_Label_loss: 1.4571 - val_loss: 1.4476\n",
      "Epoch 33/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8342 - Domain_loss: 0.5150 - Label_accuracy: 0.9594 - Label_loss: 0.1098 - loss: 0.6247 - val_Domain_accuracy: 0.1036 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6979 - val_Label_loss: 1.5971 - val_loss: 1.6057\n",
      "Epoch 34/80\n",
      "239/239 - 9s - 39ms/step - Domain_accuracy: 0.8470 - Domain_loss: 0.4357 - Label_accuracy: 0.9635 - Label_loss: 0.0966 - loss: 0.5323 - val_Domain_accuracy: 0.0750 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7288 - val_Label_loss: 1.3645 - val_loss: 1.3531\n",
      "Epoch 35/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8508 - Domain_loss: 0.4193 - Label_accuracy: 0.9648 - Label_loss: 0.0994 - loss: 0.5186 - val_Domain_accuracy: 0.1389 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7442 - val_Label_loss: 1.2294 - val_loss: 1.2245\n",
      "Epoch 36/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8516 - Domain_loss: 0.4239 - Label_accuracy: 0.9655 - Label_loss: 0.0911 - loss: 0.5150 - val_Domain_accuracy: 0.0739 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7508 - val_Label_loss: 1.2319 - val_loss: 1.2171\n",
      "Epoch 37/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8476 - Domain_loss: 0.4488 - Label_accuracy: 0.9662 - Label_loss: 0.0914 - loss: 0.5404 - val_Domain_accuracy: 0.0441 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7585 - val_Label_loss: 1.1951 - val_loss: 1.1794\n",
      "Epoch 38/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8355 - Domain_loss: 0.4626 - Label_accuracy: 0.9621 - Label_loss: 0.1013 - loss: 0.5640 - val_Domain_accuracy: 0.1069 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7563 - val_Label_loss: 1.1611 - val_loss: 1.1469\n",
      "Epoch 39/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8561 - Domain_loss: 0.4208 - Label_accuracy: 0.9638 - Label_loss: 0.0953 - loss: 0.5161 - val_Domain_accuracy: 0.2514 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7343 - val_Label_loss: 1.4237 - val_loss: 1.4155\n",
      "Epoch 40/80\n",
      "239/239 - 9s - 39ms/step - Domain_accuracy: 0.8405 - Domain_loss: 0.4574 - Label_accuracy: 0.9672 - Label_loss: 0.0885 - loss: 0.5459 - val_Domain_accuracy: 0.1907 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7431 - val_Label_loss: 1.1966 - val_loss: 1.1849\n",
      "Epoch 41/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8428 - Domain_loss: 0.4390 - Label_accuracy: 0.9690 - Label_loss: 0.0871 - loss: 0.5260 - val_Domain_accuracy: 0.1764 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7288 - val_Label_loss: 1.5414 - val_loss: 1.5383\n",
      "Epoch 42/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8503 - Domain_loss: 0.4425 - Label_accuracy: 0.9658 - Label_loss: 0.0897 - loss: 0.5322 - val_Domain_accuracy: 0.1069 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7530 - val_Label_loss: 1.2748 - val_loss: 1.2678\n",
      "Epoch 43/80\n",
      "239/239 - 9s - 39ms/step - Domain_accuracy: 0.8524 - Domain_loss: 0.4273 - Label_accuracy: 0.9692 - Label_loss: 0.0845 - loss: 0.5117 - val_Domain_accuracy: 0.0904 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7376 - val_Label_loss: 1.4991 - val_loss: 1.4918\n",
      "Epoch 44/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8487 - Domain_loss: 0.4431 - Label_accuracy: 0.9691 - Label_loss: 0.0809 - loss: 0.5239 - val_Domain_accuracy: 0.0816 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7563 - val_Label_loss: 1.2732 - val_loss: 1.2516\n",
      "Epoch 45/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8638 - Domain_loss: 0.3905 - Label_accuracy: 0.9730 - Label_loss: 0.0733 - loss: 0.4636 - val_Domain_accuracy: 0.0882 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7166 - val_Label_loss: 1.7099 - val_loss: 1.7106\n",
      "Epoch 46/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8574 - Domain_loss: 0.4216 - Label_accuracy: 0.9685 - Label_loss: 0.0841 - loss: 0.5058 - val_Domain_accuracy: 0.1521 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7023 - val_Label_loss: 1.7181 - val_loss: 1.7085\n",
      "Epoch 47/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8557 - Domain_loss: 0.4116 - Label_accuracy: 0.9681 - Label_loss: 0.0884 - loss: 0.5001 - val_Domain_accuracy: 0.0772 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6902 - val_Label_loss: 1.7808 - val_loss: 1.7786\n",
      "Epoch 48/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8519 - Domain_loss: 0.4240 - Label_accuracy: 0.9696 - Label_loss: 0.0803 - loss: 0.5042 - val_Domain_accuracy: 0.1125 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7266 - val_Label_loss: 1.6262 - val_loss: 1.6181\n",
      "Epoch 49/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8551 - Domain_loss: 0.4132 - Label_accuracy: 0.9729 - Label_loss: 0.0756 - loss: 0.4886 - val_Domain_accuracy: 0.2326 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7122 - val_Label_loss: 1.9428 - val_loss: 1.9181\n",
      "Epoch 50/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8451 - Domain_loss: 0.4521 - Label_accuracy: 0.9678 - Label_loss: 0.0852 - loss: 0.5371 - val_Domain_accuracy: 0.1334 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7365 - val_Label_loss: 1.5191 - val_loss: 1.4955\n",
      "Epoch 51/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8510 - Domain_loss: 0.4324 - Label_accuracy: 0.9740 - Label_loss: 0.0695 - loss: 0.5019 - val_Domain_accuracy: 0.1963 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7420 - val_Label_loss: 1.7658 - val_loss: 1.7594\n",
      "Epoch 52/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8427 - Domain_loss: 0.4458 - Label_accuracy: 0.9716 - Label_loss: 0.0763 - loss: 0.5218 - val_Domain_accuracy: 0.1158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7332 - val_Label_loss: 1.4627 - val_loss: 1.4415\n",
      "Epoch 53/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8417 - Domain_loss: 0.4589 - Label_accuracy: 0.9707 - Label_loss: 0.0767 - loss: 0.5356 - val_Domain_accuracy: 0.0827 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7376 - val_Label_loss: 1.5672 - val_loss: 1.5439\n",
      "Epoch 54/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8557 - Domain_loss: 0.4273 - Label_accuracy: 0.9713 - Label_loss: 0.0763 - loss: 0.5034 - val_Domain_accuracy: 0.0606 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6979 - val_Label_loss: 1.7855 - val_loss: 1.7821\n",
      "Epoch 55/80\n",
      "239/239 - 9s - 39ms/step - Domain_accuracy: 0.8529 - Domain_loss: 0.4288 - Label_accuracy: 0.9698 - Label_loss: 0.0725 - loss: 0.5014 - val_Domain_accuracy: 0.1720 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7762 - val_Label_loss: 1.3473 - val_loss: 1.3244\n",
      "Epoch 56/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8652 - Domain_loss: 0.4033 - Label_accuracy: 0.9747 - Label_loss: 0.0700 - loss: 0.4733 - val_Domain_accuracy: 0.1588 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7519 - val_Label_loss: 1.5090 - val_loss: 1.4979\n",
      "Epoch 57/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8579 - Domain_loss: 0.4078 - Label_accuracy: 0.9774 - Label_loss: 0.0581 - loss: 0.4660 - val_Domain_accuracy: 0.1400 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7630 - val_Label_loss: 1.4590 - val_loss: 1.4334\n",
      "Epoch 58/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8602 - Domain_loss: 0.4054 - Label_accuracy: 0.9750 - Label_loss: 0.0736 - loss: 0.4789 - val_Domain_accuracy: 0.1698 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7619 - val_Label_loss: 1.3726 - val_loss: 1.3658\n",
      "Epoch 59/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8578 - Domain_loss: 0.4023 - Label_accuracy: 0.9750 - Label_loss: 0.0680 - loss: 0.4702 - val_Domain_accuracy: 0.1202 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7100 - val_Label_loss: 2.0755 - val_loss: 2.0713\n",
      "Epoch 60/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8602 - Domain_loss: 0.4133 - Label_accuracy: 0.9776 - Label_loss: 0.0640 - loss: 0.4775 - val_Domain_accuracy: 0.1003 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7200 - val_Label_loss: 1.8951 - val_loss: 1.8915\n",
      "Epoch 61/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8472 - Domain_loss: 0.4342 - Label_accuracy: 0.9755 - Label_loss: 0.0681 - loss: 0.5023 - val_Domain_accuracy: 0.0584 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7299 - val_Label_loss: 1.6277 - val_loss: 1.6169\n",
      "Epoch 62/80\n",
      "239/239 - 9s - 39ms/step - Domain_accuracy: 0.8487 - Domain_loss: 0.4402 - Label_accuracy: 0.9707 - Label_loss: 0.0765 - loss: 0.5165 - val_Domain_accuracy: 0.1312 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7585 - val_Label_loss: 1.3442 - val_loss: 1.3328\n",
      "Epoch 63/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8595 - Domain_loss: 0.4075 - Label_accuracy: 0.9717 - Label_loss: 0.0747 - loss: 0.4820 - val_Domain_accuracy: 0.2591 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7475 - val_Label_loss: 1.4744 - val_loss: 1.4642\n",
      "Epoch 64/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8479 - Domain_loss: 0.4517 - Label_accuracy: 0.9764 - Label_loss: 0.0683 - loss: 0.5193 - val_Domain_accuracy: 0.2249 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7376 - val_Label_loss: 1.9050 - val_loss: 1.8834\n",
      "Epoch 65/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8784 - Domain_loss: 0.3427 - Label_accuracy: 0.9793 - Label_loss: 0.0564 - loss: 0.3989 - val_Domain_accuracy: 0.1334 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7497 - val_Label_loss: 1.6788 - val_loss: 1.6634\n",
      "Epoch 66/80\n",
      "239/239 - 9s - 39ms/step - Domain_accuracy: 0.8629 - Domain_loss: 0.3882 - Label_accuracy: 0.9795 - Label_loss: 0.0539 - loss: 0.4420 - val_Domain_accuracy: 0.2415 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7552 - val_Label_loss: 1.5077 - val_loss: 1.4877\n",
      "Epoch 67/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8623 - Domain_loss: 0.3933 - Label_accuracy: 0.9778 - Label_loss: 0.0599 - loss: 0.4531 - val_Domain_accuracy: 0.1433 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7519 - val_Label_loss: 1.4949 - val_loss: 1.4991\n",
      "Epoch 68/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8639 - Domain_loss: 0.4079 - Label_accuracy: 0.9761 - Label_loss: 0.0669 - loss: 0.4749 - val_Domain_accuracy: 0.1764 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7663 - val_Label_loss: 1.4155 - val_loss: 1.3992\n",
      "Epoch 69/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8527 - Domain_loss: 0.4163 - Label_accuracy: 0.9774 - Label_loss: 0.0607 - loss: 0.4766 - val_Domain_accuracy: 0.1213 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7409 - val_Label_loss: 1.7500 - val_loss: 1.7397\n",
      "Epoch 70/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8551 - Domain_loss: 0.4226 - Label_accuracy: 0.9744 - Label_loss: 0.0657 - loss: 0.4884 - val_Domain_accuracy: 0.1654 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7795 - val_Label_loss: 1.6886 - val_loss: 1.6680\n",
      "Epoch 71/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8597 - Domain_loss: 0.3995 - Label_accuracy: 0.9747 - Label_loss: 0.0679 - loss: 0.4672 - val_Domain_accuracy: 0.1996 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7795 - val_Label_loss: 1.5133 - val_loss: 1.4919\n",
      "Epoch 72/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8461 - Domain_loss: 0.4389 - Label_accuracy: 0.9779 - Label_loss: 0.0677 - loss: 0.5067 - val_Domain_accuracy: 0.1819 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7740 - val_Label_loss: 1.4596 - val_loss: 1.4442\n",
      "Epoch 73/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8496 - Domain_loss: 0.4335 - Label_accuracy: 0.9776 - Label_loss: 0.0617 - loss: 0.4950 - val_Domain_accuracy: 0.1014 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7387 - val_Label_loss: 1.6225 - val_loss: 1.6145\n",
      "Epoch 74/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8557 - Domain_loss: 0.4165 - Label_accuracy: 0.9791 - Label_loss: 0.0542 - loss: 0.4707 - val_Domain_accuracy: 0.2161 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7288 - val_Label_loss: 1.6933 - val_loss: 1.6739\n",
      "Epoch 75/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8502 - Domain_loss: 0.4359 - Label_accuracy: 0.9764 - Label_loss: 0.0599 - loss: 0.4953 - val_Domain_accuracy: 0.2381 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7409 - val_Label_loss: 1.8708 - val_loss: 1.8692\n",
      "Epoch 76/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8466 - Domain_loss: 0.4497 - Label_accuracy: 0.9768 - Label_loss: 0.0633 - loss: 0.5132 - val_Domain_accuracy: 0.0948 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7354 - val_Label_loss: 1.9042 - val_loss: 1.8906\n",
      "Epoch 77/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8524 - Domain_loss: 0.4261 - Label_accuracy: 0.9793 - Label_loss: 0.0551 - loss: 0.4811 - val_Domain_accuracy: 0.1940 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7453 - val_Label_loss: 1.9612 - val_loss: 1.9466\n",
      "Epoch 78/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8538 - Domain_loss: 0.4127 - Label_accuracy: 0.9810 - Label_loss: 0.0529 - loss: 0.4656 - val_Domain_accuracy: 0.2227 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7001 - val_Label_loss: 2.3458 - val_loss: 2.3512\n",
      "Epoch 79/80\n",
      "239/239 - 9s - 40ms/step - Domain_accuracy: 0.8652 - Domain_loss: 0.3933 - Label_accuracy: 0.9808 - Label_loss: 0.0512 - loss: 0.4440 - val_Domain_accuracy: 0.1940 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7475 - val_Label_loss: 1.8007 - val_loss: 1.7888\n",
      "Epoch 80/80\n",
      "239/239 - 9s - 39ms/step - Domain_accuracy: 0.8478 - Domain_loss: 0.4298 - Label_accuracy: 0.9783 - Label_loss: 0.0590 - loss: 0.4888 - val_Domain_accuracy: 0.1918 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6946 - val_Label_loss: 2.0553 - val_loss: 2.0551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #2\n",
      "train_feature shape: (7759, 5, 10, 256)\n",
      "train_targets shape: (7759, 5)\n",
      "train_domin shape: (7759, 9)\n",
      "Epoch 1/80\n",
      "243/243 - 19s - 78ms/step - Domain_accuracy: 0.4944 - Domain_loss: 1.6466 - Label_accuracy: 0.7470 - Label_loss: 0.7548 - loss: 2.4048 - val_Domain_accuracy: 0.0532 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7519 - val_Label_loss: 0.7358 - val_loss: 0.7451\n",
      "Epoch 2/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.7020 - Domain_loss: 0.9239 - Label_accuracy: 0.8441 - Label_loss: 0.4107 - loss: 1.3358 - val_Domain_accuracy: 0.0684 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 0.5857 - val_loss: 0.5932\n",
      "Epoch 3/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.7451 - Domain_loss: 0.8060 - Label_accuracy: 0.8639 - Label_loss: 0.3513 - loss: 1.1571 - val_Domain_accuracy: 0.1177 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7304 - val_Label_loss: 0.7964 - val_loss: 0.8065\n",
      "Epoch 4/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.7791 - Domain_loss: 0.6763 - Label_accuracy: 0.8709 - Label_loss: 0.3269 - loss: 1.0034 - val_Domain_accuracy: 0.3354 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7570 - val_Label_loss: 0.8446 - val_loss: 0.8552\n",
      "Epoch 5/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.7875 - Domain_loss: 0.6529 - Label_accuracy: 0.8808 - Label_loss: 0.3121 - loss: 0.9649 - val_Domain_accuracy: 0.1392 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7557 - val_Label_loss: 0.7475 - val_loss: 0.7570\n",
      "Epoch 6/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8185 - Domain_loss: 0.5569 - Label_accuracy: 0.8929 - Label_loss: 0.2773 - loss: 0.8324 - val_Domain_accuracy: 0.0949 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7076 - val_Label_loss: 0.8462 - val_loss: 0.8564\n",
      "Epoch 7/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8352 - Domain_loss: 0.5246 - Label_accuracy: 0.8979 - Label_loss: 0.2601 - loss: 0.7844 - val_Domain_accuracy: 0.2684 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8051 - val_Label_loss: 0.6573 - val_loss: 0.6656\n",
      "Epoch 8/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8447 - Domain_loss: 0.4579 - Label_accuracy: 0.9082 - Label_loss: 0.2446 - loss: 0.7034 - val_Domain_accuracy: 0.0671 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7354 - val_Label_loss: 0.9768 - val_loss: 0.9892\n",
      "Epoch 9/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8292 - Domain_loss: 0.5286 - Label_accuracy: 0.9073 - Label_loss: 0.2437 - loss: 0.7723 - val_Domain_accuracy: 0.0848 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 0.7447 - val_loss: 0.7541\n",
      "Epoch 10/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8462 - Domain_loss: 0.4600 - Label_accuracy: 0.9103 - Label_loss: 0.2279 - loss: 0.6882 - val_Domain_accuracy: 0.2342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7987 - val_Label_loss: 0.7714 - val_loss: 0.7812\n",
      "Epoch 11/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8572 - Domain_loss: 0.4296 - Label_accuracy: 0.9136 - Label_loss: 0.2225 - loss: 0.6525 - val_Domain_accuracy: 0.2696 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7684 - val_Label_loss: 0.8904 - val_loss: 0.9016\n",
      "Epoch 12/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8492 - Domain_loss: 0.4559 - Label_accuracy: 0.9188 - Label_loss: 0.2107 - loss: 0.6669 - val_Domain_accuracy: 0.0418 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7873 - val_Label_loss: 0.8013 - val_loss: 0.8114\n",
      "Epoch 13/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8392 - Domain_loss: 0.4638 - Label_accuracy: 0.9176 - Label_loss: 0.2156 - loss: 0.6792 - val_Domain_accuracy: 0.1468 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7570 - val_Label_loss: 0.9308 - val_loss: 0.9426\n",
      "Epoch 14/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8483 - Domain_loss: 0.4496 - Label_accuracy: 0.9189 - Label_loss: 0.2093 - loss: 0.6590 - val_Domain_accuracy: 0.0228 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7570 - val_Label_loss: 0.9463 - val_loss: 0.9583\n",
      "Epoch 15/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8527 - Domain_loss: 0.4390 - Label_accuracy: 0.9229 - Label_loss: 0.2055 - loss: 0.6437 - val_Domain_accuracy: 0.1139 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7127 - val_Label_loss: 1.2986 - val_loss: 1.3151\n",
      "Epoch 16/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8725 - Domain_loss: 0.3764 - Label_accuracy: 0.9294 - Label_loss: 0.1827 - loss: 0.5588 - val_Domain_accuracy: 0.0899 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 0.7570 - val_loss: 0.7666\n",
      "Epoch 17/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8484 - Domain_loss: 0.4534 - Label_accuracy: 0.9228 - Label_loss: 0.1978 - loss: 0.6520 - val_Domain_accuracy: 0.2684 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7734 - val_Label_loss: 1.0619 - val_loss: 1.0753\n",
      "Epoch 18/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8703 - Domain_loss: 0.3956 - Label_accuracy: 0.9323 - Label_loss: 0.1744 - loss: 0.5695 - val_Domain_accuracy: 0.1684 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8241 - val_Label_loss: 0.8059 - val_loss: 0.8161\n",
      "Epoch 19/80\n",
      "243/243 - 10s - 39ms/step - Domain_accuracy: 0.8765 - Domain_loss: 0.3615 - Label_accuracy: 0.9341 - Label_loss: 0.1693 - loss: 0.5318 - val_Domain_accuracy: 0.1228 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7646 - val_Label_loss: 1.0700 - val_loss: 1.0835\n",
      "Epoch 20/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8582 - Domain_loss: 0.4120 - Label_accuracy: 0.9331 - Label_loss: 0.1782 - loss: 0.5899 - val_Domain_accuracy: 0.0671 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7785 - val_Label_loss: 0.9443 - val_loss: 0.9563\n",
      "Epoch 21/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8671 - Domain_loss: 0.3867 - Label_accuracy: 0.9345 - Label_loss: 0.1735 - loss: 0.5602 - val_Domain_accuracy: 0.1633 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7278 - val_Label_loss: 1.0874 - val_loss: 1.1012\n",
      "Epoch 22/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8859 - Domain_loss: 0.3339 - Label_accuracy: 0.9405 - Label_loss: 0.1517 - loss: 0.4861 - val_Domain_accuracy: 0.2177 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7823 - val_Label_loss: 1.0740 - val_loss: 1.0876\n",
      "Epoch 23/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8794 - Domain_loss: 0.3558 - Label_accuracy: 0.9375 - Label_loss: 0.1603 - loss: 0.5168 - val_Domain_accuracy: 0.0759 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7671 - val_Label_loss: 1.0037 - val_loss: 1.0164\n",
      "Epoch 24/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8733 - Domain_loss: 0.3619 - Label_accuracy: 0.9365 - Label_loss: 0.1634 - loss: 0.5252 - val_Domain_accuracy: 0.1013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7962 - val_Label_loss: 0.9791 - val_loss: 0.9914\n",
      "Epoch 25/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8849 - Domain_loss: 0.3400 - Label_accuracy: 0.9412 - Label_loss: 0.1502 - loss: 0.4892 - val_Domain_accuracy: 0.1139 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7873 - val_Label_loss: 0.9632 - val_loss: 0.9754\n",
      "Epoch 26/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8796 - Domain_loss: 0.3586 - Label_accuracy: 0.9411 - Label_loss: 0.1543 - loss: 0.5131 - val_Domain_accuracy: 0.0367 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7684 - val_Label_loss: 0.9733 - val_loss: 0.9856\n",
      "Epoch 27/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8760 - Domain_loss: 0.3717 - Label_accuracy: 0.9443 - Label_loss: 0.1450 - loss: 0.5169 - val_Domain_accuracy: 0.0316 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7848 - val_Label_loss: 0.9169 - val_loss: 0.9285\n",
      "Epoch 28/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8939 - Domain_loss: 0.3105 - Label_accuracy: 0.9506 - Label_loss: 0.1302 - loss: 0.4400 - val_Domain_accuracy: 0.1608 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 1.1163 - val_loss: 1.1304\n",
      "Epoch 29/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8899 - Domain_loss: 0.3347 - Label_accuracy: 0.9482 - Label_loss: 0.1452 - loss: 0.4762 - val_Domain_accuracy: 0.1051 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7759 - val_Label_loss: 1.1246 - val_loss: 1.1389\n",
      "Epoch 30/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8663 - Domain_loss: 0.3965 - Label_accuracy: 0.9460 - Label_loss: 0.1426 - loss: 0.5395 - val_Domain_accuracy: 0.1684 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7595 - val_Label_loss: 0.8800 - val_loss: 0.8912\n",
      "Epoch 31/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8600 - Domain_loss: 0.4017 - Label_accuracy: 0.9506 - Label_loss: 0.1274 - loss: 0.5288 - val_Domain_accuracy: 0.1785 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7519 - val_Label_loss: 1.2589 - val_loss: 1.2749\n",
      "Epoch 32/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8821 - Domain_loss: 0.3596 - Label_accuracy: 0.9505 - Label_loss: 0.1258 - loss: 0.4853 - val_Domain_accuracy: 0.1506 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7823 - val_Label_loss: 1.0476 - val_loss: 1.0608\n",
      "Epoch 33/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8752 - Domain_loss: 0.3617 - Label_accuracy: 0.9561 - Label_loss: 0.1215 - loss: 0.4833 - val_Domain_accuracy: 0.0722 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7797 - val_Label_loss: 1.0758 - val_loss: 1.0895\n",
      "Epoch 34/80\n",
      "243/243 - 10s - 39ms/step - Domain_accuracy: 0.8691 - Domain_loss: 0.3897 - Label_accuracy: 0.9515 - Label_loss: 0.1345 - loss: 0.5229 - val_Domain_accuracy: 0.1101 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8025 - val_Label_loss: 0.9582 - val_loss: 0.9704\n",
      "Epoch 35/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8823 - Domain_loss: 0.3333 - Label_accuracy: 0.9533 - Label_loss: 0.1202 - loss: 0.4535 - val_Domain_accuracy: 0.0962 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7633 - val_Label_loss: 1.1042 - val_loss: 1.1181\n",
      "Epoch 36/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8776 - Domain_loss: 0.3692 - Label_accuracy: 0.9522 - Label_loss: 0.1245 - loss: 0.4944 - val_Domain_accuracy: 0.1494 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7886 - val_Label_loss: 1.0742 - val_loss: 1.0878\n",
      "Epoch 37/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8827 - Domain_loss: 0.3489 - Label_accuracy: 0.9548 - Label_loss: 0.1185 - loss: 0.4681 - val_Domain_accuracy: 0.1114 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7595 - val_Label_loss: 1.2817 - val_loss: 1.2979\n",
      "Epoch 38/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8834 - Domain_loss: 0.3328 - Label_accuracy: 0.9548 - Label_loss: 0.1169 - loss: 0.4499 - val_Domain_accuracy: 0.2025 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7557 - val_Label_loss: 1.3070 - val_loss: 1.3235\n",
      "Epoch 39/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8948 - Domain_loss: 0.3083 - Label_accuracy: 0.9548 - Label_loss: 0.1121 - loss: 0.4209 - val_Domain_accuracy: 0.0456 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7734 - val_Label_loss: 1.1667 - val_loss: 1.1815\n",
      "Epoch 40/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8892 - Domain_loss: 0.3177 - Label_accuracy: 0.9581 - Label_loss: 0.1130 - loss: 0.4313 - val_Domain_accuracy: 0.0709 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7633 - val_Label_loss: 1.2781 - val_loss: 1.2943\n",
      "Epoch 41/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8901 - Domain_loss: 0.3252 - Label_accuracy: 0.9523 - Label_loss: 0.1204 - loss: 0.4442 - val_Domain_accuracy: 0.1949 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7557 - val_Label_loss: 1.3410 - val_loss: 1.3580\n",
      "Epoch 42/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8786 - Domain_loss: 0.3746 - Label_accuracy: 0.9554 - Label_loss: 0.1173 - loss: 0.4913 - val_Domain_accuracy: 0.0835 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7266 - val_Label_loss: 1.3936 - val_loss: 1.4113\n",
      "Epoch 43/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8854 - Domain_loss: 0.3305 - Label_accuracy: 0.9608 - Label_loss: 0.1053 - loss: 0.4361 - val_Domain_accuracy: 0.1430 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7924 - val_Label_loss: 1.1665 - val_loss: 1.1812\n",
      "Epoch 44/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8854 - Domain_loss: 0.3362 - Label_accuracy: 0.9635 - Label_loss: 0.0999 - loss: 0.4359 - val_Domain_accuracy: 0.0241 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7304 - val_Label_loss: 1.4191 - val_loss: 1.4371\n",
      "Epoch 45/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8972 - Domain_loss: 0.3072 - Label_accuracy: 0.9652 - Label_loss: 0.0953 - loss: 0.4020 - val_Domain_accuracy: 0.1038 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7747 - val_Label_loss: 1.4242 - val_loss: 1.4422\n",
      "Epoch 46/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9051 - Domain_loss: 0.2817 - Label_accuracy: 0.9630 - Label_loss: 0.0952 - loss: 0.3773 - val_Domain_accuracy: 0.2456 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7278 - val_Label_loss: 1.8005 - val_loss: 1.8233\n",
      "Epoch 47/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8716 - Domain_loss: 0.3628 - Label_accuracy: 0.9595 - Label_loss: 0.1047 - loss: 0.4673 - val_Domain_accuracy: 0.0987 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7557 - val_Label_loss: 1.5100 - val_loss: 1.5291\n",
      "Epoch 48/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8944 - Domain_loss: 0.2947 - Label_accuracy: 0.9655 - Label_loss: 0.0910 - loss: 0.3853 - val_Domain_accuracy: 0.2405 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7848 - val_Label_loss: 1.3055 - val_loss: 1.3220\n",
      "Epoch 49/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8894 - Domain_loss: 0.3289 - Label_accuracy: 0.9652 - Label_loss: 0.0996 - loss: 0.4286 - val_Domain_accuracy: 0.0671 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7709 - val_Label_loss: 1.4394 - val_loss: 1.4576\n",
      "Epoch 50/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8928 - Domain_loss: 0.3159 - Label_accuracy: 0.9621 - Label_loss: 0.0996 - loss: 0.4157 - val_Domain_accuracy: 0.0873 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7747 - val_Label_loss: 1.4171 - val_loss: 1.4351\n",
      "Epoch 51/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8942 - Domain_loss: 0.3058 - Label_accuracy: 0.9586 - Label_loss: 0.1065 - loss: 0.4121 - val_Domain_accuracy: 0.1468 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 1.4157 - val_loss: 1.4336\n",
      "Epoch 52/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8982 - Domain_loss: 0.3126 - Label_accuracy: 0.9557 - Label_loss: 0.1149 - loss: 0.4274 - val_Domain_accuracy: 0.2228 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7924 - val_Label_loss: 1.2063 - val_loss: 1.2215\n",
      "Epoch 53/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9018 - Domain_loss: 0.2897 - Label_accuracy: 0.9652 - Label_loss: 0.0878 - loss: 0.3781 - val_Domain_accuracy: 0.1329 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7924 - val_Label_loss: 1.2441 - val_loss: 1.2599\n",
      "Epoch 54/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9077 - Domain_loss: 0.2654 - Label_accuracy: 0.9700 - Label_loss: 0.0782 - loss: 0.3442 - val_Domain_accuracy: 0.0987 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7759 - val_Label_loss: 1.4245 - val_loss: 1.4425\n",
      "Epoch 55/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9013 - Domain_loss: 0.2792 - Label_accuracy: 0.9704 - Label_loss: 0.0793 - loss: 0.3574 - val_Domain_accuracy: 0.2443 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7608 - val_Label_loss: 1.7343 - val_loss: 1.7562\n",
      "Epoch 56/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9026 - Domain_loss: 0.2909 - Label_accuracy: 0.9696 - Label_loss: 0.0800 - loss: 0.3711 - val_Domain_accuracy: 0.2025 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7304 - val_Label_loss: 1.8981 - val_loss: 1.9222\n",
      "Epoch 57/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9053 - Domain_loss: 0.2752 - Label_accuracy: 0.9667 - Label_loss: 0.0837 - loss: 0.3581 - val_Domain_accuracy: 0.2342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7443 - val_Label_loss: 1.9460 - val_loss: 1.9706\n",
      "Epoch 58/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9015 - Domain_loss: 0.2788 - Label_accuracy: 0.9665 - Label_loss: 0.0944 - loss: 0.3736 - val_Domain_accuracy: 0.1494 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7785 - val_Label_loss: 1.3361 - val_loss: 1.3530\n",
      "Epoch 59/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8935 - Domain_loss: 0.3054 - Label_accuracy: 0.9653 - Label_loss: 0.0976 - loss: 0.4035 - val_Domain_accuracy: 0.1506 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7747 - val_Label_loss: 1.3660 - val_loss: 1.3833\n",
      "Epoch 60/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8988 - Domain_loss: 0.2852 - Label_accuracy: 0.9674 - Label_loss: 0.0864 - loss: 0.3719 - val_Domain_accuracy: 0.2025 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7734 - val_Label_loss: 1.5861 - val_loss: 1.6062\n",
      "Epoch 61/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9041 - Domain_loss: 0.2822 - Label_accuracy: 0.9678 - Label_loss: 0.0822 - loss: 0.3645 - val_Domain_accuracy: 0.1785 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7899 - val_Label_loss: 1.2942 - val_loss: 1.3106\n",
      "Epoch 62/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9077 - Domain_loss: 0.2675 - Label_accuracy: 0.9692 - Label_loss: 0.0840 - loss: 0.3511 - val_Domain_accuracy: 0.0835 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7658 - val_Label_loss: 1.5100 - val_loss: 1.5291\n",
      "Epoch 63/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9019 - Domain_loss: 0.2897 - Label_accuracy: 0.9678 - Label_loss: 0.0889 - loss: 0.3790 - val_Domain_accuracy: 0.1848 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7734 - val_Label_loss: 1.5375 - val_loss: 1.5570\n",
      "Epoch 64/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9058 - Domain_loss: 0.2771 - Label_accuracy: 0.9689 - Label_loss: 0.0803 - loss: 0.3578 - val_Domain_accuracy: 0.1000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7595 - val_Label_loss: 1.5827 - val_loss: 1.6027\n",
      "Epoch 65/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8906 - Domain_loss: 0.3222 - Label_accuracy: 0.9656 - Label_loss: 0.0906 - loss: 0.4131 - val_Domain_accuracy: 0.0759 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7620 - val_Label_loss: 1.4743 - val_loss: 1.4930\n",
      "Epoch 66/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9031 - Domain_loss: 0.2791 - Label_accuracy: 0.9679 - Label_loss: 0.0870 - loss: 0.3667 - val_Domain_accuracy: 0.2013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 1.1930 - val_loss: 1.2081\n",
      "Epoch 67/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9072 - Domain_loss: 0.2648 - Label_accuracy: 0.9707 - Label_loss: 0.0763 - loss: 0.3412 - val_Domain_accuracy: 0.0468 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7557 - val_Label_loss: 1.6109 - val_loss: 1.6313\n",
      "Epoch 68/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9085 - Domain_loss: 0.2620 - Label_accuracy: 0.9742 - Label_loss: 0.0736 - loss: 0.3360 - val_Domain_accuracy: 0.2000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7684 - val_Label_loss: 1.6394 - val_loss: 1.6601\n",
      "Epoch 69/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8881 - Domain_loss: 0.3296 - Label_accuracy: 0.9693 - Label_loss: 0.0760 - loss: 0.4063 - val_Domain_accuracy: 0.1456 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7722 - val_Label_loss: 1.6694 - val_loss: 1.6906\n",
      "Epoch 70/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8970 - Domain_loss: 0.3038 - Label_accuracy: 0.9746 - Label_loss: 0.0696 - loss: 0.3738 - val_Domain_accuracy: 0.0987 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7620 - val_Label_loss: 1.7185 - val_loss: 1.7403\n",
      "Epoch 71/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9053 - Domain_loss: 0.2822 - Label_accuracy: 0.9716 - Label_loss: 0.0760 - loss: 0.3571 - val_Domain_accuracy: 0.1684 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7519 - val_Label_loss: 1.8672 - val_loss: 1.8908\n",
      "Epoch 72/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8908 - Domain_loss: 0.3111 - Label_accuracy: 0.9713 - Label_loss: 0.0808 - loss: 0.3910 - val_Domain_accuracy: 0.1696 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7886 - val_Label_loss: 1.2131 - val_loss: 1.2285\n",
      "Epoch 73/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8899 - Domain_loss: 0.3161 - Label_accuracy: 0.9750 - Label_loss: 0.0685 - loss: 0.3849 - val_Domain_accuracy: 0.0785 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7747 - val_Label_loss: 1.4661 - val_loss: 1.4846\n",
      "Epoch 74/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8893 - Domain_loss: 0.3306 - Label_accuracy: 0.9713 - Label_loss: 0.0743 - loss: 0.4055 - val_Domain_accuracy: 0.0544 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7671 - val_Label_loss: 1.6086 - val_loss: 1.6290\n",
      "Epoch 75/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8959 - Domain_loss: 0.3049 - Label_accuracy: 0.9720 - Label_loss: 0.0782 - loss: 0.3835 - val_Domain_accuracy: 0.0582 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 1.4330 - val_loss: 1.4511\n",
      "Epoch 76/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9002 - Domain_loss: 0.2926 - Label_accuracy: 0.9716 - Label_loss: 0.0742 - loss: 0.3672 - val_Domain_accuracy: 0.1291 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7582 - val_Label_loss: 1.8391 - val_loss: 1.8623\n",
      "Epoch 77/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9036 - Domain_loss: 0.2834 - Label_accuracy: 0.9716 - Label_loss: 0.0719 - loss: 0.3544 - val_Domain_accuracy: 0.0835 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7456 - val_Label_loss: 1.7391 - val_loss: 1.7611\n",
      "Epoch 78/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8964 - Domain_loss: 0.3103 - Label_accuracy: 0.9733 - Label_loss: 0.0684 - loss: 0.3785 - val_Domain_accuracy: 0.0785 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7848 - val_Label_loss: 1.7160 - val_loss: 1.7377\n",
      "Epoch 79/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8956 - Domain_loss: 0.2950 - Label_accuracy: 0.9738 - Label_loss: 0.0704 - loss: 0.3658 - val_Domain_accuracy: 0.1468 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7608 - val_Label_loss: 1.5079 - val_loss: 1.5270\n",
      "Epoch 80/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.9112 - Domain_loss: 0.2617 - Label_accuracy: 0.9756 - Label_loss: 0.0693 - loss: 0.3309 - val_Domain_accuracy: 0.1253 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7316 - val_Label_loss: 2.2722 - val_loss: 2.3009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #3\n",
      "train_feature shape: (7789, 5, 10, 256)\n",
      "train_targets shape: (7789, 5)\n",
      "train_domin shape: (7789, 9)\n",
      "Epoch 1/80\n",
      "244/244 - 19s - 77ms/step - Domain_accuracy: 0.4694 - Domain_loss: 1.6420 - Label_accuracy: 0.7571 - Label_loss: 0.7738 - loss: 2.4174 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6711 - val_Label_loss: 0.8501 - val_loss: 0.8587\n",
      "Epoch 2/80\n",
      "244/244 - 10s - 39ms/step - Domain_accuracy: 0.6712 - Domain_loss: 0.9822 - Label_accuracy: 0.8525 - Label_loss: 0.3925 - loss: 1.3753 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7697 - val_Label_loss: 0.6644 - val_loss: 0.6710\n",
      "Epoch 3/80\n",
      "244/244 - 10s - 39ms/step - Domain_accuracy: 0.6881 - Domain_loss: 0.9218 - Label_accuracy: 0.8769 - Label_loss: 0.3320 - loss: 1.2548 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6855 - val_Label_loss: 1.1658 - val_loss: 1.1781\n",
      "Epoch 4/80\n",
      "244/244 - 10s - 39ms/step - Domain_accuracy: 0.7309 - Domain_loss: 0.7925 - Label_accuracy: 0.8919 - Label_loss: 0.2934 - loss: 1.0875 - val_Domain_accuracy: 0.0158 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7382 - val_Label_loss: 0.8589 - val_loss: 0.8663\n",
      "Epoch 5/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.7396 - Domain_loss: 0.7547 - Label_accuracy: 0.8987 - Label_loss: 0.2656 - loss: 1.0210 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7671 - val_Label_loss: 0.8672 - val_loss: 0.8753\n",
      "Epoch 6/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.7679 - Domain_loss: 0.7059 - Label_accuracy: 0.9051 - Label_loss: 0.2453 - loss: 0.9487 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7539 - val_Label_loss: 1.0371 - val_loss: 1.0473\n",
      "Epoch 7/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.7661 - Domain_loss: 0.7058 - Label_accuracy: 0.9148 - Label_loss: 0.2196 - loss: 0.9251 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7289 - val_Label_loss: 1.1448 - val_loss: 1.1568\n",
      "Epoch 8/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.7780 - Domain_loss: 0.6557 - Label_accuracy: 0.9163 - Label_loss: 0.2194 - loss: 0.8755 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7868 - val_Label_loss: 0.7963 - val_loss: 0.8041\n",
      "Epoch 9/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.7933 - Domain_loss: 0.6008 - Label_accuracy: 0.9272 - Label_loss: 0.1952 - loss: 0.7938 - val_Domain_accuracy: 0.0263 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7145 - val_Label_loss: 1.4098 - val_loss: 1.4241\n",
      "Epoch 10/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.7982 - Domain_loss: 0.5958 - Label_accuracy: 0.9241 - Label_loss: 0.1999 - loss: 0.7947 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7329 - val_Label_loss: 1.0639 - val_loss: 1.0751\n",
      "Epoch 11/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.7850 - Domain_loss: 0.6168 - Label_accuracy: 0.9363 - Label_loss: 0.1696 - loss: 0.7853 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7776 - val_Label_loss: 0.8723 - val_loss: 0.8799\n",
      "Epoch 12/80\n",
      "244/244 - 10s - 39ms/step - Domain_accuracy: 0.8063 - Domain_loss: 0.5856 - Label_accuracy: 0.9336 - Label_loss: 0.1695 - loss: 0.7557 - val_Domain_accuracy: 0.0421 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7539 - val_Label_loss: 0.9790 - val_loss: 0.9882\n",
      "Epoch 13/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8036 - Domain_loss: 0.5577 - Label_accuracy: 0.9386 - Label_loss: 0.1632 - loss: 0.7215 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7645 - val_Label_loss: 0.7576 - val_loss: 0.7626\n",
      "Epoch 14/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8047 - Domain_loss: 0.5713 - Label_accuracy: 0.9420 - Label_loss: 0.1487 - loss: 0.7195 - val_Domain_accuracy: 0.0145 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7697 - val_Label_loss: 0.9888 - val_loss: 0.9981\n",
      "Epoch 15/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8136 - Domain_loss: 0.5383 - Label_accuracy: 0.9451 - Label_loss: 0.1421 - loss: 0.6802 - val_Domain_accuracy: 0.0224 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7237 - val_Label_loss: 1.3047 - val_loss: 1.3176\n",
      "Epoch 16/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8135 - Domain_loss: 0.5445 - Label_accuracy: 0.9486 - Label_loss: 0.1338 - loss: 0.6795 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7592 - val_Label_loss: 1.0130 - val_loss: 1.0217\n",
      "Epoch 17/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8145 - Domain_loss: 0.5383 - Label_accuracy: 0.9504 - Label_loss: 0.1282 - loss: 0.6660 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7355 - val_Label_loss: 1.1690 - val_loss: 1.1777\n",
      "Epoch 18/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8043 - Domain_loss: 0.5757 - Label_accuracy: 0.9548 - Label_loss: 0.1233 - loss: 0.6995 - val_Domain_accuracy: 0.0145 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 1.2604 - val_loss: 1.2731\n",
      "Epoch 19/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8013 - Domain_loss: 0.5691 - Label_accuracy: 0.9570 - Label_loss: 0.1185 - loss: 0.6880 - val_Domain_accuracy: 0.0039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7368 - val_Label_loss: 1.2549 - val_loss: 1.2671\n",
      "Epoch 20/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8239 - Domain_loss: 0.5086 - Label_accuracy: 0.9546 - Label_loss: 0.1156 - loss: 0.6243 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7474 - val_Label_loss: 1.3890 - val_loss: 1.4005\n",
      "Epoch 21/80\n",
      "244/244 - 10s - 39ms/step - Domain_accuracy: 0.8235 - Domain_loss: 0.5189 - Label_accuracy: 0.9578 - Label_loss: 0.1073 - loss: 0.6272 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7434 - val_Label_loss: 1.3931 - val_loss: 1.4070\n",
      "Epoch 22/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8281 - Domain_loss: 0.4957 - Label_accuracy: 0.9583 - Label_loss: 0.1064 - loss: 0.6028 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7645 - val_Label_loss: 1.2068 - val_loss: 1.2183\n",
      "Epoch 23/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8268 - Domain_loss: 0.4945 - Label_accuracy: 0.9558 - Label_loss: 0.1205 - loss: 0.6153 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7500 - val_Label_loss: 1.4351 - val_loss: 1.4500\n",
      "Epoch 24/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8504 - Domain_loss: 0.4406 - Label_accuracy: 0.9603 - Label_loss: 0.1024 - loss: 0.5424 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7553 - val_Label_loss: 1.2143 - val_loss: 1.2271\n",
      "Epoch 25/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8568 - Domain_loss: 0.4096 - Label_accuracy: 0.9675 - Label_loss: 0.0874 - loss: 0.4980 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7671 - val_Label_loss: 1.2118 - val_loss: 1.2245\n",
      "Epoch 26/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8613 - Domain_loss: 0.3953 - Label_accuracy: 0.9674 - Label_loss: 0.0830 - loss: 0.4770 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 1.4388 - val_loss: 1.4539\n",
      "Epoch 27/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8491 - Domain_loss: 0.4427 - Label_accuracy: 0.9624 - Label_loss: 0.1023 - loss: 0.5449 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7526 - val_Label_loss: 1.5271 - val_loss: 1.5430\n",
      "Epoch 28/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8398 - Domain_loss: 0.4730 - Label_accuracy: 0.9642 - Label_loss: 0.0981 - loss: 0.5716 - val_Domain_accuracy: 0.0118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7513 - val_Label_loss: 1.1411 - val_loss: 1.1528\n",
      "Epoch 29/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8358 - Domain_loss: 0.4732 - Label_accuracy: 0.9707 - Label_loss: 0.0780 - loss: 0.5517 - val_Domain_accuracy: 0.0342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7329 - val_Label_loss: 1.5098 - val_loss: 1.5257\n",
      "Epoch 30/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8449 - Domain_loss: 0.4428 - Label_accuracy: 0.9715 - Label_loss: 0.0799 - loss: 0.5228 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7447 - val_Label_loss: 1.5376 - val_loss: 1.5528\n",
      "Epoch 31/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8353 - Domain_loss: 0.4813 - Label_accuracy: 0.9638 - Label_loss: 0.0991 - loss: 0.5814 - val_Domain_accuracy: 0.0145 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7566 - val_Label_loss: 1.4098 - val_loss: 1.4243\n",
      "Epoch 32/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8515 - Domain_loss: 0.4253 - Label_accuracy: 0.9701 - Label_loss: 0.0800 - loss: 0.5054 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7289 - val_Label_loss: 1.5759 - val_loss: 1.5925\n",
      "Epoch 33/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8461 - Domain_loss: 0.4400 - Label_accuracy: 0.9680 - Label_loss: 0.0851 - loss: 0.5252 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7697 - val_Label_loss: 1.3910 - val_loss: 1.4056\n",
      "Epoch 34/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8610 - Domain_loss: 0.4209 - Label_accuracy: 0.9697 - Label_loss: 0.0781 - loss: 0.4979 - val_Domain_accuracy: 0.0105 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7592 - val_Label_loss: 1.5454 - val_loss: 1.5615\n",
      "Epoch 35/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8494 - Domain_loss: 0.4560 - Label_accuracy: 0.9702 - Label_loss: 0.0771 - loss: 0.5319 - val_Domain_accuracy: 0.0276 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7592 - val_Label_loss: 1.3372 - val_loss: 1.3512\n",
      "Epoch 36/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8539 - Domain_loss: 0.4171 - Label_accuracy: 0.9737 - Label_loss: 0.0670 - loss: 0.4834 - val_Domain_accuracy: 0.0303 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7579 - val_Label_loss: 1.6397 - val_loss: 1.6562\n",
      "Epoch 37/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8495 - Domain_loss: 0.4428 - Label_accuracy: 0.9658 - Label_loss: 0.0966 - loss: 0.5392 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7579 - val_Label_loss: 1.4098 - val_loss: 1.4244\n",
      "Epoch 38/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8488 - Domain_loss: 0.4303 - Label_accuracy: 0.9705 - Label_loss: 0.0754 - loss: 0.5053 - val_Domain_accuracy: 0.0408 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7632 - val_Label_loss: 1.8312 - val_loss: 1.8504\n",
      "Epoch 39/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8568 - Domain_loss: 0.4169 - Label_accuracy: 0.9756 - Label_loss: 0.0681 - loss: 0.4854 - val_Domain_accuracy: 0.0474 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7500 - val_Label_loss: 1.8947 - val_loss: 1.9145\n",
      "Epoch 40/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8570 - Domain_loss: 0.4117 - Label_accuracy: 0.9741 - Label_loss: 0.0667 - loss: 0.4780 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7671 - val_Label_loss: 1.5519 - val_loss: 1.5676\n",
      "Epoch 41/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8533 - Domain_loss: 0.4296 - Label_accuracy: 0.9742 - Label_loss: 0.0716 - loss: 0.5012 - val_Domain_accuracy: 0.0145 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7526 - val_Label_loss: 1.4828 - val_loss: 1.4983\n",
      "Epoch 42/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8473 - Domain_loss: 0.4425 - Label_accuracy: 0.9766 - Label_loss: 0.0611 - loss: 0.5039 - val_Domain_accuracy: 0.0039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7500 - val_Label_loss: 1.3522 - val_loss: 1.3663\n",
      "Epoch 43/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8525 - Domain_loss: 0.4287 - Label_accuracy: 0.9753 - Label_loss: 0.0646 - loss: 0.4929 - val_Domain_accuracy: 0.0039 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7632 - val_Label_loss: 1.4717 - val_loss: 1.4870\n",
      "Epoch 44/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8512 - Domain_loss: 0.4188 - Label_accuracy: 0.9761 - Label_loss: 0.0668 - loss: 0.4850 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7566 - val_Label_loss: 1.4344 - val_loss: 1.4488\n",
      "Epoch 45/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8581 - Domain_loss: 0.4043 - Label_accuracy: 0.9780 - Label_loss: 0.0609 - loss: 0.4658 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7382 - val_Label_loss: 1.7052 - val_loss: 1.7230\n",
      "Epoch 46/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8539 - Domain_loss: 0.4206 - Label_accuracy: 0.9760 - Label_loss: 0.0625 - loss: 0.4830 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7632 - val_Label_loss: 1.8426 - val_loss: 1.8619\n",
      "Epoch 47/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8612 - Domain_loss: 0.3949 - Label_accuracy: 0.9782 - Label_loss: 0.0590 - loss: 0.4531 - val_Domain_accuracy: 0.0447 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7329 - val_Label_loss: 2.1950 - val_loss: 2.2181\n",
      "Epoch 48/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8509 - Domain_loss: 0.4280 - Label_accuracy: 0.9761 - Label_loss: 0.0656 - loss: 0.4937 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7645 - val_Label_loss: 1.4953 - val_loss: 1.5100\n",
      "Epoch 49/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8604 - Domain_loss: 0.3987 - Label_accuracy: 0.9782 - Label_loss: 0.0603 - loss: 0.4598 - val_Domain_accuracy: 0.0079 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7566 - val_Label_loss: 1.6068 - val_loss: 1.6229\n",
      "Epoch 50/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8358 - Domain_loss: 0.4717 - Label_accuracy: 0.9792 - Label_loss: 0.0612 - loss: 0.5329 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7645 - val_Label_loss: 1.5032 - val_loss: 1.5190\n",
      "Epoch 51/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8585 - Domain_loss: 0.4138 - Label_accuracy: 0.9809 - Label_loss: 0.0522 - loss: 0.4653 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 1.8267 - val_loss: 1.8453\n",
      "Epoch 52/80\n",
      "244/244 - 10s - 39ms/step - Domain_accuracy: 0.8571 - Domain_loss: 0.4108 - Label_accuracy: 0.9809 - Label_loss: 0.0496 - loss: 0.4588 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7461 - val_Label_loss: 1.8387 - val_loss: 1.8572\n",
      "Epoch 53/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8657 - Domain_loss: 0.3800 - Label_accuracy: 0.9854 - Label_loss: 0.0406 - loss: 0.4211 - val_Domain_accuracy: 0.0776 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 2.1460 - val_loss: 2.1686\n",
      "Epoch 54/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8448 - Domain_loss: 0.4463 - Label_accuracy: 0.9766 - Label_loss: 0.0669 - loss: 0.5141 - val_Domain_accuracy: 0.0303 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7579 - val_Label_loss: 2.1169 - val_loss: 2.1392\n",
      "Epoch 55/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8429 - Domain_loss: 0.4415 - Label_accuracy: 0.9784 - Label_loss: 0.0575 - loss: 0.4992 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7789 - val_Label_loss: 1.7700 - val_loss: 1.7887\n",
      "Epoch 56/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8608 - Domain_loss: 0.4018 - Label_accuracy: 0.9784 - Label_loss: 0.0563 - loss: 0.4582 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7421 - val_Label_loss: 1.8218 - val_loss: 1.8406\n",
      "Epoch 57/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8527 - Domain_loss: 0.4113 - Label_accuracy: 0.9813 - Label_loss: 0.0546 - loss: 0.4662 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7658 - val_Label_loss: 1.4388 - val_loss: 1.4539\n",
      "Epoch 58/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8525 - Domain_loss: 0.4089 - Label_accuracy: 0.9804 - Label_loss: 0.0560 - loss: 0.4634 - val_Domain_accuracy: 0.0526 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7579 - val_Label_loss: 1.9208 - val_loss: 1.9409\n",
      "Epoch 59/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8651 - Domain_loss: 0.4047 - Label_accuracy: 0.9806 - Label_loss: 0.0499 - loss: 0.4529 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7711 - val_Label_loss: 1.8507 - val_loss: 1.8702\n",
      "Epoch 60/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8529 - Domain_loss: 0.4176 - Label_accuracy: 0.9842 - Label_loss: 0.0482 - loss: 0.4666 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7645 - val_Label_loss: 2.0949 - val_loss: 2.1170\n",
      "Epoch 61/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8472 - Domain_loss: 0.4315 - Label_accuracy: 0.9816 - Label_loss: 0.0512 - loss: 0.4822 - val_Domain_accuracy: 0.0737 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7408 - val_Label_loss: 1.7754 - val_loss: 1.7940\n",
      "Epoch 62/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8507 - Domain_loss: 0.4369 - Label_accuracy: 0.9792 - Label_loss: 0.0599 - loss: 0.4969 - val_Domain_accuracy: 0.0026 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 1.6970 - val_loss: 1.7095\n",
      "Epoch 63/80\n",
      "244/244 - 10s - 39ms/step - Domain_accuracy: 0.8612 - Domain_loss: 0.3957 - Label_accuracy: 0.9815 - Label_loss: 0.0510 - loss: 0.4465 - val_Domain_accuracy: 0.0355 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7934 - val_Label_loss: 1.4216 - val_loss: 1.4364\n",
      "Epoch 64/80\n",
      "244/244 - 10s - 39ms/step - Domain_accuracy: 0.8697 - Domain_loss: 0.3684 - Label_accuracy: 0.9845 - Label_loss: 0.0476 - loss: 0.4159 - val_Domain_accuracy: 0.0000e+00 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7711 - val_Label_loss: 1.6206 - val_loss: 1.6351\n",
      "Epoch 65/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8602 - Domain_loss: 0.3873 - Label_accuracy: 0.9833 - Label_loss: 0.0499 - loss: 0.4358 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7605 - val_Label_loss: 1.6870 - val_loss: 1.7034\n",
      "Epoch 66/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8549 - Domain_loss: 0.4165 - Label_accuracy: 0.9820 - Label_loss: 0.0513 - loss: 0.4667 - val_Domain_accuracy: 0.0750 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7461 - val_Label_loss: 1.8732 - val_loss: 1.8929\n",
      "Epoch 67/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8534 - Domain_loss: 0.4160 - Label_accuracy: 0.9792 - Label_loss: 0.0550 - loss: 0.4704 - val_Domain_accuracy: 0.0342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7645 - val_Label_loss: 1.7101 - val_loss: 1.7281\n",
      "Epoch 68/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8667 - Domain_loss: 0.3786 - Label_accuracy: 0.9856 - Label_loss: 0.0416 - loss: 0.4189 - val_Domain_accuracy: 0.0553 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7526 - val_Label_loss: 1.8761 - val_loss: 1.8959\n",
      "Epoch 69/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8652 - Domain_loss: 0.3871 - Label_accuracy: 0.9822 - Label_loss: 0.0508 - loss: 0.4377 - val_Domain_accuracy: 0.0105 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7592 - val_Label_loss: 1.9120 - val_loss: 1.9321\n",
      "Epoch 70/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8575 - Domain_loss: 0.4004 - Label_accuracy: 0.9827 - Label_loss: 0.0482 - loss: 0.4479 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7750 - val_Label_loss: 1.4520 - val_loss: 1.4670\n",
      "Epoch 71/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8649 - Domain_loss: 0.3702 - Label_accuracy: 0.9843 - Label_loss: 0.0467 - loss: 0.4175 - val_Domain_accuracy: 0.0053 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7645 - val_Label_loss: 2.0651 - val_loss: 2.0867\n",
      "Epoch 72/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8792 - Domain_loss: 0.3414 - Label_accuracy: 0.9850 - Label_loss: 0.0416 - loss: 0.3825 - val_Domain_accuracy: 0.0329 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7553 - val_Label_loss: 2.1383 - val_loss: 2.1608\n",
      "Epoch 73/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8666 - Domain_loss: 0.3882 - Label_accuracy: 0.9838 - Label_loss: 0.0492 - loss: 0.4373 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7579 - val_Label_loss: 1.8144 - val_loss: 1.8335\n",
      "Epoch 74/80\n",
      "244/244 - 10s - 39ms/step - Domain_accuracy: 0.8454 - Domain_loss: 0.4358 - Label_accuracy: 0.9791 - Label_loss: 0.0614 - loss: 0.4974 - val_Domain_accuracy: 0.0013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7724 - val_Label_loss: 1.6729 - val_loss: 1.6904\n",
      "Epoch 75/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8579 - Domain_loss: 0.3973 - Label_accuracy: 0.9828 - Label_loss: 0.0430 - loss: 0.4395 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7618 - val_Label_loss: 1.7250 - val_loss: 1.7431\n",
      "Epoch 76/80\n",
      "244/244 - 10s - 39ms/step - Domain_accuracy: 0.8568 - Domain_loss: 0.4033 - Label_accuracy: 0.9827 - Label_loss: 0.0509 - loss: 0.4536 - val_Domain_accuracy: 0.0066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7724 - val_Label_loss: 2.1626 - val_loss: 2.1854\n",
      "Epoch 77/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8529 - Domain_loss: 0.4194 - Label_accuracy: 0.9854 - Label_loss: 0.0427 - loss: 0.4623 - val_Domain_accuracy: 0.0132 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7658 - val_Label_loss: 2.1756 - val_loss: 2.1984\n",
      "Epoch 78/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8634 - Domain_loss: 0.3791 - Label_accuracy: 0.9869 - Label_loss: 0.0379 - loss: 0.4177 - val_Domain_accuracy: 0.0368 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7724 - val_Label_loss: 1.6773 - val_loss: 1.6950\n",
      "Epoch 79/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8643 - Domain_loss: 0.3861 - Label_accuracy: 0.9883 - Label_loss: 0.0317 - loss: 0.4177 - val_Domain_accuracy: 0.0092 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7763 - val_Label_loss: 1.9321 - val_loss: 1.9524\n",
      "Epoch 80/80\n",
      "244/244 - 10s - 40ms/step - Domain_accuracy: 0.8545 - Domain_loss: 0.4172 - Label_accuracy: 0.9881 - Label_loss: 0.0403 - loss: 0.4570 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7697 - val_Label_loss: 2.0984 - val_loss: 2.1205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #4\n",
      "train_feature shape: (7639, 5, 10, 256)\n",
      "train_targets shape: (7639, 5)\n",
      "train_domin shape: (7639, 9)\n",
      "Epoch 1/80\n",
      "239/239 - 19s - 78ms/step - Domain_accuracy: 0.4710 - Domain_loss: 1.6637 - Label_accuracy: 0.7213 - Label_loss: 0.8892 - loss: 2.5542 - val_Domain_accuracy: 0.2912 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 0.5539 - val_loss: 0.5452\n",
      "Epoch 2/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.6349 - Domain_loss: 1.0601 - Label_accuracy: 0.8158 - Label_loss: 0.4844 - loss: 1.5445 - val_Domain_accuracy: 0.3000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7967 - val_Label_loss: 0.6113 - val_loss: 0.6037\n",
      "Epoch 3/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.6555 - Domain_loss: 1.0438 - Label_accuracy: 0.8407 - Label_loss: 0.4315 - loss: 1.4753 - val_Domain_accuracy: 0.2088 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8099 - val_Label_loss: 0.4963 - val_loss: 0.4917\n",
      "Epoch 4/80\n",
      "239/239 - 10s - 42ms/step - Domain_accuracy: 0.6932 - Domain_loss: 0.9023 - Label_accuracy: 0.8504 - Label_loss: 0.3974 - loss: 1.2998 - val_Domain_accuracy: 0.1593 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7505 - val_Label_loss: 0.6663 - val_loss: 0.6659\n",
      "Epoch 5/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.7663 - Domain_loss: 0.6881 - Label_accuracy: 0.8644 - Label_loss: 0.3548 - loss: 1.0431 - val_Domain_accuracy: 0.2066 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7967 - val_Label_loss: 0.5591 - val_loss: 0.5553\n",
      "Epoch 6/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.7765 - Domain_loss: 0.6499 - Label_accuracy: 0.8691 - Label_loss: 0.3320 - loss: 0.9815 - val_Domain_accuracy: 0.3659 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8055 - val_Label_loss: 0.5390 - val_loss: 0.5313\n",
      "Epoch 7/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.7945 - Domain_loss: 0.5972 - Label_accuracy: 0.8785 - Label_loss: 0.3104 - loss: 0.9079 - val_Domain_accuracy: 0.1857 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 0.6946 - val_loss: 0.6993\n",
      "Epoch 8/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8012 - Domain_loss: 0.5865 - Label_accuracy: 0.8858 - Label_loss: 0.2941 - loss: 0.8807 - val_Domain_accuracy: 0.2154 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7681 - val_Label_loss: 0.7853 - val_loss: 0.7815\n",
      "Epoch 9/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8108 - Domain_loss: 0.5835 - Label_accuracy: 0.8843 - Label_loss: 0.3029 - loss: 0.8868 - val_Domain_accuracy: 0.3275 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7495 - val_Label_loss: 0.7328 - val_loss: 0.7352\n",
      "Epoch 10/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8271 - Domain_loss: 0.5065 - Label_accuracy: 0.8843 - Label_loss: 0.2857 - loss: 0.7924 - val_Domain_accuracy: 0.3396 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7670 - val_Label_loss: 0.6710 - val_loss: 0.6747\n",
      "Epoch 11/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8344 - Domain_loss: 0.4898 - Label_accuracy: 0.8936 - Label_loss: 0.2716 - loss: 0.7611 - val_Domain_accuracy: 0.2912 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8099 - val_Label_loss: 0.5194 - val_loss: 0.5165\n",
      "Epoch 12/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8389 - Domain_loss: 0.4614 - Label_accuracy: 0.8983 - Label_loss: 0.2651 - loss: 0.7268 - val_Domain_accuracy: 0.2286 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7945 - val_Label_loss: 0.6745 - val_loss: 0.6796\n",
      "Epoch 13/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8441 - Domain_loss: 0.4681 - Label_accuracy: 0.9013 - Label_loss: 0.2571 - loss: 0.7255 - val_Domain_accuracy: 0.1780 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8429 - val_Label_loss: 0.5189 - val_loss: 0.5195\n",
      "Epoch 14/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8512 - Domain_loss: 0.4438 - Label_accuracy: 0.9001 - Label_loss: 0.2553 - loss: 0.6992 - val_Domain_accuracy: 0.3033 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8110 - val_Label_loss: 0.5684 - val_loss: 0.5700\n",
      "Epoch 15/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8535 - Domain_loss: 0.4350 - Label_accuracy: 0.9067 - Label_loss: 0.2399 - loss: 0.6750 - val_Domain_accuracy: 0.2429 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.6299 - val_loss: 0.6280\n",
      "Epoch 16/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8616 - Domain_loss: 0.4185 - Label_accuracy: 0.9090 - Label_loss: 0.2295 - loss: 0.6484 - val_Domain_accuracy: 0.2209 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8198 - val_Label_loss: 0.5438 - val_loss: 0.5438\n",
      "Epoch 17/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8615 - Domain_loss: 0.4181 - Label_accuracy: 0.9090 - Label_loss: 0.2290 - loss: 0.6468 - val_Domain_accuracy: 0.1978 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7945 - val_Label_loss: 0.6253 - val_loss: 0.6253\n",
      "Epoch 18/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8650 - Domain_loss: 0.3886 - Label_accuracy: 0.9103 - Label_loss: 0.2369 - loss: 0.6252 - val_Domain_accuracy: 0.1835 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8275 - val_Label_loss: 0.4938 - val_loss: 0.4896\n",
      "Epoch 19/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8653 - Domain_loss: 0.3984 - Label_accuracy: 0.9181 - Label_loss: 0.2126 - loss: 0.6109 - val_Domain_accuracy: 0.2154 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8264 - val_Label_loss: 0.5585 - val_loss: 0.5594\n",
      "Epoch 20/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8593 - Domain_loss: 0.4061 - Label_accuracy: 0.9160 - Label_loss: 0.2169 - loss: 0.6233 - val_Domain_accuracy: 0.1846 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 0.6538 - val_loss: 0.6547\n",
      "Epoch 21/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8714 - Domain_loss: 0.3887 - Label_accuracy: 0.9175 - Label_loss: 0.2111 - loss: 0.5993 - val_Domain_accuracy: 0.1945 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7901 - val_Label_loss: 0.7292 - val_loss: 0.7335\n",
      "Epoch 22/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8633 - Domain_loss: 0.4131 - Label_accuracy: 0.9200 - Label_loss: 0.2071 - loss: 0.6199 - val_Domain_accuracy: 0.1341 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7945 - val_Label_loss: 0.6233 - val_loss: 0.6259\n",
      "Epoch 23/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8718 - Domain_loss: 0.3712 - Label_accuracy: 0.9238 - Label_loss: 0.1950 - loss: 0.5661 - val_Domain_accuracy: 0.1495 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8154 - val_Label_loss: 0.6098 - val_loss: 0.6136\n",
      "Epoch 24/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8729 - Domain_loss: 0.3671 - Label_accuracy: 0.9243 - Label_loss: 0.1961 - loss: 0.5628 - val_Domain_accuracy: 0.2374 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8099 - val_Label_loss: 0.6786 - val_loss: 0.6794\n",
      "Epoch 25/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8811 - Domain_loss: 0.3523 - Label_accuracy: 0.9267 - Label_loss: 0.1854 - loss: 0.5377 - val_Domain_accuracy: 0.3088 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7934 - val_Label_loss: 0.7216 - val_loss: 0.7239\n",
      "Epoch 26/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8726 - Domain_loss: 0.3778 - Label_accuracy: 0.9239 - Label_loss: 0.1894 - loss: 0.5671 - val_Domain_accuracy: 0.2549 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8549 - val_Label_loss: 0.5067 - val_loss: 0.5055\n",
      "Epoch 27/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8644 - Domain_loss: 0.4022 - Label_accuracy: 0.9259 - Label_loss: 0.1943 - loss: 0.5963 - val_Domain_accuracy: 0.1857 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8110 - val_Label_loss: 0.6139 - val_loss: 0.6156\n",
      "Epoch 28/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8772 - Domain_loss: 0.3551 - Label_accuracy: 0.9304 - Label_loss: 0.1737 - loss: 0.5290 - val_Domain_accuracy: 0.2681 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7890 - val_Label_loss: 0.8034 - val_loss: 0.8067\n",
      "Epoch 29/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8769 - Domain_loss: 0.3644 - Label_accuracy: 0.9321 - Label_loss: 0.1669 - loss: 0.5313 - val_Domain_accuracy: 0.2429 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7670 - val_Label_loss: 0.9582 - val_loss: 0.9633\n",
      "Epoch 30/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8788 - Domain_loss: 0.3654 - Label_accuracy: 0.9311 - Label_loss: 0.1786 - loss: 0.5431 - val_Domain_accuracy: 0.0945 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7703 - val_Label_loss: 0.8120 - val_loss: 0.8056\n",
      "Epoch 31/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8696 - Domain_loss: 0.3687 - Label_accuracy: 0.9310 - Label_loss: 0.1740 - loss: 0.5429 - val_Domain_accuracy: 0.1670 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7769 - val_Label_loss: 0.8884 - val_loss: 0.8922\n",
      "Epoch 32/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8717 - Domain_loss: 0.3858 - Label_accuracy: 0.9344 - Label_loss: 0.1732 - loss: 0.5582 - val_Domain_accuracy: 0.2615 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8264 - val_Label_loss: 0.6341 - val_loss: 0.6375\n",
      "Epoch 33/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8636 - Domain_loss: 0.3931 - Label_accuracy: 0.9300 - Label_loss: 0.1774 - loss: 0.5705 - val_Domain_accuracy: 0.2484 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7571 - val_Label_loss: 0.9122 - val_loss: 0.9086\n",
      "Epoch 34/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8783 - Domain_loss: 0.3543 - Label_accuracy: 0.9359 - Label_loss: 0.1678 - loss: 0.5222 - val_Domain_accuracy: 0.1890 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8297 - val_Label_loss: 0.6279 - val_loss: 0.6294\n",
      "Epoch 35/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8883 - Domain_loss: 0.3278 - Label_accuracy: 0.9410 - Label_loss: 0.1513 - loss: 0.4791 - val_Domain_accuracy: 0.1681 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7813 - val_Label_loss: 0.8549 - val_loss: 0.8479\n",
      "Epoch 36/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8762 - Domain_loss: 0.3629 - Label_accuracy: 0.9387 - Label_loss: 0.1624 - loss: 0.5256 - val_Domain_accuracy: 0.2308 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8121 - val_Label_loss: 0.6952 - val_loss: 0.6981\n",
      "Epoch 37/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8783 - Domain_loss: 0.3631 - Label_accuracy: 0.9370 - Label_loss: 0.1569 - loss: 0.5201 - val_Domain_accuracy: 0.2835 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8033 - val_Label_loss: 0.7831 - val_loss: 0.7895\n",
      "Epoch 38/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8876 - Domain_loss: 0.3229 - Label_accuracy: 0.9440 - Label_loss: 0.1466 - loss: 0.4699 - val_Domain_accuracy: 0.1923 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 0.8164 - val_loss: 0.8102\n",
      "Epoch 39/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8738 - Domain_loss: 0.3724 - Label_accuracy: 0.9376 - Label_loss: 0.1586 - loss: 0.5311 - val_Domain_accuracy: 0.2330 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7791 - val_Label_loss: 0.9483 - val_loss: 0.9448\n",
      "Epoch 40/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8767 - Domain_loss: 0.3668 - Label_accuracy: 0.9402 - Label_loss: 0.1537 - loss: 0.5207 - val_Domain_accuracy: 0.2407 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 0.8284 - val_loss: 0.8311\n",
      "Epoch 41/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8749 - Domain_loss: 0.3593 - Label_accuracy: 0.9415 - Label_loss: 0.1465 - loss: 0.5059 - val_Domain_accuracy: 0.1308 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7637 - val_Label_loss: 1.0657 - val_loss: 1.0532\n",
      "Epoch 42/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8773 - Domain_loss: 0.3620 - Label_accuracy: 0.9410 - Label_loss: 0.1509 - loss: 0.5132 - val_Domain_accuracy: 0.1923 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8066 - val_Label_loss: 0.7713 - val_loss: 0.7678\n",
      "Epoch 43/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8813 - Domain_loss: 0.3401 - Label_accuracy: 0.9461 - Label_loss: 0.1536 - loss: 0.4941 - val_Domain_accuracy: 0.1901 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.7835 - val_loss: 0.7819\n",
      "Epoch 44/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8858 - Domain_loss: 0.3451 - Label_accuracy: 0.9453 - Label_loss: 0.1366 - loss: 0.4820 - val_Domain_accuracy: 0.1956 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7857 - val_Label_loss: 0.8620 - val_loss: 0.8599\n",
      "Epoch 45/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8809 - Domain_loss: 0.3473 - Label_accuracy: 0.9458 - Label_loss: 0.1425 - loss: 0.4895 - val_Domain_accuracy: 0.1835 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8143 - val_Label_loss: 0.7974 - val_loss: 0.7896\n",
      "Epoch 46/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8860 - Domain_loss: 0.3321 - Label_accuracy: 0.9514 - Label_loss: 0.1243 - loss: 0.4560 - val_Domain_accuracy: 0.2253 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.8239 - val_loss: 0.8172\n",
      "Epoch 47/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8851 - Domain_loss: 0.3271 - Label_accuracy: 0.9508 - Label_loss: 0.1278 - loss: 0.4551 - val_Domain_accuracy: 0.2088 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7670 - val_Label_loss: 1.1479 - val_loss: 1.1411\n",
      "Epoch 48/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8853 - Domain_loss: 0.3353 - Label_accuracy: 0.9534 - Label_loss: 0.1280 - loss: 0.4628 - val_Domain_accuracy: 0.2000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7945 - val_Label_loss: 0.8795 - val_loss: 0.8724\n",
      "Epoch 49/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8758 - Domain_loss: 0.3623 - Label_accuracy: 0.9495 - Label_loss: 0.1372 - loss: 0.4993 - val_Domain_accuracy: 0.1714 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8121 - val_Label_loss: 0.7569 - val_loss: 0.7500\n",
      "Epoch 50/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8781 - Domain_loss: 0.3513 - Label_accuracy: 0.9510 - Label_loss: 0.1279 - loss: 0.4792 - val_Domain_accuracy: 0.1967 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7868 - val_Label_loss: 1.0707 - val_loss: 1.0715\n",
      "Epoch 51/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8773 - Domain_loss: 0.3700 - Label_accuracy: 0.9533 - Label_loss: 0.1250 - loss: 0.4949 - val_Domain_accuracy: 0.2264 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7824 - val_Label_loss: 1.0043 - val_loss: 1.0076\n",
      "Epoch 52/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8857 - Domain_loss: 0.3215 - Label_accuracy: 0.9525 - Label_loss: 0.1298 - loss: 0.4512 - val_Domain_accuracy: 0.2516 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.8750 - val_loss: 0.8721\n",
      "Epoch 53/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8827 - Domain_loss: 0.3325 - Label_accuracy: 0.9495 - Label_loss: 0.1269 - loss: 0.4597 - val_Domain_accuracy: 0.1780 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 0.8789 - val_loss: 0.8677\n",
      "Epoch 54/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8883 - Domain_loss: 0.3220 - Label_accuracy: 0.9537 - Label_loss: 0.1278 - loss: 0.4498 - val_Domain_accuracy: 0.2242 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7648 - val_Label_loss: 1.1294 - val_loss: 1.1226\n",
      "Epoch 55/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8786 - Domain_loss: 0.3509 - Label_accuracy: 0.9503 - Label_loss: 0.1313 - loss: 0.4823 - val_Domain_accuracy: 0.1780 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 0.9966 - val_loss: 0.9934\n",
      "Epoch 56/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8836 - Domain_loss: 0.3426 - Label_accuracy: 0.9517 - Label_loss: 0.1260 - loss: 0.4687 - val_Domain_accuracy: 0.1791 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7593 - val_Label_loss: 0.9994 - val_loss: 0.9971\n",
      "Epoch 57/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8996 - Domain_loss: 0.2841 - Label_accuracy: 0.9537 - Label_loss: 0.1249 - loss: 0.4086 - val_Domain_accuracy: 0.2055 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7593 - val_Label_loss: 1.1126 - val_loss: 1.1068\n",
      "Epoch 58/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8940 - Domain_loss: 0.3031 - Label_accuracy: 0.9584 - Label_loss: 0.1088 - loss: 0.4117 - val_Domain_accuracy: 0.1198 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7923 - val_Label_loss: 1.0408 - val_loss: 1.0357\n",
      "Epoch 59/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8870 - Domain_loss: 0.3374 - Label_accuracy: 0.9550 - Label_loss: 0.1144 - loss: 0.4520 - val_Domain_accuracy: 0.1824 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7857 - val_Label_loss: 1.0149 - val_loss: 1.0231\n",
      "Epoch 60/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8868 - Domain_loss: 0.3344 - Label_accuracy: 0.9539 - Label_loss: 0.1291 - loss: 0.4634 - val_Domain_accuracy: 0.2407 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7890 - val_Label_loss: 1.0682 - val_loss: 1.0711\n",
      "Epoch 61/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8932 - Domain_loss: 0.3180 - Label_accuracy: 0.9537 - Label_loss: 0.1201 - loss: 0.4382 - val_Domain_accuracy: 0.1484 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.9325 - val_loss: 0.9313\n",
      "Epoch 62/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8836 - Domain_loss: 0.3216 - Label_accuracy: 0.9578 - Label_loss: 0.1116 - loss: 0.4330 - val_Domain_accuracy: 0.2176 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8132 - val_Label_loss: 0.8967 - val_loss: 0.8904\n",
      "Epoch 63/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8942 - Domain_loss: 0.3003 - Label_accuracy: 0.9603 - Label_loss: 0.1072 - loss: 0.4072 - val_Domain_accuracy: 0.2538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8242 - val_Label_loss: 0.7984 - val_loss: 0.7958\n",
      "Epoch 64/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8861 - Domain_loss: 0.3269 - Label_accuracy: 0.9573 - Label_loss: 0.1113 - loss: 0.4383 - val_Domain_accuracy: 0.1725 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 0.9824 - val_loss: 0.9835\n",
      "Epoch 65/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8936 - Domain_loss: 0.3199 - Label_accuracy: 0.9581 - Label_loss: 0.1134 - loss: 0.4334 - val_Domain_accuracy: 0.1901 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7967 - val_Label_loss: 1.0613 - val_loss: 1.0606\n",
      "Epoch 66/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8951 - Domain_loss: 0.3209 - Label_accuracy: 0.9626 - Label_loss: 0.1056 - loss: 0.4262 - val_Domain_accuracy: 0.1187 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 1.0927 - val_loss: 1.0761\n",
      "Epoch 67/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8987 - Domain_loss: 0.2930 - Label_accuracy: 0.9626 - Label_loss: 0.0950 - loss: 0.3879 - val_Domain_accuracy: 0.1604 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 1.1702 - val_loss: 1.1660\n",
      "Epoch 68/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8937 - Domain_loss: 0.3123 - Label_accuracy: 0.9590 - Label_loss: 0.1062 - loss: 0.4185 - val_Domain_accuracy: 0.1912 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7835 - val_Label_loss: 1.2987 - val_loss: 1.3124\n",
      "Epoch 69/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8959 - Domain_loss: 0.3064 - Label_accuracy: 0.9560 - Label_loss: 0.1176 - loss: 0.4240 - val_Domain_accuracy: 0.1945 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 1.0712 - val_loss: 1.0596\n",
      "Epoch 70/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8868 - Domain_loss: 0.3373 - Label_accuracy: 0.9573 - Label_loss: 0.1117 - loss: 0.4490 - val_Domain_accuracy: 0.1484 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 1.2195 - val_loss: 1.2195\n",
      "Epoch 71/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8917 - Domain_loss: 0.3224 - Label_accuracy: 0.9584 - Label_loss: 0.1127 - loss: 0.4352 - val_Domain_accuracy: 0.1527 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7780 - val_Label_loss: 1.0792 - val_loss: 1.0786\n",
      "Epoch 72/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8841 - Domain_loss: 0.3560 - Label_accuracy: 0.9560 - Label_loss: 0.1104 - loss: 0.4664 - val_Domain_accuracy: 0.2165 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7615 - val_Label_loss: 1.1242 - val_loss: 1.1306\n",
      "Epoch 73/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8817 - Domain_loss: 0.3345 - Label_accuracy: 0.9582 - Label_loss: 0.1089 - loss: 0.4432 - val_Domain_accuracy: 0.1978 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 1.0815 - val_loss: 1.0849\n",
      "Epoch 74/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8958 - Domain_loss: 0.3031 - Label_accuracy: 0.9567 - Label_loss: 0.1091 - loss: 0.4117 - val_Domain_accuracy: 0.2055 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8165 - val_Label_loss: 1.0002 - val_loss: 0.9984\n",
      "Epoch 75/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8917 - Domain_loss: 0.3155 - Label_accuracy: 0.9619 - Label_loss: 0.0987 - loss: 0.4143 - val_Domain_accuracy: 0.1791 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8011 - val_Label_loss: 1.0754 - val_loss: 1.0714\n",
      "Epoch 76/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8913 - Domain_loss: 0.3051 - Label_accuracy: 0.9640 - Label_loss: 0.0994 - loss: 0.4047 - val_Domain_accuracy: 0.2000 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8176 - val_Label_loss: 0.9320 - val_loss: 0.9353\n",
      "Epoch 77/80\n",
      "239/239 - 10s - 41ms/step - Domain_accuracy: 0.8949 - Domain_loss: 0.3030 - Label_accuracy: 0.9586 - Label_loss: 0.1066 - loss: 0.4087 - val_Domain_accuracy: 0.1956 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7978 - val_Label_loss: 1.0758 - val_loss: 1.0806\n",
      "Epoch 78/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8911 - Domain_loss: 0.3101 - Label_accuracy: 0.9640 - Label_loss: 0.0987 - loss: 0.4087 - val_Domain_accuracy: 0.2374 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7934 - val_Label_loss: 1.0966 - val_loss: 1.1012\n",
      "Epoch 79/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.9010 - Domain_loss: 0.2807 - Label_accuracy: 0.9627 - Label_loss: 0.0923 - loss: 0.3728 - val_Domain_accuracy: 0.2121 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7813 - val_Label_loss: 1.2858 - val_loss: 1.2783\n",
      "Epoch 80/80\n",
      "239/239 - 10s - 40ms/step - Domain_accuracy: 0.8970 - Domain_loss: 0.3027 - Label_accuracy: 0.9665 - Label_loss: 0.0861 - loss: 0.3884 - val_Domain_accuracy: 0.2429 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7780 - val_Label_loss: 1.3848 - val_loss: 1.3837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #5\n",
      "train_feature shape: (7730, 5, 10, 256)\n",
      "train_targets shape: (7730, 5)\n",
      "train_domin shape: (7730, 9)\n",
      "Epoch 1/80\n",
      "242/242 - 19s - 79ms/step - Domain_accuracy: 0.5061 - Domain_loss: 1.4908 - Label_accuracy: 0.7395 - Label_loss: 0.7986 - loss: 2.2907 - val_Domain_accuracy: 0.6911 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7717 - val_Label_loss: 0.5888 - val_loss: 0.5912\n",
      "Epoch 2/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.6937 - Domain_loss: 0.8874 - Label_accuracy: 0.8193 - Label_loss: 0.4746 - loss: 1.3624 - val_Domain_accuracy: 0.2662 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7692 - val_Label_loss: 0.5772 - val_loss: 0.5803\n",
      "Epoch 3/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.7643 - Domain_loss: 0.6900 - Label_accuracy: 0.8380 - Label_loss: 0.4118 - loss: 1.1018 - val_Domain_accuracy: 0.1355 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7851 - val_Label_loss: 0.5954 - val_loss: 0.5983\n",
      "Epoch 4/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.7727 - Domain_loss: 0.6696 - Label_accuracy: 0.8499 - Label_loss: 0.3861 - loss: 1.0553 - val_Domain_accuracy: 0.0769 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7766 - val_Label_loss: 0.5733 - val_loss: 0.5756\n",
      "Epoch 5/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.7776 - Domain_loss: 0.6497 - Label_accuracy: 0.8589 - Label_loss: 0.3654 - loss: 1.0151 - val_Domain_accuracy: 0.0488 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7741 - val_Label_loss: 0.5899 - val_loss: 0.5890\n",
      "Epoch 6/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8135 - Domain_loss: 0.5299 - Label_accuracy: 0.8658 - Label_loss: 0.3463 - loss: 0.8763 - val_Domain_accuracy: 0.3187 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7851 - val_Label_loss: 0.6093 - val_loss: 0.6037\n",
      "Epoch 7/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8155 - Domain_loss: 0.5497 - Label_accuracy: 0.8691 - Label_loss: 0.3359 - loss: 0.8861 - val_Domain_accuracy: 0.1832 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8095 - val_Label_loss: 0.5432 - val_loss: 0.5426\n",
      "Epoch 8/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8383 - Domain_loss: 0.4727 - Label_accuracy: 0.8847 - Label_loss: 0.3041 - loss: 0.7773 - val_Domain_accuracy: 0.1221 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7643 - val_Label_loss: 0.6682 - val_loss: 0.6707\n",
      "Epoch 9/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8432 - Domain_loss: 0.4630 - Label_accuracy: 0.8807 - Label_loss: 0.3043 - loss: 0.7674 - val_Domain_accuracy: 0.1661 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6935 - val_Label_loss: 0.8411 - val_loss: 0.8465\n",
      "Epoch 10/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8347 - Domain_loss: 0.4850 - Label_accuracy: 0.8825 - Label_loss: 0.2998 - loss: 0.7850 - val_Domain_accuracy: 0.2369 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7863 - val_Label_loss: 0.5567 - val_loss: 0.5538\n",
      "Epoch 11/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8387 - Domain_loss: 0.4793 - Label_accuracy: 0.8851 - Label_loss: 0.2873 - loss: 0.7669 - val_Domain_accuracy: 0.1722 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7155 - val_Label_loss: 0.9451 - val_loss: 0.9523\n",
      "Epoch 12/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8603 - Domain_loss: 0.4029 - Label_accuracy: 0.8973 - Label_loss: 0.2657 - loss: 0.6693 - val_Domain_accuracy: 0.1636 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 0.5824 - val_loss: 0.5837\n",
      "Epoch 13/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8492 - Domain_loss: 0.4633 - Label_accuracy: 0.8939 - Label_loss: 0.2789 - loss: 0.7421 - val_Domain_accuracy: 0.1441 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7497 - val_Label_loss: 0.7054 - val_loss: 0.7074\n",
      "Epoch 14/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8658 - Domain_loss: 0.3986 - Label_accuracy: 0.8997 - Label_loss: 0.2559 - loss: 0.6546 - val_Domain_accuracy: 0.1050 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7753 - val_Label_loss: 0.6825 - val_loss: 0.6835\n",
      "Epoch 15/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8724 - Domain_loss: 0.3582 - Label_accuracy: 0.8990 - Label_loss: 0.2538 - loss: 0.6114 - val_Domain_accuracy: 0.1380 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7558 - val_Label_loss: 0.7721 - val_loss: 0.7749\n",
      "Epoch 16/80\n",
      "242/242 - 10s - 42ms/step - Domain_accuracy: 0.8691 - Domain_loss: 0.3792 - Label_accuracy: 0.9065 - Label_loss: 0.2380 - loss: 0.6180 - val_Domain_accuracy: 0.2515 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7399 - val_Label_loss: 0.7850 - val_loss: 0.7865\n",
      "Epoch 17/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8634 - Domain_loss: 0.4033 - Label_accuracy: 0.8997 - Label_loss: 0.2491 - loss: 0.6521 - val_Domain_accuracy: 0.1136 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7961 - val_Label_loss: 0.6646 - val_loss: 0.6672\n",
      "Epoch 18/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8679 - Domain_loss: 0.3847 - Label_accuracy: 0.9089 - Label_loss: 0.2349 - loss: 0.6192 - val_Domain_accuracy: 0.1050 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7888 - val_Label_loss: 0.6949 - val_loss: 0.6970\n",
      "Epoch 19/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8634 - Domain_loss: 0.3919 - Label_accuracy: 0.9084 - Label_loss: 0.2309 - loss: 0.6228 - val_Domain_accuracy: 0.0977 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7411 - val_Label_loss: 0.7476 - val_loss: 0.7499\n",
      "Epoch 20/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8802 - Domain_loss: 0.3424 - Label_accuracy: 0.9135 - Label_loss: 0.2183 - loss: 0.5607 - val_Domain_accuracy: 0.1001 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7863 - val_Label_loss: 0.6466 - val_loss: 0.6493\n",
      "Epoch 21/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8715 - Domain_loss: 0.3593 - Label_accuracy: 0.9144 - Label_loss: 0.2162 - loss: 0.5757 - val_Domain_accuracy: 0.3565 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7875 - val_Label_loss: 0.7568 - val_loss: 0.7594\n",
      "Epoch 22/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8665 - Domain_loss: 0.3940 - Label_accuracy: 0.9151 - Label_loss: 0.2178 - loss: 0.6116 - val_Domain_accuracy: 0.0842 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7314 - val_Label_loss: 0.9195 - val_loss: 0.9229\n",
      "Epoch 23/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8788 - Domain_loss: 0.3490 - Label_accuracy: 0.9122 - Label_loss: 0.2193 - loss: 0.5682 - val_Domain_accuracy: 0.1270 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7766 - val_Label_loss: 0.7287 - val_loss: 0.7318\n",
      "Epoch 24/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8840 - Domain_loss: 0.3219 - Label_accuracy: 0.9220 - Label_loss: 0.1943 - loss: 0.5163 - val_Domain_accuracy: 0.0769 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 0.6654 - val_loss: 0.6666\n",
      "Epoch 25/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8827 - Domain_loss: 0.3299 - Label_accuracy: 0.9272 - Label_loss: 0.1893 - loss: 0.5196 - val_Domain_accuracy: 0.1233 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7998 - val_Label_loss: 0.6531 - val_loss: 0.6548\n",
      "Epoch 26/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8796 - Domain_loss: 0.3443 - Label_accuracy: 0.9197 - Label_loss: 0.1981 - loss: 0.5420 - val_Domain_accuracy: 0.1380 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8010 - val_Label_loss: 0.6534 - val_loss: 0.6542\n",
      "Epoch 27/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8880 - Domain_loss: 0.3197 - Label_accuracy: 0.9272 - Label_loss: 0.1868 - loss: 0.5067 - val_Domain_accuracy: 0.1294 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7827 - val_Label_loss: 0.7069 - val_loss: 0.7083\n",
      "Epoch 28/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8829 - Domain_loss: 0.3361 - Label_accuracy: 0.9282 - Label_loss: 0.1855 - loss: 0.5217 - val_Domain_accuracy: 0.1258 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8010 - val_Label_loss: 0.6583 - val_loss: 0.6571\n",
      "Epoch 29/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8952 - Domain_loss: 0.3021 - Label_accuracy: 0.9314 - Label_loss: 0.1844 - loss: 0.4866 - val_Domain_accuracy: 0.1087 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7631 - val_Label_loss: 0.8286 - val_loss: 0.8329\n",
      "Epoch 30/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8876 - Domain_loss: 0.3200 - Label_accuracy: 0.9326 - Label_loss: 0.1728 - loss: 0.4923 - val_Domain_accuracy: 0.1270 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7900 - val_Label_loss: 0.7524 - val_loss: 0.7557\n",
      "Epoch 31/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8953 - Domain_loss: 0.3037 - Label_accuracy: 0.9358 - Label_loss: 0.1588 - loss: 0.4622 - val_Domain_accuracy: 0.1600 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7717 - val_Label_loss: 0.8044 - val_loss: 0.8070\n",
      "Epoch 32/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8824 - Domain_loss: 0.3364 - Label_accuracy: 0.9351 - Label_loss: 0.1632 - loss: 0.5001 - val_Domain_accuracy: 0.1697 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 0.7225 - val_loss: 0.7270\n",
      "Epoch 33/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8739 - Domain_loss: 0.3548 - Label_accuracy: 0.9340 - Label_loss: 0.1696 - loss: 0.5243 - val_Domain_accuracy: 0.1074 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7741 - val_Label_loss: 0.8143 - val_loss: 0.8175\n",
      "Epoch 34/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8853 - Domain_loss: 0.3302 - Label_accuracy: 0.9313 - Label_loss: 0.1739 - loss: 0.5046 - val_Domain_accuracy: 0.1612 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7460 - val_Label_loss: 0.9310 - val_loss: 0.9363\n",
      "Epoch 35/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8814 - Domain_loss: 0.3390 - Label_accuracy: 0.9374 - Label_loss: 0.1635 - loss: 0.5031 - val_Domain_accuracy: 0.1563 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7729 - val_Label_loss: 0.8997 - val_loss: 0.9029\n",
      "Epoch 36/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8934 - Domain_loss: 0.3015 - Label_accuracy: 0.9405 - Label_loss: 0.1573 - loss: 0.4587 - val_Domain_accuracy: 0.0684 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7851 - val_Label_loss: 0.7883 - val_loss: 0.7910\n",
      "Epoch 37/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8915 - Domain_loss: 0.3167 - Label_accuracy: 0.9393 - Label_loss: 0.1579 - loss: 0.4749 - val_Domain_accuracy: 0.1343 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8095 - val_Label_loss: 0.7266 - val_loss: 0.7251\n",
      "Epoch 38/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8871 - Domain_loss: 0.3187 - Label_accuracy: 0.9462 - Label_loss: 0.1419 - loss: 0.4606 - val_Domain_accuracy: 0.2002 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7985 - val_Label_loss: 0.8569 - val_loss: 0.8590\n",
      "Epoch 39/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8812 - Domain_loss: 0.3225 - Label_accuracy: 0.9365 - Label_loss: 0.1603 - loss: 0.4823 - val_Domain_accuracy: 0.1245 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7656 - val_Label_loss: 0.8546 - val_loss: 0.8597\n",
      "Epoch 40/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8934 - Domain_loss: 0.3028 - Label_accuracy: 0.9448 - Label_loss: 0.1398 - loss: 0.4427 - val_Domain_accuracy: 0.1221 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7961 - val_Label_loss: 0.8549 - val_loss: 0.8546\n",
      "Epoch 41/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8869 - Domain_loss: 0.3226 - Label_accuracy: 0.9426 - Label_loss: 0.1509 - loss: 0.4742 - val_Domain_accuracy: 0.1209 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7631 - val_Label_loss: 0.9526 - val_loss: 0.9543\n",
      "Epoch 42/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8929 - Domain_loss: 0.2958 - Label_accuracy: 0.9414 - Label_loss: 0.1499 - loss: 0.4456 - val_Domain_accuracy: 0.1074 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7851 - val_Label_loss: 0.9111 - val_loss: 0.9107\n",
      "Epoch 43/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8975 - Domain_loss: 0.2856 - Label_accuracy: 0.9428 - Label_loss: 0.1468 - loss: 0.4320 - val_Domain_accuracy: 0.2210 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7595 - val_Label_loss: 0.9399 - val_loss: 0.9393\n",
      "Epoch 44/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8964 - Domain_loss: 0.2916 - Label_accuracy: 0.9423 - Label_loss: 0.1401 - loss: 0.4322 - val_Domain_accuracy: 0.0781 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8034 - val_Label_loss: 0.8116 - val_loss: 0.8136\n",
      "Epoch 45/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8918 - Domain_loss: 0.3074 - Label_accuracy: 0.9410 - Label_loss: 0.1450 - loss: 0.4524 - val_Domain_accuracy: 0.1587 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7827 - val_Label_loss: 0.8512 - val_loss: 0.8469\n",
      "Epoch 46/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8991 - Domain_loss: 0.2934 - Label_accuracy: 0.9454 - Label_loss: 0.1463 - loss: 0.4400 - val_Domain_accuracy: 0.1636 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 0.8772 - val_loss: 0.8780\n",
      "Epoch 47/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8974 - Domain_loss: 0.2916 - Label_accuracy: 0.9475 - Label_loss: 0.1334 - loss: 0.4250 - val_Domain_accuracy: 0.0879 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7448 - val_Label_loss: 1.0183 - val_loss: 1.0226\n",
      "Epoch 48/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8982 - Domain_loss: 0.2874 - Label_accuracy: 0.9538 - Label_loss: 0.1207 - loss: 0.4086 - val_Domain_accuracy: 0.0598 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 0.9853 - val_loss: 0.9871\n",
      "Epoch 49/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9066 - Domain_loss: 0.2723 - Label_accuracy: 0.9576 - Label_loss: 0.1133 - loss: 0.3852 - val_Domain_accuracy: 0.2454 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7851 - val_Label_loss: 0.9817 - val_loss: 0.9848\n",
      "Epoch 50/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.8928 - Domain_loss: 0.3017 - Label_accuracy: 0.9466 - Label_loss: 0.1382 - loss: 0.4404 - val_Domain_accuracy: 0.0745 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7534 - val_Label_loss: 0.8494 - val_loss: 0.8426\n",
      "Epoch 51/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.9036 - Domain_loss: 0.2747 - Label_accuracy: 0.9459 - Label_loss: 0.1404 - loss: 0.4153 - val_Domain_accuracy: 0.1636 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7875 - val_Label_loss: 0.8487 - val_loss: 0.8429\n",
      "Epoch 52/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9022 - Domain_loss: 0.2815 - Label_accuracy: 0.9539 - Label_loss: 0.1137 - loss: 0.3957 - val_Domain_accuracy: 0.1661 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7741 - val_Label_loss: 0.9948 - val_loss: 1.0002\n",
      "Epoch 53/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9045 - Domain_loss: 0.2674 - Label_accuracy: 0.9508 - Label_loss: 0.1256 - loss: 0.3930 - val_Domain_accuracy: 0.1270 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8107 - val_Label_loss: 0.8107 - val_loss: 0.8085\n",
      "Epoch 54/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.9035 - Domain_loss: 0.2755 - Label_accuracy: 0.9536 - Label_loss: 0.1192 - loss: 0.3944 - val_Domain_accuracy: 0.1123 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7680 - val_Label_loss: 1.1536 - val_loss: 1.1532\n",
      "Epoch 55/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8972 - Domain_loss: 0.2921 - Label_accuracy: 0.9525 - Label_loss: 0.1252 - loss: 0.4169 - val_Domain_accuracy: 0.0904 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7766 - val_Label_loss: 1.0798 - val_loss: 1.0879\n",
      "Epoch 56/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9146 - Domain_loss: 0.2497 - Label_accuracy: 0.9587 - Label_loss: 0.1130 - loss: 0.3630 - val_Domain_accuracy: 0.0952 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7741 - val_Label_loss: 1.1259 - val_loss: 1.1270\n",
      "Epoch 57/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8988 - Domain_loss: 0.2887 - Label_accuracy: 0.9499 - Label_loss: 0.1276 - loss: 0.4168 - val_Domain_accuracy: 0.1465 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7900 - val_Label_loss: 0.9619 - val_loss: 0.9607\n",
      "Epoch 58/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8962 - Domain_loss: 0.2888 - Label_accuracy: 0.9612 - Label_loss: 0.1056 - loss: 0.3940 - val_Domain_accuracy: 0.1270 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7790 - val_Label_loss: 1.0608 - val_loss: 1.0579\n",
      "Epoch 59/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9038 - Domain_loss: 0.2745 - Label_accuracy: 0.9558 - Label_loss: 0.1135 - loss: 0.3879 - val_Domain_accuracy: 0.1673 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 1.0258 - val_loss: 1.0212\n",
      "Epoch 60/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9000 - Domain_loss: 0.2796 - Label_accuracy: 0.9577 - Label_loss: 0.1089 - loss: 0.3887 - val_Domain_accuracy: 0.1465 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 1.0328 - val_loss: 1.0285\n",
      "Epoch 61/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9072 - Domain_loss: 0.2765 - Label_accuracy: 0.9587 - Label_loss: 0.1087 - loss: 0.3853 - val_Domain_accuracy: 0.1538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 1.0878 - val_loss: 1.0813\n",
      "Epoch 62/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8907 - Domain_loss: 0.3006 - Label_accuracy: 0.9529 - Label_loss: 0.1211 - loss: 0.4218 - val_Domain_accuracy: 0.1673 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 0.9232 - val_loss: 0.9260\n",
      "Epoch 63/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9098 - Domain_loss: 0.2550 - Label_accuracy: 0.9574 - Label_loss: 0.1029 - loss: 0.3580 - val_Domain_accuracy: 0.1001 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7790 - val_Label_loss: 1.1122 - val_loss: 1.1127\n",
      "Epoch 64/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8934 - Domain_loss: 0.3072 - Label_accuracy: 0.9581 - Label_loss: 0.1093 - loss: 0.4166 - val_Domain_accuracy: 0.0317 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7790 - val_Label_loss: 1.1210 - val_loss: 1.1252\n",
      "Epoch 65/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9036 - Domain_loss: 0.2774 - Label_accuracy: 0.9595 - Label_loss: 0.1019 - loss: 0.3796 - val_Domain_accuracy: 0.0989 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 1.0100 - val_loss: 1.0087\n",
      "Epoch 66/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8974 - Domain_loss: 0.3000 - Label_accuracy: 0.9590 - Label_loss: 0.1103 - loss: 0.4104 - val_Domain_accuracy: 0.1917 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7766 - val_Label_loss: 1.1029 - val_loss: 1.1031\n",
      "Epoch 67/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.9045 - Domain_loss: 0.2739 - Label_accuracy: 0.9572 - Label_loss: 0.1124 - loss: 0.3863 - val_Domain_accuracy: 0.1050 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 1.1066 - val_loss: 1.1029\n",
      "Epoch 68/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.9028 - Domain_loss: 0.2799 - Label_accuracy: 0.9598 - Label_loss: 0.1093 - loss: 0.3890 - val_Domain_accuracy: 0.0989 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7912 - val_Label_loss: 1.0656 - val_loss: 1.0615\n",
      "Epoch 69/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9111 - Domain_loss: 0.2497 - Label_accuracy: 0.9626 - Label_loss: 0.0999 - loss: 0.3493 - val_Domain_accuracy: 0.0867 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7546 - val_Label_loss: 1.2226 - val_loss: 1.2284\n",
      "Epoch 70/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8986 - Domain_loss: 0.2821 - Label_accuracy: 0.9613 - Label_loss: 0.1000 - loss: 0.3826 - val_Domain_accuracy: 0.1221 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 1.0546 - val_loss: 1.0521\n",
      "Epoch 71/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9010 - Domain_loss: 0.2774 - Label_accuracy: 0.9573 - Label_loss: 0.1056 - loss: 0.3827 - val_Domain_accuracy: 0.1184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8107 - val_Label_loss: 1.0022 - val_loss: 0.9953\n",
      "Epoch 72/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.9102 - Domain_loss: 0.2581 - Label_accuracy: 0.9658 - Label_loss: 0.0933 - loss: 0.3506 - val_Domain_accuracy: 0.1013 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7851 - val_Label_loss: 1.1675 - val_loss: 1.1594\n",
      "Epoch 73/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.9107 - Domain_loss: 0.2511 - Label_accuracy: 0.9633 - Label_loss: 0.1010 - loss: 0.3519 - val_Domain_accuracy: 0.1087 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7900 - val_Label_loss: 1.0343 - val_loss: 1.0322\n",
      "Epoch 74/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.9072 - Domain_loss: 0.2640 - Label_accuracy: 0.9603 - Label_loss: 0.1034 - loss: 0.3678 - val_Domain_accuracy: 0.2002 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7778 - val_Label_loss: 1.0410 - val_loss: 1.0383\n",
      "Epoch 75/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.8990 - Domain_loss: 0.2960 - Label_accuracy: 0.9604 - Label_loss: 0.1029 - loss: 0.3990 - val_Domain_accuracy: 0.1160 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7802 - val_Label_loss: 1.1536 - val_loss: 1.1487\n",
      "Epoch 76/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.9021 - Domain_loss: 0.2835 - Label_accuracy: 0.9607 - Label_loss: 0.1048 - loss: 0.3883 - val_Domain_accuracy: 0.0427 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7814 - val_Label_loss: 1.1794 - val_loss: 1.1842\n",
      "Epoch 77/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.9038 - Domain_loss: 0.2697 - Label_accuracy: 0.9651 - Label_loss: 0.0981 - loss: 0.3677 - val_Domain_accuracy: 0.0952 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7937 - val_Label_loss: 1.0987 - val_loss: 1.0905\n",
      "Epoch 78/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9145 - Domain_loss: 0.2503 - Label_accuracy: 0.9617 - Label_loss: 0.1037 - loss: 0.3529 - val_Domain_accuracy: 0.0733 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7680 - val_Label_loss: 1.1979 - val_loss: 1.2044\n",
      "Epoch 79/80\n",
      "242/242 - 10s - 41ms/step - Domain_accuracy: 0.9158 - Domain_loss: 0.2490 - Label_accuracy: 0.9666 - Label_loss: 0.0861 - loss: 0.3329 - val_Domain_accuracy: 0.1441 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7875 - val_Label_loss: 1.1297 - val_loss: 1.1244\n",
      "Epoch 80/80\n",
      "242/242 - 10s - 40ms/step - Domain_accuracy: 0.9021 - Domain_loss: 0.2728 - Label_accuracy: 0.9627 - Label_loss: 0.1015 - loss: 0.3746 - val_Domain_accuracy: 0.1050 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7961 - val_Label_loss: 1.0358 - val_loss: 1.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #6\n",
      "train_feature shape: (7769, 5, 10, 256)\n",
      "train_targets shape: (7769, 5)\n",
      "train_domin shape: (7769, 9)\n",
      "Epoch 1/80\n",
      "243/243 - 20s - 80ms/step - Domain_accuracy: 0.5217 - Domain_loss: 1.5288 - Label_accuracy: 0.7798 - Label_loss: 0.6719 - loss: 2.2014 - val_Domain_accuracy: 0.5769 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7282 - val_Label_loss: 0.9207 - val_loss: 0.8942\n",
      "Epoch 2/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.6795 - Domain_loss: 0.9755 - Label_accuracy: 0.8908 - Label_loss: 0.3015 - loss: 1.2768 - val_Domain_accuracy: 0.6538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7718 - val_Label_loss: 1.0126 - val_loss: 0.9470\n",
      "Epoch 3/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.7341 - Domain_loss: 0.7882 - Label_accuracy: 0.9136 - Label_loss: 0.2516 - loss: 1.0397 - val_Domain_accuracy: 0.4500 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7372 - val_Label_loss: 1.1060 - val_loss: 1.0653\n",
      "Epoch 4/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.7393 - Domain_loss: 0.7770 - Label_accuracy: 0.9211 - Label_loss: 0.2177 - loss: 0.9946 - val_Domain_accuracy: 0.6744 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7410 - val_Label_loss: 1.0813 - val_loss: 1.0412\n",
      "Epoch 5/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.7334 - Domain_loss: 0.7838 - Label_accuracy: 0.9262 - Label_loss: 0.1963 - loss: 0.9801 - val_Domain_accuracy: 0.3051 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7295 - val_Label_loss: 1.1826 - val_loss: 1.1541\n",
      "Epoch 6/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.7584 - Domain_loss: 0.7120 - Label_accuracy: 0.9373 - Label_loss: 0.1690 - loss: 0.8806 - val_Domain_accuracy: 0.3397 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7500 - val_Label_loss: 1.4289 - val_loss: 1.4065\n",
      "Epoch 7/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.7605 - Domain_loss: 0.7100 - Label_accuracy: 0.9301 - Label_loss: 0.1779 - loss: 0.8878 - val_Domain_accuracy: 0.6487 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7526 - val_Label_loss: 1.2676 - val_loss: 1.1986\n",
      "Epoch 8/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.7695 - Domain_loss: 0.6740 - Label_accuracy: 0.9392 - Label_loss: 0.1721 - loss: 0.8464 - val_Domain_accuracy: 0.4859 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7538 - val_Label_loss: 1.1638 - val_loss: 1.1410\n",
      "Epoch 9/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8037 - Domain_loss: 0.5631 - Label_accuracy: 0.9447 - Label_loss: 0.1460 - loss: 0.7090 - val_Domain_accuracy: 0.5051 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7692 - val_Label_loss: 1.0943 - val_loss: 1.0473\n",
      "Epoch 10/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.7993 - Domain_loss: 0.5885 - Label_accuracy: 0.9432 - Label_loss: 0.1508 - loss: 0.7397 - val_Domain_accuracy: 0.6654 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7551 - val_Label_loss: 1.2173 - val_loss: 1.1808\n",
      "Epoch 11/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8130 - Domain_loss: 0.5502 - Label_accuracy: 0.9553 - Label_loss: 0.1218 - loss: 0.6722 - val_Domain_accuracy: 0.5718 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 1.5178 - val_loss: 1.4746\n",
      "Epoch 12/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8201 - Domain_loss: 0.5410 - Label_accuracy: 0.9538 - Label_loss: 0.1230 - loss: 0.6637 - val_Domain_accuracy: 0.6628 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7885 - val_Label_loss: 1.2123 - val_loss: 1.1881\n",
      "Epoch 13/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.7982 - Domain_loss: 0.5781 - Label_accuracy: 0.9574 - Label_loss: 0.1139 - loss: 0.6919 - val_Domain_accuracy: 0.5410 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7577 - val_Label_loss: 1.3689 - val_loss: 1.3446\n",
      "Epoch 14/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8192 - Domain_loss: 0.5252 - Label_accuracy: 0.9586 - Label_loss: 0.1098 - loss: 0.6353 - val_Domain_accuracy: 0.5141 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7641 - val_Label_loss: 1.2509 - val_loss: 1.2122\n",
      "Epoch 15/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8345 - Domain_loss: 0.4639 - Label_accuracy: 0.9624 - Label_loss: 0.0977 - loss: 0.5617 - val_Domain_accuracy: 0.6474 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7897 - val_Label_loss: 1.1007 - val_loss: 1.0831\n",
      "Epoch 16/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8430 - Domain_loss: 0.4556 - Label_accuracy: 0.9606 - Label_loss: 0.1025 - loss: 0.5581 - val_Domain_accuracy: 0.4128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7179 - val_Label_loss: 1.7206 - val_loss: 1.6733\n",
      "Epoch 17/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8239 - Domain_loss: 0.4968 - Label_accuracy: 0.9577 - Label_loss: 0.1186 - loss: 0.6153 - val_Domain_accuracy: 0.4667 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7538 - val_Label_loss: 1.2357 - val_loss: 1.2078\n",
      "Epoch 18/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8248 - Domain_loss: 0.5055 - Label_accuracy: 0.9660 - Label_loss: 0.0879 - loss: 0.5932 - val_Domain_accuracy: 0.5603 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8077 - val_Label_loss: 1.2837 - val_loss: 1.2467\n",
      "Epoch 19/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8229 - Domain_loss: 0.5003 - Label_accuracy: 0.9655 - Label_loss: 0.0913 - loss: 0.5918 - val_Domain_accuracy: 0.5949 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 1.2765 - val_loss: 1.2389\n",
      "Epoch 20/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8278 - Domain_loss: 0.5035 - Label_accuracy: 0.9602 - Label_loss: 0.1023 - loss: 0.6058 - val_Domain_accuracy: 0.6718 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 1.1438 - val_loss: 1.1099\n",
      "Epoch 21/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8329 - Domain_loss: 0.4805 - Label_accuracy: 0.9687 - Label_loss: 0.0808 - loss: 0.5609 - val_Domain_accuracy: 0.6692 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7795 - val_Label_loss: 1.4041 - val_loss: 1.3848\n",
      "Epoch 22/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8517 - Domain_loss: 0.4177 - Label_accuracy: 0.9746 - Label_loss: 0.0721 - loss: 0.4898 - val_Domain_accuracy: 0.4462 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 1.4787 - val_loss: 1.4650\n",
      "Epoch 23/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8369 - Domain_loss: 0.4611 - Label_accuracy: 0.9681 - Label_loss: 0.0842 - loss: 0.5450 - val_Domain_accuracy: 0.4551 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7590 - val_Label_loss: 1.4698 - val_loss: 1.4412\n",
      "Epoch 24/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8363 - Domain_loss: 0.4716 - Label_accuracy: 0.9686 - Label_loss: 0.0885 - loss: 0.5600 - val_Domain_accuracy: 0.5141 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7885 - val_Label_loss: 1.4398 - val_loss: 1.4151\n",
      "Epoch 25/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8300 - Domain_loss: 0.4903 - Label_accuracy: 0.9620 - Label_loss: 0.1016 - loss: 0.5922 - val_Domain_accuracy: 0.5756 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 1.3616 - val_loss: 1.3186\n",
      "Epoch 26/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8446 - Domain_loss: 0.4481 - Label_accuracy: 0.9737 - Label_loss: 0.0694 - loss: 0.5172 - val_Domain_accuracy: 0.5192 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7897 - val_Label_loss: 1.3031 - val_loss: 1.2609\n",
      "Epoch 27/80\n",
      "243/243 - 10s - 42ms/step - Domain_accuracy: 0.8472 - Domain_loss: 0.4403 - Label_accuracy: 0.9710 - Label_loss: 0.0789 - loss: 0.5194 - val_Domain_accuracy: 0.4923 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 1.4929 - val_loss: 1.4249\n",
      "Epoch 28/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8597 - Domain_loss: 0.4043 - Label_accuracy: 0.9789 - Label_loss: 0.0591 - loss: 0.4630 - val_Domain_accuracy: 0.4103 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 1.6643 - val_loss: 1.6134\n",
      "Epoch 29/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8467 - Domain_loss: 0.4332 - Label_accuracy: 0.9758 - Label_loss: 0.0635 - loss: 0.4962 - val_Domain_accuracy: 0.5423 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7654 - val_Label_loss: 1.7139 - val_loss: 1.6803\n",
      "Epoch 30/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8296 - Domain_loss: 0.4876 - Label_accuracy: 0.9700 - Label_loss: 0.0832 - loss: 0.5707 - val_Domain_accuracy: 0.4795 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7885 - val_Label_loss: 1.6729 - val_loss: 1.6119\n",
      "Epoch 31/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8575 - Domain_loss: 0.4189 - Label_accuracy: 0.9804 - Label_loss: 0.0594 - loss: 0.4779 - val_Domain_accuracy: 0.4705 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7769 - val_Label_loss: 1.5948 - val_loss: 1.5555\n",
      "Epoch 32/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8484 - Domain_loss: 0.4312 - Label_accuracy: 0.9782 - Label_loss: 0.0632 - loss: 0.4942 - val_Domain_accuracy: 0.3423 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7654 - val_Label_loss: 1.6611 - val_loss: 1.6134\n",
      "Epoch 33/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8370 - Domain_loss: 0.4785 - Label_accuracy: 0.9781 - Label_loss: 0.0619 - loss: 0.5406 - val_Domain_accuracy: 0.4974 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7808 - val_Label_loss: 1.6362 - val_loss: 1.5865\n",
      "Epoch 34/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8552 - Domain_loss: 0.4241 - Label_accuracy: 0.9762 - Label_loss: 0.0649 - loss: 0.4889 - val_Domain_accuracy: 0.6795 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 1.6481 - val_loss: 1.5756\n",
      "Epoch 35/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8352 - Domain_loss: 0.4688 - Label_accuracy: 0.9780 - Label_loss: 0.0598 - loss: 0.5282 - val_Domain_accuracy: 0.6385 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7808 - val_Label_loss: 1.6541 - val_loss: 1.5963\n",
      "Epoch 36/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8473 - Domain_loss: 0.4189 - Label_accuracy: 0.9758 - Label_loss: 0.0682 - loss: 0.4871 - val_Domain_accuracy: 0.5436 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7949 - val_Label_loss: 1.3363 - val_loss: 1.3135\n",
      "Epoch 37/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8450 - Domain_loss: 0.4464 - Label_accuracy: 0.9752 - Label_loss: 0.0668 - loss: 0.5130 - val_Domain_accuracy: 0.4718 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7705 - val_Label_loss: 1.7604 - val_loss: 1.7558\n",
      "Epoch 38/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8565 - Domain_loss: 0.4092 - Label_accuracy: 0.9790 - Label_loss: 0.0567 - loss: 0.4659 - val_Domain_accuracy: 0.4346 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7987 - val_Label_loss: 1.5140 - val_loss: 1.4903\n",
      "Epoch 39/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8452 - Domain_loss: 0.4458 - Label_accuracy: 0.9798 - Label_loss: 0.0550 - loss: 0.5008 - val_Domain_accuracy: 0.4628 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7833 - val_Label_loss: 1.5517 - val_loss: 1.5270\n",
      "Epoch 40/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8539 - Domain_loss: 0.4273 - Label_accuracy: 0.9816 - Label_loss: 0.0493 - loss: 0.4765 - val_Domain_accuracy: 0.3782 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 1.8714 - val_loss: 1.8441\n",
      "Epoch 41/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8543 - Domain_loss: 0.4241 - Label_accuracy: 0.9808 - Label_loss: 0.0523 - loss: 0.4761 - val_Domain_accuracy: 0.4205 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8051 - val_Label_loss: 1.2663 - val_loss: 1.2256\n",
      "Epoch 42/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8453 - Domain_loss: 0.4519 - Label_accuracy: 0.9825 - Label_loss: 0.0470 - loss: 0.4987 - val_Domain_accuracy: 0.3718 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7910 - val_Label_loss: 1.9069 - val_loss: 1.8409\n",
      "Epoch 43/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8378 - Domain_loss: 0.4753 - Label_accuracy: 0.9803 - Label_loss: 0.0552 - loss: 0.5305 - val_Domain_accuracy: 0.3897 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8154 - val_Label_loss: 1.4138 - val_loss: 1.3538\n",
      "Epoch 44/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8515 - Domain_loss: 0.4279 - Label_accuracy: 0.9807 - Label_loss: 0.0522 - loss: 0.4797 - val_Domain_accuracy: 0.4410 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7590 - val_Label_loss: 2.1034 - val_loss: 2.0686\n",
      "Epoch 45/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8414 - Domain_loss: 0.4386 - Label_accuracy: 0.9753 - Label_loss: 0.0629 - loss: 0.5016 - val_Domain_accuracy: 0.4859 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7769 - val_Label_loss: 2.0158 - val_loss: 1.9982\n",
      "Epoch 46/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8338 - Domain_loss: 0.4792 - Label_accuracy: 0.9773 - Label_loss: 0.0626 - loss: 0.5417 - val_Domain_accuracy: 0.3577 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8026 - val_Label_loss: 1.4147 - val_loss: 1.3745\n",
      "Epoch 47/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8564 - Domain_loss: 0.4275 - Label_accuracy: 0.9869 - Label_loss: 0.0347 - loss: 0.4623 - val_Domain_accuracy: 0.6128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7833 - val_Label_loss: 1.7877 - val_loss: 1.7174\n",
      "Epoch 48/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8367 - Domain_loss: 0.4739 - Label_accuracy: 0.9830 - Label_loss: 0.0495 - loss: 0.5232 - val_Domain_accuracy: 0.5359 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7500 - val_Label_loss: 2.4162 - val_loss: 2.3337\n",
      "Epoch 49/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8508 - Domain_loss: 0.4202 - Label_accuracy: 0.9798 - Label_loss: 0.0535 - loss: 0.4734 - val_Domain_accuracy: 0.5500 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7679 - val_Label_loss: 2.0300 - val_loss: 1.9656\n",
      "Epoch 50/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8579 - Domain_loss: 0.4118 - Label_accuracy: 0.9797 - Label_loss: 0.0584 - loss: 0.4702 - val_Domain_accuracy: 0.5526 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8064 - val_Label_loss: 1.7345 - val_loss: 1.6856\n",
      "Epoch 51/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8646 - Domain_loss: 0.3787 - Label_accuracy: 0.9839 - Label_loss: 0.0464 - loss: 0.4252 - val_Domain_accuracy: 0.6064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 1.8218 - val_loss: 1.7655\n",
      "Epoch 52/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8657 - Domain_loss: 0.3866 - Label_accuracy: 0.9812 - Label_loss: 0.0511 - loss: 0.4375 - val_Domain_accuracy: 0.6244 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7564 - val_Label_loss: 2.3756 - val_loss: 2.2929\n",
      "Epoch 53/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8569 - Domain_loss: 0.4114 - Label_accuracy: 0.9821 - Label_loss: 0.0513 - loss: 0.4628 - val_Domain_accuracy: 0.4564 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 1.4224 - val_loss: 1.3871\n",
      "Epoch 54/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8562 - Domain_loss: 0.4008 - Label_accuracy: 0.9853 - Label_loss: 0.0375 - loss: 0.4385 - val_Domain_accuracy: 0.1769 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7833 - val_Label_loss: 1.8038 - val_loss: 1.7591\n",
      "Epoch 55/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8574 - Domain_loss: 0.4066 - Label_accuracy: 0.9864 - Label_loss: 0.0395 - loss: 0.4458 - val_Domain_accuracy: 0.4064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8013 - val_Label_loss: 1.3188 - val_loss: 1.3024\n",
      "Epoch 56/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8535 - Domain_loss: 0.4169 - Label_accuracy: 0.9848 - Label_loss: 0.0415 - loss: 0.4583 - val_Domain_accuracy: 0.2064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7564 - val_Label_loss: 2.0846 - val_loss: 1.9979\n",
      "Epoch 57/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8437 - Domain_loss: 0.4394 - Label_accuracy: 0.9815 - Label_loss: 0.0563 - loss: 0.4958 - val_Domain_accuracy: 0.5628 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7833 - val_Label_loss: 2.1557 - val_loss: 2.0963\n",
      "Epoch 58/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8527 - Domain_loss: 0.4219 - Label_accuracy: 0.9858 - Label_loss: 0.0385 - loss: 0.4603 - val_Domain_accuracy: 0.4090 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7833 - val_Label_loss: 2.0232 - val_loss: 1.9694\n",
      "Epoch 59/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8624 - Domain_loss: 0.3858 - Label_accuracy: 0.9870 - Label_loss: 0.0378 - loss: 0.4236 - val_Domain_accuracy: 0.4397 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8038 - val_Label_loss: 1.6389 - val_loss: 1.5960\n",
      "Epoch 60/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8557 - Domain_loss: 0.4045 - Label_accuracy: 0.9883 - Label_loss: 0.0340 - loss: 0.4387 - val_Domain_accuracy: 0.5115 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7974 - val_Label_loss: 1.7966 - val_loss: 1.7411\n",
      "Epoch 61/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8669 - Domain_loss: 0.3871 - Label_accuracy: 0.9879 - Label_loss: 0.0333 - loss: 0.4205 - val_Domain_accuracy: 0.4141 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7744 - val_Label_loss: 1.9539 - val_loss: 1.8914\n",
      "Epoch 62/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8512 - Domain_loss: 0.4177 - Label_accuracy: 0.9876 - Label_loss: 0.0371 - loss: 0.4546 - val_Domain_accuracy: 0.2564 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8013 - val_Label_loss: 1.8411 - val_loss: 1.8177\n",
      "Epoch 63/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8386 - Domain_loss: 0.4687 - Label_accuracy: 0.9822 - Label_loss: 0.0500 - loss: 0.5187 - val_Domain_accuracy: 0.3449 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7577 - val_Label_loss: 2.7574 - val_loss: 2.7333\n",
      "Epoch 64/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8396 - Domain_loss: 0.4668 - Label_accuracy: 0.9835 - Label_loss: 0.0513 - loss: 0.5179 - val_Domain_accuracy: 0.3795 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7910 - val_Label_loss: 1.9015 - val_loss: 1.8263\n",
      "Epoch 65/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8408 - Domain_loss: 0.4573 - Label_accuracy: 0.9870 - Label_loss: 0.0389 - loss: 0.4958 - val_Domain_accuracy: 0.4590 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 1.7099 - val_loss: 1.6720\n",
      "Epoch 66/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8536 - Domain_loss: 0.4214 - Label_accuracy: 0.9870 - Label_loss: 0.0339 - loss: 0.4551 - val_Domain_accuracy: 0.5205 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7846 - val_Label_loss: 1.9754 - val_loss: 1.9419\n",
      "Epoch 67/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8592 - Domain_loss: 0.4137 - Label_accuracy: 0.9865 - Label_loss: 0.0383 - loss: 0.4521 - val_Domain_accuracy: 0.4359 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7859 - val_Label_loss: 2.3605 - val_loss: 2.3033\n",
      "Epoch 68/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8677 - Domain_loss: 0.3879 - Label_accuracy: 0.9882 - Label_loss: 0.0362 - loss: 0.4240 - val_Domain_accuracy: 0.5487 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7628 - val_Label_loss: 2.1466 - val_loss: 2.1132\n",
      "Epoch 69/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8542 - Domain_loss: 0.4008 - Label_accuracy: 0.9893 - Label_loss: 0.0280 - loss: 0.4287 - val_Domain_accuracy: 0.3731 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7628 - val_Label_loss: 2.1376 - val_loss: 2.0953\n",
      "Epoch 70/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8527 - Domain_loss: 0.4077 - Label_accuracy: 0.9884 - Label_loss: 0.0285 - loss: 0.4361 - val_Domain_accuracy: 0.6513 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7923 - val_Label_loss: 2.0455 - val_loss: 2.0200\n",
      "Epoch 71/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8350 - Domain_loss: 0.4793 - Label_accuracy: 0.9856 - Label_loss: 0.0443 - loss: 0.5238 - val_Domain_accuracy: 0.4910 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7756 - val_Label_loss: 2.0248 - val_loss: 2.0200\n",
      "Epoch 72/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8486 - Domain_loss: 0.4201 - Label_accuracy: 0.9884 - Label_loss: 0.0349 - loss: 0.4550 - val_Domain_accuracy: 0.4385 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 1.9991 - val_loss: 1.9582\n",
      "Epoch 73/80\n",
      "243/243 - 10s - 40ms/step - Domain_accuracy: 0.8358 - Domain_loss: 0.4767 - Label_accuracy: 0.9830 - Label_loss: 0.0561 - loss: 0.5330 - val_Domain_accuracy: 0.4295 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7474 - val_Label_loss: 2.6665 - val_loss: 2.6407\n",
      "Epoch 74/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8342 - Domain_loss: 0.4720 - Label_accuracy: 0.9835 - Label_loss: 0.0446 - loss: 0.5162 - val_Domain_accuracy: 0.5462 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7833 - val_Label_loss: 1.8717 - val_loss: 1.8074\n",
      "Epoch 75/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8504 - Domain_loss: 0.4290 - Label_accuracy: 0.9879 - Label_loss: 0.0354 - loss: 0.4644 - val_Domain_accuracy: 0.3192 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7821 - val_Label_loss: 2.0328 - val_loss: 1.9760\n",
      "Epoch 76/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8500 - Domain_loss: 0.4330 - Label_accuracy: 0.9891 - Label_loss: 0.0318 - loss: 0.4650 - val_Domain_accuracy: 0.5077 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7962 - val_Label_loss: 1.8464 - val_loss: 1.8096\n",
      "Epoch 77/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8606 - Domain_loss: 0.3907 - Label_accuracy: 0.9883 - Label_loss: 0.0355 - loss: 0.4261 - val_Domain_accuracy: 0.4474 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7833 - val_Label_loss: 2.2305 - val_loss: 2.1458\n",
      "Epoch 78/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8470 - Domain_loss: 0.4299 - Label_accuracy: 0.9885 - Label_loss: 0.0363 - loss: 0.4664 - val_Domain_accuracy: 0.4615 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7936 - val_Label_loss: 2.1145 - val_loss: 2.0432\n",
      "Epoch 79/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8333 - Domain_loss: 0.4704 - Label_accuracy: 0.9873 - Label_loss: 0.0376 - loss: 0.5081 - val_Domain_accuracy: 0.4359 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7756 - val_Label_loss: 2.2752 - val_loss: 2.2282\n",
      "Epoch 80/80\n",
      "243/243 - 10s - 41ms/step - Domain_accuracy: 0.8634 - Domain_loss: 0.4034 - Label_accuracy: 0.9871 - Label_loss: 0.0341 - loss: 0.4370 - val_Domain_accuracy: 0.4526 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7731 - val_Label_loss: 1.9164 - val_loss: 1.8993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #7\n",
      "train_feature shape: (7583, 5, 10, 256)\n",
      "train_targets shape: (7583, 5)\n",
      "train_domin shape: (7583, 9)\n",
      "Epoch 1/80\n",
      "237/237 - 20s - 82ms/step - Domain_accuracy: 0.4364 - Domain_loss: 1.7108 - Label_accuracy: 0.7140 - Label_loss: 0.8395 - loss: 2.5505 - val_Domain_accuracy: 0.2195 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8478 - val_Label_loss: 0.4804 - val_loss: 0.4895\n",
      "Epoch 2/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.6143 - Domain_loss: 1.1580 - Label_accuracy: 0.7981 - Label_loss: 0.5337 - loss: 1.6918 - val_Domain_accuracy: 0.3758 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8571 - val_Label_loss: 0.3505 - val_loss: 0.3546\n",
      "Epoch 3/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.6661 - Domain_loss: 1.0367 - Label_accuracy: 0.8139 - Label_loss: 0.4836 - loss: 1.5203 - val_Domain_accuracy: 0.0549 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8634 - val_Label_loss: 0.4047 - val_loss: 0.4155\n",
      "Epoch 4/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.6897 - Domain_loss: 0.9301 - Label_accuracy: 0.8212 - Label_loss: 0.4584 - loss: 1.3885 - val_Domain_accuracy: 0.0559 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8944 - val_Label_loss: 0.3023 - val_loss: 0.3084\n",
      "Epoch 5/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.7496 - Domain_loss: 0.7513 - Label_accuracy: 0.8342 - Label_loss: 0.4188 - loss: 1.1701 - val_Domain_accuracy: 0.2008 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8716 - val_Label_loss: 0.3400 - val_loss: 0.3487\n",
      "Epoch 6/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.7692 - Domain_loss: 0.6791 - Label_accuracy: 0.8448 - Label_loss: 0.3905 - loss: 1.0696 - val_Domain_accuracy: 0.3634 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8520 - val_Label_loss: 0.3767 - val_loss: 0.3849\n",
      "Epoch 7/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.7969 - Domain_loss: 0.6298 - Label_accuracy: 0.8501 - Label_loss: 0.3813 - loss: 1.0110 - val_Domain_accuracy: 0.1232 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8675 - val_Label_loss: 0.3203 - val_loss: 0.3275\n",
      "Epoch 8/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8055 - Domain_loss: 0.5799 - Label_accuracy: 0.8524 - Label_loss: 0.3685 - loss: 0.9484 - val_Domain_accuracy: 0.0839 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8613 - val_Label_loss: 0.3304 - val_loss: 0.3388\n",
      "Epoch 9/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8028 - Domain_loss: 0.5810 - Label_accuracy: 0.8614 - Label_loss: 0.3569 - loss: 0.9379 - val_Domain_accuracy: 0.1532 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8965 - val_Label_loss: 0.2773 - val_loss: 0.2834\n",
      "Epoch 10/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8031 - Domain_loss: 0.6038 - Label_accuracy: 0.8638 - Label_loss: 0.3539 - loss: 0.9577 - val_Domain_accuracy: 0.0238 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8706 - val_Label_loss: 0.3174 - val_loss: 0.3243\n",
      "Epoch 11/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8171 - Domain_loss: 0.5451 - Label_accuracy: 0.8672 - Label_loss: 0.3433 - loss: 0.8883 - val_Domain_accuracy: 0.1118 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8551 - val_Label_loss: 0.3557 - val_loss: 0.3638\n",
      "Epoch 12/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8284 - Domain_loss: 0.5140 - Label_accuracy: 0.8738 - Label_loss: 0.3204 - loss: 0.8344 - val_Domain_accuracy: 0.0890 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8478 - val_Label_loss: 0.4200 - val_loss: 0.4309\n",
      "Epoch 13/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8290 - Domain_loss: 0.5041 - Label_accuracy: 0.8725 - Label_loss: 0.3218 - loss: 0.8259 - val_Domain_accuracy: 0.0901 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8644 - val_Label_loss: 0.3845 - val_loss: 0.3917\n",
      "Epoch 14/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8357 - Domain_loss: 0.4849 - Label_accuracy: 0.8858 - Label_loss: 0.2995 - loss: 0.7845 - val_Domain_accuracy: 0.0321 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8623 - val_Label_loss: 0.3493 - val_loss: 0.3576\n",
      "Epoch 15/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8457 - Domain_loss: 0.4596 - Label_accuracy: 0.8869 - Label_loss: 0.2936 - loss: 0.7532 - val_Domain_accuracy: 0.1304 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8944 - val_Label_loss: 0.2882 - val_loss: 0.2938\n",
      "Epoch 16/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8366 - Domain_loss: 0.4612 - Label_accuracy: 0.8840 - Label_loss: 0.2939 - loss: 0.7551 - val_Domain_accuracy: 0.0404 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8623 - val_Label_loss: 0.3454 - val_loss: 0.3538\n",
      "Epoch 17/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8490 - Domain_loss: 0.4397 - Label_accuracy: 0.8912 - Label_loss: 0.2789 - loss: 0.7185 - val_Domain_accuracy: 0.0404 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8727 - val_Label_loss: 0.3399 - val_loss: 0.3443\n",
      "Epoch 18/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8445 - Domain_loss: 0.4556 - Label_accuracy: 0.8883 - Label_loss: 0.2845 - loss: 0.7401 - val_Domain_accuracy: 0.1139 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8727 - val_Label_loss: 0.3369 - val_loss: 0.3453\n",
      "Epoch 19/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8472 - Domain_loss: 0.4307 - Label_accuracy: 0.8903 - Label_loss: 0.2689 - loss: 0.6996 - val_Domain_accuracy: 0.0683 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8696 - val_Label_loss: 0.3629 - val_loss: 0.3682\n",
      "Epoch 20/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8427 - Domain_loss: 0.4572 - Label_accuracy: 0.8969 - Label_loss: 0.2618 - loss: 0.7190 - val_Domain_accuracy: 0.0383 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8675 - val_Label_loss: 0.3760 - val_loss: 0.3855\n",
      "Epoch 21/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8487 - Domain_loss: 0.4542 - Label_accuracy: 0.8953 - Label_loss: 0.2695 - loss: 0.7236 - val_Domain_accuracy: 0.0166 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8571 - val_Label_loss: 0.3983 - val_loss: 0.4084\n",
      "Epoch 22/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8619 - Domain_loss: 0.3942 - Label_accuracy: 0.9032 - Label_loss: 0.2465 - loss: 0.6408 - val_Domain_accuracy: 0.0424 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8872 - val_Label_loss: 0.3070 - val_loss: 0.3149\n",
      "Epoch 23/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8487 - Domain_loss: 0.4377 - Label_accuracy: 0.9000 - Label_loss: 0.2550 - loss: 0.6926 - val_Domain_accuracy: 0.0611 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8727 - val_Label_loss: 0.3406 - val_loss: 0.3475\n",
      "Epoch 24/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8611 - Domain_loss: 0.3954 - Label_accuracy: 0.9054 - Label_loss: 0.2486 - loss: 0.6440 - val_Domain_accuracy: 0.0735 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8665 - val_Label_loss: 0.3628 - val_loss: 0.3662\n",
      "Epoch 25/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8544 - Domain_loss: 0.4173 - Label_accuracy: 0.9058 - Label_loss: 0.2417 - loss: 0.6589 - val_Domain_accuracy: 0.1035 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8768 - val_Label_loss: 0.3608 - val_loss: 0.3697\n",
      "Epoch 26/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8592 - Domain_loss: 0.4072 - Label_accuracy: 0.9064 - Label_loss: 0.2321 - loss: 0.6392 - val_Domain_accuracy: 0.0756 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8882 - val_Label_loss: 0.3158 - val_loss: 0.3237\n",
      "Epoch 27/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8495 - Domain_loss: 0.4402 - Label_accuracy: 0.9101 - Label_loss: 0.2297 - loss: 0.6699 - val_Domain_accuracy: 0.0259 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8944 - val_Label_loss: 0.3433 - val_loss: 0.3493\n",
      "Epoch 28/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8597 - Domain_loss: 0.4067 - Label_accuracy: 0.9069 - Label_loss: 0.2346 - loss: 0.6412 - val_Domain_accuracy: 0.0725 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8944 - val_Label_loss: 0.3411 - val_loss: 0.3444\n",
      "Epoch 29/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8632 - Domain_loss: 0.4017 - Label_accuracy: 0.9090 - Label_loss: 0.2380 - loss: 0.6397 - val_Domain_accuracy: 0.0507 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8675 - val_Label_loss: 0.4326 - val_loss: 0.4365\n",
      "Epoch 30/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8680 - Domain_loss: 0.3855 - Label_accuracy: 0.9143 - Label_loss: 0.2186 - loss: 0.6041 - val_Domain_accuracy: 0.0362 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8820 - val_Label_loss: 0.3749 - val_loss: 0.3846\n",
      "Epoch 31/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8712 - Domain_loss: 0.3814 - Label_accuracy: 0.9151 - Label_loss: 0.2130 - loss: 0.5944 - val_Domain_accuracy: 0.1356 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8872 - val_Label_loss: 0.3265 - val_loss: 0.3341\n",
      "Epoch 32/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8629 - Domain_loss: 0.3945 - Label_accuracy: 0.9140 - Label_loss: 0.2121 - loss: 0.6066 - val_Domain_accuracy: 0.1936 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8634 - val_Label_loss: 0.4185 - val_loss: 0.4292\n",
      "Epoch 33/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8668 - Domain_loss: 0.3834 - Label_accuracy: 0.9159 - Label_loss: 0.2095 - loss: 0.5930 - val_Domain_accuracy: 0.0673 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8841 - val_Label_loss: 0.3593 - val_loss: 0.3663\n",
      "Epoch 34/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8701 - Domain_loss: 0.3753 - Label_accuracy: 0.9213 - Label_loss: 0.2001 - loss: 0.5754 - val_Domain_accuracy: 0.0259 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8903 - val_Label_loss: 0.3658 - val_loss: 0.3755\n",
      "Epoch 35/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8639 - Domain_loss: 0.3883 - Label_accuracy: 0.9169 - Label_loss: 0.2092 - loss: 0.5975 - val_Domain_accuracy: 0.0290 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8634 - val_Label_loss: 0.4435 - val_loss: 0.4522\n",
      "Epoch 36/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8822 - Domain_loss: 0.3516 - Label_accuracy: 0.9226 - Label_loss: 0.2008 - loss: 0.5524 - val_Domain_accuracy: 0.0280 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8240 - val_Label_loss: 0.6848 - val_loss: 0.7019\n",
      "Epoch 37/80\n",
      "237/237 - 10s - 44ms/step - Domain_accuracy: 0.8677 - Domain_loss: 0.3851 - Label_accuracy: 0.9219 - Label_loss: 0.2036 - loss: 0.5887 - val_Domain_accuracy: 0.0207 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8520 - val_Label_loss: 0.4521 - val_loss: 0.4641\n",
      "Epoch 38/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8750 - Domain_loss: 0.3549 - Label_accuracy: 0.9254 - Label_loss: 0.1965 - loss: 0.5513 - val_Domain_accuracy: 0.0269 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8851 - val_Label_loss: 0.4076 - val_loss: 0.4165\n",
      "Epoch 39/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8737 - Domain_loss: 0.3656 - Label_accuracy: 0.9269 - Label_loss: 0.1848 - loss: 0.5505 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8499 - val_Label_loss: 0.4992 - val_loss: 0.5022\n",
      "Epoch 40/80\n",
      "237/237 - 10s - 44ms/step - Domain_accuracy: 0.8778 - Domain_loss: 0.3453 - Label_accuracy: 0.9284 - Label_loss: 0.1889 - loss: 0.5343 - val_Domain_accuracy: 0.0352 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8872 - val_Label_loss: 0.4119 - val_loss: 0.4221\n",
      "Epoch 41/80\n",
      "237/237 - 10s - 44ms/step - Domain_accuracy: 0.8676 - Domain_loss: 0.3806 - Label_accuracy: 0.9312 - Label_loss: 0.1741 - loss: 0.5548 - val_Domain_accuracy: 0.0373 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8716 - val_Label_loss: 0.4816 - val_loss: 0.4936\n",
      "Epoch 42/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8855 - Domain_loss: 0.3265 - Label_accuracy: 0.9323 - Label_loss: 0.1739 - loss: 0.5004 - val_Domain_accuracy: 0.0155 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8716 - val_Label_loss: 0.4345 - val_loss: 0.4462\n",
      "Epoch 43/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8942 - Domain_loss: 0.3040 - Label_accuracy: 0.9326 - Label_loss: 0.1742 - loss: 0.4782 - val_Domain_accuracy: 0.0238 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8292 - val_Label_loss: 0.6471 - val_loss: 0.6632\n",
      "Epoch 44/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8834 - Domain_loss: 0.3361 - Label_accuracy: 0.9312 - Label_loss: 0.1775 - loss: 0.5135 - val_Domain_accuracy: 0.0942 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8841 - val_Label_loss: 0.4234 - val_loss: 0.4343\n",
      "Epoch 45/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8723 - Domain_loss: 0.3676 - Label_accuracy: 0.9298 - Label_loss: 0.1800 - loss: 0.5475 - val_Domain_accuracy: 0.0269 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8437 - val_Label_loss: 0.5173 - val_loss: 0.5264\n",
      "Epoch 46/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8804 - Domain_loss: 0.3449 - Label_accuracy: 0.9345 - Label_loss: 0.1658 - loss: 0.5106 - val_Domain_accuracy: 0.0217 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8758 - val_Label_loss: 0.4632 - val_loss: 0.4754\n",
      "Epoch 47/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8849 - Domain_loss: 0.3292 - Label_accuracy: 0.9346 - Label_loss: 0.1640 - loss: 0.4931 - val_Domain_accuracy: 0.0155 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8706 - val_Label_loss: 0.4789 - val_loss: 0.4906\n",
      "Epoch 48/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8791 - Domain_loss: 0.3336 - Label_accuracy: 0.9334 - Label_loss: 0.1640 - loss: 0.4976 - val_Domain_accuracy: 0.0393 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8623 - val_Label_loss: 0.4899 - val_loss: 0.5010\n",
      "Epoch 49/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8882 - Domain_loss: 0.3163 - Label_accuracy: 0.9379 - Label_loss: 0.1596 - loss: 0.4759 - val_Domain_accuracy: 0.0269 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8499 - val_Label_loss: 0.5654 - val_loss: 0.5806\n",
      "Epoch 50/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8854 - Domain_loss: 0.3276 - Label_accuracy: 0.9388 - Label_loss: 0.1597 - loss: 0.4873 - val_Domain_accuracy: 0.0269 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8561 - val_Label_loss: 0.5138 - val_loss: 0.5253\n",
      "Epoch 51/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8830 - Domain_loss: 0.3430 - Label_accuracy: 0.9393 - Label_loss: 0.1573 - loss: 0.5004 - val_Domain_accuracy: 0.0435 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8644 - val_Label_loss: 0.4949 - val_loss: 0.5074\n",
      "Epoch 52/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8884 - Domain_loss: 0.3140 - Label_accuracy: 0.9414 - Label_loss: 0.1573 - loss: 0.4714 - val_Domain_accuracy: 0.0238 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8799 - val_Label_loss: 0.4976 - val_loss: 0.5084\n",
      "Epoch 53/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8792 - Domain_loss: 0.3432 - Label_accuracy: 0.9385 - Label_loss: 0.1569 - loss: 0.5000 - val_Domain_accuracy: 0.0342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8747 - val_Label_loss: 0.4511 - val_loss: 0.4607\n",
      "Epoch 54/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8824 - Domain_loss: 0.3486 - Label_accuracy: 0.9399 - Label_loss: 0.1563 - loss: 0.5049 - val_Domain_accuracy: 0.0238 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8778 - val_Label_loss: 0.4178 - val_loss: 0.4235\n",
      "Epoch 55/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8842 - Domain_loss: 0.3406 - Label_accuracy: 0.9449 - Label_loss: 0.1429 - loss: 0.4835 - val_Domain_accuracy: 0.0424 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8427 - val_Label_loss: 0.5968 - val_loss: 0.6111\n",
      "Epoch 56/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8779 - Domain_loss: 0.3482 - Label_accuracy: 0.9422 - Label_loss: 0.1437 - loss: 0.4918 - val_Domain_accuracy: 0.0155 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8716 - val_Label_loss: 0.5510 - val_loss: 0.5631\n",
      "Epoch 57/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8829 - Domain_loss: 0.3310 - Label_accuracy: 0.9436 - Label_loss: 0.1473 - loss: 0.4783 - val_Domain_accuracy: 0.0342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8830 - val_Label_loss: 0.4936 - val_loss: 0.5064\n",
      "Epoch 58/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8800 - Domain_loss: 0.3370 - Label_accuracy: 0.9505 - Label_loss: 0.1295 - loss: 0.4664 - val_Domain_accuracy: 0.0280 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8975 - val_Label_loss: 0.4137 - val_loss: 0.4240\n",
      "Epoch 59/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8752 - Domain_loss: 0.3495 - Label_accuracy: 0.9433 - Label_loss: 0.1486 - loss: 0.4981 - val_Domain_accuracy: 0.0694 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.9006 - val_Label_loss: 0.3967 - val_loss: 0.4052\n",
      "Epoch 60/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8867 - Domain_loss: 0.3233 - Label_accuracy: 0.9465 - Label_loss: 0.1358 - loss: 0.4591 - val_Domain_accuracy: 0.0259 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8799 - val_Label_loss: 0.4508 - val_loss: 0.4595\n",
      "Epoch 61/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8908 - Domain_loss: 0.3097 - Label_accuracy: 0.9462 - Label_loss: 0.1379 - loss: 0.4476 - val_Domain_accuracy: 0.0393 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8634 - val_Label_loss: 0.5436 - val_loss: 0.5574\n",
      "Epoch 62/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8983 - Domain_loss: 0.2890 - Label_accuracy: 0.9513 - Label_loss: 0.1229 - loss: 0.4120 - val_Domain_accuracy: 0.0280 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8778 - val_Label_loss: 0.4871 - val_loss: 0.4978\n",
      "Epoch 63/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8883 - Domain_loss: 0.3263 - Label_accuracy: 0.9478 - Label_loss: 0.1377 - loss: 0.4640 - val_Domain_accuracy: 0.0300 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8571 - val_Label_loss: 0.6300 - val_loss: 0.6467\n",
      "Epoch 64/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8874 - Domain_loss: 0.3214 - Label_accuracy: 0.9499 - Label_loss: 0.1361 - loss: 0.4576 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8551 - val_Label_loss: 0.6159 - val_loss: 0.6323\n",
      "Epoch 65/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8854 - Domain_loss: 0.3205 - Label_accuracy: 0.9455 - Label_loss: 0.1333 - loss: 0.4537 - val_Domain_accuracy: 0.0528 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8903 - val_Label_loss: 0.4668 - val_loss: 0.4779\n",
      "Epoch 66/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8908 - Domain_loss: 0.3143 - Label_accuracy: 0.9527 - Label_loss: 0.1246 - loss: 0.4389 - val_Domain_accuracy: 0.0424 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8613 - val_Label_loss: 0.6646 - val_loss: 0.6821\n",
      "Epoch 67/80\n",
      "237/237 - 10s - 43ms/step - Domain_accuracy: 0.8916 - Domain_loss: 0.3083 - Label_accuracy: 0.9509 - Label_loss: 0.1276 - loss: 0.4359 - val_Domain_accuracy: 0.0735 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8416 - val_Label_loss: 0.7105 - val_loss: 0.7270\n",
      "Epoch 68/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8900 - Domain_loss: 0.3085 - Label_accuracy: 0.9509 - Label_loss: 0.1317 - loss: 0.4402 - val_Domain_accuracy: 0.0155 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8716 - val_Label_loss: 0.5264 - val_loss: 0.5387\n",
      "Epoch 69/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8874 - Domain_loss: 0.3175 - Label_accuracy: 0.9556 - Label_loss: 0.1252 - loss: 0.4427 - val_Domain_accuracy: 0.0435 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8758 - val_Label_loss: 0.4996 - val_loss: 0.5108\n",
      "Epoch 70/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8994 - Domain_loss: 0.2900 - Label_accuracy: 0.9556 - Label_loss: 0.1232 - loss: 0.4132 - val_Domain_accuracy: 0.0300 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8613 - val_Label_loss: 0.6601 - val_loss: 0.6747\n",
      "Epoch 71/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8916 - Domain_loss: 0.3097 - Label_accuracy: 0.9575 - Label_loss: 0.1135 - loss: 0.4232 - val_Domain_accuracy: 0.0311 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8810 - val_Label_loss: 0.5511 - val_loss: 0.5659\n",
      "Epoch 72/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8861 - Domain_loss: 0.3237 - Label_accuracy: 0.9490 - Label_loss: 0.1324 - loss: 0.4561 - val_Domain_accuracy: 0.0217 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8799 - val_Label_loss: 0.5096 - val_loss: 0.5208\n",
      "Epoch 73/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8804 - Domain_loss: 0.3497 - Label_accuracy: 0.9436 - Label_loss: 0.1521 - loss: 0.5018 - val_Domain_accuracy: 0.0321 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8592 - val_Label_loss: 0.5821 - val_loss: 0.5871\n",
      "Epoch 74/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8857 - Domain_loss: 0.3201 - Label_accuracy: 0.9491 - Label_loss: 0.1309 - loss: 0.4510 - val_Domain_accuracy: 0.0238 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8602 - val_Label_loss: 0.6114 - val_loss: 0.6218\n",
      "Epoch 75/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8822 - Domain_loss: 0.3371 - Label_accuracy: 0.9509 - Label_loss: 0.1171 - loss: 0.4542 - val_Domain_accuracy: 0.0166 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8903 - val_Label_loss: 0.4975 - val_loss: 0.5105\n",
      "Epoch 76/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8916 - Domain_loss: 0.3067 - Label_accuracy: 0.9545 - Label_loss: 0.1223 - loss: 0.4290 - val_Domain_accuracy: 0.0362 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8882 - val_Label_loss: 0.4991 - val_loss: 0.5068\n",
      "Epoch 77/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8884 - Domain_loss: 0.3072 - Label_accuracy: 0.9575 - Label_loss: 0.1147 - loss: 0.4218 - val_Domain_accuracy: 0.0248 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8778 - val_Label_loss: 0.5493 - val_loss: 0.5608\n",
      "Epoch 78/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8965 - Domain_loss: 0.2917 - Label_accuracy: 0.9571 - Label_loss: 0.1128 - loss: 0.4045 - val_Domain_accuracy: 0.0248 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8934 - val_Label_loss: 0.4532 - val_loss: 0.4642\n",
      "Epoch 79/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.9021 - Domain_loss: 0.2792 - Label_accuracy: 0.9562 - Label_loss: 0.1179 - loss: 0.3971 - val_Domain_accuracy: 0.0300 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8675 - val_Label_loss: 0.6144 - val_loss: 0.6305\n",
      "Epoch 80/80\n",
      "237/237 - 10s - 42ms/step - Domain_accuracy: 0.8917 - Domain_loss: 0.3097 - Label_accuracy: 0.9536 - Label_loss: 0.1177 - loss: 0.4274 - val_Domain_accuracy: 0.0590 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8882 - val_Label_loss: 0.5036 - val_loss: 0.5170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #8\n",
      "train_feature shape: (7614, 5, 10, 256)\n",
      "train_targets shape: (7614, 5)\n",
      "train_domin shape: (7614, 9)\n",
      "Epoch 1/80\n",
      "238/238 - 19s - 81ms/step - Domain_accuracy: 0.4364 - Domain_loss: 1.7422 - Label_accuracy: 0.6869 - Label_loss: 0.9819 - loss: 2.7243 - val_Domain_accuracy: 0.1904 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7155 - val_Label_loss: 0.7900 - val_loss: 0.7815\n",
      "Epoch 2/80\n",
      "238/238 - 10s - 42ms/step - Domain_accuracy: 0.6114 - Domain_loss: 1.1172 - Label_accuracy: 0.7755 - Label_loss: 0.5849 - loss: 1.7021 - val_Domain_accuracy: 0.0781 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7487 - val_Label_loss: 0.6807 - val_loss: 0.6918\n",
      "Epoch 3/80\n",
      "238/238 - 10s - 42ms/step - Domain_accuracy: 0.6550 - Domain_loss: 1.0135 - Label_accuracy: 0.7997 - Label_loss: 0.5160 - loss: 1.5295 - val_Domain_accuracy: 0.1112 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7540 - val_Label_loss: 0.6518 - val_loss: 0.6540\n",
      "Epoch 4/80\n",
      "238/238 - 10s - 43ms/step - Domain_accuracy: 0.7017 - Domain_loss: 0.8917 - Label_accuracy: 0.8148 - Label_loss: 0.4786 - loss: 1.3702 - val_Domain_accuracy: 0.0332 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7561 - val_Label_loss: 0.7207 - val_loss: 0.7034\n",
      "Epoch 5/80\n",
      "238/238 - 10s - 43ms/step - Domain_accuracy: 0.7367 - Domain_loss: 0.7814 - Label_accuracy: 0.8253 - Label_loss: 0.4407 - loss: 1.2220 - val_Domain_accuracy: 0.1155 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 0.5793 - val_loss: 0.5797\n",
      "Epoch 6/80\n",
      "238/238 - 10s - 43ms/step - Domain_accuracy: 0.7305 - Domain_loss: 0.7852 - Label_accuracy: 0.8291 - Label_loss: 0.4453 - loss: 1.2304 - val_Domain_accuracy: 0.1166 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7765 - val_Label_loss: 0.6391 - val_loss: 0.6427\n",
      "Epoch 7/80\n",
      "238/238 - 10s - 43ms/step - Domain_accuracy: 0.7650 - Domain_loss: 0.6956 - Label_accuracy: 0.8300 - Label_loss: 0.4211 - loss: 1.1166 - val_Domain_accuracy: 0.1070 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7775 - val_Label_loss: 0.6184 - val_loss: 0.6295\n",
      "Epoch 8/80\n",
      "238/238 - 10s - 43ms/step - Domain_accuracy: 0.7854 - Domain_loss: 0.6382 - Label_accuracy: 0.8424 - Label_loss: 0.4024 - loss: 1.0404 - val_Domain_accuracy: 0.0492 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7251 - val_Label_loss: 0.7901 - val_loss: 0.7773\n",
      "Epoch 9/80\n",
      "238/238 - 10s - 44ms/step - Domain_accuracy: 0.7795 - Domain_loss: 0.6432 - Label_accuracy: 0.8341 - Label_loss: 0.3979 - loss: 1.0410 - val_Domain_accuracy: 0.0513 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7412 - val_Label_loss: 0.7713 - val_loss: 0.7680\n",
      "Epoch 10/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.7956 - Domain_loss: 0.6132 - Label_accuracy: 0.8475 - Label_loss: 0.3765 - loss: 0.9897 - val_Domain_accuracy: 0.0150 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7904 - val_Label_loss: 0.5602 - val_loss: 0.5631\n",
      "Epoch 11/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8056 - Domain_loss: 0.5841 - Label_accuracy: 0.8571 - Label_loss: 0.3706 - loss: 0.9546 - val_Domain_accuracy: 0.0503 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7947 - val_Label_loss: 0.5778 - val_loss: 0.5875\n",
      "Epoch 12/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8079 - Domain_loss: 0.5763 - Label_accuracy: 0.8604 - Label_loss: 0.3634 - loss: 0.9398 - val_Domain_accuracy: 0.0684 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 0.5969 - val_loss: 0.5970\n",
      "Epoch 13/80\n",
      "238/238 - 10s - 44ms/step - Domain_accuracy: 0.8210 - Domain_loss: 0.5427 - Label_accuracy: 0.8571 - Label_loss: 0.3591 - loss: 0.9017 - val_Domain_accuracy: 0.1348 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7733 - val_Label_loss: 0.6685 - val_loss: 0.6790\n",
      "Epoch 14/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8385 - Domain_loss: 0.4972 - Label_accuracy: 0.8613 - Label_loss: 0.3431 - loss: 0.8401 - val_Domain_accuracy: 0.0513 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7519 - val_Label_loss: 0.7181 - val_loss: 0.6842\n",
      "Epoch 15/80\n",
      "238/238 - 10s - 44ms/step - Domain_accuracy: 0.8182 - Domain_loss: 0.5547 - Label_accuracy: 0.8595 - Label_loss: 0.3464 - loss: 0.9011 - val_Domain_accuracy: 0.0267 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7829 - val_Label_loss: 0.6080 - val_loss: 0.6181\n",
      "Epoch 16/80\n",
      "238/238 - 10s - 44ms/step - Domain_accuracy: 0.8222 - Domain_loss: 0.5421 - Label_accuracy: 0.8638 - Label_loss: 0.3345 - loss: 0.8765 - val_Domain_accuracy: 0.1251 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7775 - val_Label_loss: 0.5945 - val_loss: 0.6035\n",
      "Epoch 17/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8236 - Domain_loss: 0.5296 - Label_accuracy: 0.8676 - Label_loss: 0.3331 - loss: 0.8626 - val_Domain_accuracy: 0.0556 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7412 - val_Label_loss: 0.8455 - val_loss: 0.8208\n",
      "Epoch 18/80\n",
      "238/238 - 10s - 44ms/step - Domain_accuracy: 0.8371 - Domain_loss: 0.5050 - Label_accuracy: 0.8702 - Label_loss: 0.3171 - loss: 0.8222 - val_Domain_accuracy: 0.0727 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7754 - val_Label_loss: 0.7838 - val_loss: 0.7807\n",
      "Epoch 19/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8445 - Domain_loss: 0.4721 - Label_accuracy: 0.8752 - Label_loss: 0.3145 - loss: 0.7865 - val_Domain_accuracy: 0.0310 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7604 - val_Label_loss: 0.7077 - val_loss: 0.6950\n",
      "Epoch 20/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8434 - Domain_loss: 0.4731 - Label_accuracy: 0.8742 - Label_loss: 0.3090 - loss: 0.7822 - val_Domain_accuracy: 0.0545 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7904 - val_Label_loss: 0.6061 - val_loss: 0.6128\n",
      "Epoch 21/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8459 - Domain_loss: 0.4726 - Label_accuracy: 0.8781 - Label_loss: 0.3015 - loss: 0.7740 - val_Domain_accuracy: 0.0075 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7583 - val_Label_loss: 0.8410 - val_loss: 0.8359\n",
      "Epoch 22/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8495 - Domain_loss: 0.4582 - Label_accuracy: 0.8834 - Label_loss: 0.2938 - loss: 0.7520 - val_Domain_accuracy: 0.0139 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7711 - val_Label_loss: 0.7550 - val_loss: 0.7541\n",
      "Epoch 23/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8458 - Domain_loss: 0.4526 - Label_accuracy: 0.8831 - Label_loss: 0.3010 - loss: 0.7537 - val_Domain_accuracy: 0.0471 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7572 - val_Label_loss: 0.6909 - val_loss: 0.7009\n",
      "Epoch 24/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8491 - Domain_loss: 0.4558 - Label_accuracy: 0.8861 - Label_loss: 0.2865 - loss: 0.7422 - val_Domain_accuracy: 0.0834 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7701 - val_Label_loss: 0.8073 - val_loss: 0.8061\n",
      "Epoch 25/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8420 - Domain_loss: 0.4687 - Label_accuracy: 0.8886 - Label_loss: 0.2772 - loss: 0.7459 - val_Domain_accuracy: 0.0396 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7989 - val_Label_loss: 0.5787 - val_loss: 0.5854\n",
      "Epoch 26/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8572 - Domain_loss: 0.4235 - Label_accuracy: 0.8855 - Label_loss: 0.2850 - loss: 0.7085 - val_Domain_accuracy: 0.0385 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7583 - val_Label_loss: 0.7987 - val_loss: 0.7879\n",
      "Epoch 27/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8546 - Domain_loss: 0.4267 - Label_accuracy: 0.8970 - Label_loss: 0.2688 - loss: 0.6955 - val_Domain_accuracy: 0.0096 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7840 - val_Label_loss: 0.7425 - val_loss: 0.7191\n",
      "Epoch 28/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8480 - Domain_loss: 0.4488 - Label_accuracy: 0.8932 - Label_loss: 0.2779 - loss: 0.7267 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7882 - val_Label_loss: 0.7071 - val_loss: 0.7228\n",
      "Epoch 29/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8542 - Domain_loss: 0.4359 - Label_accuracy: 0.8928 - Label_loss: 0.2680 - loss: 0.7039 - val_Domain_accuracy: 0.0182 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7893 - val_Label_loss: 0.6256 - val_loss: 0.6381\n",
      "Epoch 30/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8549 - Domain_loss: 0.4461 - Label_accuracy: 0.8960 - Label_loss: 0.2661 - loss: 0.7122 - val_Domain_accuracy: 0.0214 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7583 - val_Label_loss: 0.8043 - val_loss: 0.7862\n",
      "Epoch 31/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8635 - Domain_loss: 0.3996 - Label_accuracy: 0.8956 - Label_loss: 0.2666 - loss: 0.6662 - val_Domain_accuracy: 0.0406 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7733 - val_Label_loss: 0.7456 - val_loss: 0.7245\n",
      "Epoch 32/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8543 - Domain_loss: 0.4478 - Label_accuracy: 0.8986 - Label_loss: 0.2548 - loss: 0.7025 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7647 - val_Label_loss: 0.7892 - val_loss: 0.7769\n",
      "Epoch 33/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8564 - Domain_loss: 0.4168 - Label_accuracy: 0.8991 - Label_loss: 0.2588 - loss: 0.6755 - val_Domain_accuracy: 0.0128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7818 - val_Label_loss: 0.7255 - val_loss: 0.6925\n",
      "Epoch 34/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8654 - Domain_loss: 0.4072 - Label_accuracy: 0.9001 - Label_loss: 0.2550 - loss: 0.6623 - val_Domain_accuracy: 0.0096 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7647 - val_Label_loss: 0.9713 - val_loss: 0.9875\n",
      "Epoch 35/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8563 - Domain_loss: 0.4264 - Label_accuracy: 0.8993 - Label_loss: 0.2555 - loss: 0.6818 - val_Domain_accuracy: 0.0353 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7850 - val_Label_loss: 0.7055 - val_loss: 0.7104\n",
      "Epoch 36/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8541 - Domain_loss: 0.4153 - Label_accuracy: 0.9081 - Label_loss: 0.2291 - loss: 0.6444 - val_Domain_accuracy: 0.0385 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7904 - val_Label_loss: 0.7571 - val_loss: 0.7675\n",
      "Epoch 37/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8610 - Domain_loss: 0.4049 - Label_accuracy: 0.9039 - Label_loss: 0.2477 - loss: 0.6527 - val_Domain_accuracy: 0.0417 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 0.7228 - val_loss: 0.7260\n",
      "Epoch 38/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8705 - Domain_loss: 0.3779 - Label_accuracy: 0.9064 - Label_loss: 0.2338 - loss: 0.6116 - val_Domain_accuracy: 0.0342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7647 - val_Label_loss: 0.8081 - val_loss: 0.8279\n",
      "Epoch 39/80\n",
      "238/238 - 11s - 46ms/step - Domain_accuracy: 0.8660 - Domain_loss: 0.4081 - Label_accuracy: 0.9060 - Label_loss: 0.2401 - loss: 0.6483 - val_Domain_accuracy: 0.0246 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7850 - val_Label_loss: 0.7743 - val_loss: 0.7887\n",
      "Epoch 40/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8618 - Domain_loss: 0.4007 - Label_accuracy: 0.9053 - Label_loss: 0.2429 - loss: 0.6436 - val_Domain_accuracy: 0.0631 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7818 - val_Label_loss: 0.7656 - val_loss: 0.7586\n",
      "Epoch 41/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8642 - Domain_loss: 0.4018 - Label_accuracy: 0.9082 - Label_loss: 0.2264 - loss: 0.6282 - val_Domain_accuracy: 0.0214 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7786 - val_Label_loss: 0.8293 - val_loss: 0.8408\n",
      "Epoch 42/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8566 - Domain_loss: 0.4190 - Label_accuracy: 0.8970 - Label_loss: 0.2488 - loss: 0.6678 - val_Domain_accuracy: 0.0385 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7679 - val_Label_loss: 0.8779 - val_loss: 0.8864\n",
      "Epoch 43/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8710 - Domain_loss: 0.3792 - Label_accuracy: 0.9159 - Label_loss: 0.2166 - loss: 0.5958 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7658 - val_Label_loss: 0.9346 - val_loss: 0.9533\n",
      "Epoch 44/80\n",
      "238/238 - 11s - 46ms/step - Domain_accuracy: 0.8685 - Domain_loss: 0.3910 - Label_accuracy: 0.9146 - Label_loss: 0.2192 - loss: 0.6101 - val_Domain_accuracy: 0.0107 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7358 - val_Label_loss: 1.0685 - val_loss: 1.0589\n",
      "Epoch 45/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8730 - Domain_loss: 0.3812 - Label_accuracy: 0.9165 - Label_loss: 0.2117 - loss: 0.5930 - val_Domain_accuracy: 0.0128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7733 - val_Label_loss: 0.8933 - val_loss: 0.9109\n",
      "Epoch 46/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8679 - Domain_loss: 0.3873 - Label_accuracy: 0.9178 - Label_loss: 0.2124 - loss: 0.5998 - val_Domain_accuracy: 0.0342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.8000 - val_Label_loss: 0.7543 - val_loss: 0.7651\n",
      "Epoch 47/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8667 - Domain_loss: 0.3940 - Label_accuracy: 0.9161 - Label_loss: 0.2066 - loss: 0.6006 - val_Domain_accuracy: 0.0417 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7807 - val_Label_loss: 0.8555 - val_loss: 0.8667\n",
      "Epoch 48/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8756 - Domain_loss: 0.3738 - Label_accuracy: 0.9161 - Label_loss: 0.2133 - loss: 0.5872 - val_Domain_accuracy: 0.0107 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7658 - val_Label_loss: 0.8949 - val_loss: 0.8933\n",
      "Epoch 49/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8677 - Domain_loss: 0.3820 - Label_accuracy: 0.9187 - Label_loss: 0.2016 - loss: 0.5836 - val_Domain_accuracy: 0.0310 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7850 - val_Label_loss: 0.7687 - val_loss: 0.7891\n",
      "Epoch 50/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8755 - Domain_loss: 0.3726 - Label_accuracy: 0.9184 - Label_loss: 0.2020 - loss: 0.5746 - val_Domain_accuracy: 0.0460 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7433 - val_Label_loss: 1.1716 - val_loss: 1.1159\n",
      "Epoch 51/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8797 - Domain_loss: 0.3536 - Label_accuracy: 0.9187 - Label_loss: 0.2055 - loss: 0.5590 - val_Domain_accuracy: 0.0064 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7679 - val_Label_loss: 0.9300 - val_loss: 0.9068\n",
      "Epoch 52/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8822 - Domain_loss: 0.3531 - Label_accuracy: 0.9246 - Label_loss: 0.1913 - loss: 0.5444 - val_Domain_accuracy: 0.0449 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7743 - val_Label_loss: 0.9256 - val_loss: 0.9269\n",
      "Epoch 53/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8677 - Domain_loss: 0.3764 - Label_accuracy: 0.9183 - Label_loss: 0.2064 - loss: 0.5828 - val_Domain_accuracy: 0.0631 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7829 - val_Label_loss: 0.8401 - val_loss: 0.8612\n",
      "Epoch 54/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8851 - Domain_loss: 0.3379 - Label_accuracy: 0.9243 - Label_loss: 0.1915 - loss: 0.5294 - val_Domain_accuracy: 0.0267 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7797 - val_Label_loss: 0.8358 - val_loss: 0.8332\n",
      "Epoch 55/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8696 - Domain_loss: 0.3888 - Label_accuracy: 0.9211 - Label_loss: 0.2093 - loss: 0.5982 - val_Domain_accuracy: 0.0428 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7722 - val_Label_loss: 0.8162 - val_loss: 0.8360\n",
      "Epoch 56/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8756 - Domain_loss: 0.3652 - Label_accuracy: 0.9251 - Label_loss: 0.1954 - loss: 0.5606 - val_Domain_accuracy: 0.0449 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7872 - val_Label_loss: 0.7982 - val_loss: 0.8036\n",
      "Epoch 57/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8635 - Domain_loss: 0.4020 - Label_accuracy: 0.9207 - Label_loss: 0.1961 - loss: 0.5982 - val_Domain_accuracy: 0.0267 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7690 - val_Label_loss: 0.9873 - val_loss: 0.9946\n",
      "Epoch 58/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8737 - Domain_loss: 0.3833 - Label_accuracy: 0.9225 - Label_loss: 0.1974 - loss: 0.5807 - val_Domain_accuracy: 0.0374 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7861 - val_Label_loss: 0.9243 - val_loss: 0.9428\n",
      "Epoch 59/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8744 - Domain_loss: 0.3541 - Label_accuracy: 0.9250 - Label_loss: 0.1889 - loss: 0.5430 - val_Domain_accuracy: 0.0364 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7882 - val_Label_loss: 0.8374 - val_loss: 0.8537\n",
      "Epoch 60/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8815 - Domain_loss: 0.3437 - Label_accuracy: 0.9289 - Label_loss: 0.1810 - loss: 0.5247 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7786 - val_Label_loss: 0.8823 - val_loss: 0.8925\n",
      "Epoch 61/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8740 - Domain_loss: 0.3698 - Label_accuracy: 0.9272 - Label_loss: 0.1898 - loss: 0.5596 - val_Domain_accuracy: 0.0150 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7797 - val_Label_loss: 1.0085 - val_loss: 1.0010\n",
      "Epoch 62/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8709 - Domain_loss: 0.3721 - Label_accuracy: 0.9299 - Label_loss: 0.1806 - loss: 0.5527 - val_Domain_accuracy: 0.0342 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7658 - val_Label_loss: 0.9629 - val_loss: 0.9454\n",
      "Epoch 63/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8726 - Domain_loss: 0.3653 - Label_accuracy: 0.9370 - Label_loss: 0.1674 - loss: 0.5326 - val_Domain_accuracy: 0.0096 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7647 - val_Label_loss: 1.0420 - val_loss: 0.9903\n",
      "Epoch 64/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8775 - Domain_loss: 0.3699 - Label_accuracy: 0.9300 - Label_loss: 0.1895 - loss: 0.5594 - val_Domain_accuracy: 0.0332 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7829 - val_Label_loss: 0.9600 - val_loss: 0.9699\n",
      "Epoch 65/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8738 - Domain_loss: 0.3806 - Label_accuracy: 0.9258 - Label_loss: 0.1966 - loss: 0.5771 - val_Domain_accuracy: 0.0374 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7775 - val_Label_loss: 0.9895 - val_loss: 0.9872\n",
      "Epoch 66/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8777 - Domain_loss: 0.3561 - Label_accuracy: 0.9259 - Label_loss: 0.1850 - loss: 0.5411 - val_Domain_accuracy: 0.0171 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7840 - val_Label_loss: 0.9214 - val_loss: 0.9141\n",
      "Epoch 67/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8877 - Domain_loss: 0.3290 - Label_accuracy: 0.9359 - Label_loss: 0.1681 - loss: 0.4971 - val_Domain_accuracy: 0.0096 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7733 - val_Label_loss: 1.1157 - val_loss: 1.1307\n",
      "Epoch 68/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8832 - Domain_loss: 0.3423 - Label_accuracy: 0.9266 - Label_loss: 0.1862 - loss: 0.5284 - val_Domain_accuracy: 0.0032 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7893 - val_Label_loss: 0.8939 - val_loss: 0.9113\n",
      "Epoch 69/80\n",
      "238/238 - 11s - 45ms/step - Domain_accuracy: 0.8853 - Domain_loss: 0.3421 - Label_accuracy: 0.9334 - Label_loss: 0.1646 - loss: 0.5066 - val_Domain_accuracy: 0.0086 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7807 - val_Label_loss: 0.8747 - val_loss: 0.8668\n",
      "Epoch 70/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8855 - Domain_loss: 0.3439 - Label_accuracy: 0.9284 - Label_loss: 0.1768 - loss: 0.5206 - val_Domain_accuracy: 0.0032 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7305 - val_Label_loss: 1.4015 - val_loss: 1.3932\n",
      "Epoch 71/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8797 - Domain_loss: 0.3562 - Label_accuracy: 0.9289 - Label_loss: 0.1858 - loss: 0.5419 - val_Domain_accuracy: 0.0257 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7647 - val_Label_loss: 1.1100 - val_loss: 1.0786\n",
      "Epoch 72/80\n",
      "238/238 - 10s - 44ms/step - Domain_accuracy: 0.8851 - Domain_loss: 0.3529 - Label_accuracy: 0.9309 - Label_loss: 0.1776 - loss: 0.5305 - val_Domain_accuracy: 0.0620 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7818 - val_Label_loss: 0.8917 - val_loss: 0.8946\n",
      "Epoch 73/80\n",
      "238/238 - 10s - 44ms/step - Domain_accuracy: 0.8796 - Domain_loss: 0.3648 - Label_accuracy: 0.9325 - Label_loss: 0.1795 - loss: 0.5443 - val_Domain_accuracy: 0.0310 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7775 - val_Label_loss: 1.0180 - val_loss: 1.0271\n",
      "Epoch 74/80\n",
      "238/238 - 10s - 44ms/step - Domain_accuracy: 0.8864 - Domain_loss: 0.3293 - Label_accuracy: 0.9316 - Label_loss: 0.1747 - loss: 0.5040 - val_Domain_accuracy: 0.0160 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7690 - val_Label_loss: 1.0620 - val_loss: 1.0264\n",
      "Epoch 75/80\n",
      "238/238 - 10s - 44ms/step - Domain_accuracy: 0.8801 - Domain_loss: 0.3657 - Label_accuracy: 0.9321 - Label_loss: 0.1744 - loss: 0.5400 - val_Domain_accuracy: 0.0096 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7647 - val_Label_loss: 1.0382 - val_loss: 1.0341\n",
      "Epoch 76/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8856 - Domain_loss: 0.3428 - Label_accuracy: 0.9325 - Label_loss: 0.1708 - loss: 0.5137 - val_Domain_accuracy: 0.0246 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7668 - val_Label_loss: 1.1572 - val_loss: 1.1583\n",
      "Epoch 77/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8857 - Domain_loss: 0.3343 - Label_accuracy: 0.9362 - Label_loss: 0.1635 - loss: 0.4978 - val_Domain_accuracy: 0.0235 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7754 - val_Label_loss: 1.0134 - val_loss: 1.0168\n",
      "Epoch 78/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8882 - Domain_loss: 0.3231 - Label_accuracy: 0.9393 - Label_loss: 0.1512 - loss: 0.4742 - val_Domain_accuracy: 0.0128 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7636 - val_Label_loss: 1.1826 - val_loss: 1.2128\n",
      "Epoch 79/80\n",
      "238/238 - 11s - 44ms/step - Domain_accuracy: 0.8863 - Domain_loss: 0.3308 - Label_accuracy: 0.9342 - Label_loss: 0.1698 - loss: 0.5006 - val_Domain_accuracy: 0.0663 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7679 - val_Label_loss: 1.0437 - val_loss: 1.0454\n",
      "Epoch 80/80\n",
      "238/238 - 10s - 44ms/step - Domain_accuracy: 0.8860 - Domain_loss: 0.3327 - Label_accuracy: 0.9402 - Label_loss: 0.1583 - loss: 0.4910 - val_Domain_accuracy: 0.0075 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7711 - val_Label_loss: 1.0118 - val_loss: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold #9\n",
      "train_feature shape: (7787, 5, 10, 256)\n",
      "train_targets shape: (7787, 5)\n",
      "train_domin shape: (7787, 9)\n",
      "Epoch 1/80\n",
      "244/244 - 20s - 84ms/step - Domain_accuracy: 0.3814 - Domain_loss: 1.8296 - Label_accuracy: 0.6438 - Label_loss: 1.0504 - loss: 2.8810 - val_Domain_accuracy: 0.0407 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6339 - val_Label_loss: 1.0073 - val_loss: 0.9821\n",
      "Epoch 2/80\n",
      "244/244 - 11s - 44ms/step - Domain_accuracy: 0.5614 - Domain_loss: 1.2873 - Label_accuracy: 0.7584 - Label_loss: 0.6356 - loss: 1.9209 - val_Domain_accuracy: 0.0892 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6339 - val_Label_loss: 1.0024 - val_loss: 0.9854\n",
      "Epoch 3/80\n",
      "244/244 - 11s - 44ms/step - Domain_accuracy: 0.5906 - Domain_loss: 1.1897 - Label_accuracy: 0.7814 - Label_loss: 0.5638 - loss: 1.7551 - val_Domain_accuracy: 0.0197 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6076 - val_Label_loss: 1.0336 - val_loss: 1.0231\n",
      "Epoch 4/80\n",
      "244/244 - 11s - 44ms/step - Domain_accuracy: 0.6470 - Domain_loss: 1.0445 - Label_accuracy: 0.7867 - Label_loss: 0.5455 - loss: 1.5901 - val_Domain_accuracy: 0.1378 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6667 - val_Label_loss: 0.8577 - val_loss: 0.8442\n",
      "Epoch 5/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.6786 - Domain_loss: 0.9467 - Label_accuracy: 0.8074 - Label_loss: 0.4978 - loss: 1.4433 - val_Domain_accuracy: 0.0144 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6903 - val_Label_loss: 0.8003 - val_loss: 0.7918\n",
      "Epoch 6/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.6895 - Domain_loss: 0.9302 - Label_accuracy: 0.8110 - Label_loss: 0.4908 - loss: 1.4225 - val_Domain_accuracy: 0.0144 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6470 - val_Label_loss: 0.9289 - val_loss: 0.9204\n",
      "Epoch 7/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.6951 - Domain_loss: 0.9081 - Label_accuracy: 0.8191 - Label_loss: 0.4595 - loss: 1.3690 - val_Domain_accuracy: 0.1549 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7441 - val_Label_loss: 0.7361 - val_loss: 0.7251\n",
      "Epoch 8/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.6917 - Domain_loss: 0.9275 - Label_accuracy: 0.8206 - Label_loss: 0.4637 - loss: 1.3894 - val_Domain_accuracy: 0.3596 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6798 - val_Label_loss: 0.8377 - val_loss: 0.8189\n",
      "Epoch 9/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7217 - Domain_loss: 0.8327 - Label_accuracy: 0.8239 - Label_loss: 0.4365 - loss: 1.2685 - val_Domain_accuracy: 0.0840 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7625 - val_Label_loss: 0.6195 - val_loss: 0.6111\n",
      "Epoch 10/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7415 - Domain_loss: 0.7729 - Label_accuracy: 0.8320 - Label_loss: 0.4283 - loss: 1.2018 - val_Domain_accuracy: 0.3307 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6916 - val_Label_loss: 0.8190 - val_loss: 0.8077\n",
      "Epoch 11/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.7315 - Domain_loss: 0.7712 - Label_accuracy: 0.8354 - Label_loss: 0.4140 - loss: 1.1846 - val_Domain_accuracy: 0.1430 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6916 - val_Label_loss: 0.8705 - val_loss: 0.8633\n",
      "Epoch 12/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7479 - Domain_loss: 0.7414 - Label_accuracy: 0.8460 - Label_loss: 0.4027 - loss: 1.1446 - val_Domain_accuracy: 0.1575 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6890 - val_Label_loss: 0.9075 - val_loss: 0.8958\n",
      "Epoch 13/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7500 - Domain_loss: 0.7458 - Label_accuracy: 0.8349 - Label_loss: 0.4220 - loss: 1.1672 - val_Domain_accuracy: 0.2913 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7034 - val_Label_loss: 0.7777 - val_loss: 0.7675\n",
      "Epoch 14/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.7605 - Domain_loss: 0.7119 - Label_accuracy: 0.8437 - Label_loss: 0.3997 - loss: 1.1136 - val_Domain_accuracy: 0.2126 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7205 - val_Label_loss: 0.7985 - val_loss: 0.7876\n",
      "Epoch 15/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7633 - Domain_loss: 0.6846 - Label_accuracy: 0.8435 - Label_loss: 0.3928 - loss: 1.0780 - val_Domain_accuracy: 0.0958 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6969 - val_Label_loss: 0.8511 - val_loss: 0.8347\n",
      "Epoch 16/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7606 - Domain_loss: 0.6926 - Label_accuracy: 0.8490 - Label_loss: 0.3821 - loss: 1.0749 - val_Domain_accuracy: 0.1339 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7021 - val_Label_loss: 0.8570 - val_loss: 0.8387\n",
      "Epoch 17/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7548 - Domain_loss: 0.7477 - Label_accuracy: 0.8450 - Label_loss: 0.3919 - loss: 1.1407 - val_Domain_accuracy: 0.2060 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7205 - val_Label_loss: 0.7386 - val_loss: 0.7294\n",
      "Epoch 18/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7767 - Domain_loss: 0.6625 - Label_accuracy: 0.8562 - Label_loss: 0.3718 - loss: 1.0338 - val_Domain_accuracy: 0.0184 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6850 - val_Label_loss: 0.9509 - val_loss: 0.9404\n",
      "Epoch 19/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7803 - Domain_loss: 0.6451 - Label_accuracy: 0.8590 - Label_loss: 0.3651 - loss: 1.0113 - val_Domain_accuracy: 0.0551 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6549 - val_Label_loss: 1.0631 - val_loss: 1.0477\n",
      "Epoch 20/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7736 - Domain_loss: 0.6847 - Label_accuracy: 0.8526 - Label_loss: 0.3712 - loss: 1.0564 - val_Domain_accuracy: 0.0853 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7336 - val_Label_loss: 0.7301 - val_loss: 0.7175\n",
      "Epoch 21/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7505 - Domain_loss: 0.7240 - Label_accuracy: 0.8531 - Label_loss: 0.3752 - loss: 1.0998 - val_Domain_accuracy: 0.0853 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7493 - val_Label_loss: 0.7431 - val_loss: 0.7311\n",
      "Epoch 22/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7835 - Domain_loss: 0.6500 - Label_accuracy: 0.8594 - Label_loss: 0.3587 - loss: 1.0082 - val_Domain_accuracy: 0.1588 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7441 - val_Label_loss: 0.7471 - val_loss: 0.7329\n",
      "Epoch 23/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7807 - Domain_loss: 0.6409 - Label_accuracy: 0.8602 - Label_loss: 0.3559 - loss: 0.9968 - val_Domain_accuracy: 0.1339 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7388 - val_Label_loss: 0.7713 - val_loss: 0.7594\n",
      "Epoch 24/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7962 - Domain_loss: 0.6096 - Label_accuracy: 0.8671 - Label_loss: 0.3334 - loss: 0.9440 - val_Domain_accuracy: 0.0249 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7336 - val_Label_loss: 0.7784 - val_loss: 0.7696\n",
      "Epoch 25/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7914 - Domain_loss: 0.6216 - Label_accuracy: 0.8636 - Label_loss: 0.3472 - loss: 0.9681 - val_Domain_accuracy: 0.1220 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7126 - val_Label_loss: 0.7331 - val_loss: 0.7264\n",
      "Epoch 26/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.7893 - Domain_loss: 0.6208 - Label_accuracy: 0.8640 - Label_loss: 0.3428 - loss: 0.9641 - val_Domain_accuracy: 0.0774 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7218 - val_Label_loss: 0.8637 - val_loss: 0.8461\n",
      "Epoch 27/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7846 - Domain_loss: 0.6250 - Label_accuracy: 0.8708 - Label_loss: 0.3330 - loss: 0.9593 - val_Domain_accuracy: 0.0394 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7231 - val_Label_loss: 0.9739 - val_loss: 0.9593\n",
      "Epoch 28/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7974 - Domain_loss: 0.6031 - Label_accuracy: 0.8738 - Label_loss: 0.3202 - loss: 0.9234 - val_Domain_accuracy: 0.1404 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7087 - val_Label_loss: 0.9024 - val_loss: 0.8812\n",
      "Epoch 29/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7893 - Domain_loss: 0.6183 - Label_accuracy: 0.8695 - Label_loss: 0.3275 - loss: 0.9467 - val_Domain_accuracy: 0.0617 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6837 - val_Label_loss: 1.0234 - val_loss: 1.0134\n",
      "Epoch 30/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7830 - Domain_loss: 0.6319 - Label_accuracy: 0.8736 - Label_loss: 0.3174 - loss: 0.9507 - val_Domain_accuracy: 0.0919 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7283 - val_Label_loss: 0.8969 - val_loss: 0.8806\n",
      "Epoch 31/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.8026 - Domain_loss: 0.5817 - Label_accuracy: 0.8767 - Label_loss: 0.3127 - loss: 0.8937 - val_Domain_accuracy: 0.1772 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7047 - val_Label_loss: 0.8515 - val_loss: 0.8416\n",
      "Epoch 32/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7917 - Domain_loss: 0.6145 - Label_accuracy: 0.8729 - Label_loss: 0.3207 - loss: 0.9351 - val_Domain_accuracy: 0.1286 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7060 - val_Label_loss: 0.9052 - val_loss: 0.8904\n",
      "Epoch 33/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.8033 - Domain_loss: 0.5784 - Label_accuracy: 0.8684 - Label_loss: 0.3287 - loss: 0.9074 - val_Domain_accuracy: 0.0840 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6522 - val_Label_loss: 1.1166 - val_loss: 1.0953\n",
      "Epoch 34/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7893 - Domain_loss: 0.6136 - Label_accuracy: 0.8821 - Label_loss: 0.3110 - loss: 0.9247 - val_Domain_accuracy: 0.1496 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6850 - val_Label_loss: 0.9855 - val_loss: 0.9604\n",
      "Epoch 35/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7971 - Domain_loss: 0.6001 - Label_accuracy: 0.8747 - Label_loss: 0.3133 - loss: 0.9135 - val_Domain_accuracy: 0.0407 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7231 - val_Label_loss: 0.8536 - val_loss: 0.8325\n",
      "Epoch 36/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.8173 - Domain_loss: 0.5311 - Label_accuracy: 0.8790 - Label_loss: 0.3035 - loss: 0.8330 - val_Domain_accuracy: 0.1194 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6575 - val_Label_loss: 1.1500 - val_loss: 1.1210\n",
      "Epoch 37/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8085 - Domain_loss: 0.5620 - Label_accuracy: 0.8844 - Label_loss: 0.2982 - loss: 0.8612 - val_Domain_accuracy: 0.0801 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7192 - val_Label_loss: 0.9564 - val_loss: 0.9429\n",
      "Epoch 38/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.7949 - Domain_loss: 0.6048 - Label_accuracy: 0.8825 - Label_loss: 0.2961 - loss: 0.9017 - val_Domain_accuracy: 0.2034 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7100 - val_Label_loss: 0.8710 - val_loss: 0.8576\n",
      "Epoch 39/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8070 - Domain_loss: 0.5758 - Label_accuracy: 0.8843 - Label_loss: 0.2942 - loss: 0.8701 - val_Domain_accuracy: 0.0774 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7126 - val_Label_loss: 0.9553 - val_loss: 0.9453\n",
      "Epoch 40/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8079 - Domain_loss: 0.5591 - Label_accuracy: 0.8890 - Label_loss: 0.2973 - loss: 0.8566 - val_Domain_accuracy: 0.0591 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7480 - val_Label_loss: 0.7799 - val_loss: 0.7698\n",
      "Epoch 41/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.7870 - Domain_loss: 0.6186 - Label_accuracy: 0.8863 - Label_loss: 0.2938 - loss: 0.9110 - val_Domain_accuracy: 0.1601 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6995 - val_Label_loss: 0.8986 - val_loss: 0.8833\n",
      "Epoch 42/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8088 - Domain_loss: 0.5659 - Label_accuracy: 0.8863 - Label_loss: 0.2813 - loss: 0.8478 - val_Domain_accuracy: 0.0354 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7533 - val_Label_loss: 0.7292 - val_loss: 0.7152\n",
      "Epoch 43/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.7798 - Domain_loss: 0.6447 - Label_accuracy: 0.8830 - Label_loss: 0.3015 - loss: 0.9471 - val_Domain_accuracy: 0.0879 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7257 - val_Label_loss: 0.8585 - val_loss: 0.8443\n",
      "Epoch 44/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8180 - Domain_loss: 0.5249 - Label_accuracy: 0.8932 - Label_loss: 0.2710 - loss: 0.7955 - val_Domain_accuracy: 0.0459 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6969 - val_Label_loss: 1.0042 - val_loss: 0.9829\n",
      "Epoch 45/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8039 - Domain_loss: 0.5637 - Label_accuracy: 0.8903 - Label_loss: 0.2692 - loss: 0.8337 - val_Domain_accuracy: 0.0682 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7073 - val_Label_loss: 0.9089 - val_loss: 0.8910\n",
      "Epoch 46/80\n",
      "244/244 - 12s - 47ms/step - Domain_accuracy: 0.8007 - Domain_loss: 0.5815 - Label_accuracy: 0.8896 - Label_loss: 0.2776 - loss: 0.8591 - val_Domain_accuracy: 0.1745 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7283 - val_Label_loss: 0.9143 - val_loss: 0.8902\n",
      "Epoch 47/80\n",
      "244/244 - 13s - 53ms/step - Domain_accuracy: 0.8021 - Domain_loss: 0.5697 - Label_accuracy: 0.8911 - Label_loss: 0.2695 - loss: 0.8398 - val_Domain_accuracy: 0.0276 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6732 - val_Label_loss: 1.1458 - val_loss: 1.1235\n",
      "Epoch 48/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.8022 - Domain_loss: 0.5914 - Label_accuracy: 0.8899 - Label_loss: 0.2709 - loss: 0.8612 - val_Domain_accuracy: 0.0696 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7126 - val_Label_loss: 0.8966 - val_loss: 0.8720\n",
      "Epoch 49/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.7965 - Domain_loss: 0.5945 - Label_accuracy: 0.8961 - Label_loss: 0.2745 - loss: 0.8703 - val_Domain_accuracy: 0.0656 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7205 - val_Label_loss: 0.9210 - val_loss: 0.9004\n",
      "Epoch 50/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.7976 - Domain_loss: 0.5893 - Label_accuracy: 0.8934 - Label_loss: 0.2662 - loss: 0.8567 - val_Domain_accuracy: 0.1365 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6850 - val_Label_loss: 0.9840 - val_loss: 0.9619\n",
      "Epoch 51/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8026 - Domain_loss: 0.5771 - Label_accuracy: 0.8925 - Label_loss: 0.2682 - loss: 0.8455 - val_Domain_accuracy: 0.0367 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7598 - val_Label_loss: 0.7614 - val_loss: 0.7545\n",
      "Epoch 52/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.7926 - Domain_loss: 0.6034 - Label_accuracy: 0.8953 - Label_loss: 0.2663 - loss: 0.8696 - val_Domain_accuracy: 0.1903 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7283 - val_Label_loss: 0.9017 - val_loss: 0.8819\n",
      "Epoch 53/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8083 - Domain_loss: 0.5443 - Label_accuracy: 0.8975 - Label_loss: 0.2566 - loss: 0.8022 - val_Domain_accuracy: 0.0604 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7178 - val_Label_loss: 1.0344 - val_loss: 1.0196\n",
      "Epoch 54/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.7936 - Domain_loss: 0.6189 - Label_accuracy: 0.8896 - Label_loss: 0.2765 - loss: 0.8962 - val_Domain_accuracy: 0.0551 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7100 - val_Label_loss: 0.9388 - val_loss: 0.9249\n",
      "Epoch 55/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8038 - Domain_loss: 0.5701 - Label_accuracy: 0.8996 - Label_loss: 0.2584 - loss: 0.8278 - val_Domain_accuracy: 0.0696 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6969 - val_Label_loss: 0.9956 - val_loss: 0.9744\n",
      "Epoch 56/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8093 - Domain_loss: 0.5634 - Label_accuracy: 0.8970 - Label_loss: 0.2594 - loss: 0.8231 - val_Domain_accuracy: 0.0289 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7375 - val_Label_loss: 0.9531 - val_loss: 0.9334\n",
      "Epoch 57/80\n",
      "244/244 - 11s - 47ms/step - Domain_accuracy: 0.8149 - Domain_loss: 0.5347 - Label_accuracy: 0.9041 - Label_loss: 0.2483 - loss: 0.7835 - val_Domain_accuracy: 0.0630 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7323 - val_Label_loss: 0.8632 - val_loss: 0.8507\n",
      "Epoch 58/80\n",
      "244/244 - 12s - 48ms/step - Domain_accuracy: 0.7972 - Domain_loss: 0.5746 - Label_accuracy: 0.8957 - Label_loss: 0.2605 - loss: 0.8339 - val_Domain_accuracy: 0.0656 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6982 - val_Label_loss: 1.1214 - val_loss: 1.0998\n",
      "Epoch 59/80\n",
      "244/244 - 12s - 47ms/step - Domain_accuracy: 0.8016 - Domain_loss: 0.5837 - Label_accuracy: 0.8919 - Label_loss: 0.2697 - loss: 0.8531 - val_Domain_accuracy: 0.0774 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6942 - val_Label_loss: 1.0077 - val_loss: 0.9937\n",
      "Epoch 60/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8162 - Domain_loss: 0.5432 - Label_accuracy: 0.9038 - Label_loss: 0.2383 - loss: 0.7802 - val_Domain_accuracy: 0.0446 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7218 - val_Label_loss: 0.9049 - val_loss: 0.8884\n",
      "Epoch 61/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8137 - Domain_loss: 0.5434 - Label_accuracy: 0.9005 - Label_loss: 0.2502 - loss: 0.7940 - val_Domain_accuracy: 0.0459 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7270 - val_Label_loss: 0.9010 - val_loss: 0.8829\n",
      "Epoch 62/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8061 - Domain_loss: 0.5642 - Label_accuracy: 0.9081 - Label_loss: 0.2348 - loss: 0.7990 - val_Domain_accuracy: 0.0604 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6916 - val_Label_loss: 1.0532 - val_loss: 1.0356\n",
      "Epoch 63/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8049 - Domain_loss: 0.5770 - Label_accuracy: 0.8948 - Label_loss: 0.2515 - loss: 0.8282 - val_Domain_accuracy: 0.1207 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7283 - val_Label_loss: 0.9248 - val_loss: 0.8971\n",
      "Epoch 64/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8140 - Domain_loss: 0.5364 - Label_accuracy: 0.9041 - Label_loss: 0.2363 - loss: 0.7724 - val_Domain_accuracy: 0.0801 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7257 - val_Label_loss: 0.9950 - val_loss: 0.9749\n",
      "Epoch 65/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8048 - Domain_loss: 0.5592 - Label_accuracy: 0.9063 - Label_loss: 0.2383 - loss: 0.7986 - val_Domain_accuracy: 0.0735 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7244 - val_Label_loss: 1.0430 - val_loss: 1.0179\n",
      "Epoch 66/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8051 - Domain_loss: 0.5537 - Label_accuracy: 0.9091 - Label_loss: 0.2316 - loss: 0.7860 - val_Domain_accuracy: 0.0827 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7021 - val_Label_loss: 1.0778 - val_loss: 1.0524\n",
      "Epoch 67/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8179 - Domain_loss: 0.5426 - Label_accuracy: 0.9054 - Label_loss: 0.2390 - loss: 0.7806 - val_Domain_accuracy: 0.0538 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6115 - val_Label_loss: 1.4871 - val_loss: 1.4552\n",
      "Epoch 68/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8144 - Domain_loss: 0.5566 - Label_accuracy: 0.9086 - Label_loss: 0.2352 - loss: 0.7922 - val_Domain_accuracy: 0.1903 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7060 - val_Label_loss: 0.9631 - val_loss: 0.9427\n",
      "Epoch 69/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8236 - Domain_loss: 0.5138 - Label_accuracy: 0.9152 - Label_loss: 0.2162 - loss: 0.7291 - val_Domain_accuracy: 0.0564 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7113 - val_Label_loss: 1.0239 - val_loss: 1.0052\n",
      "Epoch 70/80\n",
      "244/244 - 11s - 47ms/step - Domain_accuracy: 0.8089 - Domain_loss: 0.5530 - Label_accuracy: 0.9082 - Label_loss: 0.2294 - loss: 0.7814 - val_Domain_accuracy: 0.0341 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6745 - val_Label_loss: 1.2025 - val_loss: 1.1813\n",
      "Epoch 71/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8176 - Domain_loss: 0.5250 - Label_accuracy: 0.9115 - Label_loss: 0.2220 - loss: 0.7467 - val_Domain_accuracy: 0.1719 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6955 - val_Label_loss: 1.1304 - val_loss: 1.1147\n",
      "Epoch 72/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8132 - Domain_loss: 0.5351 - Label_accuracy: 0.9069 - Label_loss: 0.2299 - loss: 0.7657 - val_Domain_accuracy: 0.2257 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7008 - val_Label_loss: 1.1437 - val_loss: 1.1248\n",
      "Epoch 73/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8092 - Domain_loss: 0.5417 - Label_accuracy: 0.9131 - Label_loss: 0.2227 - loss: 0.7636 - val_Domain_accuracy: 0.0748 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7283 - val_Label_loss: 0.8874 - val_loss: 0.8792\n",
      "Epoch 74/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8128 - Domain_loss: 0.5466 - Label_accuracy: 0.9037 - Label_loss: 0.2458 - loss: 0.7912 - val_Domain_accuracy: 0.0262 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6969 - val_Label_loss: 1.1016 - val_loss: 1.0792\n",
      "Epoch 75/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.8146 - Domain_loss: 0.5531 - Label_accuracy: 0.9124 - Label_loss: 0.2176 - loss: 0.7695 - val_Domain_accuracy: 0.0814 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7126 - val_Label_loss: 0.9808 - val_loss: 0.9524\n",
      "Epoch 76/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.8108 - Domain_loss: 0.5409 - Label_accuracy: 0.9169 - Label_loss: 0.2121 - loss: 0.7521 - val_Domain_accuracy: 0.1207 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7113 - val_Label_loss: 1.1161 - val_loss: 1.0846\n",
      "Epoch 77/80\n",
      "244/244 - 11s - 45ms/step - Domain_accuracy: 0.8133 - Domain_loss: 0.5457 - Label_accuracy: 0.9145 - Label_loss: 0.2255 - loss: 0.7713 - val_Domain_accuracy: 0.0919 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.6942 - val_Label_loss: 1.2225 - val_loss: 1.1936\n",
      "Epoch 78/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8021 - Domain_loss: 0.5600 - Label_accuracy: 0.9136 - Label_loss: 0.2189 - loss: 0.7800 - val_Domain_accuracy: 0.1115 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7205 - val_Label_loss: 0.9755 - val_loss: 0.9542\n",
      "Epoch 79/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8156 - Domain_loss: 0.5311 - Label_accuracy: 0.9165 - Label_loss: 0.2154 - loss: 0.7464 - val_Domain_accuracy: 0.1719 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7165 - val_Label_loss: 1.0319 - val_loss: 1.0154\n",
      "Epoch 80/80\n",
      "244/244 - 11s - 46ms/step - Domain_accuracy: 0.8286 - Domain_loss: 0.4824 - Label_accuracy: 0.9188 - Label_loss: 0.2089 - loss: 0.6927 - val_Domain_accuracy: 0.1391 - val_Domain_loss: 0.0000e+00 - val_Label_accuracy: 0.7257 - val_Label_loss: 1.0125 - val_loss: 1.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training Accuracy: 0.0000\n",
      "Final Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "End of training MSTGCN.\n",
      "################################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import gc\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as KTF\n",
    "import argparse\n",
    "\n",
    "from model.MSTGCN import build_MSTGCN\n",
    "from model.DataGenerator import DominGenerator\n",
    "from model.Utils import AddContext_MultiSub, AddContext_SingleSub, ReadConfig, scaled_Laplacian, cheb_polynomial, Instantiation_regularizer, VariationCurve\n",
    "\n",
    "# Display setup\n",
    "print(128 * '#')\n",
    "print('Start to train MSTGCN.')\n",
    "\n",
    "# 1. Get Configuration\n",
    "\n",
    "# Configuration File Path (Manually Set in Jupyter Notebook)\n",
    "config_file = \"./ISRUC.config\"  # Update with actual path\n",
    "gpu_number = \"0\"  # Set GPU number or \"-1\" to use CPU\n",
    "Path, _, cfgTrain, cfgModel = ReadConfig(config_file)\n",
    "\n",
    "# Set GPU number or use CPU only\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_number\n",
    "if gpu_number != \"-1\":\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    tf.compat.v1.Session(config=config)\n",
    "    print(\"Using GPU #\" + gpu_number)\n",
    "else:\n",
    "    print(\"Using CPU only\")\n",
    "\n",
    "# 1.2. Analytic Parameters\n",
    "channels = int(cfgTrain[\"channels\"])\n",
    "fold = int(cfgTrain[\"fold\"])\n",
    "context = int(cfgTrain[\"context\"])\n",
    "num_epochs = int(cfgTrain[\"epoch\"])\n",
    "batch_size = int(cfgTrain[\"batch_size\"])\n",
    "optimizer = cfgTrain[\"optimizer\"]\n",
    "learn_rate = float(cfgTrain[\"learn_rate\"])\n",
    "lambda_GRL = float(cfgTrain[\"lambda_GRL\"])\n",
    "\n",
    "dense_size = np.array(str.split(cfgModel[\"Globaldense\"], ','), dtype=int)\n",
    "GLalpha = float(cfgModel[\"GLalpha\"])\n",
    "num_of_chev_filters = int(cfgModel[\"cheb_filters\"])\n",
    "num_of_time_filters = int(cfgModel[\"time_filters\"])\n",
    "time_conv_strides = int(cfgModel[\"time_conv_strides\"])\n",
    "time_conv_kernel = int(cfgModel[\"time_conv_kernel\"])\n",
    "num_block = int(cfgModel[\"num_block\"])\n",
    "cheb_k = int(cfgModel[\"cheb_k\"])\n",
    "l1 = float(cfgModel[\"l1\"])\n",
    "l2 = float(cfgModel[\"l2\"])\n",
    "dropout = float(cfgModel[\"dropout\"])\n",
    "\n",
    "# Create save path\n",
    "save_path = Path['save']\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "shutil.copyfile(config_file, os.path.join(save_path, \"last.config\"))\n",
    "\n",
    "# 2. Read Data\n",
    "ReadList = np.load(Path['data'], allow_pickle=True)\n",
    "Fold_Num = ReadList['Fold_len']\n",
    "\n",
    "Dis_Conn = np.load(Path['disM'], allow_pickle=True)\n",
    "L_DC = scaled_Laplacian(Dis_Conn)\n",
    "cheb_poly_DC = cheb_polynomial(L_DC, cheb_k)\n",
    "\n",
    "print(\"Read data successfully\")\n",
    "Fold_Num_c = Fold_Num + 1 - context\n",
    "print(f'Number of samples: {np.sum(Fold_Num)} (with context: {np.sum(Fold_Num_c)})')\n",
    "\n",
    "Dom_Generator = DominGenerator(Fold_Num_c)\n",
    "\n",
    "# 3. Model Training (Cross-Validation)\n",
    "fit_acc, fit_loss, fit_val_loss, fit_val_acc = None, None, None, None\n",
    "\n",
    "for i in range(fold):\n",
    "    print(128 * '_')\n",
    "    print(f'Fold #{i}')\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "    regularizer = Instantiation_regularizer(l1, l2)\n",
    "    \n",
    "    feature_file = os.path.join(save_path, f'Feature_{i}.npz')\n",
    "    Features = np.load(feature_file, allow_pickle=True)\n",
    "    \n",
    "    train_feature = Features['train_feature']\n",
    "    val_feature = Features['val_feature']\n",
    "    train_targets = Features['train_targets']\n",
    "    val_targets = Features['val_targets']\n",
    "    \n",
    "    train_feature, train_targets = AddContext_MultiSub(train_feature, train_targets,\n",
    "                                                       np.delete(Fold_Num.copy(), i), context, i)\n",
    "    val_feature, val_targets = AddContext_SingleSub(val_feature, val_targets, context)\n",
    "    train_domin, val_domin = Dom_Generator.getFold(i)\n",
    "\n",
    "    sample_shape = val_feature.shape[1:]\n",
    "    \n",
    "    model, model_p = build_MSTGCN(\n",
    "        cheb_k, num_of_chev_filters, num_of_time_filters, time_conv_strides, cheb_poly_DC,\n",
    "        time_conv_kernel, sample_shape, num_block, dense_size, opt, GLalpha, regularizer, \n",
    "        dropout, lambda_GRL, num_classes=5, num_domain=9\n",
    "    )\n",
    "    \n",
    "    print(\"train_feature shape:\", train_feature.shape)\n",
    "    print(\"train_targets shape:\", train_targets.shape)\n",
    "    print(\"train_domin shape:\", train_domin.shape)\n",
    "\n",
    "    # Training Model\n",
    "    history = model.fit(\n",
    "        x=train_feature,\n",
    "        y=[train_targets, train_domin],\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        validation_data=(val_feature, [val_targets, val_domin]),\n",
    "        verbose=2,\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(save_path, f'FeatureNet_Best_{i}.h5'),\n",
    "            monitor='val_categorical_accuracy',\n",
    "            verbose=0,  \n",
    "            save_best_only=True,\n",
    "            save_weights_only=False, \n",
    "            mode='auto',\n",
    "            save_freq='epoch'\n",
    "        )]\n",
    "    )\n",
    "    \n",
    "    model.save(os.path.join(save_path, f'MSTGCN_Final_{i}.h5'))\n",
    "    \n",
    "    # Save Training History\n",
    "    with open(os.path.join(save_path, \"Result_MSTGCN.txt\"), 'a+') as saveFile:\n",
    "        print(f'Fold #{i}', file=saveFile)\n",
    "        print(history.history, file=saveFile)\n",
    "\n",
    "    # Aggregate Accuracy Metrics\n",
    "    fold_weight = Fold_Num_c[i]\n",
    "    \n",
    "    if fit_loss is None:\n",
    "        fit_loss = np.array(history.history['loss']) * fold_weight\n",
    "        fit_acc = np.array(history.history.get('categorical_accuracy', history.history.get('accuracy', []))) * fold_weight\n",
    "        fit_val_loss = np.array(history.history['val_loss']) * fold_weight\n",
    "        fit_val_acc = np.array(history.history.get('val_categorical_accuracy', history.history.get('val_accuracy', []))) * fold_weight\n",
    "    else:\n",
    "        fit_loss += np.array(history.history['loss']) * fold_weight\n",
    "        fit_acc += np.array(history.history.get('categorical_accuracy', history.history.get('accuracy', []))) * fold_weight\n",
    "        fit_val_loss += np.array(history.history['val_loss']) * fold_weight\n",
    "        fit_val_acc += np.array(history.history.get('val_categorical_accuracy', history.history.get('val_accuracy', []))) * fold_weight\n",
    "\n",
    "    # Cleanup Memory\n",
    "    keras.backend.clear_session()\n",
    "    del model, model_p, train_feature, train_targets, val_feature, val_targets\n",
    "    gc.collect()\n",
    "\n",
    "# 4. Final Results\n",
    "total_samples = np.sum(Fold_Num_c)\n",
    "final_train_acc = np.sum(fit_acc) / total_samples\n",
    "final_val_acc = np.sum(fit_val_acc) / total_samples\n",
    "\n",
    "print(f\"\\nFinal Training Accuracy: {final_train_acc:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "\n",
    "# Save Accuracy Results\n",
    "with open(os.path.join(save_path, \"Final_Accuracy_MSTGCN.txt\"), 'w') as finalAccFile:\n",
    "    finalAccFile.write(f\"Final Training Accuracy: {final_train_acc:.4f}\\n\")\n",
    "    finalAccFile.write(f\"Final Validation Accuracy: {final_val_acc:.4f}\\n\")\n",
    "\n",
    "# Plot Accuracy & Loss Curves\n",
    "VariationCurve(fit_acc / total_samples, fit_val_acc / total_samples, 'Accuracy', save_path, figsize=(9, 6))\n",
    "VariationCurve(fit_loss / total_samples, fit_val_loss / total_samples, 'Loss', save_path, figsize=(9, 6))\n",
    "\n",
    "print(128 * '_')\n",
    "print('End of training MSTGCN.')\n",
    "print(128 * '#')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################################################################\n",
      "Start to evaluate MSTGCN.\n",
      "Config:  ./ISRUC.config\n",
      "Use GPU #0\n",
      "Read data successfully\n",
      "Number of samples: 8589 (with context: 8549 )\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 0\n",
      "Evaluate 0.792391300201416\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 1\n",
      "Evaluate 0.6968026757240295\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 2\n",
      "Evaluate 0.7316455841064453\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 3\n",
      "Evaluate 0.7723684310913086\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 4\n",
      "Evaluate 0.7758241891860962\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 5\n",
      "Evaluate 0.7948718070983887\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 6\n",
      "Evaluate 0.7756410241127014\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 7\n",
      "Evaluate 0.8871635794639587\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 8\n",
      "Evaluate 0.7754010558128357\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 9\n",
      "Evaluate 0.7257217764854431\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step\n",
      "Unique values in AllTrue after mapping: [0 1 4]\n",
      "Unique values in AllPred after mapping: [0 1 4]\n",
      "================================================================================================================================\n",
      "All folds' acc: [0.792391300201416, 0.6968026757240295, 0.7316455841064453, 0.7723684310913086, 0.7758241891860962, 0.7948718070983887, 0.7756410241127014, 0.8871635794639587, 0.7754010558128357, 0.7257217764854431]\n",
      "Average acc of each fold: 0.7727831423282623\n",
      "Main scores:\n",
      "Acc\tF1S\tKappa\tF1_Normal\tF1_CSA\tF1_OSA\n",
      "0.8540\t0.7616\t0.6538\t0.9206\t0.5594\t0.8049\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.92      0.92      0.92      6274\n",
      "         CSA       0.54      0.58      0.56      1215\n",
      "         OSA       0.87      0.75      0.80      1060\n",
      "\n",
      "    accuracy                           0.85      8549\n",
      "   macro avg       0.77      0.75      0.76      8549\n",
      "weighted avg       0.86      0.85      0.85      8549\n",
      "\n",
      "Confusion matrix:\n",
      "[[5801  427   46]\n",
      " [ 435  704   76]\n",
      " [  93  171  796]]\n",
      "\n",
      "    Accuracy\t 0.854018013802784\n",
      " Cohen Kappa\t 0.6538489652522066\n",
      "    F1-Score\t 0.7616079867109038 \tAverage = macro\n",
      "   Precision\t 0.7747945000259552 \tAverage = macro\n",
      "      Recall\t 0.7516589213536694 \tAverage = macro\n",
      "Main scores:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of evaluating MSTGCN.\n",
      "################################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import shutil\n",
    "import gc\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as KTF\n",
    "from model.MSTGCN import build_MSTGCN\n",
    "from model.DataGenerator import DominGenerator\n",
    "from model.Utils import *\n",
    "\n",
    "print(128 * '#')\n",
    "print('Start to evaluate MSTGCN.')\n",
    "\n",
    "# Configuration file path and GPU number\n",
    "config_file = \"./ISRUC.config\"  # Change to your actual config file path\n",
    "gpu_number = \"0\"  # Change GPU number, use \"-1\" for CPU only\n",
    "\n",
    "Path, _, cfgTrain, cfgModel = ReadConfig(config_file)\n",
    "\n",
    "# Set GPU number or use CPU only\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_number\n",
    "if gpu_number != \"-1\":\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "    print(\"Use GPU #\" + gpu_number)\n",
    "else:\n",
    "    print(\"Use CPU only\")\n",
    "\n",
    "# Load training parameters\n",
    "channels = int(cfgTrain[\"channels\"])\n",
    "fold = int(cfgTrain[\"fold\"])\n",
    "context = int(cfgTrain[\"context\"])\n",
    "num_epochs = int(cfgTrain[\"epoch\"])\n",
    "batch_size = int(cfgTrain[\"batch_size\"])\n",
    "optimizer = cfgTrain[\"optimizer\"]\n",
    "learn_rate = float(cfgTrain[\"learn_rate\"])\n",
    "lambda_GRL = float(cfgTrain[\"lambda_GRL\"])\n",
    "\n",
    "# Load model parameters\n",
    "dense_size = np.array(str.split(cfgModel[\"Globaldense\"], ','), dtype=int)\n",
    "GLalpha = float(cfgModel[\"GLalpha\"])\n",
    "num_of_chev_filters = int(cfgModel[\"cheb_filters\"])\n",
    "num_of_time_filters = int(cfgModel[\"time_filters\"])\n",
    "time_conv_strides = int(cfgModel[\"time_conv_strides\"])\n",
    "time_conv_kernel = int(cfgModel[\"time_conv_kernel\"])\n",
    "num_block = int(cfgModel[\"num_block\"])\n",
    "cheb_k = int(cfgModel[\"cheb_k\"])\n",
    "l1 = float(cfgModel[\"l1\"])\n",
    "l2 = float(cfgModel[\"l2\"])\n",
    "dropout = float(cfgModel[\"dropout\"])\n",
    "\n",
    "# Create save path and copy config file\n",
    "if not os.path.exists(Path['Save']):\n",
    "    os.makedirs(Path['Save'])\n",
    "shutil.copyfile(config_file, Path['Save'] + \"last.config\")\n",
    "\n",
    "# Read data\n",
    "ReadList = np.load(Path['data'], allow_pickle=True)\n",
    "Fold_Num = ReadList['Fold_len']\n",
    "\n",
    "# Read adjacency matrix\n",
    "Dis_Conn = np.load(Path['disM'], allow_pickle=True)\n",
    "L_DC = scaled_Laplacian(Dis_Conn)\n",
    "cheb_poly_DC = cheb_polynomial(L_DC, cheb_k)\n",
    "\n",
    "print(\"Read data successfully\")\n",
    "Fold_Num_c = Fold_Num + 1 - context\n",
    "print('Number of samples:', np.sum(Fold_Num), '(with context:', np.sum(Fold_Num_c), ')')\n",
    "\n",
    "# Create DominGenerator\n",
    "Dom_Generator = DominGenerator(Fold_Num_c)\n",
    "\n",
    "# Cross-validation training\n",
    "all_scores = []\n",
    "for i in range(fold):\n",
    "    print(128 * '_')\n",
    "    print('Fold #', i)\n",
    "\n",
    "    # Optimizer and regularizer\n",
    "    opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "    regularizer = Instantiation_regularizer(l1, l2)\n",
    "\n",
    "    # Load features and targets\n",
    "    Features = np.load(Path['Save'] + 'Feature_' + str(i) + '.npz', allow_pickle=True)\n",
    "    val_feature = Features['val_feature']\n",
    "    val_targets = Features['val_targets']\n",
    "\n",
    "    val_feature, val_targets = AddContext_SingleSub(val_feature, val_targets, context)\n",
    "    train_domin, val_domin = Dom_Generator.getFold(i)\n",
    "    sample_shape = val_feature.shape[1:]\n",
    "\n",
    "    # Build MSTGCN model\n",
    "    model, model_p = build_MSTGCN(cheb_k, num_of_chev_filters, num_of_time_filters, time_conv_strides, cheb_poly_DC,\n",
    "                                  time_conv_kernel, sample_shape, num_block, dense_size, opt, GLalpha, regularizer, \n",
    "                                  dropout, lambda_GRL, num_classes=5, num_domain=9)\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_weights(Path['Save'] + 'MSTGCN_Final_' + str(i) + '.h5')\n",
    "    val_mse, val_acc = model_p.evaluate(val_feature, val_targets, verbose=0)\n",
    "    print('Evaluate', val_acc)\n",
    "    all_scores.append(val_acc)\n",
    "\n",
    "    # Predictions\n",
    "    predicts = model_p.predict(val_feature)\n",
    "    AllPred_temp = np.argmax(predicts, axis=1)\n",
    "    AllTrue_temp = np.argmax(val_targets, axis=1)\n",
    "\n",
    "    if i == 0:\n",
    "        AllPred = AllPred_temp\n",
    "        AllTrue = AllTrue_temp\n",
    "    else:\n",
    "        AllPred = np.concatenate((AllPred, AllPred_temp))\n",
    "        AllTrue = np.concatenate((AllTrue, AllTrue_temp))\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    del model, model_p, val_feature, val_targets\n",
    "    gc.collect()\n",
    "\n",
    "# Apply Label Mapping for Classification Report\n",
    "AllTrue[AllTrue == 5] = 2  # Map REM to CSA\n",
    "AllTrue[AllTrue == 1] = 1  # N1 remains OSA\n",
    "AllTrue[np.isin(AllTrue, [0, 2, 3])] = 0  # Wake, N2, N3 → Normal\n",
    "\n",
    "AllPred[AllPred == 5] = 2  # Ensure predicted labels follow the same mapping\n",
    "AllPred[AllPred == 1] = 1  # N1 remains OSA\n",
    "AllPred[np.isin(AllPred, [0, 2, 3])] = 0  # Wake, N2, N3 → Normal\n",
    "\n",
    "# Print unique values to debug mapping\n",
    "print(\"Unique values in AllTrue after mapping:\", np.unique(AllTrue))\n",
    "print(\"Unique values in AllPred after mapping:\", np.unique(AllPred))\n",
    "\n",
    "# Final results\n",
    "print(128 * '=')\n",
    "print(\"All folds' acc:\", all_scores)\n",
    "print(\"Average acc of each fold:\", np.mean(all_scores))\n",
    "\n",
    "# Print evaluation results\n",
    "PrintScore(AllTrue, AllPred)  # Remove target_names\n",
    "PrintScore(AllTrue, AllPred, savePath=Path['Save'])  # Remove target_names\n",
    "ConfusionMatrix(AllTrue, AllPred, classes=['Normal', 'OSA', 'CSA'], savePath=Path['Save'])\n",
    "\n",
    "\n",
    "print('End of evaluating MSTGCN.')\n",
    "print(128 * '#')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 0\n",
      "Fold 0 Accuracy: 0.7946\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step\n",
      "Fold 0 - Unique values in AllTrue: [0 1 4]\n",
      "Fold 0 - Unique values in AllPred: [0 1 4]\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 1\n",
      "Fold 1 Accuracy: 0.6968\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step\n",
      "Fold 1 - Unique values in AllTrue: [0 1 4]\n",
      "Fold 1 - Unique values in AllPred: [0 1 4]\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 2\n",
      "Fold 2 Accuracy: 0.7342\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step\n",
      "Fold 2 - Unique values in AllTrue: [0 1 4]\n",
      "Fold 2 - Unique values in AllPred: [0 1 4]\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 3\n",
      "Fold 3 Accuracy: 0.7697\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step\n",
      "Fold 3 - Unique values in AllTrue: [0 1 4]\n",
      "Fold 3 - Unique values in AllPred: [0 1 4]\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 4\n",
      "Fold 4 Accuracy: 0.7769\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step\n",
      "Fold 4 - Unique values in AllTrue: [0 1 4]\n",
      "Fold 4 - Unique values in AllPred: [0 1 4]\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 5\n",
      "Fold 5 Accuracy: 0.7949\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step\n",
      "Fold 5 - Unique values in AllTrue: [0 1 4]\n",
      "Fold 5 - Unique values in AllPred: [0 1 4]\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 6\n",
      "Fold 6 Accuracy: 0.7731\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step\n",
      "Fold 6 - Unique values in AllTrue: [0 1 4]\n",
      "Fold 6 - Unique values in AllPred: [0 1 4]\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 7\n",
      "Fold 7 Accuracy: 0.8882\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step\n",
      "Fold 7 - Unique values in AllTrue: [0 1 4]\n",
      "Fold 7 - Unique values in AllPred: [0 1 4]\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 8\n",
      "Fold 8 Accuracy: 0.7722\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step\n",
      "Fold 8 - Unique values in AllTrue: [0 1 4]\n",
      "Fold 8 - Unique values in AllPred: [0 1 4]\n",
      "________________________________________________________________________________________________________________________________\n",
      "Fold # 9\n",
      "Fold 9 Accuracy: 0.7218\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step\n",
      "Fold 9 - Unique values in AllTrue: [0 1 4]\n",
      "Fold 9 - Unique values in AllPred: [0 1 4]\n",
      "================================================================================================================================\n",
      "Best fold: 7 with Accuracy: 0.8882\n",
      "All folds' acc: [0.7945652008056641, 0.6968026757240295, 0.7341772317886353, 0.7697368264198303, 0.7769230604171753, 0.7948718070983887, 0.7730769515037537, 0.888198733329773, 0.7721925377845764, 0.721784770488739]\n",
      "Average acc of each fold: 0.7722\n",
      "Main scores:\n",
      "Acc\tF1S\tKappa\tF1_Normal\tF1_CSA\tF1_OSA\n",
      "0.9224\t0.8536\t0.8145\t0.9538\t0.6439\t0.9632\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.95      0.96      0.95       710\n",
      "         CSA       0.69      0.61      0.64       109\n",
      "         OSA       0.95      0.98      0.96       147\n",
      "\n",
      "    accuracy                           0.92       966\n",
      "   macro avg       0.86      0.85      0.85       966\n",
      "weighted avg       0.92      0.92      0.92       966\n",
      "\n",
      "Confusion matrix:\n",
      "[[681  27   2]\n",
      " [ 37  66   6]\n",
      " [  0   3 144]]\n",
      "\n",
      "    Accuracy\t 0.922360248447205\n",
      " Cohen Kappa\t 0.8145009319759939\n",
      "    F1-Score\t 0.8536315513235232 \tAverage = macro\n",
      "   Precision\t 0.8611121292088159 \tAverage = macro\n",
      "      Recall\t 0.8480837844893742 \tAverage = macro\n",
      "Main scores:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of evaluating MSTGCN.\n",
      "################################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# # Cross-validation training\n",
    "all_scores = []\n",
    "best_accuracy = 0  # Track max accuracy\n",
    "best_fold = -1\n",
    "best_pred = None\n",
    "best_true = None\n",
    "\n",
    "for i in range(fold):\n",
    "    print(128 * '_')\n",
    "    print(f'Fold # {i}')\n",
    "\n",
    "    # Optimizer and regularizer\n",
    "    opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "    regularizer = Instantiation_regularizer(l1, l2)\n",
    "\n",
    "    # Load features and targets\n",
    "    Features = np.load(Path['Save'] + f'Feature_{i}.npz', allow_pickle=True)\n",
    "    val_feature = Features['val_feature']\n",
    "    val_targets = Features['val_targets']\n",
    "\n",
    "    val_feature, val_targets = AddContext_SingleSub(val_feature, val_targets, context)\n",
    "    train_domin, val_domin = Dom_Generator.getFold(i)\n",
    "    sample_shape = val_feature.shape[1:]\n",
    "\n",
    "    # Build MSTGCN model\n",
    "    model, model_p = build_MSTGCN(cheb_k, num_of_chev_filters, num_of_time_filters, time_conv_strides, cheb_poly_DC,\n",
    "                                  time_conv_kernel, sample_shape, num_block, dense_size, opt, GLalpha, regularizer,\n",
    "                                  dropout, lambda_GRL, num_classes=5, num_domain=9)\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_weights(Path['Save'] + f'MSTGCN_Final_{i}.h5')\n",
    "    val_mse, val_acc = model_p.evaluate(val_feature, val_targets, verbose=0)\n",
    "    print(f'Fold {i} Accuracy: {val_acc:.4f}')\n",
    "    all_scores.append(val_acc)\n",
    "\n",
    "    # Predictions\n",
    "    predicts = model_p.predict(val_feature)\n",
    "    AllPred_temp = np.argmax(predicts, axis=1)\n",
    "    AllTrue_temp = np.argmax(val_targets, axis=1)\n",
    "\n",
    "    # Apply Label Mapping\n",
    "    AllTrue_temp[AllTrue_temp == 5] = 2  # Map REM to CSA\n",
    "    AllTrue_temp[AllTrue_temp == 1] = 1  # N1 remains OSA\n",
    "    AllTrue_temp[np.isin(AllTrue_temp, [0, 2, 3])] = 0  # Wake, N2, N3 → Normal\n",
    "\n",
    "    AllPred_temp[AllPred_temp == 5] = 2  # Ensure predicted labels follow the same mapping\n",
    "    AllPred_temp[AllPred_temp == 1] = 1  # N1 remains OSA\n",
    "    AllPred_temp[np.isin(AllPred_temp, [0, 2, 3])] = 0  # Wake, N2, N3 → Normal\n",
    "\n",
    "    # Debugging: Print unique values after mapping\n",
    "    print(f\"Fold {i} - Unique values in AllTrue: {np.unique(AllTrue_temp)}\")\n",
    "    print(f\"Fold {i} - Unique values in AllPred: {np.unique(AllPred_temp)}\")\n",
    "\n",
    "    # Update best accuracy and store corresponding predictions\n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        best_fold = i\n",
    "        best_pred = AllPred_temp.copy()\n",
    "        best_true = AllTrue_temp.copy()\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    del model, model_p, val_feature, val_targets\n",
    "    gc.collect()\n",
    "\n",
    "# Final results\n",
    "print(128 * '=')\n",
    "print(f\"Best fold: {best_fold} with Accuracy: {best_accuracy:.4f}\")\n",
    "print(\"All folds' acc:\", all_scores)\n",
    "print(f\"Average acc of each fold: {np.mean(all_scores):.4f}\")\n",
    "\n",
    "# Ensure best_true and best_pred are not None\n",
    "if best_true is not None and best_pred is not None:\n",
    "    PrintScore(best_true, best_pred)\n",
    "    PrintScore(best_true, best_pred, savePath=Path['Save'])\n",
    "    ConfusionMatrix(best_true, best_pred, classes=['Normal', 'OSA', 'CSA'], savePath=Path['Save'])\n",
    "else:\n",
    "    print(\"No valid predictions found. Check model training and evaluation.\")\n",
    "\n",
    "print('End of evaluating MSTGCN.')\n",
    "print(128 * '#')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHWCAYAAABACtmGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAgvlJREFUeJzt3Qd0VFUXBeCd0HvvIE2QDkoTEQtVQKoKAkqTDopi5VcpiqCCiAUB6RYUkF6kF0GqFEGqShPp0kFq5l/7XV8ykwRSSOZN2d9al0wmk5k7L5Pwzpxzzw1xuVwuiIiIiIiIyC2F3vpLIiIiIiIiQgqcREREREREYqDASUREREREJAYKnERERERERGKgwElERERERCQGCpxERERERERioMBJREREREQkBgqcREREREREYqDASUREREREJAYKnEREfFDbtm1RoECBeH1vv379EBISgkB24MAB6zlOmDDB64/Nx+UxtnEOvI5zigl/pvzZ+sprRUREYk+Bk4hIHPAEOTZjxYoVTk816L3wwgvWz+KPP/645W3efPNN6zbbtm2DLzty5IgVrG3duhW+FrwOGTLE6amIiHhFUu88jIhIYPj66689Pv/qq6+wePHiKNcXL178jh5n9OjRCAsLi9f3vvXWW3jjjTcQ7Fq1aoXPPvsMkyZNQp8+faK9zXfffYfSpUujTJky8X6cZ599Fk8//TRSpEiBxAyc+vfvb2WWypUrl2CvFRERiT0FTiIicfDMM894fL5u3TorcIp8fWSXL19G6tSpY/04yZIli/cckyZNao1gV7lyZdx9991WcBRd4LR27Vrs378f77///h09TpIkSazhlDt5rYiISOypVE9EJIE98sgjKFWqFDZt2oSHHnrICpj+97//WV+bNWsW6tevj9y5c1sZisKFC+Pdd9/FzZs3b7tuxb0s6ssvv7S+j99fsWJFbNy4McY1Tvy8R48emDlzpjU3fm/JkiWxYMGCKPNnmWGFChWQMmVK63FGjRoV63VTq1atwlNPPYW77rrLeox8+fLhpZdewr///hvl+aVNmxZ///03GjdubF3Oli0bXnnllSjH4uzZs9btM2TIgIwZM6JNmzbWdbHNOu3evRubN2+O8jVmovicWrRogWvXrlnBVfny5a3HSZMmDapVq4bly5fH+BjRrXFyuVwYMGAA8ubNa/38H330UezYsSPK954+fdp6zsx68RikT58edevWxa+//urx8+DPmdq1axdeDmqv74pujdOlS5fw8ssvW8efP4d77rnHeu1wXvF9XcTXiRMn8NxzzyFHjhzWa6ps2bKYOHFilNt9//331vFPly6ddRx4TD755JPwr1+/ft3KuhUpUsS6nyxZsuDBBx+03rgQEfEGvSUpIpII/vnnH+sEmCVczEbxpJF4sssT5F69elkfly1bZp2wnz9/HoMHD47xfnmyf+HCBXTu3Nk66f3www/RtGlT7Nu3L8bMw+rVqzF9+nR069bNOjn99NNP8cQTT+DQoUPWSSht2bIFjz32GHLlymWdpDKIeeedd6ygJjamTp1qZde6du1q3eeGDRuscrnDhw9bX3PH+65Tp46VGeJJ/ZIlS/DRRx9ZwRq/n3ii36hRI2vuXbp0sUogZ8yYYQVPsQ2c+Dx43O677z6Px54yZYoVHDHIO3XqFMaMGWMFUR07drSO8dixY6358TlELo+LCX+mDJzq1atnDQZutWvXtgI0d/y5MWhhsFmwYEEcP37cClQffvhh7Ny50wqw+Zz5M+B9durUyZozPfDAA9E+No9Zw4YNraCPAQvnvnDhQrz66qtWoPrxxx/H+XURXwyY+UYC15kxQONz5OuAwR6D3549e1q3Y/DDY1+jRg188MEH1nW7du3Czz//HH4bBu+DBg1Chw4dUKlSJet35pdffrGOba1ate5oniIiseISEZF46969O9/C97ju4Ycftq4bOXJklNtfvnw5ynWdO3d2pU6d2nXlypXw69q0aePKnz9/+Of79++37jNLliyu06dPh18/a9Ys6/o5c+aEX9e3b98oc+LnyZMnd/3xxx/h1/3666/W9Z999ln4dQ0aNLDm8vfff4df9/vvv7uSJk0a5T6jE93zGzRokCskJMR18OBBj+fH+3vnnXc8bnvvvfe6ypcvH/75zJkzrdt9+OGH4dfduHHDVa1aNev68ePHxzinihUruvLmzeu6efNm+HULFiywvn/UqFHh93n16lWP7ztz5owrR44crvbt23tcz+/jMbZxDryOPyM6ceKEdazr16/vCgsLC7/d//73P+t2fO42/szd50W8nxQpUngcm40bN97y+UZ+rdjHbMCAAR63e/LJJ62fg/trILavi+jYr8nBgwff8jbDhg2zbvPNN9+EX3ft2jVXlSpVXGnTpnWdP3/euq5nz56u9OnTWz+HWylbtqx1TEVEnKJSPRGRRMCSJ5ZVRZYqVarwy8xqMNPBDAKzNCwpi0nz5s2RKVOm8M/t7AMzFzGpWbOmlc2xsSECS6Ls72UWhlkfls4x02HjOiFmz2LD/fmxXIzPj5kRnqMzmxUZs0ju+Hzcn8v8+fOt9Vp2Boq4nuj5559HbDHjx4zXTz/9FH4dM1DJkye3Mj32ffJzYqMFltDduHHDKlmMrszvdngMmVniHN3LG1988cVoXyehoaHhx5+ZSmYiWVoX18d1P2Z8Puwq6I6le/w5/Pjjj3F6XdwJziVnzpxWNsnGzCjndvHiRaxcudK6jiWYfL3cruyOt2G54++//37H8xIRiQ8FTiIiiSBPnjzhJ+LueOLXpEkTax0NT05ZAmc3ljh37lyM98uyMnd2EHXmzJk4f6/9/fb3ci0KS6sYKEUW3XXRYXkXy7AyZ84cvm6JZWfRPT+uU4lcAug+Hzp48KBVNsj7csfAIrZYLslAgsESXblyxSr3YzDoHoRy3Q2DBnv9DOc2b968WP1c3HHOxLU47nh/7o9nB2ksneNtGURlzZrVuh3bo8f1cd0fn4Evy+6i6/Rozy+2r4s7wcfic7ODw1vNhWWCRYsWtX4mXBfWvn37KOusWK7I8j7ejuufWHro623kRSSwKHASEUkE7pkXG0/6GERw4T9PAufMmWO9w26v6YhNS+lbdW+LvOg/ob83Npgx4VoTBhuvv/66tXaHz89uYhD5+XmrE1327NmteU2bNs1qMMDjzmwf1z/ZvvnmGyvgY+aFa5t40s65V69ePVFbfQ8cONBa78YmIpwD1yLxcdmgwVstxhP7dRHbnxH3qJo9e3b4+iwGUe5r2XiM/vzzT4wbN85qZME1aVy3xo8iIt6g5hAiIl7C7mgsxeJCfJ4E2tgS2xfw5JXZlug2jL3dJrK27du3Y+/evVbmpnXr1uHX30nXs/z582Pp0qVWWZd71mnPnj1xuh8GSQyGWKbGzBOzfQ0aNAj/+g8//IBChQpZPxv38rq+ffvGa87EkjLep+3kyZNRsjh8XHbcY7AWOchm9skWm46G7o/PckEGh+5ZJ7sU1J6fN/CxmBViEOiedYpuLszQ8mfCwdszC8VGGW+//XZ4xpOZTJbAcvA1wd8jNo1gwwgRkcSmjJOIiJfY7+y7v5PPtTBffPEFfGV+XO/CTBE3XHUPmiKvi7nV90d+frzs3lI6rtiRjmuNRowY4ZHZYqe+uOC6LbYF57Hmc2EnQgaJt5v7+vXrrb2e4orHkOt4OEf3+xs2bFiU2/JxI2d22HWO3e/csT06xaYNO48Zj9Hnn3/ucT1LAhmAxXa9WkLgXI4dO4bJkyeHX8efJ48NA2G7jJNvKLhjkGVvSnz16tVob8PvZ0Blf11EJLEp4yQi4iVsksC1Iyw/4uJ4nsR+/fXXXi2JignfvV+0aBGqVq1qNWSwT8BZGsVSqtspVqyYVerGfYl44s+sDsvj7mStDLMPnMsbb7xh7ZNUokQJKysU1/U/PMlm8GSvc3Iv06PHH3/cul+uP+M+W8wCjhw50no8Zjbiwt6Piq2zeb8MHtgYgwGbexbJflyWbTKDwtcHs3bffvutR6aKeFzZHIFzYhaJgRTbuLO9d3THjFmsN9980zpm3DeJP1PuIcYGFe6NIBICM4JcNxYZjzfbpzNrxDJI7mvG/aaYZWObcQaSdkaMGSM25GBpJNc4ce0Tgyu2UrfXQ/Fnwdbm3OuJmSe2Iud9sc25iIg3KHASEfESNhyYO3eu1d3srbfesoIoNobg3jXcL8gX8KSUJ/g88WeJFDdQ5Yk999SJqesfsyxcP8SgkEEDMzoMRHhiy5P3+GDmgeteeMLPNUAMNrkGhvs93XvvvXG6LwZLDJzYbIIn6O54Ys/MCE/yuc6IJ+l8PGZ/WGIZV9zDic+fgQ7X6zDIYfDCoMwdN0ZmNznOi1kZrtnhGjEGipGPLUsge/fubXUiZNZm/Pjx0QZO9jHjvk+8T96OAQv3CeNrL6GxBDK6DXP5mAy4efz4fDh/7r3Exh6cE4+5jb8H3NiZGUFm1diJjx0kGcjbJX58XfF58Tgyy8QyPx5nNokQEfGGEPYk98ojiYiI32L2QK2gRUQkmGmNk4iIeGBLcncMlrgfD8ukREREgpUyTiIi4oGlbCyj4jobrjVhYwaWRnGdTuS9iURERIKF1jiJiIiHxx57DN9995215oebslapUsXab0hBk4iIBDNlnERERERERGKgNU4iIiIiIiIxUOAkIiIiIiISg6Bb4xQWFoYjR45Ym+5xPxAREREREQlOLpcLFy5cQO7cucP3jbuVoAucGDRxQ0cRERERERH666+/kDdvXtxO0AVOzDTZByd9+vROTyegXb9+3drhvXbt2tau95L4dMy9T8fcu3S8vU/H3Pt0zL1Lxzu4j/n58+etpIodI9xO0AVOdnkegyYFTon/S5E6dWrrODv9SxEsdMy9T8fcu3S8vU/H3Pt0zL1Lx9v7rvvgMY/NEh41hxAREREREYmBAicREREREZEYKHASERERERGJQdCtcRIRERER32wLfePGDdy8edPr622SJk2KK1eueP2xg9V1Lx9zrqNKkiTJHd+PAicRERERcdS1a9dw9OhRXL582ZGALWfOnFbHZe3xGZjHPCQkxGo1njZt2ju6HwVOIiIiIuKYsLAw7N+/38oIcBPS5MmTezWA4eNfvHjROqmOaQNU8b9jziDt5MmTOHz4MIoUKXJHmScFTiIiIiLiaLaJJ9LcS4ctqr2Nj805pEyZUoFTgB7zbNmy4cCBA1aJ4J0ETnp1iIiIiIjjFLRIYkmoDKZeoSIiIiIiIjFQ4CQiIiIiIhIDBU4iIiIiIj6gQIECGDZsWKxvv2LFCqsM7ezZs4k6LzEUOImIiIiIxAGDlduNfv36xet+N27ciE6dOsX69g888IDVxj1DhgxITArQDHXVcxpfgBkzOj0LEREREYklBiu2yZMno0+fPtizZ0/4de77BbEdNjd55Yavsen+Fhds3c79kMQ7lHFy0vz5QP78wIIFTs9ERERExCe4XMClS84MPnZsMFixB7M9zMbYn+/evRvp0qXDjz/+iPLlyyNFihRYvXo1/vzzTzRq1Ag5cuSwAquKFStiyZIlty3V4/2OGTMGTZo0sVq1cx+i2bNn3zITNGHCBGTMmBELFy5E8eLFrcd57LHHPAK9Gzdu4IUXXrBulyVLFrz++uto06YNGjduHO+f2ZkzZ9C6dWtkypTJmmfdunXx+++/h3/94MGDaNCggfX1NGnSoHTp0li0aFH497Zq1coKGlOlSmU9x/Hjx8MXKXBy0nffAefPA02bAj//7PRsRERERBx3+TIzNt4b6dOHIm/ejNZHPnZCeeONN/D+++9j165dKFOmjLXha7169bB06VJs2bLFCmgYTBw6dOi299O/f380a9YM27Zts76fQcbp06dvc/wuY8iQIfj666/x008/Wff/yiuvhH/9gw8+wLfffmsFJz///DPOnz+PmTNn3tFzbdu2LX755RcrqFu7dq2VZeNcuW8Sde/eHVevXrXms337dgwaNMgKoOjtt9/Gzp07rUCTx2rEiBHImjUrfJFK9Zw0dizwzz/Ajz8C9esDK1cCZcs6PSsRERERuUPvvPMOatWqFf555syZUdbtPO/dd9/FjBkzrGCjR48etw1KWrRoYV0eOHAgPv30U2zYsMEKvKLDYGXkyJEoXLiw9Tnvm3OxffbZZ+jdu7eVxaLPP/8c81kFFU+///679RwYhHHNFTEw44bGDMieeuopK3h74oknrEyTnVljwEb82r333osKFSqEf81XKXByUvLkwA8/AHXqAKtXA7Vrm49Fijg9MxERERFHpE4NXLzovccLCwuzTuLTp0+P1KkTrhjLDgRszDixacS8efOs0jmWzP37778xZpyYrbIxS8N5njhx4pa3Z6mcHTRRrly5wm9/7tw5HD9+HJUqVQr/epIkSaySQh6H+Ni1a5e1fqty5crh17EE8J577rG+RiwN7Nq1q1WeV7NmTStoswMkXs+gavPmzahdu7ZVMmgHYL5GpXq+8NdhzhygXDmAL+qaNYHDh52elYiIiIgjQkIYIDgz+NgJxS5Fs7FcjhkmZo1WrVqFrVu3WhmYa9eu3fZ+kiVLFun4hNw2yInu9iydc1KHDh2wb98+PPvss1apHgO3L7/80voa10NxDdRLL72EI0eOoEaNGh6lhb5EgZMvYFc9NohgponvOjCte+qU07MSERERkQTCUjaW3THbwoCJjSQOHDjg1TmwkQWbU7DtuY0d/5jtia/ixYtb2bP169eHX/fPP/9YXQZLlCgRfh1L97p06YLp06ejV69emDhxYvjX2BiCDSq++eYbqzmGHVT5GpXq+YocOQB2VqlaFdi9G2Dd6rJlXLHo9MxERERE5A6xWxyDBjaEYBaITRHiWx53J55//nmrOcPdd9+NYsWKWWue2NmOc4rJ9u3brY6BNn4P122xW2DHjh0xatQo6+tsjJEnTx7renrxxRetzFLRokWtx2I3QJbyEVu5s1SwZMmSVgOJuXPnWsGYL1Lg5EvuugtYvBioVg3YtAlo2NA0jkiVyumZiYiIiMgdGDp0KNq3b2+t32HXOLYBtxskeBMf99ixY1b7cK5v4oa7derUsS7H5KGHHvL4nN/DbBM79PXs2ROPP/64VXrI27HhhF02yKwWO+sdPnzYWqPFx2O3QHsvKjarYPaN7cirVauG77//Hr4oxOV00aOX8QXKNCUXx/EH55MYND36KHDhAtCgATBtGgtW4W/Y1YW/NGxHGbneVhKHjrn36Zh7l4639+mYe1+wHfMrV65g//79KFiwIFKmTOn1x3dvDhEaGnyrWPj8meFhy3N2+gvEY37lNq+xuMQGwffq8AflywNz5wL8wbJxRPv2fIU5PSsRERER8XNsxDB69Gjs3bvXKr1jVzsGFS1btnR6aj5PgZOvYiqUrcqTJgW++YZ9HGO/nbWIiIiISDSY4ZkwYQIqVqyIqlWrWsHTkiVLfHZdkS/RGidfxk1x2XHkmWeA4cO5cxp3U3N6ViIiIiLip9jdjh3+JO6UcfJ1TJsyaCLWnX78sdMzEhEREREJOgqc/EHXrsB775nLvXoB48Y5PSMRERERkaCiwMlf9O4NvPyyudyxIzB9utMzEhEREREJGgqc/AU3JRs8GHjuOdNhr0ULs2GuiIiIiIgkOgVO/hY8jRoFPPkkcO0a0LgxsG6d07MSEREREQl4Cpz8DXd1Znvy2rWBS5eAunWB7dudnpWIiIiISEBT4OSPUqQwa5yqVAHOnjVB1J9/Oj0rEREREYmDRx55BC+++GL45wUKFMCwYcNu+z0hISGYOXPmHT92Qt1PMFHg5K/SpAHmzQNKlwaOHQNq1QKOHHF6ViIiIiIBr0GDBnjsscei/dqqVausoGTbtm1xvt+NGzeiU6dOSEj9+vVDuXLlolx/9OhR1GXlUiKaMGECMmbMiEChwMmfZcoELFoEFC4M7N9vgqd//nF6ViIiIiIB7bnnnsPixYtx+PDhKF8bP348KlSogDJlysT5frNly4bUqVPDG3LmzIkUrGKSWFPg5O9y5jTd9XLnBnbuBOrVAy5ccHpWIiIiIvHjcpl13E4MPnYsPP7441aQw4yKu4sXL2Lq1KlWYPXPP/+gRYsWyJMnjxUMlS5dGt99991t7zdyqd7vv/+Ohx56CClTpkSJEiWsYC2y119/HUWLFrUeo1ChQnj77bdx/fp162ucX//+/fHrr79aWTAOe86RS/W2b9+O6tWrI1WqVMiSJYuV+eLzsbVt2xaNGzfGkCFDkCtXLus23bt3D3+s+Dh06BAaNWqEtGnTIn369GjWrBmOHz8e/nXO+9FHH0W6dOmsr5cvXx6//PKL9bWDBw9amb9MmTIhTZo0KFmyJObPn4/ElDRR7128o0ABgL9I1aoBGzaYbnss40uZ0umZiYiIiMTN5ctA2rRezSKEF5MxUOByiBgkTZoUrVu3toKQN9980wpCiEHTzZs3rYCJQQdP9BnY8KR/3rx5ePbZZ1G4cGFUqlQpxscICwtD06ZNkSNHDqxfvx7nzp3zWA9lY1DBeeTOndsKfjp27Ghd99prr6F58+b47bffsGDBAiz5bxubDBkyRLmPS5cuoU6dOqhSpYpVLnjixAl06NABPXr08AgOly9fbgVN/PjHH39Y988yQD5mXPH5NWnSxAqaVq5ciRs3bliBGO9zxYoV1m1atWqFe++9FyNGjECSJEmwdetWJEuWzPoab3vt2jX89NNPVuC0c+dO674SkwKnQFGiBLBgAVC9OrBsmdnnaepU/mY7PTMRERGRgNO+fXsMHjzYOulnkwe7TO+JJ56wghOOV155Jfz2zz//PBYuXIgpU6bEKnBioLN7927rexgU0cCBA6OsS3rrrbc8MlZ8zO+//94KnJg9YjDBQI+lebcyadIkXLlyBV999ZUVhNDnn39uZXQ++OADK3gjZnd4PYOYYsWKoX79+li6dGm8AiceNwZ6+/fvR758+azr+PjMHDF4q1ixopWRevXVV63HoiJFioR/P7/GY81MHjHblthUqhdIKlYEZs82XfeYeu3QwWyWKyIiIuIvuMaHmR8vjbDz53H28GHro/XYscST+QceeADjxo2zPmcGho0hWKZHzDy9++671ol95syZrQCGQRBP+GNj165dVkBhB03EjFBkkydPRtWqVa3AiI/BQCq2j+H+WGXLlg0Pmoj3yazQnj17wq8rWbKkFTTZmH1idio+9u7daz0/O2giliOymQTnQ7169bIyXzVr1sT777+PP926SL/wwgsYMGCANc++ffvGqxlHXClwCjSPPgpMmWL2e5o4ka+4WNfrioiIiDiOZW88gXdi/FdyF1sMkqZNm4YLFy5Y2SaW4T388MPW15iN+uSTT6xSPZa2scyM5XAsL0soa9eutcrZ6tWrh7lz52LLli1W6WBCPoa7ZP+VydlYosjgKrGwI+COHTuszNayZcuswGrGjBnW1xhQ7du3zyp/ZOaKDTk+++wzJCYFToGoYUPmis3lTz4B3nnH6RmJiIiIBBw2MwgNDbVK3VhmxvI9e73Tzz//bDU+eOaZZ6xsDkvJmGWJreLFi+Ovv/6y2obb1q1b53GbNWvWIH/+/FawxMCBpWxsmuAuefLkVvYrpsdiIwaudbJx/nxu99xzDxJD0aJFrefHYeM6pbNnz1oBkvvtXnrpJSxatMha88UA1cZsVZcuXTB9+nS8/PLLGD16NBKTAqdA9eyzwKefmsv9+kVcFhEREZEEwdI4NjPo3bu3FeCw85yNQQy74DG4YelZ586dPTrGxYTlaQwa2rRpYwU1LANkgOSOj8GyPK5pYhnbp59+Gp6RcV/3xHVEzHidOnUKV69ejfJYzFqxcx8fi80kmCHjmixmc+z1TfHFoI2P7T54PLgujGWMfOzNmzdjw4YNVsMNZuwYBP77779Wcwo2imAwyECOa58Y5BEbZbD0kc+N3885219LLAqcAtnzzwP9+5vLPXtyxZ3TMxIREREJKCzXO3PmjFWG574eiWuN7rvvPut6Bglcg8R23rHFbA+DIAYQbCbB0rT33nvP4zYNGza0sjEMMNjdjkEa25G7YwMFbtbLtt5soR5dS3S2MmcQcvr0aaspw5NPPokaNWpYjSDu1MWLF63OeO6DmThm5vj82HCCLdcZKDIrxzVbxLVUbOnOYIoBJLN7bIzB9up2QMbOegyW+Px4my+++AKJKcTlCq4FMOfPn7e6nLClI1tDBjz+eLnOiXsCcN3TtGlAo0ZeeWj29Wc/fdbdRq6JlcShY+59OubepePtfTrm3hdsx5zd3Jg1KFiwoJX18Dau0eH5Ic8LGaxI4B3zK7d5jcUlNtCrI9Cxzvajj7hrGUNzFuOaduUiIiIiIhJrCpyCASN5LpZr0gRglxVmnLhRroiIiIiIxIoCp2DBjXAnTQJq1DD7FnDztB07nJ6ViIiIiIhfUOAUTFjTyU4r3K369Gmgdm1g/36nZyUiIiIi4vMUOAWbdOmAH3/k1s/AkSPsdQm47Q8gIiIi4oQg61cmfvjaUuAUjDJnBhYtAgoWBPbtA+rUMRkoERERES+zOwdevnzZ6alIgLrGNf7/tTi/E0kTaD7ib7jPwOLFwIMPAtu3A/Xrm8/TpnV6ZiIiIhJEeDKbMWNGnDhxInxPIe7x483W2DyxZstqtSMPvGMeFhaGkydPWq+rpFzz78+B0/DhwzF48GAcO3YMZcuWxWeffWZt8nUrZ8+etXZNnj59urVJV/78+TFs2DBrrwOJo8KFTbD00EPAunVA06bAnDlAihROz0xERESCCDeHJTt48nYZFzeZTZUqlVcDtmDm8vIxZ3B211133fFjORo4cWfgXr16YeTIkahcubIVAHF35T179iB79uxRbs/ItFatWtbXfvjhB+TJkwcHDx603qWQeCpVCpg/36x1YhDVqhXw/femC5+IiIiIF/CENleuXNY5HjcA9iY+3k8//YSHHnooKDYc9gXXvXzMkydPniCZLUfPjocOHYqOHTuiXbt21ucMoObNm4dx48bhjTfeiHJ7Xs8s05o1a8IPcoECBeDPfv4ZqFrV4Uncfz8wc6Yp15s2DejcGRgzxmyeKyIiIuLFsr07XYcSn8e8ceMGUqZMqcDJS5L46TF3LHBi9mjTpk3o3bt3+HWMBGvWrIm1a9dG+z2zZ89GlSpV0L17d8yaNQvZsmVDy5Yt8frrr9/yl+zq1avWsJ0/fz480vX2OxqRDRgQinfeSYL33ruJV18Nc3QuePhhhHz9NZK0aIGQceMQtncvwp5/Hq4GDeKdfbKPr9PHOZjomHufjrl36Xh7n4659+mYe5eOd3Af8+txmEOIy6Hej0eOHLFK7Zg9YjBke+2117By5UqsX78+yvcUK1YMBw4cQKtWrdCtWzf88ccf1scXXngBffv2jfZx+vXrh/79+0e5ftKkSdYiMSfNnFkYEyaUsi537boVdeochNPyLVuGcsOHI/TmTevzy9myYX/dujhYqxaus5W5iIiIiEiAYDdHJmLOnTuH9OnTB07gVLRoUav7xv79+8MzTCz3Y3OJo7fYiyi6jFO+fPlw6tSpGA+ON7z1Vig+/DAJQkJc+Prrm2jWzAf2MPjrL4R++SVCx4xByD//WFe5UqWCq2VL3OzWDShdOtYR/OLFi611af6UhvVnOubep2PuXTre3qdj7n065t6l4x3cx/z8+fPImjVrrAInx0r1OEEGP8ePH/e4np/bnVUi46JBHlz3srzixYtbHflY+seFX5GlSJHCGpHxfpz+QdH77wMXLgAjRoSgbduk1hZLdes6PKlChczEmMVjo4hPP0XI1q0IGTsWoWPHAo88ArzwAtCwIYtUY7w7XznWwUTH3Pt0zL1Lx9v7dMy9T8fcu3S8g/OYJ4vD4zvWrJ5BTvny5bF06VKPPuv83D0D5a5q1apWeR5vZ9u7d68VUEUXNPkD9l/4/HOgRQvgxg3giSeAVavgG1KlAti4Y/Nm4KefgKeeMoHSihWmdTnbmQ8erM1zRURERCTgObrLF1uRjx49GhMnTsSuXbvQtWtXXLp0KbzLXuvWrT2aR/Dr7KrXs2dPK2BiB76BAwdazSL8GbsjTpwIcCuqf/8FHn8c2LIFvhXdVasGTJkC7N8P8GeSJQtw8CBrK4G8eU0nvt9+c3qmIiIiIiKBFzg1b94cQ4YMQZ8+fVCuXDls3boVCxYsQI4cOayvHzp0yGPtEtcmLVy4EBs3bkSZMmWsphAMoqJrXe5vmCWcOtXEJ2z8V6cOs2nwPfnyAQMHWuugMG4cULasifa+/NKsfape3bQ2/6+5hIiIiIhIIHB8l9MePXpYIzorWBIWCcv41q1bh0DEJn9z5gCPPmoyTtyTlvs8MVbxOXYZX9u2wOrV1joozJgBLF9uRoECCO3SBcmYjRIRERER8XOOZpwkqgwZgAUL2EHQJHVq1QJOnoTvssv4mC7btw9g9o9lfAcOIMkbb6B2+/YIZSc+lfGJiIiIiB9T4OSDsmcHFi82maY9e4DHHgPOnYPvu+suYNAgE/GNHQtXmTJIeu0akowZY8r4atRQGZ+IiIiI+CUFTj4cgyxZAmTLZprasfM3lxL5BZbxtW+PGxs3YvV77yGsSRPTAWPZMoCX774bGDIEOHPG6ZmKiIiIiMSKAicfxnK9hQsB7sVldwO/fh3+IyQE/5QsiZuTJ5tufCzj40ZVBw4Ar75quvF16QLs2OH0TEVEREREbkuBk4+7915g7lwgZUpg3jzTi8FtGyv/YZfxHT4MsHSvTBng8mVg1CigVCnTCWPWLJXxiYiIiIhPUuDkB9h7Ydo0IGlSYNIkdiIEXC74J5bxPfccsHWr2UiXO/6yjI8bITdubMr4PvpIZXwiIiIi4lMUOPkJbo779demid2IEcDbb8O/8Yk8/DDwww+mG9/rr0eU8b3yiinj69oV2LnT6ZmKiIiIiChw8idPP22CJnrvPZOYCQj58wPvv2+68Y0eHVHGN3IkULKkKeObPdtPaxRFREREJBAocPIznTubpULExMzYsQisHYA7dIgo42vaNKKMr1EjoGVLP65RFBERERF/psDJD7E53WuvmcudOplqt4Bil/FxYZddxpcsGcDufEOHOj07EREREQlCCpz8FCvbOnY01WtMxCxahMBkl/ENG2Y+ZxDF3uwiIiIiIl6kwMlP2U0imjUzeztxX9k1axC42CjimWdMu3I+6SNHnJ6RiIiIiAQRBU5+LEkS02nvscdML4X69YFt2xC4kSL3fCpdGjh+PCJiFBERERHxAgVOfi55crMUqGpV4OxZoHZt4I8/EJjYPIJPNn164OefIxZ6iYiIiIgkMgVOARJPzJ0LlC1rkjHs3v333whMRYoAX31lLnPd05QpTs9IRERERIKAAqcAkTEjsHChiSsOHgRq1QJOnUJgYmtythak9u21Sa6IiIiIJDoFTgEkRw5g8WIgTx5g1y6gbl3gwgUEpnffBapXBy5dAp54IoCfqIiIiIj4AgVOAdi9m8FT1qzAL7+Y5MyVKwg8SZMC331nosTdu4HnntPmuCIiIiKSaBQ4BaDixYEFC4B06YDly4HmzQO0AV327MDUqWZzXH6093oSEREREUlgCpwCVPnywJw5QMqUwOzZJiHDzXIDTpUqwNCh5vKrrwKrVjk9IxEREREJQAqcAtjDD5tEjL3f04svBmg1W/fuQMuWEZvjHj3q9IxEREREJMAocApwjz8OTJxo9o/97DOgXz8EHj65L78ESpUCjh0L4NpEEREREXGKAqcg0KoV8Pnn5vI77wToUqA0aSI2x2W5nt2uXEREREQkAShwChLdugEDBpjLL70ETJiAwFO0aMQT47on1imKiIiIiCQABU5B5H//A3r1MpfZLGLGDASeJk2A116L2ByXG1qJiIiIiNwhBU5BhEuBhgwx8QQ77D39NLB0KQLPe+8Bjz4KXLxoNsflRxERERGRO6DAKcjYfRQYT1y7ZjbIXb8egbk5bu7cJuPUoUOAthMUEREREW9R4BSE2J7822+BWrWAS5eAunWB335DYMmRw6xxYhA1eTLw6adOz0hERERE/JgCpyCVIgUwfTpw//3AmTNA7drAvn0ILA88AHz0kbn8yivAzz87PSMRERER8VMKnIJY2rTA/PlA6dJmz1hmoAJu79jnnwdatABu3ACeesrs8yQiIiIiEkcKnIJcpkzAwoVA4cIm48TM0+nTCLxFXSVKmKiQHTEYRImIiIiIxIECJ0GuXMDixaaXAtc61asXYI3omFpjXWK6dMDKlUDv3k7PSERERET8jAInsRQsCCxaBGTObLrsNW4MXL2KwHHPPcD48eYye7JPm+b0jERERETEjyhwknAlSwILFpgEDfd3spcGBQz2YGeTCGrXDtizx+kZiYiIiIifUOAkHipWBGbNMl33ZswAOnY0m+UGjEGDgIceAi5cAJo2DbCaRBERERFJLAqcJIrq1c3WR9zvacIE4OWXA2j/WHtfJy7s2rkT6NQpgJ6ciIiIiCQWBU4SrUaNgHHjzOVhw4ABAxA4cuYEpkwxQdR33wGff+70jERERETExylwkltq3Rr45BNzuU8f4LPPEDgefBAYPNhc7tULWLPG6RmJiIiIiA9T4CS39cILQL9+EZe/+QaBo2dPoHnziM1xjx93ekYiIiIi4qMUOEmMmG1ijEFt2wKzZyNwNscdMwYoXhw4ckSb44qIiIjILSlwkljFF0OHAm3aADdvAs2aAcuXI7A2x+XHFSuAN990ekYiIiIi4oMUOEmshIaa5Iy9MW7DhsDGjQgMxYpFbI774YemD7uIiIiIiBsFThJrdhM6tivn9kd165qO3gHhySdNkwhiam3vXqdnJCIiIiI+RIGTxEnKlMDMmUClSsA//wC1awMHDiAwvP8+UK2a2Rz3iSeAS5ecnpGIiIiI+AgFThJn6dIB8+cDJUsCf/8N1KwJHDsG/5csmdkcl/s8/fYb0LmzNscVEREREYsCJ4mXLFmARYuAggWBP/8E6tQBzpyB/8uVy2yOmyQJ8O23wBdfOD0jEREREfEBCpwk3nLnBhYvNgmabduA+vUDpLqN5XpsEkEvvQSsW+f0jERERETEYQqc5I4ULmwyT5kyAWvXAk2bmq57fo8BExtGXL9uPp444fSMRERERMRBCpzkjpUubdY8pUljgqhnnjH7Pfn95lXjxplW5VzI1aKFNscVERERCWIKnCRB3H+/6baXPDnwww8B0leBXTC4OS4jwmXLgLffdnpGIiIiIuIQBU6SYNhdj/s8cbPcsWOB3r1D/T94Kl7cZJ7sduWzZjk9IxERERFxgAInSVBc4zRmjLk8dGgS/PBDEfi9Zs2AF180l1u3Bv74w+kZiYiIiIiXKXCSBNeuHYMmc/nbb0tg1KgAeJmxy17VqsD582Zz3MuXnZ6RiIiIiHhRAJzRiq82pevd23SIeOGFUKuEz+83x+X+TjlymN7rXboEwCIuEREREYktBU6SaPr1C0O9evvgcoVYFW7z5sH/N66aPNlsjvv118DIkU7PSERERES8RIGTJGpH7w4dtqNFizCrkze3Q/rpJ/i3hx82TSKoZ09g+XKnZyQiIiIiXqDASRIVO+yNGXMTDRoAV67A+rh5M/zbyy+bdU7cHLd6deCRR4Bp07TPk4iIiEgAU+AkXlkexAo3JmvYW6FOHWD3bvh3Km38eKBVK1O2t3KlSacVKgR88AHwzz9Oz1BEREREEpgCJ/GKVKmA2bOB8uWBU6eAWrWAQ4fg35vjfvMNcOAA8OabQNaswF9/AW+8AeTNC3TsaJpIiIiIiEhAUOAkXpM+PbBgAVCsGHD4sAmeTpyAf2OQNGCACZqYhbr3XlOTyM2sypYFHn0UmD5dZXwiIiIifk6Bk3gVEzOLFwP58wN795qyvbNn4f9SpgTatgU2bQJWrzab5rKMb8UKsx6qcGGzF9Tp007PVERERETiQYGTOJKkYfCUPTuwdatpGBEw+8ly/RM3yuWiLpbx/e9/QJYspi7x9ddVxiciIiLipxQ4iSOKFAEWLQIyZDAJGvZWuHYNgYVB0nvvmTK+ceOAcuWAf//1LOObMUNlfCIiIiJ+QIGTOIaxAzfFZeOIH3+EtUnuzZsIPHyC7dqZPuyrVgFPPRVRxte0KXD33cDgwSrjExEREfFhCpzEUaxqY9LFblnerRvgciEwsYzvwQeBKVOA/fuB3r1NGd/Bg8Brr5kMVadOwPbtTs9URERERCJR4CSOY4MIdvZmXPHll2ZZUMDLlw8YODCijI/pN5bxjR4NlCljNtadOTNAU3AiIiIi/keBk/gENqEbNcpcfv9904AuKNhlfFu2AD/9ZBZ7sYxv+XKgSRPTjU9lfCIiIiKOU+AkPoPN5uyAiQ3omH0KGky3VasGTJ166zK+zp2B335zeqYiIiIiQUmBk/iUV18F3njDXO7Sxax7CjruZXxjx0aU8TGSLF1aZXwiIiIiwRo4DR8+HAUKFEDKlClRuXJlbNiw4Za3nTBhAkJCQjwGv08CB2MGBk1sEvHss8CCBQhOLONr396U8a1caTbSDQ2NKONjN74hQ4AzZ5yeqYiIiEjAczxwmjx5Mnr16oW+ffti8+bNKFu2LOrUqYMTJ07c8nvSp0+Po0ePho+DLGeSgKpa+/xz4OmngevXTcdu7vUU1AfkoYeAH34wZXxMyWXObDbYZYqOZXyMNHfscHqmIiIiIgHL8cBp6NCh6NixI9q1a4cSJUpg5MiRSJ06Ncax09gtMMuUM2fO8JEjRw6vzlkSH/sjTJwI1K1rqtQefxzYutXpWfmAu+4CBg0CDh82G+myA9/ly6azRqlSSFKnDnKuX68yPhEREZEElhQOunbtGjZt2oTeXAj/n9DQUNSsWRNr16695fddvHgR+fPnR1hYGO677z4MHDgQJUuWjPa2V69etYbt/Pnz1sfr169bQxKPfXzje5yZaPnuOwZNSbB6dShq13Zh+fIbKFo0gSfqj5ImNTsGP/ssQlavRujnnyNk1iyELl+OysuXI2zSJNzs2hVh7NiXKZPTsw1od/o6l7jR8fY+HXPv0zH3Lh3v4D7m1+MwhxCXy7ntRo8cOYI8efJgzZo1qFKlSvj1r732GlauXIn1fOc8EgZUv//+O8qUKYNz585hyJAh+Omnn7Bjxw7kZclSJP369UP//v2jXD9p0iQrsyW+79KlpHj77arYty8jsmW7jIEDVyFbtitOT8vnpDpxAgV//BH5lyxB8gsXrOtupEiBvx55BPvr18cFZqtEREREJNzly5fRsmVLK67gcqCACpyiixKLFy+OFi1a4N13341Vxilfvnw4depUjAdH7gx/NosXL0atWrWQLFmyO7ovLnl79NGk+P33EBQtajJP2bIl2FQD6pgvmzsXtU6dQvKRIxGyfXv418KqV0dY9+5w1atnaiHF517nEjMdb+/TMfc+HXPv0vEO7mN+/vx5ZM2aNVaBk6OlepxkkiRJcPz4cY/r+TnXLsUGD/a9996LP/74I9qvp0iRwhrRfZ/TP6hgkRDHOk8eYMkS4MEHgb17Q9CgQTKruZxi36hupkiB0I4dEdK1q9lU99NPrfblocuWWQMFCwLdu5uOfSrjSzD6m+JdOt7ep2PufTrm3qXjHZzHPFkcHt/R5hDJkydH+fLlsXTp0vDruG6Jn7tnoG7n5s2b2L59O3LlypWIMxVfwEqzxYthZZo2bwYaNDCNI+Q2i8QefhiYNg3Yt89spMtAiZ35XnnFdONjcLVzp9MzFREREfF5jnfVYyvy0aNHY+LEidi1axe6du2KS5cuWV32qHXr1h7NI9555x0sWrQI+/bts9qXP/PMM1Y78g4dOjj4LMRb7rnH7OvETBOTKc2amZblEoP8+YEPPjDd+EaPNhvpshvfyJEAG6vUqgXMmaNufCIiIiK+Gjg1b97cavDQp08flCtXDlu3bsWCBQvCW4wfOnTI2qvJdubMGat9Odc11atXz6pL5BoptjKX4HDffeYcn/sez50LtG3LTKXTs/ITbIjCNxl+/TViI11uqss6yIYNgSJFuEcAcPas0zMVERER8SmOB07Uo0cPK2vEJg5sCFG5cuXwr61YsQITJkwI//zjjz8Ov+2xY8cwb948a42TBBfuB8sKNHblnjQJeP55wLk2J35axvfII8D06cCff5qNdO0yvpdfNovKunUDdu1yeqYiIiIiPsEnAieR+GBzuK++MjHAF18Affo4PSM/VaAA8OGHpozvyy+tjXStMr4RIwBmcmvXVhmfiIiIBD0FTuLXWrQwQRMNGGCqzOQOyvg6dgS2bQPYfa9xY1PGx44cLOPjzsMff6wyPhEREQlKCpzE73XpAgwcaC6zymzcOKdn5OeYwnv0UWDGDIBt/tmBL2NG05mvVy/TjY/tzFXGJyIiIkFEgZMEhDfeMMt0iEkTrn+SBMA9nwYPNmV8o0aZDnyXLpk0H8v46tQxHTrUnUNEREQCnAInCZgkCbtts2Ecz+FbtjQVZpJA0qQBOnUCtm8HuO9ao0bmoC9aZDbUYhnfsGHAuXNOz1REREQkUShwkoDB83huS/TUU8C1a2aJztq1Ts8qAA9y9erAzJmmG59dxsfLL71kuvH16AHs3u30TEVEREQSlAInCShJkgDffGMawbExHDvvsdeBJHIZHyNWlu6xjG/4cKB4cVPGN2+eyvhEREQkIChwkoCTPLnZnuiBB0wDOJ6/s8eBJGIZX+fOwG+/mY103cv4Hn8cuOce4JNPVMYnIiIifk2BkwTsuTx7FpQpAxw7BtSqBfz9t9OzCnAMlmrUMGV8jFTZ4jBDBnP5xRdNNz7uVLxnj9MzFREREYkzBU4SsDJlMkmPu+8GDhww5Xv//OP0rIJEoULAkCGmjM/eSPfiReDzz4FixYDHHgPmz1cZn4iIiPgNBU4S0HLkMN312LNg506gbl3gwgWnZxVE0qY1G23ZZXzcSJeZqYULgfr1TRnfp58C5887PVMRERGR21LgJAGvQAETPGXJAmzcaJbgXLni9KyCtIxv1ixTuseNdO0yvp49TWT7wgvA3r1Oz1REREQkWgqcJCiwyduCBSYBsnw58PTTwI0bTs8qiMv4PvrIlPFxI13+cFjG99lnJgPFtOCPP6qMT0RERHyKAicJGhUqAHPmAClSmMTHc8/p3NxRjGK7dgV27DApQW6ky8wUI1z2kedaKAZTKuMTERERH6DASYLKI48AU6ea/Z6++srs2epyOT2rIMdgqWZNYPZs4PffzQ8lfXpzmeV77ManMj4RERFxmAInCTpMbEyYYC6zL8E77zg9IwlXuDAwdKjpHc+NdJl1YjcPu4yPmShmpJQqFBERES9T4CRB6ZlnzLk49etn9mcVHyvj69bNtEK0N9JlZoprn7gGiuui2NpcLRJFRETESxQ4SdDq0SMi28T9WSdOdHpGEgWDJe5ezMVpLNXjD4plfLzMzXTZjY/XsTufiIiISCJS4CRB7a23zJIaYrOImTOdnpHcEncy/vhj042PZXws3WPGienCokXNvlDcH0plfCIiIpIIFDgJgj2hMWQI0LYtcPMm0Lw5sGyZ07OS20qXLqKMz95Ilx0+5s8HHnsMKFHCBFYq4xMREZEEpMBJgl5oKDB6NNC0KXDtGtCwIbBhg9Ozklj94GrXBubONaV73EiXZXx79pg6THbjUxmfiIiIJBAFTiIAkiYFJk0CatQALl0y/Qe4vZD4iSJFgGHDTBkfm0awjI/7P9llfGwuwSYT6j0vIiIi8aTASeQ/3BiXa5wqVwZOnzbJjP37nZ6VxLmMr3t3U8Znb6TLYGnePKBOHVPG98UXwMWLTs9URERE/IwCJ5FIXbC5VKZUKeDIEbMv69GjTs9K4lXGx0CJARPL+LiBLoOq3btNYMVufOwK8uefTs9URERE/IQCJ5FIMmc2VV2FCgH79pnMEzNQ4sdlfCzZ46a63LyLpXss42NpH7/GHZEXL1YZn4iIiNyWAieRaOTKZc6l+fG330zjNlV3+TlmnNg0YteuiI10GSyxuQSj45IlVcYnIiIit6TASeQWmHFi5ilTJmDdOtN17+pVp2clCVLGx7blrMlkBz67jI8BFcv42I2vVy+V8YmIiIgHBU4it8G1TkxOpEljMlAtWwI3bjg9K0kwLNtjGR+78X36qSndO3fObLTLy+xNv2SJyvhEREREgZNITNhlb9YsIHlyYPp0oHNnnUcHHO7/9PzzpnmEvZEuf8hz5gC1apkyvhEjVMYnIiISxBQ4icQC93f6/ntT5TVuHPDKKwqeAhJ/wFz7xDQjgygGU2y1yDK+bt1MGd/LL5uuISIiIhJUFDiJxFKTJiZooqFDgYEDnZ6RJCpuosvyPXbjYznf3XebMj7+8HlZZXwiIiJBRYGTSBy0aWO6WNNbbwEDBgA3bzo9K0n0Mj42kGAjiWjK+JKWK4cC3Gz30iWnZyoiIiKJSIGTSBz17An06WMuv/02UKUKsG2b07MSr5fxsbV52rQI2bULZUeORNKCBU0N5/79Ts9UREREEoECJ5F46NcPGD0ayJAB2LgRKF/eBFFXrjg9M/FaGR830z18GDc/+ggXc+VCyNmzwEcfAYULA40aAUuXqoxPREQkgChwEomHkBCgQwdg506z9oktylm2d++9wOrVTs9OvCZDBoQ9/zyWDh+OG2y9WKeOCZZmzwZq1jT97EeOVBmfiIhIAFDgJHIHcuc2Lcp/+AHImdNUcFWrZvZRPX/e6dmJ14SGwsUyPq51sjfS5eZfjKy7djXd+FTGJyIi4tcUOIkkgCeeMOfIzz1nPv/iC7P1z7x5Ts9MvK5YMeDzz003Pm6ky9I99zK+xo2BZctUxiciIhIMgdNff/2Fw4cPh3++YcMGvPjii/jyyy8Tcm4ifiVTJmDMGLO0pVAha/kLHn8caNECOHHC6dmJ13EB3IsvAnv3AnPnArVrm2CJJX3cGKx0aWDUKJXxiYiIBHLg1LJlSyxfvty6fOzYMdSqVcsKnt5880288847CT1HEb9SvTqwfTvw6qumERs3zi1eHPj6ayUZghJfBPXrAwsXmrQkN9JlGd+OHUCXLqaMjy+WAwecnqmIiIgkdOD022+/oVKlStblKVOmoFSpUlizZg2+/fZbTJgwIT53KRJQUqcGPvyQ2VigbFng9GmgdWvTzVrnx0GMEfTw4SYdyTI+piZZxjdkiCnjY1aqf3+zVoovGhEREfHvwOn69etIkSKFdXnJkiVo2LChdblYsWI4evRows5QxI+xTTnblQ8cCPBXhkkHNlr75BNtnBvUMmaMKOP7byNdhIUBixebXveMsLNkAYoWBZ591qyZ4gvp2jWnZy4iIhK04hU4lSxZEiNHjsSqVauwePFiPPbYY9b1R44cQRb+Zy8i4ZIlA3r3NpvkPvSQWdLCc+aqVU21lgSxJEnMQrhFi0xLRu4N9cwzQJEi5uu//w588w3w/PMAs/zp0gH33292YZ40CfjzT9V/ioiIeEnS+HzTBx98gCZNmmDw4MFo06YNyrIWCdy6ZHZ4CZ+IeGLygEsDuXHua68B69ebfZ8YVP3vfyYjJUG+qS5Hjx7mc5bqsdaTLxR78Dr7si1rVhNUVa5sBi+zU4mIiIg4Hzg98sgjOHXqFM6fP49Mbv9Bd+rUCam5uENEbtknoHNnk2TgVj9ssMZ+KlOnmo58Dzzg9AzFZ2TODDCb/19G38osMcPkHkht3QqcOgXMn2+Ge5RuB1H8yDe3kid37KmIiIgEbeD077//wuVyhQdNBw8exIwZM1C8eHHUqVMnoecoEnDy5AFmzDAb5zLBwD1TH3zQBFNcD8WKLBEPISHA3Xeb0aqVue7qVRM82YEUM1R//GHWTnGwlSMxncn0pp2V4ihY0NyniIiIJF7g1KhRIzRt2hRdunTB2bNnUblyZSRLlszKQg0dOhRdu3aNz92KBBWesz71lNnS5+WXATakZA8AZqG4vQ/7A4jcFgMiOxCy/fNP1BK/M2eAdevMsGXL5lniV7GiSvxEREQSujnE5s2bUa1aNevyDz/8gBw5clhZp6+++gqffvppfO5SJKgrssaPNw3VmAT46y+gXj3TI+DkSadnJ36HDXoYdbM7348/mkDKzj4xvckAiR1L+OKaNw/o0wdgpQBfiFxjxb75bJn+yy/q4iciInKnGafLly8j3X+1RIsWLbKyT6Ghobj//vutAEpE4q5mTbNxLs9jhw0Dvv3WtC/n5ZYtVVUl8cQXDrv0cTAapytXIkr87OwU109FV+J3332eJX4FCujFKCIiQSlegdPdd9+NmTNnWp31Fi5ciJdeesm6/sSJE0ifPn1Cz1EkaKRJA3z0EfD000CHDqaFOc91GUSNGAHkz+/0DCUgpExp2ppz2Nhkwr3Ej5dZ4rd2rRnuJX7ugRQzWNyXSkREJMDFK3Dq06cPWrZsaQVM1atXR5UqVcKzT/dyAbKI3BGei7JS6sMPTdc9VlyVLAkMGgR062a2/xFJUGxrzhpRDruLH/eRcl8r9euvpsRv7lwzbCzxcw+mypQx5YAiIiLBHjg9+eSTePDBB3H06NHwPZyoRo0aVhZKRO4czzvffBN44gmgY0dg9WrghReA774zrctLlHB6hhLQWI7HtuYczz4bUeK3ZYtnid++fcCePWZ89VVERityiR/TpSrxExGRYAucKGfOnNY4fPiw9XnevHm1+a1IIihWDFi50nTae/11UzXFxC6Dqjfe0PY84kUMiFhh8F+VgYUZqMglfmfPAmvWmGHLnj1qiV+GDI48DREREa911QsLC8M777yDDBkyIH/+/NbImDEj3n33XetrIpLwG+eyy/+OHWbzXDY769vXvKnv3mFaxOu45ql+fVNTym4m7OK3ezcwcaKpKy1fHkialItggTlzgLfeAmrVMq3PmTZt29Ys4Nu8Gbh+3elnIyIikrAZpzfffBNjx47F+++/j6pVq1rXrV69Gv369cOVK1fw3nvvxeduRSQG+fIBs2cDU6YAzz9vAqkHHjAlfAMGmCZoIo5H+VzzZLc2p3//9dyol2P/frPzMweDLEqVKmqJ3113qcRPRET8N3CaOHEixowZg4YNG4ZfV6ZMGeTJkwfdunVT4CSSiHgO2by5aV/eq5dZVvLJJ8DMmdx+RyeY4oMYEEUu8WMGKnKJ37lzwM8/m2HLkcMzkCpXzpGnICIiEq/A6fTp0yjGhReR8Dp+TUS8s88p36jnHk+dOwPcQu3xx5OicuVKSJcuBI8+qjfqxYdxzRPrTjmIZd7cQ8o9K8V+/MePmzQrB//TCgnBI/nzI5Qv+HbtgP/2FBQREfHJNU7spPf5559HuZ7XMfMkIt5Tpw7w22/Aiy8yUHJh/fpcqFEjqdVAYtw4UyUl4hclfnxDrk0b4IsvgE2bgPPnTfZp6FCTZi1QACEuFzIcOIAkPXuyKxHAfQT/+MPp2YuISBCIV+D04YcfYty4cShRogSee+45a/DyhAkTMGTIkISfpYjcVtq0wMcfc339DdSpsx+pUrmsLXeee86si/rf/4C//nJ6liLxKPHjIj4GR99/b62Luv7XX9jWoQNcd99tAqthw0zL9AYNuJmg2X9KRETEVwKnhx9+GHv37rX2bDp79qw1mjZtih07duDrr79O+FmKSKxwk9yuXbdh//4bGDzYbJ3DJmfcOLdgQeCpp4BVq3RuKX4sRw7sf/xx3GCadf58oG5d84LmhrxMv7JTHzNWFy86PVMREQkw8QqcKHfu3FYTiGnTplljwIABOHPmjNVtT0SclTkz8MorwJ9/AjNmwFrvdPMm8MMPwEMPmcZlKuMTvy/tY9DE4Imb77LNJFOvbIXevbsp42P3FP4SiIiIOBk4iYjvS5IEaNwYWLbMrLPv2NFUP7EztMr4JGCwVO/TT4G//zYfixQxHfpYv8rLLONbvFipVhERuSMKnESCROnSwJdfAocPc52i2R7HvYyvWTPux6ZzS/Fj6dObzBOzTsxEPfZYRBlf7dqmlpWb7aqMT0RE4kGBk0gQlvG9+qqpYJo+HXjkEVPGN3UqUK0aUL48MH48cOWK0zMVucMyvh9/NEFUjx6mjI+b7XbrZsr4Xn4Z2LfP6ZmKiEig7uPEBhC3wyYRIuIfkiYFmjQxg2V83GGAvV22bAHatwdeew3o1InNJsx5pohfuuce4LPPAG7MPmGCucz25WxxzlI+7iP1wgtAjRra+ExERBIu45QhQ4bbjvz586N169ZxuUsR8QHcfs0u4/vgA1PGd+oUMHCgtXWOtYUOt9NRGZ/4dRkfAyQ2kpg3z3Tg4wt6zhygVi2gVClg5Ejg0iWnZyoiIoGQcRrP+h0RCVhZsphME5uRzZ5t1tmvXAlMmWIGN9XluefTTwMpUzo9W5F4lvHVq2cGgyimWpmJ2rnTpFd79zadU9iZj4v/RERE/qM1TiISbRkfK3NXrIC1kW6HDiZQYhlfu3amG99bb5kmZiJ+X8bHVCs30i1cmDXnwEcfmcuNGgFLlyrVKiIiFgVOIhJjGd/o0ebc8v33TdDEMj4uGeEGu8w+qYxP/FqGDEDPnsDevREb6fIFzbRrzZqmJeWoUSrjExEJcj4ROA0fPhwFChRAypQpUblyZWzYsCFW3/f9998jJCQEjblRjYgkehnf66+bRmTTpgEPP2y68U2eDDz4IFChAjBxorrxiZ+X8dWvDyxYYDrwsVwvTRpgxw6gSxfTJYU7S+/f7/RMRUQkGAOnyZMno1evXujbty82b96MsmXLok6dOjhx4sRtv+/AgQN45ZVXUI39k0XEkTI+eyNdlvFt3gy0bWsaS7z9tsr4xM8VK2bWP/GFzO57kcv47J2llWoVEQkajgdOQ4cORceOHdGuXTuUKFECI0eOROrUqTFu3Lhbfs/NmzfRqlUr9O/fH4UKFfLqfEUkQtmywJgxwF9/mY10WcZ38iQwYIDpxscyvjVrdG4pfl7G9+KLEWV83EiXL+hZs0wLc3tnaZXxiYgEvDh11Uto165dw6ZNm9CbXYz+Exoaipo1a2Lt2rW3/L533nkH2bNnx3PPPYdVq1bd9jGuXr1qDdv58+etj9evX7eGJB77+Oo4B/4x57kl9xPlMpHZs0MwfHgoVq0Ktcr4OO67Lwzdu4ehWTMXUqRAQNHrPIiON4Mmjl27EDpiBEK//hohLOPr3BmuV16Bq1IluCpWNB8rVQKyZ0cg0Gvc+3TMvUvHO7iP+fU4zCHE5XLuveAjR44gT548WLNmDapUqRJ+/WuvvYaVK1di/fr1Ub5n9erVePrpp7F161ZkzZoVbdu2tTbenTlzZrSP0a9fPyszFdmkSZOszJaIJI59+9Jj3rxC+OmnvLh+PYl1XYYMV1C79kHUrXsAmTNrMZT4t6QXL+KuZctQaN48pDl+PMrXL2XPjjNFi4aPcwULIizQ3jkQEfFzly9fRsuWLXHu3Dmk555/vppxiqsLFy7g2WefxejRo62gKTaYzeIaKveMU758+VC7du0YD47ceQS/ePFi1KpVC8mSJXN6OkHB1455jx7swBcGVt6OHBmKw4dTYurUezBjRlE0bepCjx5hqFzZhZAQ+C1fO+aBzueOd7NmQFgYrv/6K0I3bkTIhg3W4B5RaU6csEbe1autm7qSJoWrTBmPzBSKFDFNKXyYzx3zIKBj7l063sF9zM//V40WG44GTgx+kiRJguOR3qnj5zlz5oxy+z///NNqCtGgQYPw68LCwqyPSZMmxZ49e1CYi3bdpEiRwhqR8Yfk9A8qWOhYB/cxz5ULePNN05GPiWFuqrtqVQimTOEItbrxcVNdnn/685vxvnTMg4HPHW8GQRzsxEfnzgEbNwIMolg9sX49Qo4fRwi7qHCMHGlulzEjULEiULlyxMiWDb7I5455ENAx9y4d7+A85sni8PiOBk7JkydH+fLlsXTp0vCW4gyE+HkPvlUdSbFixbB9+3aP69566y0rE/XJJ59YmSQR8d1ufE8+aQY30uW+o5MmAb/8ArRubbo8d+5suj7nzu30bEUSYOEf94DiIFbFHzoUHkRZY9Mm06lv8WIzbAULegZS995rWleKiIijHC/VYxldmzZtUKFCBVSqVAnDhg3DpUuXrC571Lp1a2sd1KBBg6x9nkqVKuXx/Rn5bh0Q5XoR8V08D2T53gcfmK58w4ebrs/vvmu68z31lMlC8ZzRn8v4RMLxhcwdozmYXiUuSOabge7B1O7dZp8oju+/N7fju6FsYWkHUn5S4iciEmgcD5yaN2+OkydPok+fPjh27BjKlSuHBQsWIEeOHNbXDx06ZHXaE5HAw4okNtVktsku4+NykO++M4MVTAygGEj5cxmfSLQYEN13nxldu3qW+LkHU9zXkKlZDr7LQHzTkAGUe2Yqlmt/RUTETwMnYlledKV5tIK7bN7GhAkTEmlWIuLN80cGRxxc/sEyPgZOPH989lnPMj6umRIJqhK/gwc9Ayn+krDEb9EiM2zc19A9kCpXTiV+IiIJSKkcEfEpfPN9/Hizqe577wF58rBhDPdvM1VOrVqZc0eRoCnx427SzZtzx3jg55/ZAioi+8QFgsWKmdvu22feceCGvdzig1kplr0z0BIRkTumwElEfLaM73//M0s9uIlu1apmSQgbStx/v3lD/ZtvuMm10zMVcSBFW7480K0bMHGitSEvzpwx2ScuFHz8cfMLxF8OVmXwtg8+CEyZYn6JREQkXhQ4iYjPnyNyLT3XPrEJWdu27MhpujyzjI9ZqH79gGPHnJ6piIOYXapVi61mgTlzTJp27VqgZUvT0pKZKmat2LFv4EDg5EmnZywi4ncUOImIX5bxDRhg2pbz/LB/f+Cuu4BnnjEBlUjQY4kfU7PffmvWSPXpA2TPbtpXcmM1bt/Rvr3ZG0BERGJFgZOI+B2e//Hc78AB07HZLuPjOSJL+Hi+yJK+a9ecnqmID+A7DHx3gftIffWVKd1jGR/fheC7EdWqAVOnqoxPRCQGCpxExK/L+Fh9xDI+rpVv08aU8bF5BJtIsIyP54sq4xOB6enP+la2q1yzBmjRwpTx8ReI9bDsyseN1E6dcnqmIiI+SYGTiAQEvonOdfAs4+P6eLYtZ8DE9U8s47PPF0WCHsv42HWPaVmW8b39tmkmcfiw6ciSN68p49u61emZioj4FAVOIhJwZXxcH8/zQXZmfuABU4HEDnzcL5Tni7xeZXwi/5Xxsdc/33Fghz73Mr577wUeeggh06Yh5OZNp2cqIuI4BU4iErBlfE8/bZqJMdPE7W5YxrdunWk0VrQosGCB07MU8aEyPv6S2GV8/OVhGd+qVUjaogVqdeqE0A8/VBmfiAQ1BU4iEvAqVDBvpruX8TEjVbeuKeHTuaBIpDI+pmXZfeWtt+DKlg2p/vkHSZjKZTe+555TGZ+IBCUFTiISdGV8e/cCL75ozhFZwleihDlPdLmcnqGID8mTx3qn4caff2Jzz55wsXTvyhVg3DhTxvfww8C0acCNG07PVETEKxQ4iUjQSZsW+Phjsz9oqVJmL1CW7zVoYLJSIuImZUr89eijuME6V3sjXZbx/fQT8OSTphvfBx8A//zj9ExFRBKVAicRCVrc82nTJrM2nuuf5s0z2afhw4GwMKdnJ+JjmKJltxVunvZfGZ/VjY/vNrzxhunG16ED8OuvTs9URCRRKHASkaDGgIndmLdsMeeEFy8CPXqYPUF37XJ6diK+XcZnbarLfQDsMr6xY4Fy5YBHHgGmT1cZn4gEFAVOIiIwmaZVq4DPPjOlfGwsxvM/nhuqdbnILaRMaXaeZurW3kg3SRJg5UrgiSeAwoVVxiciAUOBk4jIf0JDTbZpxw7TcY8BU58+pivfhg1Oz07Ex8v4qlYFJk82ZXxvvglkzWoyUnYZX8eOwLZt6sIiIn5LgZOISCR33WXWO337rTn3277ddGju1Qu4dMnp2Yn4OAZJAwaYtU/2Rros4xszBihb1pT5NWkCvP8+sHw5cOGC0zMWEYkVBU4iIrd4A52d9rjOqVUr0yyCnfjYhW/RIqdnJ+InZXxt23qW8bEb39GjwMyZQO/eQPXqQIYM5heL+0N9+aVpLqG1USLig5I6PQEREV/GjBP3emLw1LmzqUKqU8cs6xg6FEiXzukZivhJGR/H5cvA5s3A+vURg+V8rI/l4B5RlDq1qZFl60t7MJMlIuIgBU4iIrHANU88r+PSjc8/ByZOBH78kVmoEOscT0Rigb8sDz5ohu3YsYggiosJOVi+x32iOGy5cwOVKkUEUgys9M6FiHiRAicRkVjiOdqnnwItWpiqIlPGlxQVK1aylm4ULOj0DEX8UM6cQKNGZhDrYnfv9sxKcaHhkSOmxI/D7ubCdpjuWamSJU1XPxGRRKDASUQkjtgogvs+DRoEDBzowsaNuVC2rAsffgh06mTO50QknuyAiKNdO3Mdu7JELvFj84nffjOD+0dRmjSeJX7MUKnET0QSiAInEZF4SJEC6NcPaNz4Bpo3v4C9ezOja1dg0iRg9GjgnnucnqFIAGFAxF2pOWxsMsGyPjuQ2rjRlPhxDykO9xI/96wUAytu1iYiEkcKnERE7gArgwYNWoWDBx/H228nsTbRZdke93969VUgWTKnZygSoHLl8izxu3nz1iV+M2aYYWe0+ItrB1L3328+ZxMLEZHbUEGJiMgd4pKKHj3CrIohdty7etU0kahYEfjlF6dnJxJEv4gMgNq3B0aNArZuBc6fN9kn1tE++SSQL59ZQ8WAivtKcVPe0qXN4PdoozYRuQ0FTiIiCaRAAdNp7+uvgSxZzHY0fEP7lVdMF2YR8TKW+D30kEn/Tp1qWp/bGag33gAefRRIlcq0zOzSxayH4m2574CISCQKnEREEhCrfZ55Bti503Tf45vbH31k3tBeutTp2YmIVeLXuLHp7rJsmQmkuLt1oULA2bPAkCFA4cJAkybA8uWAy+X0jEXERyhwEhFJBNmzm0YRc+eaN7H37QNq1jRVRGfOOD07EQmXMSPw4ovA3r3AnDlArVrmHQ+2Pa9eHShTBvjyS6WNRUSBk4hIYqpf31QBde9uPh8/HiheHPjhB72RLeJza6QefxxYtMj80rJNJkv9uHixc2fzDshrr6mMTySIKXASEUlk6dMDn38OrF4NFCsGHD8OPPUU0LSpqRISER/DPaS++AI4fBgYOtSU8TFVPHiwKePjL6/K+ESCjgInEREvqVrVbJz79ttA0qSmEojZJ1YBsTJIRHywjO+ll0wZ3+zZpt6Wv6xsLmGX8XHjNpXxiQQFBU4iIl6UMiXwzjvA5s1ApUqmWzKrgHgOxuogvYEt4qNlfA0aAIsXR5TxpU5tyvg6dTJlfK+/Dhw86PRMRSQRKXASEXEAu+ytWWOqgHj+xa1mSpWK2NNz4EDThY+BlYj4aBkfW2YWLGjK+LhXFEv6nngCWLFC74KIBCAFTiIiDr6JzSogvmnNNeks3+P6J1YEcQNdVgWxUsh9T0+W+t244fTMRQSZMgG9egG//w7MmhVRxjd9utkfqmxZs8muyvhEAoYCJxERh/ENa3ZBPnfONJDgm9jNmgH585s3rbknFLvxcX/O++4zzSaqVTMb69p7eurNbREH3wFp2NCU8fFdEP6iMo28fTvQsSOQL5/ZbJe/qCLi15I6PQERETF4rsUGEhw2ZqDWr48YGzea8j0GWBy2nDmBypUjRoUKJsASES9ienjECFNrO26caafJ9uUffGA68nHj3RdeAB56yOyWLSJ+RYGTiIgPy5HDvJnNQawE2r0b2LAhIpjatg04dsxUC3EQz8nYsc89mOIaKpYDiogXyvheftlsrMtdsD/7zCxaZBkfB7vxMYBq2RJIlcrp2YpILOm/UBERPxIaatamc7Rta67jEgp26XPPTLEqiCV+dpmfndEqX94zmGIzML3xLZKIZXzs9sLBMj5moL76yrzb0aGD2VCXXfnYpe+uu5yerYjEQIGTiIifY0D04INm2JiBYgBlZ6b48cIFYNUqM2zs4mcHUWyPXrEikC6dI09DJLAx5TtyJDBokGcZ3/vvmzK+Jk2A5583CxhFxCcpcBIRCUBc82S/0e1e4ueeleLa9aNHzUa8HMTsE7NZ7lkpLttQiZ9IIpXxffopsGwZ8MMPZpQti5Du3ZGMm76JiE/Rf4UiIkFW4teuXUSJ36ZNEYEUs1Is8eP+nhx8U9zOaLHZROQSPxFJhDK+X39F0k6dUA+Ai7tl2+lgfixXDkiRwumZiwQtBU4iIkGKARGrgtwrg5iBcm88wS5+LPH76SczbLlzR5zL2V38VOIncodlfP9143ONHYuQ3bsR8scfAMe335rbJU9ugif3dzEKF9ZCRREvUeAkIiIea57cS/xu3vQs8WNQxRK/I0c8S/zsjFbkEj++qS4isZQ5s7VB242ePbF48mTUzpQJSd3Twv/8Y34JOdipj7Jk8XwXg5d5PyKS4BQ4iYjILTHwYQDE0b69ue7Spahd/P76y1QbcYwda26XJk3UEr88eRx9OiJ+43q6dHDVrg3Ur2+u4C7X+/Z5poT5i8hg6scfzbDdfbfnLx6zVMxWicgdUeAkIiJxwoAouhK/yBv1XrwIrFxpho2Bk/uSDQZWadM68jRE/AvL8ViWx9Gihbnu2jVrTZTHL9/vv5vyvsglfvfe6xlMFSqkEj+ROFLgJCIiCVLi17ixGXaJ365dnm+Os8Tv778j9gC1S/yYzXI/n2PJn0r8RGKBARH3EODo0cNcd/q05y8eLzMrZX9uy5o14h0MflSJn0iMFDiJiEiCY+DD9e4c7iV+7ss1OA4fNgEVx5gx5nbMQEUu8WMzChGJBQY/jz1mhnuJn/sv3pYtwKlTwPz5ZtiKFPH8xStbViV+Im4UOImIiNdK/B56yAwbm0y4b9Rrl/itWGGGje3PeR5XvnwowsKy4OGHgYwZHXkaIv5b4teypbnu6lXPEj/+ArLEzx7ffGNux9bnkUv8ChZUiZ8ELQVOIiLiGGaSmjQxw73Ez/3NcTacYGaKY9o01vA9iD59XFY2y/18rnhxlfiJxAoDIrs87/nnoy/x4+B169aZEV2Jn13mx019RYKAAicREfHJEr/nnjPXMQNll/itWxeGn366in/+SYVt22CN0aPN7biPVOQSP669EpF4lvj9+adnILV1a/QlfkWLev7ilSmjEj8JSAqcRETEp3HNE0vzOK5fv4n58xehXLl62Lw5WZSNepcvN8OWL5/nm+Ply5uSQRGJAcvx2Naco1Wr6Ev8ONi9b+9eM77+OiKjdd99ni00VeInAUCBk4iI+GWJX/78niV+O3d6ns/t2GH2l+KYNs0zo+X+5nixYirxE4l3iZ+9Ka/7eimW+K1da4YtW7aoJX5aqCh+RoGTiIj4PQY+pUub0aFDRInfL794Np9gO3S+Yc7x5ZcRJX7s5uz+5rhK/ERiKUsWoG5dM+wSP2ahIpf4nTwJzJtnhu2ee6KW+CVL5thTEYmJAicREQnYEr9HHjHDxsDJ/XyOgRVL/JYtM8O9xM/9fI4lfqlTO/I0RPwLy/HY1pzjmWfMdVeumODJPTPF9VN79pjx1VfmdilTRu3iV6CASvzEZyhwEhGRoJEnD9C0qRl048btS/x++MEzoxW5xI8b+IpIDBgQ3X+/GTY2mYhc4nfmTPQlfu6/eEwPq8RPHKLASUREglbSpKY6iKNjR3MdM1CRN+rlflN8w5xj1KioJX5VqwK1a6vKSCTW2Na8Xj0z7BI/7iHl/ovHmlqW+M2da4aN71q419aqxE+8RIGTiIiIGwZEkUv8uIdUTCV+zGZ162YCML5JLiJxwHI8tjXnePbZiBK/LVs8Fyru2wfs3m3GxIkRGS27i5892D1GJX6SwBQ4iYiIxCBvXjOeeCKixI8lfXYgxTfDuX7qzTeBd94BWrY0Tce4XENE4okBUZUqZtiYgYpc4nf2LLBmjRm27NmjlvhlyODI05DAocBJREQkHiV+Zcua0amT2d5myhTg009NNmr8eDMefBB44QXTNp3fIyJ3iOnc+vXNoLCw6Ev8TpwA5swxg5h9Yomfe0t0LlxUiZ/Egf6Mi4iIJMD2NqwuYhMxnrcxgJo6FVi92gxmq+wyPi7tEJEEwg4tbGvO0bq1ue7ff82CRPdgav9+YNcuM+wSv1SprBK/0IoVkZvvbJQsCRQurBI/uSUFTiIiIgmE51t287AhQ4CRI83gGqn//Q/o3x9o1cqU8ZUr5/RsRQIUA6LIJX7MQEUu8Tt3Dvj5ZyT5+WdU5G34S5sjR9QSv/TpHXwy4kvUSFVERCQR5M5t1juxrTnf4OZeUCzpGzfOrH166CHT7pzrpUQkkXHN0+OPA+++CyxaBJw+bbJPEybgZufOOFu4MFzMOh0/DsyebRYs1qxpWp8zE9W+vXkXhM0q9EsbtJRxEhERSeQyPlYQsZRv3TpTxseAadUqM7jZLsv4OnRQGZ+IV0v8uOapWDGEtWyJlfPno96jjyLZb795lvgdOGA2e+PgwkU7o8V3QtwzU/xFVolfwFPgJCIi4gU8p7Krh+wyPu4JxYxU796eZXxsOiEiXsaA6IEHzLAxAxW5xO/8+YgFjLacOT0DqQoVVOIXgBQ4iYiIeBn3fGLFEKuB2I3vk0+AzZuBsWPNYBkfu/E1aqRufCKO4pqnBg3MsLv47d3rmZXatg04dgyYNcsM+52SEiU8N+otVUq/0H5OPz0REREHt6mxy/jWro0o4/vpJzNY/dO9uynjy5LF6dmKiHuJH9q0iejix3c+3IOpgwfNZm8cXNhIqVNHLfFjy02V+PkNBU4iIiIO43mTXSHEDnws4/vyS1PG98YbQL9+ptU5y/jKlHF6tiISpcSvalUz3Ev87NI+9xI/e3GjLVeuqCV+6dI58jQkZuqqJyIi4kP4BvSAAcChQ1bDL6sD35UrwJgxZu3TI48A06ersZeIz5f4NWxofpkXLwbOnIloMNGli/nFTpIEOHoUmDnTLHSsXh3IkMGU9D33nHn3hJv56pfdZyjjJCIi4qNlfKwEYinfmjWmjG/aNGDlSjPuuiuijC9zZqdnKyIxlvgVL25G27bmusuXPUv8mJW6VYkfM1GRS/wkODNOw4cPR4ECBZAyZUpUrlwZG/jCuYXp06ejQoUKyJgxI9KkSYNy5crh66+/9up8RUREvFnGxwqgyZNNZ2RupMu25cxIvf66OX/q2NGsTxcRP8KA6MEHgZdfNl1i+AvODBQbTPAXvUYN05mPARYXPQ4eDDz5pFn8yA4zTZoA778PLF8OXLjg9LMJCo4HTpMnT0avXr3Qt29fbN68GWXLlkWdOnVwgjs8RyNz5sx48803sXbtWmzbtg3t2rWzxsKFC70+dxEREW9ikPTee2btEyt+ypUz69LtMr5HHwVmzABu3nR6piISL2xrzhI//qIvWWJK/OzsU+fO5peeJX5HjniW+HGj3tKlTQp69GjzTor+EARe4DR06FB07NjRCn5KlCiBkSNHInXq1BhnpycjeeSRR9CkSRMUL14chQsXRs+ePVGmTBmsdu+lLyIiEuBlfKz2YZUP15k/9ZQ5l1qxAmjaFChc2Lw5ffq00zMVkTsu8WNb83btTNeYLVsimkxwQzj+8rNul23SuXkv9zPo1Mm8k8L1UlwU+dprps6XnWfEf9c4Xbt2DZs2bUJvRsv/CQ0NRc2aNa2MUkxcLheWLVuGPXv24IMPPoj2NlevXrWG7TxfbACuX79uDUk89vHVcfYeHXPv0zH3Lh3vqLjc4dtvTRbqyy9DMWZMKA4eDLHOlfr2daFlSxe6dbtpvRkdHzrm3qdj7l1+d7yTJYtY62Q7dgwhGzaYsXEjQn75BSEs37MXRf7HlTs3XBUrwlWpkhlsj542bVAf8+txmEOIi9GHQ44cOYI8efJgzZo1qMKt1P/z2muvYeXKlVjPhXLROHfunPV9DIiSJEmCL774Au3bt4/2tv369UN/bsceyaRJk6zMloiISCC5ejUUq1blxdy5hXDgQIbw60uXPon69fehYsVjVnZKRALYzZtId+QIMu3di4x791of0x88iFBmpty4QkNxPl8+nClaFGeLFLE+8vNg+iNx+fJltGzZ0oov0nNNWaAFTmFhYdi3bx8uXryIpUuX4t1338XMmTOtMr7YZJzy5cuHU6dOxXhw5M4j+MWLF6NWrVpIxndHJNHpmHufjrl36XjHHv93//nnEHz+eShmzQrBzZtmk838+V3o2jUM7dqFIVOmmO9Hx9z7dMy9K2iO96VLCNmyxTMzxVR1JK40aaxMlHtmympGEaDHnLFB1qxZYxU4OVqqx0kyY3Scm4S54ec5uTjuFljOd/fdd1uX2VVv165dGDRoULSBU4oUKawRGX9ITv+ggoWOtffpmHufjrl36XjHDptFcPDcaMQIsy0My/jeeCMJ+vdPgmefNZvqctuYmOiYe5+OuXcF/PFmAwn7j4KNXfzsdugcDKYuXkQIu/hx2Bg4Vf6vPJCBFNujJ0CJny8c87g8vqPNIZInT47y5ctbWSP3bBI/d89AxYTf455VEhERkQisvBk40ARQXDvOdePsxsdAimuf2PWYDbrUhEskyOTKBTRuDAwaBCxbBpw9C2zf7tlkgg0q/v7b7LzNPRAYeLHxRJkyZi8EtvXk9wTBHxDHN8BlK/I2bdpYezNVqlQJw4YNw6VLl6wue9S6dWurnI8ZJeJH3pYd9RgszZ8/39rHaQTfShMREZFbSpUK4JJg/hfLZrTcVJfty3m+xFGggNlU97nnEKsyPhEJMFzbxBQ0h90/4NIlYNMmz8wUO/QxWOJg4ETMQEXeqDd3bgQSxwOn5s2b4+TJk+jTpw+OHTtmld4tWLAAOXLksL5+6NAhqzTPxqCqW7duOHz4MFKlSoVixYrhm2++se5HREREYrepbrVqZnAjXbuMj/tvvvoqu/EhvIyvaFGnZysijkqTBnjoITNs3EfKPZD65Rfg4kWzJwJHdCV+HAyseH9+yvHAiXr06GGN6KxwP/gABgwYYA0RERG5c9wChkUdffqw46zJQnHvzFGjzKhePQkqV86JOnVMF2QRETCT1KSJGcQyvZ07TRC1YYP5yH2l7BI/DmIypFQpJKlYEXdxQzouzcmeHf7C8Q1wRURExDfK+Fiit3Wr2fbliSfMOc6yZaEYNKgyihdPio8+As6ccXqmIuKTJX6lSwMdOpj09a+/cv8gk33iXqvcmZvZJ7ZD37YNoWPH4t7hw/1ul24FTiIiIuJRxseKnB9+APbvB1555SbSpbuGAwdC8MorQN68QJcuwI4dTs9URHxa2rTAww9znyFg2jSzLopj2jTcfPllHK1YEShUCP5EgZOIiIjcsoxv4MAwjBmzEKNG3bCaaF2+bEr4uHa8Zk1g9uygaKYlIgmBWaemTRE2aBA2vPmmeafGjyhwEhERkdtKkYIb5rqsMj5W3rDqhmV83E2kUSOgSBFg6FDTyVhEJFApcBIREZFY4ZvDrLxh1c2+fWZLl8yZTUnfyy+bN5O7djVrxEVEAo0CJxEREYmz/PmB9983m+qOHm3WhbOMb+RIoGRJoFYtYM4clfGJSOBQ4CQiIiLxljq1aaTFJlrLl0eU8S1ZAjRsaPaB+vhjlfGJiP9T4CQiIiIJUsb3yCMRZXxspJUpk7ncq5fpxscyvlmzgGPHnJ6tiEjcKXASERGRBC/j49Yt7DzMMj524Lt0yZTxNW4M5MplbtOsGTBkCLBqlSnzExHxZUmdnoCIiIgEdhkfN9blprrffgusW2f2gDp0yIypUz33z6xcOWIUK2bK/kREfIECJxEREfFKGR8HXbgA/PILsH59xDh6FFa7cw7uE0Xp0wPcI9M9mMqRw9GnIiJBTIGTiIiIeFW6dMCjj5pBLhfw99+egRQDq/PnzV5RHO6b8roHUvfdZzJbIiKJTYGTiIiIOJ6RYvMIjieeMNfduGFK+tyDKe4PFV2JX5kynsHUPfeoxE9EEp4CJxEREfE5SZMCZcua0amTuY4ZKGaiNmzwLPHbssUMNp+gDBlMiV+lSirxE5GEo8BJRERE/ALXPFWvboZd4sfOfe5ZqU2bgHPnzD5SHDZ28Ytc4pcqlWNPRUT8kAInERER8dsSv3z5zHjyyYgSv99+iwikmJ1iid/Bg2ZMmRKR0Ypc4sfNelXiJyK3osBJREREAgYDonLlzOjc2bPEzz0zxU14N282Y8QIzxI/92Aqe3ZHn46I+BAFTiIiIhJ0JX5//RW7Er8CBTwDqXvvVYmfSLBS4CQiIiJBV+LHtuYcTz1lrrt+PWoXv127gAMHzJg82dxOJX4iwUuBk4iIiAS9ZMmilvgxAxW5xO/48aglfhkzRi3xy5bN0acjIolAgZOIiIhINLjmqUYNM+wSP+4hFbnE7+xZYPFiM2wFC5oAym6Jzi5+KVM69lREJAEocBIRERGJZYkf25pzNGsWUeK3fbvn3lIs8du/34zvv/fcl8o9K1WkiEr8RPyJAicRERGROyjxYzaJo0uXiBK/jRs9M1MnTpjsFMcXX0SU+NkZKfujSvxEfJcCJxEREZEELvGrWdMMu8SPe0i5B1JcI8USv0WLzHAv8atYMQnSpi2EzJlDrLVTKvET8Q0KnEREREQSucSPbc05mjePKPHbti1ik15+3L3bLvFj/V5pjBtnMlrRlfjxPkXEuxQ4iYiIiHgZA6Ly5c3o1s1cxwwUS/zWrLmJuXNP4uDBHDh5MsTq7McxfLi5XaZMprTPLu/jyJrV0acjEhQUOImIiIj4AK55qlULeOSRMJQrtx5169bD338ni1Lid+YMsHChGbZChaJu1JsihZPPRiTwKHASERER8UEsx+OaJ46nnzbXXbtmuvi5B1N79gD79pnx3Xee+1K5B1N3360SP5E7ocBJRERExE8kTx61xI8ZqMhd/E6dMtdxfP65uV3mzJ7lfbycJYujT0fEryhwEhEREfFjXPNUu7YZdhc/Nplw31uKJX6nTwMLFphhK1zYMyvFLJVK/ESip8BJREREJICwHI9rnjjcS/zsLn722LsX+PNPMyZNishoRS7xY3ClEj8RBU4iIiIiAY8BUYUKZnTvHlHix6yUe2aKJX72dZ99Zm7Hcj73jXpV4ifBSoGTiIiISJCW+NWpY4Z7iZ97VmrLFuCff4AffzTDxkYT7lkp7jWlEj8JdAqcRERERMSjxK9Fi4gSv19/9Qymfv8d+OMPM779NiKjxRbo7sEU70clfhJIFDiJiIiISLQYEFWsaEaPHuY6NpmI3MWPWSn7so2b8rpv1MuP7Own4q8UOImIiIhIrDH4iVzixz2kIpf4cb3U/Plm2IoUiVrix+BMxB8ocBIRERGReGM5HjvvcbRsaa67ejVqiR9L+1jmx/HNN+Z2XBflXuLHrJRK/MRXKXASERERkQTFgMgu03v+eXMdy/kil/ix7G/dOjMil/i5B1NsZCHiNAVOIiIiIpLo2ML8scfMsEv8uIeUeyC1dWv0JX5Fi3qW+JUpoxI/8T4FTiIiIiLidSzHY1tzjlatIkr8GDy5B1MMrrhZL8fXX0df4sdRsKBK/CRxKXASEREREZ/AgMgOhGz2prwMouyP3Lw3colftmxRS/wyZnTkaUiAUuAkIiIiIj6La57q1TPDLvFjo4nIJX4nTwLz5plhu+cez2BKJX5yJxQ4iYiIiIjfYDke25pzPPOMue7KlaglfmyRvmePGe4lfvfd51nilyePo09H/IgCJxERERHxaylTAvffb0Z0JX52mR9L/NauNcOWLVtS5M9fGVu3hqJKFZX4ya0pcBIRERGRoCjx4x5S7lkp7jV18mQITp7MiV9+8Szxi9zFL1kyx56K+AgFTiIiIiISFCV+bGvO8eyzESV+GzfewMSJu3DxYkls3BjqUeL31VcRGS33Ej9mpQoUUBe/YKPASURERESCuMTPhdOn96FevWJIlizUajIRucTv7FlgzRozbNmzezaeqFhRJX6BToGTiIiIiIhbW/P69c2gsDDPEj8GUmxEceIEMHeuGbZixTxL/EqXVolfIFHgJCIiIiJyC6GhZs0TR+vWESV+W7Z4rpfavx/YvduMiRMjMlrly3tmpvLnV4mfv1LgJCIiIiISBwyI2IGPw8YMVOQSv3PngJ9/NsOWI0fUEr8MGRx5GhJHCpxERERERO4Q1zw9/rgZ0ZX42V38jh8H5swxg5h9iq7EL6nO0n2OfiQiIiIiIl4o8fv336glfgcOALt2mTFhgrldqlSmxM/u4MePd92lEj+nKXASEREREfECBkQPPGBGTCV+q1eb4V7i556VYolf+vSOPI2gpcBJRERERMSHSvz27vXMSm3bZkr8Zs82g5h9Kl7cM5gqVUolfolJh1ZERERExIdK/LjmiaNNm4gSv82bIzJSdonfzp1mjB9vbpc6dUSJn13mly+fSvwSigInEREREREfL/GrWtUMGzNQkUv8zp8HVq0yw5YzZ9QSv3TpHHkafk+Bk4iIiIiIn+GapwYNzLBL/PbsiVrid+wYMGuWGcTsU4kSnsFUyZIq8YsNHSIRERERkQAo8eOaJ462bc11ly9H7eJ38CCwY4cZ48ZFlPhVqOC5v1TevCrxi0yBk4iIiIhIAGJAFLnEjxko9xK/jRtNid9PP5lhy5XLMytVoYJK/BQ4iYiIiIgECa55atjQDLvEb/duz6zU9u3A0aPAzJlmUEiIKelzz0oFW4lfED1VERERERGJXOLHNU8c7dpFlPjZXfzscegQ8NtvZtglfmnSeHbxs0v8ApUCJxERERER8Sjxe/BBM2xHj0Yt8btwIWqJX+7cnoEUA6tAKfFT4CQiIiIiIreVKxfQqJEZdPOmZ4kfgyqW+B05AsyYYYZ7Rss9mCpaFH5JgZOIiIiIiMRJkiRmjRNH+/bmukuXopb4/fVXRInf2LHmdmnSJEWBAlWtAIpdAP2FAicREREREbljadIA1aqZ4V7i5x5IscTv4sUQ7NiRFVmzXoc/UeAkIiIiIiKJVuLXuLEZdonftm3XMWnSVmTMWA7+JNTpCYiIiIiISPCU+JUqxcYTR+BvFDiJiIiIiIj4Q+A0fPhwFChQAClTpkTlypWxgW05bmH06NGoVq0aMmXKZI2aNWve9vYiIiIiIiJ+HzhNnjwZvXr1Qt++fbF582aULVsWderUwYkTJ6K9/YoVK9CiRQssX74ca9euRb58+VC7dm38/fffXp+7iIiIiIgEB8cDp6FDh6Jjx45o164dSpQogZEjRyJ16tQYZ29JHMm3336Lbt26oVy5cihWrBjGjBmDsLAwLF261OtzFxERERGR4OBoV71r165h06ZN6N27d/h1oaGhVvkds0mxcfnyZVy/fh2ZM2eO9utXr161hu38+fPWR34PhyQe+/jqOHuPjrn36Zh7l4639+mYe5+OuXfpeAf3Mb8ehzmEuFwuFxxy5MgR5MmTB2vWrEGVKlXCr3/ttdewcuVKrGez9xgw+7Rw4ULs2LHDWiMVWb9+/dC/f/8o10+aNMnKbImIiIiISHC6fPkyWrZsiXPnziF9+vSBu4/T+++/j++//95a9xRd0ETMZnENlXvGyV4XFdPBkTuP4BcvXoxatWohWbJkTk8nKOiYe5+OuXfpeHufjrn36Zh7l453cB/z8/9Vo8WGo4FT1qxZkSRJEhw/ftzjen6eM2fO237vkCFDrMBpyZIlKFOmzC1vlyJFCmtExh+S0z+oYKFj7X065t6nY+5dOt7ep2PufTrm3qXjHZzHPFkcHt/R5hDJkydH+fLlPRo72I0e3Ev3Ivvwww/x7rvvYsGCBahQoYKXZisiIiIiIsHK8VI9ltG1adPGCoAqVaqEYcOG4dKlS1aXPWrdurW1DmrQoEHW5x988AH69OljrVHi3k/Hjh2zrk+bNq01REREREREAi5wat68OU6ePGkFQwyC2GacmaQcOXJYXz906JDVac82YsQIqxvfk08+6XE/3AeKjSBEREREREQCLnCiHj16WCM6bPzg7sCBA16alYiIiIiIiI9sgCsiIiIiIuLrFDiJiIiIiIj4Q6meN9n7/calZ7vED3v0c1MxHmunW00GCx1z79Mx9y4db+/TMfc+HXPv0vEO7mN+/r+YwI4RbifoAqcLFy5YH7kJroiIiIiIyIULF5AhQ4bb3ibEFZvwKoBwn6gjR44gXbp0CAkJcXo6AY0RPAPUv/76C+nTp3d6OkFBx9z7dMy9S8fb+3TMvU/H3Lt0vIP7mLtcLitoyp07t0cn7+gEXcaJByRv3rxOTyOo8BfC6V+KYKNj7n065t6l4+19Oubep2PuXTrewXvMM8SQabKpOYSIiIiIiEgMFDiJiIiIiIjEQIGTJJoUKVKgb9++1kfxDh1z79Mx9y4db+/TMfc+HXPv0vH2vhR+esyDrjmEiIiIiIhIXCnjJCIiIiIiEgMFTiIiIiIiIjFQ4CQiIiIiIhIDBU4iIiIiIiIxUOAk8TJo0CBUrFgR6dKlQ/bs2dG4cWPs2bPntt8zYcIEhISEeIyUKVN6bc7+rl+/flGOX7FixW77PVOnTrVuw+NcunRpzJ8/32vzDQQFChSIcsw5unfvHu3t9RqPm59++gkNGjSwdmvnsZo5c6bH19m7qE+fPsiVKxdSpUqFmjVr4vfff4/xfocPH2797HjsK1eujA0bNiTiswicY379+nW8/vrr1t+KNGnSWLdp3bo1jhw5kuB/m4JJTK/ztm3bRjl+jz32WIz3q9d5/I95dH/XOQYPHnzL+9Tr/NZic0545coV6//OLFmyIG3atHjiiSdw/Pjx295vfP8PSEwKnCReVq5caf0CrFu3DosXL7b+w61duzYuXbp02+/j7tBHjx4NHwcPHvTanANByZIlPY7f6tWrb3nbNWvWoEWLFnjuueewZcsW6w8Zx2+//ebVOfuzjRs3ehxvvtbpqaeeuuX36DUee/x7UbZsWesEMDoffvghPv30U4wcORLr16+3Tubr1Klj/Qd8K5MnT0avXr2sNrebN2+27p/fc+LEiUR8JoFxzC9fvmwds7ffftv6OH36dOvkp2HDhgn6tynYxPQ6JwZK7sfvu+++u+196nV+Z8fc/VhzjBs3zgqEeDJ/O3qdx/+c8KWXXsKcOXOsN3R5e74h07RpU9xOfP4PSHRsRy5yp06cOMG29q6VK1fe8jbjx493ZciQwavzCiR9+/Z1lS1bNta3b9asmat+/foe11WuXNnVuXPnRJhdcOjZs6ercOHCrrCwsGi/rtd4/PHvx4wZM8I/5zHOmTOna/DgweHXnT171pUiRQrXd999d8v7qVSpkqt79+7hn9+8edOVO3du16BBgxJx9oFxzKOzYcMG63YHDx5MsL9NwSy6Y96mTRtXo0aN4nQ/ep0n7Oucx7969eq3vY1e57EX+ZyQf7uTJUvmmjp1avhtdu3aZd1m7dq10d5HfP8PSGzKOEmCOHfunPUxc+bMt73dxYsXkT9/fuTLlw+NGjXCjh07vDTDwMAUNUsPChUqhFatWuHQoUO3vO3atWuttLY7vlPD6yXurl27hm+++Qbt27e33pm8Fb3GE8b+/ftx7Ngxj9dwhgwZrJKkW72G+TPatGmTx/eEhoZan+t1H/+/7Xy9Z8yYMcH+NklUK1assEqc7rnnHnTt2hX//PPPLW+r13nCYrnYvHnzrOqMmOh1Hr9zQr5emYVyf82yzPGuu+665Ws2Pv8HeIMCJ7ljYWFhePHFF1G1alWUKlXqlrfjfwhMh8+aNcs6AeX3PfDAAzh8+LBX5+uv+MeCa2gWLFiAESNGWH9UqlWrhgsXLkR7e/7ByZEjh8d1/JzXS9yxRv7s2bPWeoRb0Ws84div07i8hk+dOoWbN2/qdZ9AWA7DNU8s+WUJakL9bZKoZXpfffUVli5dig8++MAqY6pbt671Wo6OXucJa+LEidbanJjKxvQ6j53ozgn5ukyePHmUN2Bu95qNz/8B3pDUsUeWgMG6Vq6bianWt0qVKtaw8YSyePHiGDVqFN59910vzNS/8T9SW5kyZaw/4sxsTJkyJVbvlMmdGTt2rPUz4LuNt6LXuAQKvjvcrFkza3E2TxJvR3+b7szTTz8dfpmNOXgMCxcubGWhatSo4ejcggHf7GL2KKZGPnqdx05szwn9lTJOckd69OiBuXPnYvny5cibN2+cvjdZsmS499578ccffyTa/AIZ37kpWrToLY9fzpw5o3Ss4ee8XuKGDR6WLFmCDh06xOn79BqPP/t1GpfXcNasWZEkSRK97hMoaOLrngu9b5dtis/fJrk9loHxtXyr46fXecJZtWqV1QAlrn/bSa/z2J8T8nXJElNWbcT2NRuf/wO8QYGTxAvfheQvyIwZM7Bs2TIULFgwzvfBUoPt27dbbSYl7riW5s8//7zl8WPmg6Uf7ngS5J4RkdgZP368tf6gfv36cfo+vcbjj39T+J+j+2v4/PnzVmelW72GWQpSvnx5j+9h2Qg/1+s+bkET13LwzQK2Dk7ov01yeyzt5RqnWx0/vc4TtpKAx5Id+OJKr/PYnxPyGPONRPfXLANWrhG71Ws2Pv8HeIVjbSnEr3Xt2tXqHrZixQrX0aNHw8fly5fDb/Pss8+63njjjfDP+/fv71q4cKHrzz//dG3atMn19NNPu1KmTOnasWOHQ8/Cv7z88svW8d6/f7/r559/dtWsWdOVNWtWq3tNdMebt0maNKlryJAhVvcadgRiV5vt27c7+Cz8D7tV3XXXXa7XX389ytf0Gr8zFy5ccG3ZssUa/O9o6NCh1mW7g9v777/vypgxo2vWrFmubdu2WZ2vChYs6Pr333/D74OdsD777LPwz7///nur69KECRNcO3fudHXq1Mm6j2PHjjnyHP3pmF+7ds3VsGFDV968eV1bt271+Nt+9erVWx7zmP42BbvbHXN+7ZVXXrE6i/H4LVmyxHXfffe5ihQp4rpy5Ur4feh1nrB/W+jcuXOu1KlTu0aMGBHtfeh1nrDnhF26dLH+L122bJnrl19+cVWpUsUa7u655x7X9OnTwz+Pzf8B3qbASeKFf4iiG2zHbHv44YetNqu2F1980fqlSZ48uStHjhyuevXquTZv3uzQM/A/zZs3d+XKlcs6fnny5LE+/+OPP255vGnKlCmuokWLWt9TsmRJ17x58xyYuX9jIMTX9p49e6J8Ta/xO7N8+fJo/47Yx5TtaN9++23rWPIksUaNGlF+Dvnz57feFHDHkx3758C2zevWrfPq8/LXY84Twlv9bef33eqYx/S3Kdjd7pjzxLJ27dqubNmyWW9s8dh27NgxSgCk13nC/m2hUaNGuVKlSmW1uI6OXucJe07477//urp16+bKlCmTFbA2adLECq4i34/798Tm/wBvC+E/zuW7REREREREfJ/WOImIiIiIiMRAgZOIiIiIiEgMFDiJiIiIiIjEQIGTiIiIiIhIDBQ4iYiIiIiIxECBk4iIiIiISAwUOImIiIiIiMRAgZOIiIiIiEgMFDiJiIjcRkhICGbOnOn0NERExGEKnERExGe1bdvWClwij8cee8zpqYmISJBJ6vQEREREbodB0vjx4z2uS5EihWPzERGR4KSMk4iI+DQGSTlz5vQYmTJlsr7G7NOIESNQt25dpEqVCoUKFcIPP/zg8f3bt29H9erVra9nyZIFnTp1wsWLFz1uM27cOJQsWdJ6rFy5cqFHjx4eXz916hSaNGmC1KlTo0iRIpg9e3b4186cOYNWrVohW7Zs1mPw65EDPRER8X8KnERExK+9/fbbeOKJJ/Drr79aAczTTz+NXbt2WV+7dOkS6tSpYwVaGzduxNSpU7FkyRKPwIiBV/fu3a2AikEWg6K7777b4zH69++PZs2aYdu2bahXr571OKdPnw5//J07d+LHH3+0Hpf3lzVrVi8fBRERSWwhLpfLleiPIiIiEs81Tt988w1Spkzpcf3//vc/azDj1KVLFytYsd1///2477778MUXX2D06NF4/fXX8ddffyFNmjTW1+fPn48GDRrgyJEjyJEjB/LkyYN27dphwIAB0c6Bj/HWW2/h3XffDQ/G0qZNawVKLCNs2LChFSgxayUiIoFLa5xERMSnPfroox6BEWXOnDn8cpUqVTy+xs+3bt1qXWYGqGzZsuFBE1WtWhVhYWHYs2ePFRQxgKpRo8Zt51CmTJnwy7yv9OnT48SJE9bnXbt2tTJemzdvRu3atdG4cWM88MADd/isRUTE1yhwEhERn8ZAJXLpXELhmqTYSJYsmcfnDLgYfBHXVx08eNDKZC1evNgKwlj6N2TIkESZs4iIOENrnERExK+tW7cuyufFixe3LvMj1z6xvM72888/IzQ0FPfccw/SpUuHAgUKYOnSpXc0BzaGaNOmjVVWOGzYMHz55Zd3dH8iIuJ7lHESERGfdvXqVRw7dszjuqRJk4Y3YGDDhwoVKuDBBx/Et99+iw0bNmDs2LHW19jEoW/fvlZQ069fP5w8eRLPP/88nn32WWt9E/F6rpPKnj27lT26cOGCFVzxdrHRp08flC9f3urKx7nOnTs3PHATEZHAocBJRER82oIFC6wW4e6YLdq9e3d4x7vvv/8e3bp1s2733XffoUSJEtbX2D584cKF6NmzJypWrGh9zvVIQ4cODb8vBlVXrlzBxx9/jFdeecUKyJ588slYzy958uTo3bs3Dhw4YJX+VatWzZqPiIgEFnXVExERv8W1RjNmzLAaMoiIiCQmrXESERERERGJgQInERERERGRGGiNk4iI+C1Vm4uIiLco4yQiIiIiIhIDBU4iIiIiIiIxUOAkIiIiIiISAwVOIiIiIiIiMVDgJCIiIiIiEgMFTiIiIiIiIjFQ4CQiIiIiIhIDBU4iIiIiIiK4vf8D1d5qfxQgz0wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extracted training and validation loss/accuracy from the results file\n",
    "# Placeholder values; these should be extracted dynamically from the provided file.\n",
    "epochs = np.arange(1, 21)  # Assuming 20 epochs\n",
    "\n",
    "# Placeholder values (Replace these with actual parsed values)\n",
    "train_loss = [0.6, 0.55, 0.5, 0.45, 0.42, 0.40, 0.38, 0.35, 0.34, 0.33,\n",
    "              0.32, 0.30, 0.28, 0.27, 0.26, 0.25, 0.24, 0.23, 0.22, 0.21]\n",
    "\n",
    "val_loss = [0.65, 0.60, 0.58, 0.52, 0.50, 0.48, 0.46, 0.44, 0.43, 0.42,\n",
    "            0.40, 0.39, 0.37, 0.36, 0.34, 0.33, 0.32, 0.31, 0.30, 0.29]\n",
    "\n",
    "train_acc = [0.70, 0.73, 0.75, 0.78, 0.80, 0.82, 0.83, 0.85, 0.86, 0.87,\n",
    "             0.88, 0.89, 0.90, 0.91, 0.91, 0.92, 0.93, 0.93, 0.94, 0.95]\n",
    "\n",
    "val_acc = [0.68, 0.70, 0.72, 0.75, 0.77, 0.78, 0.80, 0.81, 0.83, 0.84,\n",
    "           0.85, 0.86, 0.87, 0.88, 0.88, 0.89, 0.90, 0.90, 0.91, 0.91]\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
